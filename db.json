{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/bird_32_gray.png","path":"images/bird_32_gray.png","modified":1,"renderable":0},{"_id":"source/images/bird_32_gray_fail.png","path":"images/bird_32_gray_fail.png","modified":1,"renderable":0},{"_id":"source/images/code_bg.png","path":"images/code_bg.png","modified":1,"renderable":0},{"_id":"source/images/dotted-border.png","path":"images/dotted-border.png","modified":1,"renderable":0},{"_id":"source/images/email.png","path":"images/email.png","modified":1,"renderable":0},{"_id":"source/images/favicon.png","path":"images/favicon.png","modified":1,"renderable":0},{"_id":"source/images/line-tile.png","path":"images/line-tile.png","modified":1,"renderable":0},{"_id":"source/images/noise.png","path":"images/noise.png","modified":1,"renderable":0},{"_id":"source/images/rss.png","path":"images/rss.png","modified":1,"renderable":0},{"_id":"source/images/search.png","path":"images/search.png","modified":1,"renderable":0},{"_id":"source/images/wood.jpg","path":"images/wood.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/fastcgi.jpg","path":"images/2013/fastcgi.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/panda.jpg","path":"images/2013/panda.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"source/images/2013/08/class.png","path":"images/2013/08/class.png","modified":1,"renderable":0},{"_id":"source/images/2013/08/gearman.png","path":"images/2013/08/gearman.png","modified":1,"renderable":0},{"_id":"source/images/2013/08/ip.gif","path":"images/2013/08/ip.gif","modified":1,"renderable":0},{"_id":"source/images/2013/08/minigame.png","path":"images/2013/08/minigame.png","modified":1,"renderable":0},{"_id":"source/images/2013/08/ipc_unix_socket-300x300.png","path":"images/2013/08/ipc_unix_socket-300x300.png","modified":1,"renderable":0},{"_id":"source/images/2013/08/oracle.png","path":"images/2013/08/oracle.png","modified":1,"renderable":0},{"_id":"source/images/2013/10/Gitar.jpg","path":"images/2013/10/Gitar.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/10/Violin.jpg","path":"images/2013/10/Violin.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/12/nba.jpg","path":"images/2013/12/nba.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/around.jpg","path":"images/2013/douya/around.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/ICON.jpg","path":"images/2013/douya/ICON.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/chat.jpg","path":"images/2013/douya/chat.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/collect.jpg","path":"images/2013/douya/collect.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/description.jpg","path":"images/2013/douya/description.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/friend.jpg","path":"images/2013/douya/friend.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/myshare.jpg","path":"images/2013/douya/myshare.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/review.jpg","path":"images/2013/douya/review.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/settiing.jpg","path":"images/2013/douya/settiing.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/share.jpg","path":"images/2013/douya/share.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/welcom.jpg","path":"images/2013/douya/welcom.jpg","modified":1,"renderable":0},{"_id":"source/images/2014/01/skiplist.png","path":"images/2014/01/skiplist.png","modified":1,"renderable":0},{"_id":"source/images/2014/01/rework.jpg","path":"images/2014/01/rework.jpg","modified":1,"renderable":0},{"_id":"source/images/2014/10/free.png","path":"images/2014/10/free.png","modified":1,"renderable":0},{"_id":"source/images/2014/10/nestat.png","path":"images/2014/10/nestat.png","modified":1,"renderable":0},{"_id":"source/images/2015/02/suggest.png","path":"images/2015/02/suggest.png","modified":1,"renderable":0},{"_id":"source/images/2015/02/triestruct.png","path":"images/2015/02/triestruct.png","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"source/images/2013/12/Allen.jpg","path":"images/2013/12/Allen.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/12/gitar.jpg","path":"images/2013/12/gitar.jpg","modified":1,"renderable":0},{"_id":"source/images/2013/douya/main.jpg","path":"images/2013/douya/main.jpg","modified":1,"renderable":0},{"_id":"source/images/2014/04/guitar.jpg","path":"images/2014/04/guitar.jpg","modified":1,"renderable":0},{"_id":"source/images/2014/10/top.png","path":"images/2014/10/top.png","modified":1,"renderable":0},{"_id":"source/images/2016/04/flume.jpg","path":"images/2016/04/flume.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"source/images/2013/09/hadoop.png","path":"images/2013/09/hadoop.png","modified":1,"renderable":0},{"_id":"source/images/2015/08/teammate.png","path":"images/2015/08/teammate.png","modified":1,"renderable":0},{"_id":"source/images/2016/04/flume1toflume2.jpg","path":"images/2016/04/flume1toflume2.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"source/images/2017/05/dlist-delete.png","path":"images/2017/05/dlist-delete.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"source/images/2017/05/dlist-insert.png","path":"images/2017/05/dlist-insert.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1523731104000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1523731104000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1523731104000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1523731104000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1523731104000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1523731104000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1523731104000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1523731104000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1523731104000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1523731104000},{"_id":"themes/next/README.cn.md","hash":"2c766b3369ed477bce134a5450dab45bef161504","modified":1523731104000},{"_id":"themes/next/README.md","hash":"8ce60ce578963eb4e1eb5e33e1efc2fc4779af9c","modified":1523731104000},{"_id":"themes/next/_config.yml","hash":"edd13589375357b66aad4e6a8a6e98899b617c61","modified":1529236009000},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1523731104000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1523731104000},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1523731104000},{"_id":"source/about/index.md","hash":"2f35fe4a873a6a837cd6d41cf859e6165dd8ee6e","modified":1529233434000},{"_id":"source/_posts/2013-04-02-zhe-teng.markdown","hash":"a994a82288683aa90764d184bf27c52f06fd6b19","modified":1529231936000},{"_id":"source/_posts/2013-08-20-minigame-fu-wu-duan-she-ji.markdown","hash":"dfce76c95b326b788f8055e818dd0f023f9c335c","modified":1529231936000},{"_id":"source/_posts/2013-08-26-jiao-shen-ma-rong-yu-chu-pin-dou-ya-huan-shu.markdown","hash":"c1d744375750d06411be6ff6b47d60961dd67c05","modified":1529231951000},{"_id":"source/_posts/2013-08-26-si-kao-yu-fen-xiang-shi-jie-zhi-sheng-hua.markdown","hash":"52f290bc3c94e01899bf6c2ca925bc2fa9163857","modified":1529231936000},{"_id":"source/_posts/2013-08-28-fu-wu-qi-she-ji-mo-xing.markdown","hash":"8cb042e3efe30f2ce1341ab91c9e645d63fcfccc","modified":1529231936000},{"_id":"source/_posts/2013-08-28-nginxmo-kuai-kai-fa.markdown","hash":"b7cc93db37770afbde462fcda1d650c0e0e55030","modified":1529231936000},{"_id":"source/_posts/2013-08-28-thread-pool-in-python.markdown","hash":"e16a033a2c66402dc060a6acd9fc453fb4f74169","modified":1529231936000},{"_id":"source/_posts/2013-08-28-zai-lu-shang.markdown","hash":"534a68374561535164a119d35f23d86daa2ae5b5","modified":1529231936000},{"_id":"source/_posts/2013-08-28-zhe-teng-libevent.markdown","hash":"abb7b027d332b0d4c397fd9e283fb067229dc7b2","modified":1529231936000},{"_id":"source/_posts/2013-08-28-zuo-kuai-le-de-cheng-xu-yuan.markdown","hash":"263f00bcbc00e52e00b76eb97db21f70dc35373d","modified":1529231936000},{"_id":"source/_posts/2013-08-29-c-plus-plus-yu-pythonde-hun-he-bian-cheng-pythontuo-zhan-bian-xie.markdown","hash":"a4e0e7972b6e311205669cd2ec242e7df4a74ba9","modified":1529231936000},{"_id":"source/_posts/2013-08-29-dou-ban-xi-ai-wen-zhang-xia-zai-qi.markdown","hash":"cb387005491de18fa1e54b4047e8a6fade24e436","modified":1529231936000},{"_id":"source/_posts/2013-08-29-fan-hui-zhi-de-tou-che-li-jie.markdown","hash":"d96640cd0315f67659dd9b8df22b69e8f823dcbb","modified":1529231936000},{"_id":"source/_posts/2013-08-29-google-c-plus-plus-style.markdown","hash":"969196d29d99827a71fae02de05ca7f74c5aa62c","modified":1529231936000},{"_id":"source/_posts/2013-08-29-hui-gu-zeromq.markdown","hash":"b83045a1f4d87a2b4124fc2799669323e765ef16","modified":1529231936000},{"_id":"source/_posts/2013-08-29-unix-domain-socket-ipctong-xin-ji-zhi.markdown","hash":"e8dd36564e199769288ad8c056fe3a41c122fe7c","modified":1529231936000},{"_id":"source/_posts/2013-08-29-xiu-qi-xiao-bo.markdown","hash":"91663d006a4b439384ebd394f25c35960040205d","modified":1529231936000},{"_id":"source/_posts/2013-08-30-fen-bu-shi-chu-li-kuang-jia-gearman.markdown","hash":"65169be12ebaadd145db710929569edcdd975dfa","modified":1529231936000},{"_id":"source/_posts/2013-08-30-feng-pei-zhi-lu.markdown","hash":"4eef525d1f48c4b2a32b4eb86f1c3309d82cd763","modified":1529231936000},{"_id":"source/_posts/2013-08-30-jing-ran-ye-yong-dao-liao-oracle.markdown","hash":"42d976a184cae03d538fdd85ae5f6bebc27159a5","modified":1529231936000},{"_id":"source/_posts/2013-09-12-nginx-plus-luaying-dui-zai-xian-zhuang-tai-fu-wu.markdown","hash":"8952b1107791647c7736697f5280e75ecb4e2592","modified":1529231936000},{"_id":"source/_posts/2013-09-15-jsonpjie-jue-kua-yu-qing-qiu.markdown","hash":"fa76ba48afc4828d7ac3d1a49afb8cccd3cd22f0","modified":1529231936000},{"_id":"source/_posts/2013-09-21-leveldbben-di-cun-chu-yin-qing-jing-zhi-de-gong-ju.markdown","hash":"976d30f309b173a8f7a995ffe0a960b7c9d8ea87","modified":1529231936000},{"_id":"source/_posts/2013-09-22-dan-ji-wan-hadoop.markdown","hash":"735372d7359125904c6fe1579a7de9ff175bc662","modified":1529231936000},{"_id":"source/_posts/2013-09-28-shellji-qiao-xiao-jie.markdown","hash":"9a45b4060726d5965bfd9c04a410be6f08b14d34","modified":1529231936000},{"_id":"source/_posts/2013-09-29-zerorpcshi-ge-hao-dong-xi.markdown","hash":"46ec5c0b6759aab70a6e16bf716bccab6889d317","modified":1529231936000},{"_id":"source/_posts/2013-10-10-shui-de-xin-jing.markdown","hash":"da9e1ae8e6f35295603099a1fe4f71b009796d52","modified":1529231936000},{"_id":"source/_posts/2013-12-05-zui-jin-yong-dao-de-mysql.markdown","hash":"0ca62436a119ca4e874990f1dea142e1933dcc41","modified":1529231936000},{"_id":"source/_posts/2013-12-21-yu-jian.markdown","hash":"acb61ff5645e09808cce1736a37ba4ab2b09948d","modified":1529231936000},{"_id":"source/_posts/2014-01-06-re-geng-xin.markdown","hash":"4cb15d6763b9e876647ad239feb4649218dcbc87","modified":1529231936000},{"_id":"source/_posts/2014-01-07-wei-xin-gong-zhong-hao-kai-fa.markdown","hash":"f35f23fb7413ac97a60709231b260b3b5998d69d","modified":1529231936000},{"_id":"source/_posts/2014-01-24-<<rework>>-shu-zhai.markdown","hash":"a69fe1592d53a94391728c967eac8f3b39734f94","modified":1529231936000},{"_id":"source/_posts/2014-02-01-tiao-biao-skiplist.markdown","hash":"b8dae792687a6a3669b23aefcd4181ac5108a77b","modified":1529231936000},{"_id":"source/_posts/2014-02-05-shen-ru-strtokhan-shu.markdown","hash":"1cf02dce1143a372ab1d2e9653c101cccbb158ac","modified":1529231936000},{"_id":"source/_posts/2014-02-24-socketnian-bao.markdown","hash":"77357f08388a8466ebad3b8eb5d461f90f11d3f4","modified":1529231936000},{"_id":"source/_posts/2014-03-13-expect-yu-xi-tong-zi-dong-jiao-hu.markdown","hash":"d5577a1b940b41124eab9a5af46e65b980c8dcaa","modified":1529231936000},{"_id":"source/_posts/2014-04-22-liu-xia-liao-xie-dong-xi.markdown","hash":"cd0318c02333e784a556599ad7a5e42969bca0e4","modified":1529231936000},{"_id":"source/_posts/2014-04-28-wei-wen-yi-lu.markdown","hash":"54217a0f9778ae14b7cecac3b9dbd422a307ecf5","modified":1529231936000},{"_id":"source/_posts/2014-05-03-mac-an-zhuang-go.markdown","hash":"2a5adb630037c32a672cf74e8b9bf30f40c55bdc","modified":1529231936000},{"_id":"source/_posts/2014-05-03-make-setup-dot-py.markdown","hash":"83ae005e9ea05311e8a7eb0066c2cf9a5e04f8e9","modified":1529231936000},{"_id":"source/_posts/2014-05-13-nginx-pitfall.markdown","hash":"f6de6e09134605c7b296b7c8326b86b889aa9775","modified":1529231936000},{"_id":"source/_posts/2014-06-21-da-mo-de-qing-chun.markdown","hash":"aa937ed1880222c01b7ab08f5d8bb47d35a9be02","modified":1529231936000},{"_id":"source/_posts/2014-07-12-goan-zhuang-protobuf.markdown","hash":"70cfb4fdff5ae04e859fee6a07396a50afb72924","modified":1529231936000},{"_id":"source/_posts/2014-07-16-zhe-teng-docker.markdown","hash":"868b194a11ba133f33ca16bd1bc56707f4d5a27e","modified":1529231936000},{"_id":"source/_posts/2014-07-27-rsyslog-jie-shou-yuan-cheng-ri-zhi.markdown","hash":"dbe74e1bdc2953855af3081d0fbed335ec6fcb4f","modified":1529231936000},{"_id":"source/_posts/2014-09-07-percona-server-zuo-zhu-cong.markdown","hash":"a5bb10e2d474a45545b62cf5efb76b573d8992ee","modified":1529231936000},{"_id":"source/_posts/2014-10-04-redisre-bei.markdown","hash":"d8a77cddcc54f7860a662147f035bbf0194550d5","modified":1529231936000},{"_id":"source/_posts/2014-10-13-nei-cun-du-qu-na-er-la.markdown","hash":"edb0c9b5f09ad0d79b341d95586cf492510954fa","modified":1529231936000},{"_id":"source/_posts/2014-10-24-mysql-unique-index.markdown","hash":"af5e1b456a000a38a60556f0c02d595db5982f48","modified":1529231936000},{"_id":"source/_posts/2014-10-29-iptablezuo-natzhuan-fa.markdown","hash":"98a89ded708869c796282435674151096b0f7ad8","modified":1529231936000},{"_id":"source/_posts/2014-11-02-nginxyu-phpxi-tong-can-shu-pei-zhi.markdown","hash":"e00ede657bfa057e1ca0d6adb56fe4f56f552328","modified":1529231936000},{"_id":"source/_posts/2014-11-25-tired.markdown","hash":"2f600c06329e1b8f5d6563ca7a4044ff8749c665","modified":1529231936000},{"_id":"source/_posts/2014-11-29-yong-dao-de-tcpdump.markdown","hash":"0d5c6631d59113a90964e85276864027d0238971","modified":1529231936000},{"_id":"source/_posts/2014-12-13-nginxcuo-wu-ma.markdown","hash":"8798044cd6caed85171e6e7a6c5780c698a519ed","modified":1529231936000},{"_id":"source/_posts/2015-01-21-percona-toolkitxiao-xiang-li-di-pt-archiver.markdown","hash":"309b112d64412088281e24029736a0e853aaebb6","modified":1529231936000},{"_id":"source/_posts/2015-01-31-da-jian-elasticsearchyu-kibana.markdown","hash":"108cb08cc02b989ffb3d6352bca34dbdce721da2","modified":1529231936000},{"_id":"source/_posts/2015-02-03-haproxy-plus-mysql.markdown","hash":"4fb5b2097a89fef22725300a9e5effbe5fef19e8","modified":1529231936000},{"_id":"source/_posts/2015-02-08-trie-suggestion.markdown","hash":"621920c4da9c3f7bf29f56809b42e5039f3cc5db","modified":1529231936000},{"_id":"source/_posts/2015-04-05-yong-bao-docker.markdown","hash":"ac3e767c851e57d6645f0625492abf2e4d5e611f","modified":1529231936000},{"_id":"source/_posts/2015-05-10-mysql-slave-relay-log-corrupt-chu-li-he-hui-fu.markdown","hash":"d172b52b3f22ef16cc090d9cbcca16ede703131e","modified":1529231936000},{"_id":"source/_posts/2015-05-17-da-jian-postfix.markdown","hash":"c4fcbb0412e78283d67cb7fcdac0223b36d71211","modified":1529231936000},{"_id":"source/_posts/2015-06-11-qing-qiao-shi-shi-tong-ji-yong-hu-shu.markdown","hash":"b5ca73fce398a02b42c80669bfda24c6a4d17cb3","modified":1529231936000},{"_id":"source/_posts/2015-07-12-my-dot-cnfpei-zhi-yi-ju.markdown","hash":"a1d9f5669e701e38ea3b2e771b5a34f99e92dfa4","modified":1529231936000},{"_id":"source/_posts/2015-07-24-ji-lu-cuo-wu-deng-lu-de-btmpwen-jian.markdown","hash":"b6e22f34674446e5188847c1d8d112374acb0531","modified":1529231936000},{"_id":"source/_posts/2015-08-10-hackthon.markdown","hash":"e63c089bd30298579dc397b082b8af442c7e35a9","modified":1529231936000},{"_id":"source/_posts/2015-08-16-twemproxy.markdown","hash":"cca35f628432af9f1c0d0c9252cc38f713741041","modified":1529231936000},{"_id":"source/_posts/2015-08-21-supervisorjian-ting-qi.markdown","hash":"7b919740c382e0b41e44e9bddac408799aecd290","modified":1529233852000},{"_id":"source/_posts/2015-09-05-ansiblede-shi-yong-jing-yan.markdown","hash":"1c5182f46afb222eaf699b82cc9ea554af435da5","modified":1529231936000},{"_id":"source/_posts/2015-09-10-sysdig-zhi-de-yong-you.markdown","hash":"ea335818679b5c8981d97e10ed9d3de1ad4657c5","modified":1529231936000},{"_id":"source/_posts/2015-10-01-python-shi-yong-ldap.markdown","hash":"9f4e5d9b6c162be7cfd9c354de260d29d83ab312","modified":1529231936000},{"_id":"source/_posts/2015-10-06-ji-lu-shi-yong-flaskde-dian-di.markdown","hash":"fc8ba801b99075041c12a777c096bd2bee651099","modified":1529231936000},{"_id":"source/_posts/2015-10-29-gei-tengine-jia-shang-lua-tuo-zhan.markdown","hash":"6236fe20cfad4ede16a150eb9ad4177672b3a147","modified":1529231936000},{"_id":"source/_posts/2015-12-05-gre-tuning-and-keepalived.markdown","hash":"f7da087b76be11ba79ecab76e892ad9a2344db8c","modified":1529231936000},{"_id":"source/_posts/2015-12-10-fen-xi-nginxri-zhi-de-li-qi-goaccess.markdown","hash":"c0931902898aefaa1958e287fb248af6acbfbb29","modified":1529231936000},{"_id":"source/_posts/2016-01-07-shi-shi-jian-kong-nginx-qps-de-tuo-zhan.markdown","hash":"7767fcaf81aef3524df171a58bb8dfcdeab2f262","modified":1529231936000},{"_id":"source/_posts/2016-03-10-gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi.markdown","hash":"c9378eedf599d9113475e3e370a10b82484ab47f","modified":1529231936000},{"_id":"source/_posts/2016-04-23-flume-shi-shi-shou-ji-nginx-ri-zhi.markdown","hash":"9eb22e5c7fb2d1e9e7b0edf14ea056b4b4082b7f","modified":1529231936000},{"_id":"source/_posts/2016-04-24-ansible-dynamic-inventory.markdown","hash":"d233cfa431d0f495aa40a1ebd6c2bf51fb34869d","modified":1529231936000},{"_id":"source/_posts/2016-06-03-zhun-que-jian-ce-mysql-fu-zhi-yan-chi.markdown","hash":"e646618440d062b6ab4b0847c9709e931f03c651","modified":1529231936000},{"_id":"source/_posts/2016-07-16-bash-jia-zai-shun-xu.markdown","hash":"8a13b9752e12d9e714c198136e0c6884ca409fc5","modified":1529231936000},{"_id":"source/_posts/2016-07-23-celeryde-crontabshi-jian.markdown","hash":"4df6852993994cfcc2aa565eae2df831da57632b","modified":1529231936000},{"_id":"source/_posts/2016-08-01-cuckoofilter.markdown","hash":"3da90ade3149bc827fab68a452aae85c2062e5d8","modified":1529231936000},{"_id":"source/_posts/2016-09-25-gong-xiang-nei-cun-yu-xin-hao-liang.markdown","hash":"e99d0333954a533476cbe495872861e05904f659","modified":1529231936000},{"_id":"source/_posts/2016-09-28-ji-yi-ci-redis-server-bug.markdown","hash":"1c8405a0fb538ed38a7bcaeeee821115a002e682","modified":1529231936000},{"_id":"source/_posts/2016-12-02-cgroupxian-zhi-ji-suan-zi-yuan.markdown","hash":"4129486dd2306a25934241efd5df368d95c93738","modified":1529231936000},{"_id":"source/_posts/2017-02-22-zheng-xiang-yu-fan-xiang-dai-li.markdown","hash":"c5665afdfe8f01c891a545699aaf87a0be0bc478","modified":1529231936000},{"_id":"source/_posts/2017-02-25-zookeeper-bi-ji.markdown","hash":"8bc5a54abf1272fb165fd12c6b30c1514584039e","modified":1529231936000},{"_id":"source/_posts/2017-05-29-shuang-duan-lian-biao.markdown","hash":"2081cc918af5f5278c60979b877454e4044be164","modified":1529231936000},{"_id":"source/_posts/2017-06-04-mit-6-dot-824-mapreduce.markdown","hash":"31c329b0b6dbb564f95a35f722c3e8cda10a84ba","modified":1529231936000},{"_id":"source/_posts/2017-07-13-httpserver-graceful-shutdown-in-go.markdown","hash":"4e76cea34fad4c45cdadf9dcf53f616d4dae4cdb","modified":1529231936000},{"_id":"source/_posts/2018-06-17-ban-nian-sui-xiang.markdown","hash":"776febcb53de751e1cbc8057ac90fd0cf7a5c10e","modified":1529236531000},{"_id":"source/categories/index.md","hash":"7964bbb0e166c49e9d8e85fc57d36c561fb90379","modified":1529232102000},{"_id":"source/images/.DS_Store","hash":"a247078a4c6f5b79885b3e6df399a8a9e84c034c","modified":1529231216000},{"_id":"source/images/bird_32_gray.png","hash":"55345ff7370047a6b825dd235c9ce201545a0952","modified":1529231216000},{"_id":"source/images/bird_32_gray_fail.png","hash":"0c30b159e4cbb7e8a1ad826be537fc4bd79b0a8f","modified":1529231216000},{"_id":"source/images/code_bg.png","hash":"c34acd76f73ef68d62c031856bd627ffac9378f3","modified":1529231216000},{"_id":"source/images/dotted-border.png","hash":"347784b401d0d38acf5e3b6d06a90346a16a8e8c","modified":1529231216000},{"_id":"source/images/email.png","hash":"2a5d251567fabcad68fa596ebaf1508296524930","modified":1529231216000},{"_id":"source/images/favicon.png","hash":"19ca364fa2d577527b4981b7958718f9fa5a7bb0","modified":1529233469000},{"_id":"source/images/line-tile.png","hash":"a86a5d70fb0024dd295b85ea9058b43c1c5f25d3","modified":1529231216000},{"_id":"source/images/noise.png","hash":"a839ae391fbbb0a1a2b22f8aba1d8ae2a702ef34","modified":1529231216000},{"_id":"source/images/rss.png","hash":"d61fc1ccc66f081002b15532f66e054147d5f2fb","modified":1529231216000},{"_id":"source/images/search.png","hash":"3c0178651f38bff462d4feb927e4f4df87b0f9d0","modified":1529231216000},{"_id":"source/images/wood.jpg","hash":"70043f934922eca94934214931f0833a04798751","modified":1529231216000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1523731104000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"50d48c47162817a3810a9d9ad51104e83947419a","modified":1523731104000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1523731104000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1523731104000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1523731104000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1523731104000},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1523731104000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1523731104000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1523731104000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1523731104000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1523731104000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1523731104000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1523731104000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1523731104000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1523731104000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1523731104000},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1523731104000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1523731104000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1523731104000},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1523731104000},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1523731104000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1523731104000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1523731104000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1523731104000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1523731104000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1523731104000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1523731104000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1523731104000},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1523731104000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1523731104000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1523731104000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1523731104000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1523731104000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1523731104000},{"_id":"source/images/2013/fastcgi.jpg","hash":"3d27e12353c43f153490e17f0e367e920066e3e2","modified":1529231216000},{"_id":"source/images/2013/panda.jpg","hash":"3c3f9d9391962a8936f88098be8995da946e2186","modified":1529231216000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1523731104000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1523731104000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1523731104000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1523731104000},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1523731104000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1523731104000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1523731104000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1523731104000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1523731104000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1523731104000},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1523731104000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1523731104000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1523731104000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1523731104000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1523731104000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1523731104000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1523731104000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1523731104000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1523731104000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1523731104000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1523731104000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1523731104000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1523731104000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1523731104000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1523731104000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1523731104000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1523731104000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1523731104000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1523731104000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1523731104000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1523731104000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1523731104000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1523731104000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1523731104000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1523731104000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1523731104000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1523731104000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1523731104000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1523731104000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1523731104000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1523731104000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1523731104000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1523731104000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1523731104000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1523731104000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1523731104000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1523731104000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1523731104000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1523731104000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1523731104000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1523731104000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1523731104000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1523731104000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1523731104000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1523731104000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1523731104000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1523731104000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1523731104000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1523731104000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1523731104000},{"_id":"source/images/2013/08/class.png","hash":"f7724bebc971054d4df28f0feab1230f0bb8e22d","modified":1529231216000},{"_id":"source/images/2013/08/gearman.png","hash":"4bd73fae2873a680dcc659eccffeeafe37fa9326","modified":1529231216000},{"_id":"source/images/2013/08/ip.gif","hash":"4527e78a356a6468feaa98400c62fabb53da675c","modified":1529231216000},{"_id":"source/images/2013/08/minigame.png","hash":"34bb9bce493db9017e36074ac593f5f703e44df5","modified":1529231216000},{"_id":"source/images/2013/08/ipc_unix_socket-300x300.png","hash":"6c0af0c33b6712220c8792069da491a4e21b225f","modified":1529231216000},{"_id":"source/images/2013/08/oracle.png","hash":"419a753045ee3638389cb09405953e4389391307","modified":1529231216000},{"_id":"source/images/2013/10/Gitar.jpg","hash":"bc882e7e76ee2ccbbe32a134c58f79fae5cb1d3e","modified":1529231216000},{"_id":"source/images/2013/10/Violin.jpg","hash":"1648339d81ca6735d725d5c9d6caacaf4ea11842","modified":1529231216000},{"_id":"source/images/2013/12/nba.jpg","hash":"29c718e4f7cd0ad90ae859688e8ecb36c1f2b063","modified":1529231216000},{"_id":"source/images/2013/douya/around.jpg","hash":"f474d8b0947c936dfeae2b4b83a27f45056432eb","modified":1529231216000},{"_id":"source/images/2013/douya/ICON.jpg","hash":"ed6fb1b491d518bb4176badeb5154a15fa082bb9","modified":1529231216000},{"_id":"source/images/2013/douya/chat.jpg","hash":"98b6bbde13437d213c78b91d3ff7fdce32b6dabb","modified":1529231216000},{"_id":"source/images/2013/douya/collect.jpg","hash":"821c96bce387d280fbe1badc16a282a490fd0969","modified":1529231216000},{"_id":"source/images/2013/douya/description.jpg","hash":"10a2f5ab89e1d2523642099185e8c58ebcf1a49e","modified":1529231216000},{"_id":"source/images/2013/douya/friend.jpg","hash":"b1fb9e773d5e29b0ea1be34d6d933b3494b9db27","modified":1529231216000},{"_id":"source/images/2013/douya/myshare.jpg","hash":"390278beab70dc953416a5f8cd9ed777f5c611e2","modified":1529231216000},{"_id":"source/images/2013/douya/review.jpg","hash":"c8f7df9fb232ac223e5321d7a47aec636d70e568","modified":1529231216000},{"_id":"source/images/2013/douya/settiing.jpg","hash":"17da1451ef64dc0ab04f8e229933b2e0ea2a7203","modified":1529231216000},{"_id":"source/images/2013/douya/share.jpg","hash":"8148dbebcbe1c39c6be3e3e955bcff3ed80058de","modified":1529231216000},{"_id":"source/images/2013/douya/welcom.jpg","hash":"f6c1c8ea58fad081a6edde47e8a2393dc662b113","modified":1529231216000},{"_id":"source/images/2014/01/skiplist.png","hash":"9f65eebae2d66346528924af503181609f168dbf","modified":1529231216000},{"_id":"source/images/2014/01/rework.jpg","hash":"85e9aa2dc597ccd4f09259657b89086e5777ed69","modified":1529231216000},{"_id":"source/images/2014/10/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1529231216000},{"_id":"source/images/2014/10/free.png","hash":"5edfcc57d428db417a2d24eb6cf55c8e2a1e57cf","modified":1529231216000},{"_id":"source/images/2014/10/nestat.png","hash":"3ef0d6755a7506e0f23d7507612baf61b04799d1","modified":1529231216000},{"_id":"source/images/2015/02/suggest.png","hash":"12ba6f827db0a0f5f0990eca40fade2df297dc3a","modified":1529231216000},{"_id":"source/images/2015/02/triestruct.png","hash":"815436faa82c9e3a472008a284d501be4e27e20e","modified":1529231216000},{"_id":"source/images/2015/08/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1529231216000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1523731104000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1523731104000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1523731104000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1523731104000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1523731104000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1523731104000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1523731104000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1523731104000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1523731104000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1523731104000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1523731104000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1523731104000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1523731104000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1523731104000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1523731104000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1523731104000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1523731104000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1523731104000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1523731104000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1523731104000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1523731104000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1523731104000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1523731104000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1523731104000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1523731104000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1523731104000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1523731104000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1523731104000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1523731104000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1523731104000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1523731104000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1523731104000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1523731104000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1523731104000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1523731104000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1523731104000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1523731104000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1523731104000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1523731104000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1523731104000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1523731104000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1523731104000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1523731104000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1523731104000},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1523731104000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1523731104000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1523731104000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1523731104000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1523731104000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1523731104000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1523731104000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1523731104000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1523731104000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1523731104000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1523731104000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1523731104000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1523731104000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1523731104000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1523731104000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1523731104000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1523731104000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1523731104000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1523731104000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1523731104000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1523731104000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1523731104000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1523731104000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1523731104000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1523731104000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1523731104000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1523731104000},{"_id":"source/images/2013/12/Allen.jpg","hash":"beb71c162b39a330f8a7ca19315417677cf02da7","modified":1529231216000},{"_id":"source/images/2013/12/gitar.jpg","hash":"5033ea65c2dcf040bca626d2bac74c0297c46c9a","modified":1529231216000},{"_id":"source/images/2013/douya/main.jpg","hash":"5ee32e3abf1bc5ff1e947cc521816622e4178b58","modified":1529231216000},{"_id":"source/images/2014/04/guitar.jpg","hash":"a1ac5d4fecf25613440a8373499ed495069c1f48","modified":1529231216000},{"_id":"source/images/2014/10/top.png","hash":"3bb33050e8609d6b3c697b391196e84db2fded31","modified":1529231216000},{"_id":"source/images/2016/04/flume.jpg","hash":"3a2faf8e79798d88c9e75e745b0eb7f13b64b17b","modified":1529231216000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1523731104000},{"_id":"source/images/2013/09/hadoop.png","hash":"c6059a50e0d67ca8b877187d3d4c03a9bd8ffb66","modified":1529231216000},{"_id":"source/images/2015/08/teammate.png","hash":"0e58c75f06a14585a0b1eb8501c7c5a474255fb4","modified":1529231216000},{"_id":"source/images/2016/04/flume1toflume2.jpg","hash":"160b81bd0de441b51ce03fc06fa9dd1fb02349c1","modified":1529231216000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1523731104000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1523731104000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1523731104000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1523731104000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1523731104000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1523731104000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1523731104000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1523731104000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1523731104000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1523731104000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1523731104000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1523731104000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1523731104000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1523731104000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1523731104000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1523731104000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1523731104000},{"_id":"source/images/2017/05/dlist-delete.png","hash":"1e39536f859c8c83b935f2c0f5c46e740f2b2e70","modified":1529231216000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1523731104000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1523731104000},{"_id":"source/images/2017/05/dlist-insert.png","hash":"bb916f2969d562878be21cb087c846d6a97d3ec2","modified":1529231216000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1523731104000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1523731104000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1523731104000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1523731104000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1523731104000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1523731104000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1523731104000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1523731104000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1523731104000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1523731104000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1523731104000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1523731104000},{"_id":"public/about/index.html","hash":"a5fa5183de33c838896ef76fb5c68e7ef0c0070a","modified":1529309616282},{"_id":"public/categories/index.html","hash":"7c64b75ff4978748bf3e67ba9a079a9fa708441d","modified":1529309616282},{"_id":"public/2018/06/17/2018-06-17-ban-nian-sui-xiang/index.html","hash":"39aa4307f73b2764180b91b8e0988f8122c2b940","modified":1529309616283},{"_id":"public/2015/12/10/2015-12-10-fen-xi-nginxri-zhi-de-li-qi-goaccess/index.html","hash":"e7b52b326f18765e50114b3d148a7451d553580e","modified":1529309616283},{"_id":"public/2015/08/21/2015-08-21-supervisorjian-ting-qi/index.html","hash":"feb2af733a58b228950a48e658696f2bc89d4532","modified":1529309616283},{"_id":"public/2015/08/10/2015-08-10-hackthon/index.html","hash":"253e7211d037a82022f37655d54f4b7c78b2785c","modified":1529309616283},{"_id":"public/2015/07/24/2015-07-24-ji-lu-cuo-wu-deng-lu-de-btmpwen-jian/index.html","hash":"eea59a89c7700ee59b73ed7eb94685918eef08d0","modified":1529309616283},{"_id":"public/2014/11/29/2014-11-29-yong-dao-de-tcpdump/index.html","hash":"82e4fa5ab2d360597b70718386a5edaacd411266","modified":1529309616283},{"_id":"public/2014/11/25/2014-11-25-tired/index.html","hash":"a17d896e0ed1be9cb90ee959bfd88a5daccd3928","modified":1529309616284},{"_id":"public/2014/10/29/2014-10-29-iptablezuo-natzhuan-fa/index.html","hash":"66299af0f4ba8281842bf56617a410939b27bc16","modified":1529309616284},{"_id":"public/2014/10/04/2014-10-04-redisre-bei/index.html","hash":"f8ab33d2969f72c983de2422dfb43b7a520cbffb","modified":1529309616284},{"_id":"public/2014/07/27/2014-07-27-rsyslog-jie-shou-yuan-cheng-ri-zhi/index.html","hash":"1e7655eb15d3a13fc2a230a8e206faa04166aba4","modified":1529309616284},{"_id":"public/2014/07/12/2014-07-12-goan-zhuang-protobuf/index.html","hash":"bfefcd6accd1aecee30813099cd336527d2db25f","modified":1529309616284},{"_id":"public/2014/05/03/2014-05-03-mac-an-zhuang-go/index.html","hash":"b28204d94f9327de974b23c17eb721b15640842d","modified":1529309616284},{"_id":"public/2013/04/02/2013-04-02-zhe-teng/index.html","hash":"22ef30c2d2fd19b8df2a5e55858b322ea24ecaea","modified":1529309616284},{"_id":"public/2012/03/17/2013-08-28-fu-wu-qi-she-ji-mo-xing/index.html","hash":"f050940853b50daa40943643f79eee7d6be98a5b","modified":1529309616284},{"_id":"public/archives/page/10/index.html","hash":"5e5a3d77d5b759b49e43b55f9b777df129f398f0","modified":1529309616284},{"_id":"public/archives/2012/index.html","hash":"77a4d7fb7fd2757610b3ffd17538992347915050","modified":1529309616284},{"_id":"public/archives/2012/03/index.html","hash":"4d0145fcaf79b2322c9b9f3fba0c03683e122de3","modified":1529309616284},{"_id":"public/archives/2012/05/index.html","hash":"4d1cadbaffdcff5dd829a6468f9497e0d8fdc658","modified":1529309616284},{"_id":"public/archives/2012/07/index.html","hash":"7041eba52b8a6f529d332a69383b6a46d99eae65","modified":1529309616284},{"_id":"public/archives/2012/11/index.html","hash":"a43ae49ee0428262d1ae20628bd3d903cfc91432","modified":1529309616285},{"_id":"public/archives/2012/12/index.html","hash":"24317eb17145e1ae29b2916e30c15575a0928165","modified":1529309616285},{"_id":"public/archives/2013/page/3/index.html","hash":"33e6bd28443a27e40359ab530d4bdf873504ca8a","modified":1529309616285},{"_id":"public/archives/2013/02/index.html","hash":"734c838613c607d04ec590c6f9f9e24ed716da40","modified":1529309616285},{"_id":"public/archives/2013/04/index.html","hash":"8245014f4381c27188c66915472b11ca8f1102c1","modified":1529309616285},{"_id":"public/archives/2013/05/index.html","hash":"cb90c997050788bf59b0dcc038ddc26f13474cc0","modified":1529309616285},{"_id":"public/archives/2013/06/index.html","hash":"d2f3c91d9bc415bdbaead3fb9a4871fb9fd0473f","modified":1529309616285},{"_id":"public/archives/2013/07/index.html","hash":"43fda0863a9bdc6ebe510492dbe35612bbfbb600","modified":1529309616285},{"_id":"public/archives/2013/08/index.html","hash":"75c61646f97c892a2d43e566d862d67a7645055f","modified":1529309616285},{"_id":"public/archives/2013/09/index.html","hash":"5197bb1c9de11c5eee936e12a6cf08a6f4db93a0","modified":1529309616285},{"_id":"public/archives/2013/11/index.html","hash":"e401ff589ac249287cb6b96f76ddccc18e11b6d2","modified":1529309616285},{"_id":"public/archives/2013/12/index.html","hash":"65eb16e3fffd20a4f2c12a1f3d2c645a42822dc7","modified":1529309616285},{"_id":"public/archives/2014/page/3/index.html","hash":"6601f987f25e92818e6503c64e5af567095d111b","modified":1529309616285},{"_id":"public/archives/2014/01/index.html","hash":"5b417b21b8bf46adc447197db10d28e4db396352","modified":1529309616285},{"_id":"public/archives/2014/02/index.html","hash":"74f18612b3af4eeecd38ba9d8e7da21a1be0ba6d","modified":1529309616285},{"_id":"public/archives/2014/03/index.html","hash":"2620003769edf76917c9b22a661ce66900b388ba","modified":1529309616286},{"_id":"public/archives/2014/04/index.html","hash":"1586e99cbadfe42ca967822b6f69479372b4f568","modified":1529309616286},{"_id":"public/archives/2014/05/index.html","hash":"7d8f12110a7c991ada090a02e88d0445f480d4d4","modified":1529309616286},{"_id":"public/archives/2014/06/index.html","hash":"b038fb338d766cc0bb345b1ba2863659140e7469","modified":1529309616286},{"_id":"public/archives/2014/07/index.html","hash":"954f54ca0ffd2b33f9fa72d0a7e27e5c70fed320","modified":1529309616286},{"_id":"public/archives/2014/09/index.html","hash":"ff1d6b7105a1c41266d2ac3bdee133c8b238a34d","modified":1529309616286},{"_id":"public/archives/2014/10/index.html","hash":"72f245cfa5f1dc31d222ddbbafd17d4914587c61","modified":1529309616286},{"_id":"public/archives/2014/11/index.html","hash":"2f5bde8557b2f9f9955df8f06dc03bd8c6843c6a","modified":1529309616286},{"_id":"public/archives/2014/12/index.html","hash":"ad5cfbaea8eec652936a6172170d96dfe4e59c89","modified":1529309616286},{"_id":"public/archives/2015/01/index.html","hash":"50258b3f56b0df90388fb0833d4f788c3d764f08","modified":1529309616286},{"_id":"public/archives/2015/02/index.html","hash":"f30524539ae84780e04e0de7b91849ae123d6d4f","modified":1529309616286},{"_id":"public/archives/2015/04/index.html","hash":"94324a5e4ebac0234617b5122d57e85b427b86cd","modified":1529309616286},{"_id":"public/archives/2015/05/index.html","hash":"07ff66ce1e399cc6b305adc2a17c75b422f2b570","modified":1529309616286},{"_id":"public/archives/2015/06/index.html","hash":"db6b2cd99a6df538b3bcefec63a9b9627f5e9652","modified":1529309616286},{"_id":"public/archives/2015/07/index.html","hash":"bb5a8c92521705dbac231b9bde8cfafe8ca35944","modified":1529309616286},{"_id":"public/archives/2015/08/index.html","hash":"74ce945712183e21bcdb6a86f48dff65ea64832b","modified":1529309616286},{"_id":"public/archives/2015/09/index.html","hash":"3aaaac47630ae8ca2a6a7eda51719633dd7752a2","modified":1529309616287},{"_id":"public/archives/2015/10/index.html","hash":"faac2e743c9b8ed1dca13132461f1675fe6592f1","modified":1529309616287},{"_id":"public/archives/2015/12/index.html","hash":"a3b05f8d4e339f521b7c97d6fa44458e007a68dd","modified":1529309616287},{"_id":"public/archives/2016/page/2/index.html","hash":"2115af713462d7cd284f44c7893fe0b87c424cd2","modified":1529309616287},{"_id":"public/archives/2016/01/index.html","hash":"640d9a715ccc4d0e690bd3be96e085427e6e96cc","modified":1529309616287},{"_id":"public/archives/2016/03/index.html","hash":"72032c24962ab72a720a63e5e7edd7c9ee6634f7","modified":1529309616287},{"_id":"public/archives/2016/04/index.html","hash":"a1bb19471957c150a95d9798aac33937346b117e","modified":1529309616287},{"_id":"public/archives/2016/06/index.html","hash":"6352022090c1e380d3451de7b7e7f0f10a670404","modified":1529309616287},{"_id":"public/archives/2016/07/index.html","hash":"e890e74ee545a29a416ecbad07d64deaf02e0d78","modified":1529309616287},{"_id":"public/archives/2016/08/index.html","hash":"4e1eec54afd4ee27e4db6089c54c2af6dfc33819","modified":1529309616287},{"_id":"public/archives/2016/09/index.html","hash":"2880150246c57e55c9e3e3905466fd51ccf69b7e","modified":1529309616287},{"_id":"public/archives/2016/12/index.html","hash":"12c55adffb3a260b5ef33b891f3a60968fae84a5","modified":1529309616287},{"_id":"public/archives/2017/index.html","hash":"95982e88e4ed5ece93e1cb7072ca43580a2ad8b0","modified":1529309616287},{"_id":"public/archives/2017/02/index.html","hash":"033096e2e512a842133b84cdc3e128dd0a282fb3","modified":1529309616287},{"_id":"public/archives/2017/05/index.html","hash":"381aaa64b6579d697a28a243756e15b116f0b18f","modified":1529309616288},{"_id":"public/archives/2017/06/index.html","hash":"639b0e41242cafc95c6141ec5737333bbfcb2ab2","modified":1529309616288},{"_id":"public/archives/2017/07/index.html","hash":"c6840ef0407af717c168ddb2f7df9a503fdf985a","modified":1529309616288},{"_id":"public/archives/2018/index.html","hash":"5d3cff2f38dba6c663afa588d1a02a468e5aa017","modified":1529309616288},{"_id":"public/archives/2018/06/index.html","hash":"b94551238c703047b1cbcd7b0d11bb173c374915","modified":1529309616288},{"_id":"public/page/10/index.html","hash":"ef70629ff0ff32d306f7e01799b125d274fbc544","modified":1529309616288},{"_id":"public/categories/Life/index.html","hash":"655e9987560e9f50d1bb6c69ba4d6e953051a7a6","modified":1529309616288},{"_id":"public/categories/Life/page/2/index.html","hash":"95f22863382e2b5c1539503fcb5f086f9c24b432","modified":1529309616288},{"_id":"public/categories/Server/index.html","hash":"3ccc4da5f54633b4a72f17ff081d1395c1f45e99","modified":1529309616288},{"_id":"public/categories/Server/page/2/index.html","hash":"67ae9039be12e22d396d8cfe97166a6c6b9c5f9b","modified":1529309616288},{"_id":"public/categories/Product/index.html","hash":"aab3ccf03d4ff0b8a32556dc450f3119d60c9609","modified":1529309616288},{"_id":"public/categories/Programe/page/3/index.html","hash":"e2ac6b1613c507f15151ed012d07914246fa4f40","modified":1529309616288},{"_id":"public/categories/NetWork/index.html","hash":"84cf00bc81c41485dc67a3e6af7baa62f2772429","modified":1529309616288},{"_id":"public/categories/NetWork-Server/index.html","hash":"1b9b2f9c366e8efb85577ea764eb25e698092ab1","modified":1529309616288},{"_id":"public/categories/DataBase/page/2/index.html","hash":"420d1e71ea8f35ca137bf0b79e63ed91ea69e5c2","modified":1529309616288},{"_id":"public/categories/Server-DataBase/index.html","hash":"41aa35bbce29a1ab7cb8039922035ed66015fc57","modified":1529309616288},{"_id":"public/categories/Server-NetWork/index.html","hash":"bd74e369364e92ffca1078cd1d7ae48c7e20178e","modified":1529309616289},{"_id":"public/categories/Server-Product/index.html","hash":"a5fe4a97b6a5bc73b00340cf9ed6c013c846a106","modified":1529309616289},{"_id":"public/categories/System/page/2/index.html","hash":"2d303a5208490021750566957f9a3bc5e79cb39e","modified":1529309616289},{"_id":"public/2017/07/13/2017-07-13-httpserver-graceful-shutdown-in-go/index.html","hash":"6d6824998c6a5ca0bcf9fb9ac05cc675449eaa22","modified":1529309616289},{"_id":"public/2017/06/04/2017-06-04-mit-6-dot-824-mapreduce/index.html","hash":"6ba3f3a46b271228aea633c13bfbb1966e675967","modified":1529309616289},{"_id":"public/2017/05/29/2017-05-29-shuang-duan-lian-biao/index.html","hash":"936d05114a861900628d0294b0a5ed38f72e846b","modified":1529309616289},{"_id":"public/2017/02/25/2017-02-25-zookeeper-bi-ji/index.html","hash":"74b8514460a1d48f58d41c0729fcb774a515434e","modified":1529309616289},{"_id":"public/2017/02/22/2017-02-22-zheng-xiang-yu-fan-xiang-dai-li/index.html","hash":"f6fe5530fc1edbd2aaf3955823c31ae57c2af97c","modified":1529309616289},{"_id":"public/2016/12/02/2016-12-02-cgroupxian-zhi-ji-suan-zi-yuan/index.html","hash":"33c9d469ae712219ea06130f68945b10c9d3ea43","modified":1529309616289},{"_id":"public/2016/09/28/2016-09-28-ji-yi-ci-redis-server-bug/index.html","hash":"8417d213437c37b18d2e05ea4439c0d1311331a8","modified":1529309616289},{"_id":"public/2016/09/25/2016-09-25-gong-xiang-nei-cun-yu-xin-hao-liang/index.html","hash":"e610f2a936b16dd67d42055b1ef4d73815d1d460","modified":1529309616289},{"_id":"public/2016/08/01/2016-08-01-cuckoofilter/index.html","hash":"6d96a4d4f054b1e949aa62079f4803e980486515","modified":1529309616289},{"_id":"public/2016/07/23/2016-07-23-celeryde-crontabshi-jian/index.html","hash":"1551395131b9188d569fa0ea559887bd085759ac","modified":1529309616289},{"_id":"public/2016/07/16/2016-07-16-bash-jia-zai-shun-xu/index.html","hash":"3676ae0973c39b3d1d05344d674855f54a789e14","modified":1529309616289},{"_id":"public/2016/06/03/2016-06-03-zhun-que-jian-ce-mysql-fu-zhi-yan-chi/index.html","hash":"f7d4a1b5f02f99013926776c7ca598da11867f0d","modified":1529309616289},{"_id":"public/2016/04/24/2016-04-24-ansible-dynamic-inventory/index.html","hash":"cf1a79cec2eaad2068625d7245a844435dbace3f","modified":1529309616290},{"_id":"public/2016/04/23/2016-04-23-flume-shi-shi-shou-ji-nginx-ri-zhi/index.html","hash":"d43f2e22d1b2dd36e813a9f0ab9a085f0490160c","modified":1529309616290},{"_id":"public/2016/03/10/2016-03-10-gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi/index.html","hash":"f4226c47db08e517f14d0e415408c7b0147e2cce","modified":1529309616290},{"_id":"public/2016/01/07/2016-01-07-shi-shi-jian-kong-nginx-qps-de-tuo-zhan/index.html","hash":"591eab4cd878ad037cb29ca8661b924de69f84eb","modified":1529309616290},{"_id":"public/2015/12/05/2015-12-05-gre-tuning-and-keepalived/index.html","hash":"72f798cd3176d6b039f01299a96536a233b38f19","modified":1529309616290},{"_id":"public/2015/10/29/2015-10-29-gei-tengine-jia-shang-lua-tuo-zhan/index.html","hash":"a79b4aa224ce601466351e46b3cb1dec6ba4ddf9","modified":1529309616290},{"_id":"public/2015/10/06/2015-10-06-ji-lu-shi-yong-flaskde-dian-di/index.html","hash":"392e836d6bda4d40dab7a33fd2ce3f86350d9780","modified":1529309616290},{"_id":"public/2015/10/01/2015-10-01-python-shi-yong-ldap/index.html","hash":"e94fe4fb448dcf51aae64bd7742c9bad4b181f30","modified":1529309616290},{"_id":"public/2015/09/10/2015-09-10-sysdig-zhi-de-yong-you/index.html","hash":"8774106fce7ec4a0cb419921a6c605e019e9d7fa","modified":1529309616290},{"_id":"public/2015/09/05/2015-09-05-ansiblede-shi-yong-jing-yan/index.html","hash":"e14aad45da5c0d3d10e43c1d8ffcce9aff0750dd","modified":1529309616290},{"_id":"public/2015/08/16/2015-08-16-twemproxy/index.html","hash":"22d78c32725511c459692752743534ecef014118","modified":1529309616290},{"_id":"public/2015/07/12/2015-07-12-my-dot-cnfpei-zhi-yi-ju/index.html","hash":"b94ff0e2e51ff9e1a9d71dd781b86db93672028c","modified":1529309616291},{"_id":"public/2015/06/11/2015-06-11-qing-qiao-shi-shi-tong-ji-yong-hu-shu/index.html","hash":"f0ae491334f2a01fe30e3ac6109ad4f8b7a9c3d2","modified":1529309616291},{"_id":"public/2015/05/17/2015-05-17-da-jian-postfix/index.html","hash":"4ecdf5a6042381b470bafa00d61ec1241f835526","modified":1529309616291},{"_id":"public/2015/05/10/2015-05-10-mysql-slave-relay-log-corrupt-chu-li-he-hui-fu/index.html","hash":"3c9765755845f0278aaca4586cb8bfd3e8f15766","modified":1529309616291},{"_id":"public/2015/04/05/2015-04-05-yong-bao-docker/index.html","hash":"c8d427546e01d8d685d4c02bce1e82cb2b9fe999","modified":1529309616291},{"_id":"public/2015/02/08/2015-02-08-trie-suggestion/index.html","hash":"e1317cdcc6def48902415f9517667289d5a1030d","modified":1529309616291},{"_id":"public/2015/02/03/2015-02-03-haproxy-plus-mysql/index.html","hash":"c5dbfff7208d71f0dd6311d7072bae1037218425","modified":1529309616291},{"_id":"public/2015/01/31/2015-01-31-da-jian-elasticsearchyu-kibana/index.html","hash":"05f125f96d52bb75cf0e27879d7220aa1c16929e","modified":1529309616291},{"_id":"public/2015/01/21/2015-01-21-percona-toolkitxiao-xiang-li-di-pt-archiver/index.html","hash":"fb0e67eb24143600b3c7a15b68d0f3af1ef61029","modified":1529309616291},{"_id":"public/2014/12/13/2014-12-13-nginxcuo-wu-ma/index.html","hash":"6cd854c4015c38762cd4dc949d37e10812214485","modified":1529309616291},{"_id":"public/2014/11/02/2014-11-02-nginxyu-phpxi-tong-can-shu-pei-zhi/index.html","hash":"8258379ed8936d4c56f3c9b65da39164b70ccb46","modified":1529309616291},{"_id":"public/2014/10/23/2014-10-24-mysql-unique-index/index.html","hash":"180d32585b3bb19c3afa9b785aebbec9f011a061","modified":1529309616291},{"_id":"public/2014/10/13/2014-10-13-nei-cun-du-qu-na-er-la/index.html","hash":"3b40400f2fd8ed749dbe59a884625635df4bbd6a","modified":1529309616291},{"_id":"public/2014/09/07/2014-09-07-percona-server-zuo-zhu-cong/index.html","hash":"f64bb9d3c5b5d8fd0d47690718693e236e818f29","modified":1529309616291},{"_id":"public/2014/07/16/2014-07-16-zhe-teng-docker/index.html","hash":"f8416143278596290fc14603066abebb15f19651","modified":1529309616291},{"_id":"public/2014/06/21/2014-06-21-da-mo-de-qing-chun/index.html","hash":"b0a5abf1eb6d938bb29f60a1cc535b816e4e7bce","modified":1529309616292},{"_id":"public/2014/05/13/2014-05-13-nginx-pitfall/index.html","hash":"05698156ef927d471c3cc61712f19c3232d9f0f6","modified":1529309616292},{"_id":"public/2014/05/03/2014-05-03-make-setup-dot-py/index.html","hash":"788fa6fec304e511c4d8e470fb583e6648b9a3e0","modified":1529309616292},{"_id":"public/2014/04/28/2014-04-28-wei-wen-yi-lu/index.html","hash":"59420ae06655b5f6595200d887990273e2438ce1","modified":1529309616292},{"_id":"public/2014/04/22/2014-04-22-liu-xia-liao-xie-dong-xi/index.html","hash":"e82e2013ba11b5137d7fc793f218b26618a224dd","modified":1529309616292},{"_id":"public/2014/03/13/2014-03-13-expect-yu-xi-tong-zi-dong-jiao-hu/index.html","hash":"afd0dd98afb5f0ac04662dd2dd8c26312a3fdbed","modified":1529309616292},{"_id":"public/2014/02/24/2014-02-24-socketnian-bao/index.html","hash":"6ac11f835e115dde96616c4c43e840386efa9257","modified":1529309616292},{"_id":"public/2014/02/05/2014-02-05-shen-ru-strtokhan-shu/index.html","hash":"a5f6c443452d7d6450562839fd51e02d2d159a12","modified":1529309616292},{"_id":"public/2014/02/01/2014-02-01-tiao-biao-skiplist/index.html","hash":"8f4185cf073464e948b02da6fcfc2fe550b436fe","modified":1529309616292},{"_id":"public/2014/01/24/2014-01-24-<<rework>>-shu-zhai/index.html","hash":"4ce23014d73ff73c4311aa2751697ed332bc1cbb","modified":1529309616292},{"_id":"public/2014/01/07/2014-01-07-wei-xin-gong-zhong-hao-kai-fa/index.html","hash":"604a7809ed957e830abf10684a54f38bbbd0a49c","modified":1529309616292},{"_id":"public/2014/01/06/2014-01-06-re-geng-xin/index.html","hash":"5e9c64a1e532dd2147124aa41e2b8cbdc009dc03","modified":1529309616292},{"_id":"public/2013/12/21/2013-12-21-yu-jian/index.html","hash":"2db024c66388a9c177617192b77f3cddca1ebdce","modified":1529309616292},{"_id":"public/2013/12/05/2013-12-05-zui-jin-yong-dao-de-mysql/index.html","hash":"6847f6d1e34d3a85a179ab0007da3dd6efe9b627","modified":1529309616292},{"_id":"public/2013/11/10/2013-10-10-shui-de-xin-jing/index.html","hash":"57ce4a60d9e0e509d3e74ba54a8ad4211b9474ae","modified":1529309616292},{"_id":"public/2013/09/29/2013-09-29-zerorpcshi-ge-hao-dong-xi/index.html","hash":"e1020250300cd695383e0029e24ed541103a5009","modified":1529309616293},{"_id":"public/2013/09/28/2013-09-28-shellji-qiao-xiao-jie/index.html","hash":"a1f6fbbd5fc98eb5f0da7508a7021cb9785253cc","modified":1529309616293},{"_id":"public/2013/09/22/2013-09-22-dan-ji-wan-hadoop/index.html","hash":"c4ebbc386256a6f8e018ff30b0b836a8c2279432","modified":1529309616293},{"_id":"public/2013/09/21/2013-09-21-leveldbben-di-cun-chu-yin-qing-jing-zhi-de-gong-ju/index.html","hash":"0419134f930ac84ed16b611fd46c767694deaca4","modified":1529309616293},{"_id":"public/2013/09/15/2013-09-15-jsonpjie-jue-kua-yu-qing-qiu/index.html","hash":"2994b505e91f258f50c265200e4a2f19e802a136","modified":1529309616293},{"_id":"public/2013/09/12/2013-09-12-nginx-plus-luaying-dui-zai-xian-zhuang-tai-fu-wu/index.html","hash":"e764787e397f1ad988c50d2b2c96426ee0082ba6","modified":1529309616293},{"_id":"public/2013/08/20/2013-08-20-minigame-fu-wu-duan-she-ji/index.html","hash":"54617ab2b91c1172c3ca004f7d4c187c52d4b816","modified":1529309616293},{"_id":"public/2013/08/16/2013-08-30-jing-ran-ye-yong-dao-liao-oracle/index.html","hash":"4191a4411621ecd99dacc07fdaa335e026bbfb89","modified":1529309616293},{"_id":"public/2013/07/15/2013-08-30-feng-pei-zhi-lu/index.html","hash":"e778836ae2abdfe10ac9075905f0ebd987df3c44","modified":1529309616293},{"_id":"public/2013/06/29/2013-08-29-hui-gu-zeromq/index.html","hash":"f796f5ef543d41103bd12af0214c7939e6956753","modified":1529309616293},{"_id":"public/2013/06/20/2013-08-30-fen-bu-shi-chu-li-kuang-jia-gearman/index.html","hash":"5c2e69be69fcbcabd12bdce85be2eea1e92d97d7","modified":1529309616293},{"_id":"public/2013/06/17/2013-08-29-unix-domain-socket-ipctong-xin-ji-zhi/index.html","hash":"206ccde78b321f3522a225b843b515450185e8de","modified":1529309616293},{"_id":"public/2013/06/12/2013-08-29-dou-ban-xi-ai-wen-zhang-xia-zai-qi/index.html","hash":"2b65124d5750d8e8569221c3f61f04a89faffd7a","modified":1529309616294},{"_id":"public/2013/05/30/2013-08-29-xiu-qi-xiao-bo/index.html","hash":"0fdff21f2bb7c2406cc9ba33b008686e16e60540","modified":1529309616294},{"_id":"public/2013/06/08/2013-08-29-c-plus-plus-yu-pythonde-hun-he-bian-cheng-pythontuo-zhan-bian-xie/index.html","hash":"dff63e922d3a4942ab7b58c094d481dac86144dd","modified":1529309616294},{"_id":"public/2013/05/11/2013-08-29-google-c-plus-plus-style/index.html","hash":"de62223fd59a4d7696f50381bc2a5f4c92de5642","modified":1529309616294},{"_id":"public/2013/04/20/2013-08-29-fan-hui-zhi-de-tou-che-li-jie/index.html","hash":"942c4dfb90a3e99480044f120fed2bede7441755","modified":1529309616294},{"_id":"public/2013/02/17/2013-08-28-nginxmo-kuai-kai-fa/index.html","hash":"f1c585ca44d94a455ced02aa858a2f727d896dac","modified":1529309616294},{"_id":"public/2013/02/12/2013-08-28-zai-lu-shang/index.html","hash":"bd7d9764375bfcb6f50f1f5c9c21f8ba0349bab1","modified":1529309616294},{"_id":"public/2012/12/27/2013-08-28-thread-pool-in-python/index.html","hash":"e3f75fd61502c35fc59bcce179363015513a5c2e","modified":1529309616294},{"_id":"public/2012/11/28/2013-08-26-si-kao-yu-fen-xiang-shi-jie-zhi-sheng-hua/index.html","hash":"842eb6721cd0ff8b3cce0574da78774e21d2e37b","modified":1529309616309},{"_id":"public/2012/07/12/2013-08-26-jiao-shen-ma-rong-yu-chu-pin-dou-ya-huan-shu/index.html","hash":"7301dc5ba310e0f94111b456158e45242132d4fb","modified":1529309616309},{"_id":"public/2012/05/07/2013-08-28-zuo-kuai-le-de-cheng-xu-yuan/index.html","hash":"2f89c6722619b7ae13747ae92fb6c39635d1591d","modified":1529309616309},{"_id":"public/2012/03/22/2013-08-28-zhe-teng-libevent/index.html","hash":"fc3d957f8fd967612f6df7e5ba2fddee90fbec95","modified":1529309616309},{"_id":"public/archives/index.html","hash":"323461552c4757403cdf87e21a263b316fc54ee9","modified":1529309616309},{"_id":"public/archives/page/2/index.html","hash":"2f70ad4636adee9d8a7a92d8e252650d2f5350f6","modified":1529309616309},{"_id":"public/archives/page/3/index.html","hash":"781a0c270800d568c67d639cde990c8c62a9209b","modified":1529309616309},{"_id":"public/archives/page/4/index.html","hash":"e3ffedbdd76ce5f67b9cc160544df2a8ff1d6e7d","modified":1529309616310},{"_id":"public/archives/page/5/index.html","hash":"fc6d21011eca771cf14049569663b81beb88bb10","modified":1529309616310},{"_id":"public/archives/page/6/index.html","hash":"36c4de17108f0349508eabacd92e33dab61e1be6","modified":1529309616310},{"_id":"public/archives/page/7/index.html","hash":"3da706055b150b43971ca5e9fe75e6058357ed59","modified":1529309616310},{"_id":"public/archives/page/8/index.html","hash":"f4bc8f5ea0deaaa7533b9ca57a008e11f203dbe5","modified":1529309616310},{"_id":"public/archives/page/9/index.html","hash":"86ce7abe3fc60fb112ccfaf60b644d181473e76e","modified":1529309616310},{"_id":"public/archives/2013/index.html","hash":"6128db01f2028ed5f9029deffc3d0f72cf1baebd","modified":1529309616310},{"_id":"public/archives/2013/page/2/index.html","hash":"f43ba47c57bd5c2b85b59382aeb2734e0c70f054","modified":1529309616310},{"_id":"public/archives/2014/index.html","hash":"4101941cd3efdaa76bcc21d3e7ccfb29518b12e2","modified":1529309616310},{"_id":"public/archives/2014/page/2/index.html","hash":"2f4b87081b3aa572d88f58daa3baecfe2770175b","modified":1529309616310},{"_id":"public/archives/2015/index.html","hash":"2d8856b4a7d1cba4812bd4a5b3f9b1899b9434ad","modified":1529309616310},{"_id":"public/archives/2015/page/2/index.html","hash":"55d758a6b36c7588c3a37d7fca2fbe0860aba186","modified":1529309616310},{"_id":"public/archives/2016/index.html","hash":"d0c97ab65eb280d55a0ae7c5dd358fd8492c8c82","modified":1529309616310},{"_id":"public/index.html","hash":"60cb47ae2ccb856f333357b9fe6683d7ca3fca7d","modified":1529309616310},{"_id":"public/page/2/index.html","hash":"02d80c2fc2971393d3ede12910eca889b5a867ea","modified":1529309616311},{"_id":"public/page/3/index.html","hash":"95d31dee4fee9eda061f5b2f28bc31f3ce0c3ef2","modified":1529309616311},{"_id":"public/page/4/index.html","hash":"ae95a0d24eb7ea5cf03c8efa775300a801c3b8b6","modified":1529309616311},{"_id":"public/page/5/index.html","hash":"423134f30d3ffcf6815483ae37f7c3826c8e7a76","modified":1529309616311},{"_id":"public/page/6/index.html","hash":"8bfbfef039c7c5a9141a7a982e6ac89ad358c9a7","modified":1529309616311},{"_id":"public/page/7/index.html","hash":"d4f1533f00aca0d7b67fcb56ac59dc5990d9e3bb","modified":1529309616311},{"_id":"public/page/8/index.html","hash":"3f07c37537c09aeada5e5bdd0b3c76551288ad56","modified":1529309616311},{"_id":"public/page/9/index.html","hash":"076b52f91eee6a4d891ce9b888a6733d7635a923","modified":1529309616311},{"_id":"public/categories/Programe/index.html","hash":"29499abd91525d60ef28575be61a25a7a07970f6","modified":1529309616311},{"_id":"public/categories/Programe/page/2/index.html","hash":"cfcbcaf0441e30f122c4a536058606dc282f03ea","modified":1529309616311},{"_id":"public/categories/DataBase/index.html","hash":"590319e240d2a2ea3f16b2e5b856f5ba4955326b","modified":1529309616312},{"_id":"public/categories/System/index.html","hash":"c5486db8a36c16733acee080bbdd57286cbc3143","modified":1529309616312},{"_id":"public/images/bird_32_gray.png","hash":"55345ff7370047a6b825dd235c9ce201545a0952","modified":1529309616325},{"_id":"public/images/bird_32_gray_fail.png","hash":"0c30b159e4cbb7e8a1ad826be537fc4bd79b0a8f","modified":1529309616325},{"_id":"public/images/code_bg.png","hash":"c34acd76f73ef68d62c031856bd627ffac9378f3","modified":1529309616325},{"_id":"public/images/dotted-border.png","hash":"347784b401d0d38acf5e3b6d06a90346a16a8e8c","modified":1529309616325},{"_id":"public/images/favicon.png","hash":"19ca364fa2d577527b4981b7958718f9fa5a7bb0","modified":1529309616325},{"_id":"public/images/email.png","hash":"2a5d251567fabcad68fa596ebaf1508296524930","modified":1529309616325},{"_id":"public/images/line-tile.png","hash":"a86a5d70fb0024dd295b85ea9058b43c1c5f25d3","modified":1529309616325},{"_id":"public/images/search.png","hash":"3c0178651f38bff462d4feb927e4f4df87b0f9d0","modified":1529309616325},{"_id":"public/images/noise.png","hash":"a839ae391fbbb0a1a2b22f8aba1d8ae2a702ef34","modified":1529309616325},{"_id":"public/images/rss.png","hash":"d61fc1ccc66f081002b15532f66e054147d5f2fb","modified":1529309616325},{"_id":"public/images/wood.jpg","hash":"70043f934922eca94934214931f0833a04798751","modified":1529309616325},{"_id":"public/images/2013/fastcgi.jpg","hash":"3d27e12353c43f153490e17f0e367e920066e3e2","modified":1529309616325},{"_id":"public/images/2013/panda.jpg","hash":"3c3f9d9391962a8936f88098be8995da946e2186","modified":1529309616325},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1529309616325},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1529309616326},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1529309616326},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1529309616326},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1529309616326},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1529309616326},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1529309616326},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1529309616326},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1529309616326},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1529309616326},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1529309616326},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1529309616326},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1529309616326},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1529309616326},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1529309616326},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1529309616326},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1529309616326},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1529309616326},{"_id":"public/images/2013/08/class.png","hash":"f7724bebc971054d4df28f0feab1230f0bb8e22d","modified":1529309616326},{"_id":"public/images/2013/08/ip.gif","hash":"4527e78a356a6468feaa98400c62fabb53da675c","modified":1529309616326},{"_id":"public/images/2013/08/gearman.png","hash":"4bd73fae2873a680dcc659eccffeeafe37fa9326","modified":1529309616326},{"_id":"public/images/2013/08/oracle.png","hash":"419a753045ee3638389cb09405953e4389391307","modified":1529309616326},{"_id":"public/images/2013/08/ipc_unix_socket-300x300.png","hash":"6c0af0c33b6712220c8792069da491a4e21b225f","modified":1529309616326},{"_id":"public/images/2013/10/Gitar.jpg","hash":"bc882e7e76ee2ccbbe32a134c58f79fae5cb1d3e","modified":1529309616326},{"_id":"public/images/2013/10/Violin.jpg","hash":"1648339d81ca6735d725d5c9d6caacaf4ea11842","modified":1529309616327},{"_id":"public/images/2013/douya/ICON.jpg","hash":"ed6fb1b491d518bb4176badeb5154a15fa082bb9","modified":1529309616327},{"_id":"public/images/2013/douya/around.jpg","hash":"f474d8b0947c936dfeae2b4b83a27f45056432eb","modified":1529309616327},{"_id":"public/images/2013/douya/chat.jpg","hash":"98b6bbde13437d213c78b91d3ff7fdce32b6dabb","modified":1529309616327},{"_id":"public/images/2013/douya/collect.jpg","hash":"821c96bce387d280fbe1badc16a282a490fd0969","modified":1529309616327},{"_id":"public/images/2013/douya/description.jpg","hash":"10a2f5ab89e1d2523642099185e8c58ebcf1a49e","modified":1529309616327},{"_id":"public/images/2013/douya/friend.jpg","hash":"b1fb9e773d5e29b0ea1be34d6d933b3494b9db27","modified":1529309616327},{"_id":"public/images/2013/08/minigame.png","hash":"34bb9bce493db9017e36074ac593f5f703e44df5","modified":1529309616327},{"_id":"public/images/2013/12/nba.jpg","hash":"29c718e4f7cd0ad90ae859688e8ecb36c1f2b063","modified":1529309616327},{"_id":"public/images/2013/douya/myshare.jpg","hash":"390278beab70dc953416a5f8cd9ed777f5c611e2","modified":1529309616327},{"_id":"public/images/2013/douya/settiing.jpg","hash":"17da1451ef64dc0ab04f8e229933b2e0ea2a7203","modified":1529309616327},{"_id":"public/images/2013/douya/review.jpg","hash":"c8f7df9fb232ac223e5321d7a47aec636d70e568","modified":1529309616327},{"_id":"public/images/2013/douya/share.jpg","hash":"8148dbebcbe1c39c6be3e3e955bcff3ed80058de","modified":1529309616327},{"_id":"public/images/2013/douya/welcom.jpg","hash":"f6c1c8ea58fad081a6edde47e8a2393dc662b113","modified":1529309616327},{"_id":"public/images/2014/01/skiplist.png","hash":"9f65eebae2d66346528924af503181609f168dbf","modified":1529309616327},{"_id":"public/images/2014/01/rework.jpg","hash":"85e9aa2dc597ccd4f09259657b89086e5777ed69","modified":1529309616327},{"_id":"public/images/2014/10/free.png","hash":"5edfcc57d428db417a2d24eb6cf55c8e2a1e57cf","modified":1529309616327},{"_id":"public/images/2014/10/nestat.png","hash":"3ef0d6755a7506e0f23d7507612baf61b04799d1","modified":1529309616327},{"_id":"public/images/2015/02/suggest.png","hash":"12ba6f827db0a0f5f0990eca40fade2df297dc3a","modified":1529309616328},{"_id":"public/images/2015/02/triestruct.png","hash":"815436faa82c9e3a472008a284d501be4e27e20e","modified":1529309616328},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1529309616328},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1529309616328},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1529309616328},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1529309616328},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1529309616328},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1529309616328},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1529309616328},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1529309616328},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1529309616328},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1529309616328},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1529309616328},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1529309616328},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1529309616328},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1529309616328},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1529309616328},{"_id":"public/images/2013/12/Allen.jpg","hash":"beb71c162b39a330f8a7ca19315417677cf02da7","modified":1529309616754},{"_id":"public/images/2013/12/gitar.jpg","hash":"5033ea65c2dcf040bca626d2bac74c0297c46c9a","modified":1529309616758},{"_id":"public/images/2013/douya/main.jpg","hash":"5ee32e3abf1bc5ff1e947cc521816622e4178b58","modified":1529309616758},{"_id":"public/images/2014/04/guitar.jpg","hash":"a1ac5d4fecf25613440a8373499ed495069c1f48","modified":1529309616758},{"_id":"public/images/2014/10/top.png","hash":"3bb33050e8609d6b3c697b391196e84db2fded31","modified":1529309616758},{"_id":"public/images/2016/04/flume.jpg","hash":"3a2faf8e79798d88c9e75e745b0eb7f13b64b17b","modified":1529309616758},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1529309616759},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1529309616759},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1529309616775},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1529309616775},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1529309616776},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1529309616776},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1529309616776},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1529309616776},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1529309616776},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1529309616776},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1529309616776},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1529309616776},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1529309616777},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1529309616777},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1529309616777},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1529309616777},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1529309616777},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1529309616777},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1529309616777},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1529309616777},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1529309616777},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1529309616777},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1529309616777},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1529309616777},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1529309616777},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1529309616777},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1529309616777},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1529309616777},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1529309616777},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1529309616778},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1529309616778},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1529309616778},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1529309616778},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1529309616778},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1529309616778},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1529309616778},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1529309616778},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1529309616778},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1529309616778},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1529309616778},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1529309616778},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1529309616778},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1529309616778},{"_id":"public/css/main.css","hash":"f983bb8d621e8df73c35b512ac43706c782cdf2c","modified":1529309616778},{"_id":"public/images/2013/09/hadoop.png","hash":"c6059a50e0d67ca8b877187d3d4c03a9bd8ffb66","modified":1529309616778},{"_id":"public/images/2016/04/flume1toflume2.jpg","hash":"160b81bd0de441b51ce03fc06fa9dd1fb02349c1","modified":1529309616778},{"_id":"public/images/2015/08/teammate.png","hash":"0e58c75f06a14585a0b1eb8501c7c5a474255fb4","modified":1529309616778},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1529309616778},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1529309616778},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1529309616779},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1529309616785},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1529309616785},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1529309616786},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1529309616786},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1529309616786},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1529309616786},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1529309616786},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1529309616786},{"_id":"public/images/2017/05/dlist-delete.png","hash":"1e39536f859c8c83b935f2c0f5c46e740f2b2e70","modified":1529309616786},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1529309616790},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1529309616790},{"_id":"public/images/2017/05/dlist-insert.png","hash":"bb916f2969d562878be21cb087c846d6a97d3ec2","modified":1529309616791},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1529309616802},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1529309616802},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1529309616815},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1529309616815},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1529309616817},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1529309616817},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1529309616817},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1529309616817},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1529309616817},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1529309616817},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1529309616824},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1529309616824},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1529309616825},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1529309616837},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1529309616862},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1529309616875},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1529309616879},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1529309616889},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1529309616891}],"Category":[{"name":"Life","_id":"cjijzgd7y0004nctjhpprizht"},{"name":"Server","_id":"cjijzgd830008nctjedzt0js3"},{"name":"Product","_id":"cjijzgd86000cnctjo7cenkey"},{"name":"Programe","_id":"cjijzgd8e000mnctjfakgnq01"},{"name":"NetWork","_id":"cjijzgd8h000rnctjbs04cf06"},{"name":"NetWork Server","_id":"cjijzgd8p0017nctje5nwsuq3"},{"name":"DataBase","_id":"cjijzgd8r001cnctj9d7xq87b"},{"name":"Server DataBase","_id":"cjijzgd8t001hnctjxclmct0a"},{"name":"Server NetWork","_id":"cjijzgd8w001mnctj58lc9t15"},{"name":"Server Product","_id":"cjijzgd91001xnctj2c47ze31"},{"name":"System","_id":"cjijzgd9i002unctjzp9lry8e"}],"Data":[],"Page":[{"layout":"page","title":"About Me","date":"2013-10-08T13:08:00.000Z","comments":1,"sharing":true,"footer":true,"keywords":"zheng-ji","description":"zheng-ji","_content":"\n#### Info\n\n`郑纪`, `Scut`, `@Wechat`\n\n#### Motto\n> 身体和灵魂，总有一个在路上\n","source":"about/index.md","raw":"---\nlayout: page\ntitle: \"About Me\"\ndate: 2013-10-08 21:08\ncomments: true\nsharing: true\nfooter: true\nkeywords: zheng-ji\ndescription: zheng-ji\n---\n\n#### Info\n\n`郑纪`, `Scut`, `@Wechat`\n\n#### Motto\n> 身体和灵魂，总有一个在路上\n","updated":"2018-06-17T11:03:54.000Z","path":"about/index.html","_id":"cjijzgd7j0000nctjirw6iwdk","content":"<h4 id=\"Info\"><a href=\"#Info\" class=\"headerlink\" title=\"Info\"></a>Info</h4><p><code>郑纪</code>, <code>Scut</code>, <code>@Wechat</code></p>\n<h4 id=\"Motto\"><a href=\"#Motto\" class=\"headerlink\" title=\"Motto\"></a>Motto</h4><blockquote>\n<p>身体和灵魂，总有一个在路上</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"Info\"><a href=\"#Info\" class=\"headerlink\" title=\"Info\"></a>Info</h4><p><code>郑纪</code>, <code>Scut</code>, <code>@Wechat</code></p>\n<h4 id=\"Motto\"><a href=\"#Motto\" class=\"headerlink\" title=\"Motto\"></a>Motto</h4><blockquote>\n<p>身体和灵魂，总有一个在路上</p>\n</blockquote>\n"},{"title":"categories","date":"2018-06-17T10:40:50.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-06-17 18:40:50\ntype: \"categories\"\ncomments: false\n---\n","updated":"2018-06-17T10:41:42.000Z","path":"categories/index.html","layout":"page","_id":"cjijzgd7v0002nctjlget9a98","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"layout":"post","title":"折腾","date":"2013-04-02T05:53:00.000Z","comments":1,"_content":"\n{% img /images/2013/panda.jpg %}\n\n这天我被折腾疯了\n\n开始博客迁移，从 [http:innerbrilliant.sinaapp.com](http:innerbrilliant.sinaapp.com) 迁移至 [zheng-ji.info](http://zheng-ji.info)\n\n文档式编程的感觉爽 ：）\n\n","source":"_posts/2013-04-02-zhe-teng.markdown","raw":"---\nlayout: post\ntitle: \"折腾\"\ndate: 2013-04-02 13:53\ncomments: true\ncategories: Life\n---\n\n{% img /images/2013/panda.jpg %}\n\n这天我被折腾疯了\n\n开始博客迁移，从 [http:innerbrilliant.sinaapp.com](http:innerbrilliant.sinaapp.com) 迁移至 [zheng-ji.info](http://zheng-ji.info)\n\n文档式编程的感觉爽 ：）\n\n","slug":"2013-04-02-zhe-teng","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd7r0001nctjss1s50kk","content":"<img src=\"/images/2013/panda.jpg\">\n<p>这天我被折腾疯了</p>\n<p>开始博客迁移，从 <a href=\"http:innerbrilliant.sinaapp.com\" target=\"_blank\" rel=\"noopener\">http:innerbrilliant.sinaapp.com</a> 迁移至 <a href=\"http://zheng-ji.info\" target=\"_blank\" rel=\"noopener\">zheng-ji.info</a></p>\n<p>文档式编程的感觉爽 ：）</p>\n","site":{"data":{}},"excerpt":"","more":"<img src=\"/images/2013/panda.jpg\">\n<p>这天我被折腾疯了</p>\n<p>开始博客迁移，从 <a href=\"http:innerbrilliant.sinaapp.com\" target=\"_blank\" rel=\"noopener\">http:innerbrilliant.sinaapp.com</a> 迁移至 <a href=\"http://zheng-ji.info\" target=\"_blank\" rel=\"noopener\">zheng-ji.info</a></p>\n<p>文档式编程的感觉爽 ：）</p>\n"},{"layout":"post","title":"MiniGame 服务端设计","date":"2013-08-20T10:54:00.000Z","comments":1,"_content":"\n  最近和小伙伴们在做一个游戏。有机会单挑服务端了。被信任是有压力也有动力 ：），可以尝试各种好玩的技术的感觉是很爽。Jerry 和Cat 所主导的客户端，Mzt的美术都很给力。作为云风的忠实粉，可以独立设计游戏服务器后台，我对这样的挑战期待已久。\n\n#### 逻辑架构图\n{% img /images/2013/08/minigame.png %}\n\n主要由三大逻辑层组成：\n+ 连接（接入）服务器模块:   ConnServer\n+ 游戏服务器模块 ：        GameServer\n+ 缓存服务器模块：         CacheServer\n  (附：我们自己编写了静态资源的服务器功能，提供给用户下载Apk的功能)\n\n* 接入服务器模块\n服务器Socket建立，建立玩家通讯连接，为每一位连上服务器的玩家建立一个线程。\n服务器维护一个连接列表。采用map 的方式记录每一位玩家的连接信息。\n\n* 游戏服务器模块：\n    这是处理游戏业务逻辑的主要模块。它包括了消息包解析器服务（Parser），游戏大厅服务（GameRoom），账户体系服务（Account）,消息中心服务（MsgCenter）,心跳服务（Heartbeat）.日志功能模块（log）\n\n+ 消息包解析器服务（Parser）:主要实现了消息状态机。解析收到的客户端的数据包的协议号，然后将消息路由到不同功能模块去处理。\n+ 账户体系服务（Account）：提供用户注册和登陆管理的模块\n+ 游戏大厅服务（GameRoom）：采用Redis 内存数据库，构造消息队列。模拟游戏大厅，并对玩家进行配对筛选，构造set类型的匹配对完成1对1 的对战模式\n+ 消息中心服务（MsgCenter）:完成游戏过程中玩家信息的交互。\n+ 心跳服务（Heartbeat）：这是一个相对独立的进程，每7秒遍历用户信息，完成心跳检测，清理无效的过期数据，保持游戏数据的一致性.\n+ 日志功能：打印程序中的日志。\n+ 静态资源下载器（downloader）：采用tornado拓展编写web服务，提供Apk静态资源下载的模块\n\n* 缓存服务器模块\n    现阶段游戏对服务的要求不需要做到持久化的保存，于是服务器没有采用mysql之类的范式数据库。我们的数据收发一直处于频繁状态，于是我们采用了Redis这种分布式的内存数据库来实现我们的数据缓存模块，后续会介绍数据的键值设计\n\n#### 类图\n{% img /images/2013/08/class.png %}\n\n* cache数据库的设计：\n利用Redis的数据特性,新增一个用户保证用户ID的原子性。\n+ counter: 对新用户的注册执行自增操作，从而保证账号Id 唯一\n\n```\n说明 key value\n实例 counter 1\n```\n\n* 用户账号：\nKey设计为 user：name:用户名’，Value用户ID，\n为保证用户可以同时通过id 查找名字 ，也设计了 ‘user:id:ID值’值为用户名\n\n```\n说明 key                    value\n实例 User:name:zhengji         1\n实例 User:id:1                 zhengji\n```\n\n* 玩家通讯缓存设计：\nKey值：user:用户名：msg: Value:‘分数，buff_id,时间戳’\n\n```\n说明 key              value\n实例 user:zhengji:msg 100, 2,   1324256778.89\n```\n\n* 玩家匹配对设计\n在游戏大厅的功能里，我们采用了redis的list模拟了玩家等待队列的功能 在真正匹配到玩家对的时候，使用table_xx 来记录玩家匹配信息,它是一个set的类型,在游戏退出的时候会被驱动去清除该表的信息\n\n```\n说明   key      value\n实例 Table_1 ‘jerry,zhengji’\n```\n       \n为标志每个玩家的table号，我们使用了另外一个键值对\nTable:玩家名：tableindex.\n\n```\n说明   key       value\n实例 Table:zhengji 1\n```\n\n","source":"_posts/2013-08-20-minigame-fu-wu-duan-she-ji.markdown","raw":"---\nlayout: post\ntitle: \"MiniGame 服务端设计\"\ndate: 2013-08-20 18:54\ncomments: true\ncategories: Server\n---\n\n  最近和小伙伴们在做一个游戏。有机会单挑服务端了。被信任是有压力也有动力 ：），可以尝试各种好玩的技术的感觉是很爽。Jerry 和Cat 所主导的客户端，Mzt的美术都很给力。作为云风的忠实粉，可以独立设计游戏服务器后台，我对这样的挑战期待已久。\n\n#### 逻辑架构图\n{% img /images/2013/08/minigame.png %}\n\n主要由三大逻辑层组成：\n+ 连接（接入）服务器模块:   ConnServer\n+ 游戏服务器模块 ：        GameServer\n+ 缓存服务器模块：         CacheServer\n  (附：我们自己编写了静态资源的服务器功能，提供给用户下载Apk的功能)\n\n* 接入服务器模块\n服务器Socket建立，建立玩家通讯连接，为每一位连上服务器的玩家建立一个线程。\n服务器维护一个连接列表。采用map 的方式记录每一位玩家的连接信息。\n\n* 游戏服务器模块：\n    这是处理游戏业务逻辑的主要模块。它包括了消息包解析器服务（Parser），游戏大厅服务（GameRoom），账户体系服务（Account）,消息中心服务（MsgCenter）,心跳服务（Heartbeat）.日志功能模块（log）\n\n+ 消息包解析器服务（Parser）:主要实现了消息状态机。解析收到的客户端的数据包的协议号，然后将消息路由到不同功能模块去处理。\n+ 账户体系服务（Account）：提供用户注册和登陆管理的模块\n+ 游戏大厅服务（GameRoom）：采用Redis 内存数据库，构造消息队列。模拟游戏大厅，并对玩家进行配对筛选，构造set类型的匹配对完成1对1 的对战模式\n+ 消息中心服务（MsgCenter）:完成游戏过程中玩家信息的交互。\n+ 心跳服务（Heartbeat）：这是一个相对独立的进程，每7秒遍历用户信息，完成心跳检测，清理无效的过期数据，保持游戏数据的一致性.\n+ 日志功能：打印程序中的日志。\n+ 静态资源下载器（downloader）：采用tornado拓展编写web服务，提供Apk静态资源下载的模块\n\n* 缓存服务器模块\n    现阶段游戏对服务的要求不需要做到持久化的保存，于是服务器没有采用mysql之类的范式数据库。我们的数据收发一直处于频繁状态，于是我们采用了Redis这种分布式的内存数据库来实现我们的数据缓存模块，后续会介绍数据的键值设计\n\n#### 类图\n{% img /images/2013/08/class.png %}\n\n* cache数据库的设计：\n利用Redis的数据特性,新增一个用户保证用户ID的原子性。\n+ counter: 对新用户的注册执行自增操作，从而保证账号Id 唯一\n\n```\n说明 key value\n实例 counter 1\n```\n\n* 用户账号：\nKey设计为 user：name:用户名’，Value用户ID，\n为保证用户可以同时通过id 查找名字 ，也设计了 ‘user:id:ID值’值为用户名\n\n```\n说明 key                    value\n实例 User:name:zhengji         1\n实例 User:id:1                 zhengji\n```\n\n* 玩家通讯缓存设计：\nKey值：user:用户名：msg: Value:‘分数，buff_id,时间戳’\n\n```\n说明 key              value\n实例 user:zhengji:msg 100, 2,   1324256778.89\n```\n\n* 玩家匹配对设计\n在游戏大厅的功能里，我们采用了redis的list模拟了玩家等待队列的功能 在真正匹配到玩家对的时候，使用table_xx 来记录玩家匹配信息,它是一个set的类型,在游戏退出的时候会被驱动去清除该表的信息\n\n```\n说明   key      value\n实例 Table_1 ‘jerry,zhengji’\n```\n       \n为标志每个玩家的table号，我们使用了另外一个键值对\nTable:玩家名：tableindex.\n\n```\n说明   key       value\n实例 Table:zhengji 1\n```\n\n","slug":"2013-08-20-minigame-fu-wu-duan-she-ji","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd7w0003nctjtaye4kcx","content":"<p>  最近和小伙伴们在做一个游戏。有机会单挑服务端了。被信任是有压力也有动力 ：），可以尝试各种好玩的技术的感觉是很爽。Jerry 和Cat 所主导的客户端，Mzt的美术都很给力。作为云风的忠实粉，可以独立设计游戏服务器后台，我对这样的挑战期待已久。</p>\n<h4 id=\"逻辑架构图\"><a href=\"#逻辑架构图\" class=\"headerlink\" title=\"逻辑架构图\"></a>逻辑架构图</h4><img src=\"/images/2013/08/minigame.png\">\n<p>主要由三大逻辑层组成：</p>\n<ul>\n<li>连接（接入）服务器模块:   ConnServer</li>\n<li>游戏服务器模块 ：        GameServer</li>\n<li>缓存服务器模块：         CacheServer<br>(附：我们自己编写了静态资源的服务器功能，提供给用户下载Apk的功能)</li>\n</ul>\n<ul>\n<li><p>接入服务器模块<br>服务器Socket建立，建立玩家通讯连接，为每一位连上服务器的玩家建立一个线程。<br>服务器维护一个连接列表。采用map 的方式记录每一位玩家的连接信息。</p>\n</li>\n<li><p>游戏服务器模块：<br>  这是处理游戏业务逻辑的主要模块。它包括了消息包解析器服务（Parser），游戏大厅服务（GameRoom），账户体系服务（Account）,消息中心服务（MsgCenter）,心跳服务（Heartbeat）.日志功能模块（log）</p>\n</li>\n</ul>\n<ul>\n<li>消息包解析器服务（Parser）:主要实现了消息状态机。解析收到的客户端的数据包的协议号，然后将消息路由到不同功能模块去处理。</li>\n<li>账户体系服务（Account）：提供用户注册和登陆管理的模块</li>\n<li>游戏大厅服务（GameRoom）：采用Redis 内存数据库，构造消息队列。模拟游戏大厅，并对玩家进行配对筛选，构造set类型的匹配对完成1对1 的对战模式</li>\n<li>消息中心服务（MsgCenter）:完成游戏过程中玩家信息的交互。</li>\n<li>心跳服务（Heartbeat）：这是一个相对独立的进程，每7秒遍历用户信息，完成心跳检测，清理无效的过期数据，保持游戏数据的一致性.</li>\n<li>日志功能：打印程序中的日志。</li>\n<li>静态资源下载器（downloader）：采用tornado拓展编写web服务，提供Apk静态资源下载的模块</li>\n</ul>\n<ul>\n<li>缓存服务器模块<br>  现阶段游戏对服务的要求不需要做到持久化的保存，于是服务器没有采用mysql之类的范式数据库。我们的数据收发一直处于频繁状态，于是我们采用了Redis这种分布式的内存数据库来实现我们的数据缓存模块，后续会介绍数据的键值设计</li>\n</ul>\n<h4 id=\"类图\"><a href=\"#类图\" class=\"headerlink\" title=\"类图\"></a>类图</h4><img src=\"/images/2013/08/class.png\">\n<ul>\n<li>cache数据库的设计：<br>利用Redis的数据特性,新增一个用户保证用户ID的原子性。</li>\n</ul>\n<ul>\n<li>counter: 对新用户的注册执行自增操作，从而保证账号Id 唯一</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明 key value</span><br><span class=\"line\">实例 counter 1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>用户账号：<br>Key设计为 user：name:用户名’，Value用户ID，<br>为保证用户可以同时通过id 查找名字 ，也设计了 ‘user:id:ID值’值为用户名</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明 key                    value</span><br><span class=\"line\">实例 User:name:zhengji         1</span><br><span class=\"line\">实例 User:id:1                 zhengji</span><br></pre></td></tr></table></figure>\n<ul>\n<li>玩家通讯缓存设计：<br>Key值：user:用户名：msg: Value:‘分数，buff_id,时间戳’</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明 key              value</span><br><span class=\"line\">实例 user:zhengji:msg 100, 2,   1324256778.89</span><br></pre></td></tr></table></figure>\n<ul>\n<li>玩家匹配对设计<br>在游戏大厅的功能里，我们采用了redis的list模拟了玩家等待队列的功能 在真正匹配到玩家对的时候，使用table_xx 来记录玩家匹配信息,它是一个set的类型,在游戏退出的时候会被驱动去清除该表的信息</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明   key      value</span><br><span class=\"line\">实例 Table_1 ‘jerry,zhengji’</span><br></pre></td></tr></table></figure>\n<p>为标志每个玩家的table号，我们使用了另外一个键值对<br>Table:玩家名：tableindex.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明   key       value</span><br><span class=\"line\">实例 Table:zhengji 1</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>  最近和小伙伴们在做一个游戏。有机会单挑服务端了。被信任是有压力也有动力 ：），可以尝试各种好玩的技术的感觉是很爽。Jerry 和Cat 所主导的客户端，Mzt的美术都很给力。作为云风的忠实粉，可以独立设计游戏服务器后台，我对这样的挑战期待已久。</p>\n<h4 id=\"逻辑架构图\"><a href=\"#逻辑架构图\" class=\"headerlink\" title=\"逻辑架构图\"></a>逻辑架构图</h4><img src=\"/images/2013/08/minigame.png\">\n<p>主要由三大逻辑层组成：</p>\n<ul>\n<li>连接（接入）服务器模块:   ConnServer</li>\n<li>游戏服务器模块 ：        GameServer</li>\n<li>缓存服务器模块：         CacheServer<br>(附：我们自己编写了静态资源的服务器功能，提供给用户下载Apk的功能)</li>\n</ul>\n<ul>\n<li><p>接入服务器模块<br>服务器Socket建立，建立玩家通讯连接，为每一位连上服务器的玩家建立一个线程。<br>服务器维护一个连接列表。采用map 的方式记录每一位玩家的连接信息。</p>\n</li>\n<li><p>游戏服务器模块：<br>  这是处理游戏业务逻辑的主要模块。它包括了消息包解析器服务（Parser），游戏大厅服务（GameRoom），账户体系服务（Account）,消息中心服务（MsgCenter）,心跳服务（Heartbeat）.日志功能模块（log）</p>\n</li>\n</ul>\n<ul>\n<li>消息包解析器服务（Parser）:主要实现了消息状态机。解析收到的客户端的数据包的协议号，然后将消息路由到不同功能模块去处理。</li>\n<li>账户体系服务（Account）：提供用户注册和登陆管理的模块</li>\n<li>游戏大厅服务（GameRoom）：采用Redis 内存数据库，构造消息队列。模拟游戏大厅，并对玩家进行配对筛选，构造set类型的匹配对完成1对1 的对战模式</li>\n<li>消息中心服务（MsgCenter）:完成游戏过程中玩家信息的交互。</li>\n<li>心跳服务（Heartbeat）：这是一个相对独立的进程，每7秒遍历用户信息，完成心跳检测，清理无效的过期数据，保持游戏数据的一致性.</li>\n<li>日志功能：打印程序中的日志。</li>\n<li>静态资源下载器（downloader）：采用tornado拓展编写web服务，提供Apk静态资源下载的模块</li>\n</ul>\n<ul>\n<li>缓存服务器模块<br>  现阶段游戏对服务的要求不需要做到持久化的保存，于是服务器没有采用mysql之类的范式数据库。我们的数据收发一直处于频繁状态，于是我们采用了Redis这种分布式的内存数据库来实现我们的数据缓存模块，后续会介绍数据的键值设计</li>\n</ul>\n<h4 id=\"类图\"><a href=\"#类图\" class=\"headerlink\" title=\"类图\"></a>类图</h4><img src=\"/images/2013/08/class.png\">\n<ul>\n<li>cache数据库的设计：<br>利用Redis的数据特性,新增一个用户保证用户ID的原子性。</li>\n</ul>\n<ul>\n<li>counter: 对新用户的注册执行自增操作，从而保证账号Id 唯一</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明 key value</span><br><span class=\"line\">实例 counter 1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>用户账号：<br>Key设计为 user：name:用户名’，Value用户ID，<br>为保证用户可以同时通过id 查找名字 ，也设计了 ‘user:id:ID值’值为用户名</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明 key                    value</span><br><span class=\"line\">实例 User:name:zhengji         1</span><br><span class=\"line\">实例 User:id:1                 zhengji</span><br></pre></td></tr></table></figure>\n<ul>\n<li>玩家通讯缓存设计：<br>Key值：user:用户名：msg: Value:‘分数，buff_id,时间戳’</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明 key              value</span><br><span class=\"line\">实例 user:zhengji:msg 100, 2,   1324256778.89</span><br></pre></td></tr></table></figure>\n<ul>\n<li>玩家匹配对设计<br>在游戏大厅的功能里，我们采用了redis的list模拟了玩家等待队列的功能 在真正匹配到玩家对的时候，使用table_xx 来记录玩家匹配信息,它是一个set的类型,在游戏退出的时候会被驱动去清除该表的信息</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明   key      value</span><br><span class=\"line\">实例 Table_1 ‘jerry,zhengji’</span><br></pre></td></tr></table></figure>\n<p>为标志每个玩家的table号，我们使用了另外一个键值对<br>Table:玩家名：tableindex.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">说明   key       value</span><br><span class=\"line\">实例 Table:zhengji 1</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"叫神马荣誉出品–豆芽换书","date":"2012-07-11T16:22:00.000Z","comments":1,"_content":"\n**叫神马团队**在一起的最后一个作品-**《豆芽换书》**,这是我大学最后一次以leader的身份完成了团队最后的作品，而我在这其中也独立负责后台开发的功能.\n 值得纪念\n\n简介：\n>豆瓣第三方软件，基于豆瓣API开发的LBS 与 SNS的换书软件，让你的闲书不再闲，让你从此交友多了一个理由，支持百度地图定位，聊天私信功能，豆瓣书籍分享。\n\n{% img /images/2013/douya/ICON.jpg %}\n\n{% img /images/2013/douya/welcome.jpg %}\n\n{% img /images/2013/douya/main.jpg %}\n\n{% img /images/2013/douya/around.jpg %}\n\n{% img /images/2013/douya/share.jpg %}\n\n{% img /images/2013/douya/myshare.jpg %}\n\n{% img /images/2013/douya/collect.jpg %}\n\n{% img /images/2013/douya/review.jpg %}\n\n{% img /images/2013/douya/description.jpg %}\n\n{% img /images/2013/douya/friend.jpg %}\n\n{% img /images/2013/douya/chat.jpg %}\n\n{% img /images/2013/douya/settiing.jpg %}\n\n叫神马团队的简介在该软件“关于我们有介绍”~关心我们的同学可以下载使用的同时点击详情\n\n\n\n","source":"_posts/2013-08-26-jiao-shen-ma-rong-yu-chu-pin-dou-ya-huan-shu.markdown","raw":"---\nlayout: post\ntitle: \"叫神马荣誉出品–豆芽换书\"\ndate: 2012-07-12 00:22\ncomments: true\ncategories: Product\n---\n\n**叫神马团队**在一起的最后一个作品-**《豆芽换书》**,这是我大学最后一次以leader的身份完成了团队最后的作品，而我在这其中也独立负责后台开发的功能.\n 值得纪念\n\n简介：\n>豆瓣第三方软件，基于豆瓣API开发的LBS 与 SNS的换书软件，让你的闲书不再闲，让你从此交友多了一个理由，支持百度地图定位，聊天私信功能，豆瓣书籍分享。\n\n{% img /images/2013/douya/ICON.jpg %}\n\n{% img /images/2013/douya/welcome.jpg %}\n\n{% img /images/2013/douya/main.jpg %}\n\n{% img /images/2013/douya/around.jpg %}\n\n{% img /images/2013/douya/share.jpg %}\n\n{% img /images/2013/douya/myshare.jpg %}\n\n{% img /images/2013/douya/collect.jpg %}\n\n{% img /images/2013/douya/review.jpg %}\n\n{% img /images/2013/douya/description.jpg %}\n\n{% img /images/2013/douya/friend.jpg %}\n\n{% img /images/2013/douya/chat.jpg %}\n\n{% img /images/2013/douya/settiing.jpg %}\n\n叫神马团队的简介在该软件“关于我们有介绍”~关心我们的同学可以下载使用的同时点击详情\n\n\n\n","slug":"2013-08-26-jiao-shen-ma-rong-yu-chu-pin-dou-ya-huan-shu","published":1,"updated":"2018-06-17T10:39:11.000Z","photos":[],"link":"","_id":"cjijzgd7z0005nctjo6ou3n9e","content":"<p><strong>叫神马团队</strong>在一起的最后一个作品-<strong>《豆芽换书》</strong>,这是我大学最后一次以leader的身份完成了团队最后的作品，而我在这其中也独立负责后台开发的功能.<br> 值得纪念</p>\n<p>简介：</p>\n<blockquote>\n<p>豆瓣第三方软件，基于豆瓣API开发的LBS 与 SNS的换书软件，让你的闲书不再闲，让你从此交友多了一个理由，支持百度地图定位，聊天私信功能，豆瓣书籍分享。</p>\n</blockquote>\n<img src=\"/images/2013/douya/ICON.jpg\">\n<img src=\"/images/2013/douya/welcome.jpg\">\n<img src=\"/images/2013/douya/main.jpg\">\n<img src=\"/images/2013/douya/around.jpg\">\n<img src=\"/images/2013/douya/share.jpg\">\n<img src=\"/images/2013/douya/myshare.jpg\">\n<img src=\"/images/2013/douya/collect.jpg\">\n<img src=\"/images/2013/douya/review.jpg\">\n<img src=\"/images/2013/douya/description.jpg\">\n<img src=\"/images/2013/douya/friend.jpg\">\n<img src=\"/images/2013/douya/chat.jpg\">\n<img src=\"/images/2013/douya/settiing.jpg\">\n<p>叫神马团队的简介在该软件“关于我们有介绍”~关心我们的同学可以下载使用的同时点击详情</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>叫神马团队</strong>在一起的最后一个作品-<strong>《豆芽换书》</strong>,这是我大学最后一次以leader的身份完成了团队最后的作品，而我在这其中也独立负责后台开发的功能.<br> 值得纪念</p>\n<p>简介：</p>\n<blockquote>\n<p>豆瓣第三方软件，基于豆瓣API开发的LBS 与 SNS的换书软件，让你的闲书不再闲，让你从此交友多了一个理由，支持百度地图定位，聊天私信功能，豆瓣书籍分享。</p>\n</blockquote>\n<img src=\"/images/2013/douya/ICON.jpg\">\n<img src=\"/images/2013/douya/welcome.jpg\">\n<img src=\"/images/2013/douya/main.jpg\">\n<img src=\"/images/2013/douya/around.jpg\">\n<img src=\"/images/2013/douya/share.jpg\">\n<img src=\"/images/2013/douya/myshare.jpg\">\n<img src=\"/images/2013/douya/collect.jpg\">\n<img src=\"/images/2013/douya/review.jpg\">\n<img src=\"/images/2013/douya/description.jpg\">\n<img src=\"/images/2013/douya/friend.jpg\">\n<img src=\"/images/2013/douya/chat.jpg\">\n<img src=\"/images/2013/douya/settiing.jpg\">\n<p>叫神马团队的简介在该软件“关于我们有介绍”~关心我们的同学可以下载使用的同时点击详情</p>\n"},{"layout":"post","title":"思考与分享使价值升华","date":"2012-11-27T16:45:00.000Z","comments":1,"_content":"一个月匆匆过去了，还没来得及叹口气，又被生活推着向前走，耐不住很多思绪与感悟。抽空看看我冷清的博客，恍然间我已经4个月没上来过了，便有了个理由写篇东西算是为博客增点暖气。\n\n这个月经常想起kant，也就是知乎上那位风云人物，这个和我在腾讯大楼里认识的人。不知为何会记起这位大神，但有点能肯定的是，在他身上看到了我想追求的东西（独立人格，思考的魅力），有些人很奇妙，短短的交流便能让你找到了目标.比如 @ruitao,@jiahui。他们都是The gift of god：）\n\n这个月的技术关键词 **“Mongodb,Redis,Go,Zmq,Python,Tonardo” “数值计算，性能调优”**，如此云云，是不是看来很唬人呢，当我看到一个庞大的软件而且都是陌生的技术在我眼前浮现的时候，彷如在建筑“长城”，内心赞叹之余感慨万千。等到我也拾起键盘，开始构建代码的时候，也慢慢能理解到其实并不可怕。这是个过程，当你投入时间和毅力，总能给你答案，要坚信。这中间我是在不断地在提醒自己，还有很多缺点一直存在，始终没有改好（3年前我已经意识到自己急躁的心理是个大难题），不过面对真实自己的勇气我还是有的。于是也准备做好与之长时间抗战了，是不是以后也有本书叫做《与自己的缺点为友》呢？\n\n技术的学习要保持一直的理性分析真的是不易，现阶段的我是人云亦云的墙头草。听说不懂的名词就容易陷入盲目崇拜。年岁有加，知道真正核心的东西是思维方式与经验积累，这两者是水和鱼的关系。所以必须开拓视野，多积累经验。如何将知识转化为自己的东西？那就是思维方式的训练了。积极正面的思考，这对于感性思维多一点的人，如我，更是需要多点刻意的维持。奇怪的是，即便有点难熬，我还是很享受这样战胜自己的感受。那天在大巴上和chandy有不少共鸣，其中有一点便是，人的对手只有自己，你能说不是么。或许我就是一纠结狂吧：）\n\n旁边的偶像的桌上有一坨坨书。阅读便是一件很重要的事情了。人需要血液循环来新陈代谢。读书就是必不可少的事情。并不是为了追求腹有诗书气自华的装逼，只求随着知识的增长，实现上述所言的思维方式与经验的累积，thanks to ruitao 借的书和推荐的博客。《coders at work》是我最近阅读的一本采访15位伟大软件先驱的人生经历。我需要更多的阅读来broaden my horizion。以前觉得会写作的人没什么，现在突然意识到如果能把你的东西转述成逻辑分明的文章让人意会，这是一种境界，所以我也很佩服韩寒。博客的作用也在这个时候起了正能量的作用。\n\n 人们总是在拼命追求得不到的东西，当我不会某些技术的时候，便羡慕掌握这些知识，每个时期的感悟也有所不同，就像我一直记得好友说过的话，不要为了技术而技术。对于回忆，总有后知后觉，比如偶然有一天我配置属于自己的vim插件的时候，慢慢能体会别人的话了，是必须承认自己的愚笨。当然这样的例子还有很多，哈哈，我有这样一位值得骄傲的朋友@jiahui。大学将近尾声。多点机会聚聚才行。\n\n 有时候会陷入过度优化的噩梦。该如何取舍就是经验了。透过现象看本质的是多么睿智一件事。喜欢丁香园博主，便是这个原因。慢慢觉得无论身在哪里，规終到底还是需要你能解决问题。这个过程需要足够强大的内心，对于这一天，我一直在路上，虽说走的有点慢。耐心也是一种美德，嗯，it must be!\n\n 在写完程序工作的时候，我总能看到互联网上那些知名博客的分析。觉得不能一直成日埋头写代码。哪怕现阶段是追求技术，积累的阶段，生活也一样，是多线程的，也要多关注行业动态装逼的说是产品思考，不要限制自己的可能。如果有能力写些有思考性的东西，与别人分享,这样一来创造学习的机会，二来让思考升华。总而言之，只要想学习，一直都有方法。\n\n 对于选择，我想时候到了我会再次拾起破烂的笔头。好好叙述我的经历，无论周遭怎样，希望大家都慢慢变好：）\n\n 末了，终于记起为什么老是想起kant了,因为他的一句话，“思考与分享，你的价值在升华”。于是也有了这日志的诞生。\n","source":"_posts/2013-08-26-si-kao-yu-fen-xiang-shi-jie-zhi-sheng-hua.markdown","raw":"---\nlayout: post\ntitle: \"思考与分享使价值升华\"\ndate: 2012-11-28 00:45\ncomments: true\ncategories: Life\n---\n一个月匆匆过去了，还没来得及叹口气，又被生活推着向前走，耐不住很多思绪与感悟。抽空看看我冷清的博客，恍然间我已经4个月没上来过了，便有了个理由写篇东西算是为博客增点暖气。\n\n这个月经常想起kant，也就是知乎上那位风云人物，这个和我在腾讯大楼里认识的人。不知为何会记起这位大神，但有点能肯定的是，在他身上看到了我想追求的东西（独立人格，思考的魅力），有些人很奇妙，短短的交流便能让你找到了目标.比如 @ruitao,@jiahui。他们都是The gift of god：）\n\n这个月的技术关键词 **“Mongodb,Redis,Go,Zmq,Python,Tonardo” “数值计算，性能调优”**，如此云云，是不是看来很唬人呢，当我看到一个庞大的软件而且都是陌生的技术在我眼前浮现的时候，彷如在建筑“长城”，内心赞叹之余感慨万千。等到我也拾起键盘，开始构建代码的时候，也慢慢能理解到其实并不可怕。这是个过程，当你投入时间和毅力，总能给你答案，要坚信。这中间我是在不断地在提醒自己，还有很多缺点一直存在，始终没有改好（3年前我已经意识到自己急躁的心理是个大难题），不过面对真实自己的勇气我还是有的。于是也准备做好与之长时间抗战了，是不是以后也有本书叫做《与自己的缺点为友》呢？\n\n技术的学习要保持一直的理性分析真的是不易，现阶段的我是人云亦云的墙头草。听说不懂的名词就容易陷入盲目崇拜。年岁有加，知道真正核心的东西是思维方式与经验积累，这两者是水和鱼的关系。所以必须开拓视野，多积累经验。如何将知识转化为自己的东西？那就是思维方式的训练了。积极正面的思考，这对于感性思维多一点的人，如我，更是需要多点刻意的维持。奇怪的是，即便有点难熬，我还是很享受这样战胜自己的感受。那天在大巴上和chandy有不少共鸣，其中有一点便是，人的对手只有自己，你能说不是么。或许我就是一纠结狂吧：）\n\n旁边的偶像的桌上有一坨坨书。阅读便是一件很重要的事情了。人需要血液循环来新陈代谢。读书就是必不可少的事情。并不是为了追求腹有诗书气自华的装逼，只求随着知识的增长，实现上述所言的思维方式与经验的累积，thanks to ruitao 借的书和推荐的博客。《coders at work》是我最近阅读的一本采访15位伟大软件先驱的人生经历。我需要更多的阅读来broaden my horizion。以前觉得会写作的人没什么，现在突然意识到如果能把你的东西转述成逻辑分明的文章让人意会，这是一种境界，所以我也很佩服韩寒。博客的作用也在这个时候起了正能量的作用。\n\n 人们总是在拼命追求得不到的东西，当我不会某些技术的时候，便羡慕掌握这些知识，每个时期的感悟也有所不同，就像我一直记得好友说过的话，不要为了技术而技术。对于回忆，总有后知后觉，比如偶然有一天我配置属于自己的vim插件的时候，慢慢能体会别人的话了，是必须承认自己的愚笨。当然这样的例子还有很多，哈哈，我有这样一位值得骄傲的朋友@jiahui。大学将近尾声。多点机会聚聚才行。\n\n 有时候会陷入过度优化的噩梦。该如何取舍就是经验了。透过现象看本质的是多么睿智一件事。喜欢丁香园博主，便是这个原因。慢慢觉得无论身在哪里，规終到底还是需要你能解决问题。这个过程需要足够强大的内心，对于这一天，我一直在路上，虽说走的有点慢。耐心也是一种美德，嗯，it must be!\n\n 在写完程序工作的时候，我总能看到互联网上那些知名博客的分析。觉得不能一直成日埋头写代码。哪怕现阶段是追求技术，积累的阶段，生活也一样，是多线程的，也要多关注行业动态装逼的说是产品思考，不要限制自己的可能。如果有能力写些有思考性的东西，与别人分享,这样一来创造学习的机会，二来让思考升华。总而言之，只要想学习，一直都有方法。\n\n 对于选择，我想时候到了我会再次拾起破烂的笔头。好好叙述我的经历，无论周遭怎样，希望大家都慢慢变好：）\n\n 末了，终于记起为什么老是想起kant了,因为他的一句话，“思考与分享，你的价值在升华”。于是也有了这日志的诞生。\n","slug":"2013-08-26-si-kao-yu-fen-xiang-shi-jie-zhi-sheng-hua","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd810006nctjsh3nm26t","content":"<p>一个月匆匆过去了，还没来得及叹口气，又被生活推着向前走，耐不住很多思绪与感悟。抽空看看我冷清的博客，恍然间我已经4个月没上来过了，便有了个理由写篇东西算是为博客增点暖气。</p>\n<p>这个月经常想起kant，也就是知乎上那位风云人物，这个和我在腾讯大楼里认识的人。不知为何会记起这位大神，但有点能肯定的是，在他身上看到了我想追求的东西（独立人格，思考的魅力），有些人很奇妙，短短的交流便能让你找到了目标.比如 @ruitao,@jiahui。他们都是The gift of god：）</p>\n<p>这个月的技术关键词 <strong>“Mongodb,Redis,Go,Zmq,Python,Tonardo” “数值计算，性能调优”</strong>，如此云云，是不是看来很唬人呢，当我看到一个庞大的软件而且都是陌生的技术在我眼前浮现的时候，彷如在建筑“长城”，内心赞叹之余感慨万千。等到我也拾起键盘，开始构建代码的时候，也慢慢能理解到其实并不可怕。这是个过程，当你投入时间和毅力，总能给你答案，要坚信。这中间我是在不断地在提醒自己，还有很多缺点一直存在，始终没有改好（3年前我已经意识到自己急躁的心理是个大难题），不过面对真实自己的勇气我还是有的。于是也准备做好与之长时间抗战了，是不是以后也有本书叫做《与自己的缺点为友》呢？</p>\n<p>技术的学习要保持一直的理性分析真的是不易，现阶段的我是人云亦云的墙头草。听说不懂的名词就容易陷入盲目崇拜。年岁有加，知道真正核心的东西是思维方式与经验积累，这两者是水和鱼的关系。所以必须开拓视野，多积累经验。如何将知识转化为自己的东西？那就是思维方式的训练了。积极正面的思考，这对于感性思维多一点的人，如我，更是需要多点刻意的维持。奇怪的是，即便有点难熬，我还是很享受这样战胜自己的感受。那天在大巴上和chandy有不少共鸣，其中有一点便是，人的对手只有自己，你能说不是么。或许我就是一纠结狂吧：）</p>\n<p>旁边的偶像的桌上有一坨坨书。阅读便是一件很重要的事情了。人需要血液循环来新陈代谢。读书就是必不可少的事情。并不是为了追求腹有诗书气自华的装逼，只求随着知识的增长，实现上述所言的思维方式与经验的累积，thanks to ruitao 借的书和推荐的博客。《coders at work》是我最近阅读的一本采访15位伟大软件先驱的人生经历。我需要更多的阅读来broaden my horizion。以前觉得会写作的人没什么，现在突然意识到如果能把你的东西转述成逻辑分明的文章让人意会，这是一种境界，所以我也很佩服韩寒。博客的作用也在这个时候起了正能量的作用。</p>\n<p> 人们总是在拼命追求得不到的东西，当我不会某些技术的时候，便羡慕掌握这些知识，每个时期的感悟也有所不同，就像我一直记得好友说过的话，不要为了技术而技术。对于回忆，总有后知后觉，比如偶然有一天我配置属于自己的vim插件的时候，慢慢能体会别人的话了，是必须承认自己的愚笨。当然这样的例子还有很多，哈哈，我有这样一位值得骄傲的朋友@jiahui。大学将近尾声。多点机会聚聚才行。</p>\n<p> 有时候会陷入过度优化的噩梦。该如何取舍就是经验了。透过现象看本质的是多么睿智一件事。喜欢丁香园博主，便是这个原因。慢慢觉得无论身在哪里，规終到底还是需要你能解决问题。这个过程需要足够强大的内心，对于这一天，我一直在路上，虽说走的有点慢。耐心也是一种美德，嗯，it must be!</p>\n<p> 在写完程序工作的时候，我总能看到互联网上那些知名博客的分析。觉得不能一直成日埋头写代码。哪怕现阶段是追求技术，积累的阶段，生活也一样，是多线程的，也要多关注行业动态装逼的说是产品思考，不要限制自己的可能。如果有能力写些有思考性的东西，与别人分享,这样一来创造学习的机会，二来让思考升华。总而言之，只要想学习，一直都有方法。</p>\n<p> 对于选择，我想时候到了我会再次拾起破烂的笔头。好好叙述我的经历，无论周遭怎样，希望大家都慢慢变好：）</p>\n<p> 末了，终于记起为什么老是想起kant了,因为他的一句话，“思考与分享，你的价值在升华”。于是也有了这日志的诞生。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>一个月匆匆过去了，还没来得及叹口气，又被生活推着向前走，耐不住很多思绪与感悟。抽空看看我冷清的博客，恍然间我已经4个月没上来过了，便有了个理由写篇东西算是为博客增点暖气。</p>\n<p>这个月经常想起kant，也就是知乎上那位风云人物，这个和我在腾讯大楼里认识的人。不知为何会记起这位大神，但有点能肯定的是，在他身上看到了我想追求的东西（独立人格，思考的魅力），有些人很奇妙，短短的交流便能让你找到了目标.比如 @ruitao,@jiahui。他们都是The gift of god：）</p>\n<p>这个月的技术关键词 <strong>“Mongodb,Redis,Go,Zmq,Python,Tonardo” “数值计算，性能调优”</strong>，如此云云，是不是看来很唬人呢，当我看到一个庞大的软件而且都是陌生的技术在我眼前浮现的时候，彷如在建筑“长城”，内心赞叹之余感慨万千。等到我也拾起键盘，开始构建代码的时候，也慢慢能理解到其实并不可怕。这是个过程，当你投入时间和毅力，总能给你答案，要坚信。这中间我是在不断地在提醒自己，还有很多缺点一直存在，始终没有改好（3年前我已经意识到自己急躁的心理是个大难题），不过面对真实自己的勇气我还是有的。于是也准备做好与之长时间抗战了，是不是以后也有本书叫做《与自己的缺点为友》呢？</p>\n<p>技术的学习要保持一直的理性分析真的是不易，现阶段的我是人云亦云的墙头草。听说不懂的名词就容易陷入盲目崇拜。年岁有加，知道真正核心的东西是思维方式与经验积累，这两者是水和鱼的关系。所以必须开拓视野，多积累经验。如何将知识转化为自己的东西？那就是思维方式的训练了。积极正面的思考，这对于感性思维多一点的人，如我，更是需要多点刻意的维持。奇怪的是，即便有点难熬，我还是很享受这样战胜自己的感受。那天在大巴上和chandy有不少共鸣，其中有一点便是，人的对手只有自己，你能说不是么。或许我就是一纠结狂吧：）</p>\n<p>旁边的偶像的桌上有一坨坨书。阅读便是一件很重要的事情了。人需要血液循环来新陈代谢。读书就是必不可少的事情。并不是为了追求腹有诗书气自华的装逼，只求随着知识的增长，实现上述所言的思维方式与经验的累积，thanks to ruitao 借的书和推荐的博客。《coders at work》是我最近阅读的一本采访15位伟大软件先驱的人生经历。我需要更多的阅读来broaden my horizion。以前觉得会写作的人没什么，现在突然意识到如果能把你的东西转述成逻辑分明的文章让人意会，这是一种境界，所以我也很佩服韩寒。博客的作用也在这个时候起了正能量的作用。</p>\n<p> 人们总是在拼命追求得不到的东西，当我不会某些技术的时候，便羡慕掌握这些知识，每个时期的感悟也有所不同，就像我一直记得好友说过的话，不要为了技术而技术。对于回忆，总有后知后觉，比如偶然有一天我配置属于自己的vim插件的时候，慢慢能体会别人的话了，是必须承认自己的愚笨。当然这样的例子还有很多，哈哈，我有这样一位值得骄傲的朋友@jiahui。大学将近尾声。多点机会聚聚才行。</p>\n<p> 有时候会陷入过度优化的噩梦。该如何取舍就是经验了。透过现象看本质的是多么睿智一件事。喜欢丁香园博主，便是这个原因。慢慢觉得无论身在哪里，规終到底还是需要你能解决问题。这个过程需要足够强大的内心，对于这一天，我一直在路上，虽说走的有点慢。耐心也是一种美德，嗯，it must be!</p>\n<p> 在写完程序工作的时候，我总能看到互联网上那些知名博客的分析。觉得不能一直成日埋头写代码。哪怕现阶段是追求技术，积累的阶段，生活也一样，是多线程的，也要多关注行业动态装逼的说是产品思考，不要限制自己的可能。如果有能力写些有思考性的东西，与别人分享,这样一来创造学习的机会，二来让思考升华。总而言之，只要想学习，一直都有方法。</p>\n<p> 对于选择，我想时候到了我会再次拾起破烂的笔头。好好叙述我的经历，无论周遭怎样，希望大家都慢慢变好：）</p>\n<p> 末了，终于记起为什么老是想起kant了,因为他的一句话，“思考与分享，你的价值在升华”。于是也有了这日志的诞生。</p>\n"},{"layout":"post","title":"服务器设计模型","date":"2012-03-17T12:37:00.000Z","comments":1,"_content":">服务端编程的挑战很美\nSocket编程的服务器模型类型:\n\n* 循环服务器模型\n* 并发服务器模型\n* IO复用服务器模型\n\n+  循环服务器模型:\n    使用循环方法去逐个处理客户端连接和请求\n\n+ 并发服务器的简单模型:\n使用进程处理客户端的连接和请求\n\n+ 并发服务器的TCP分类:\n\n使用了进程池或者线程池的进行客户端请求处理的框架和方法，并按照accept处理情况进行不同状态的划分\n*单客户端单进程，统一accept()\n*单客户端单进程，统一accept()\n*单客户端单线程，各线程独自accept(),使用互斥锁\n*并发服务模型使用IO复用:\n\n使用同一处理模块监视多个客户端链接并进行处理.在系统开始的时候，建立多个不同工作类型的处理单元，例如处理连接单元，处理业务单元等。在客户端来的时候，将客户端的连接放在一个状态池中，对所有客户端的连接状态在一个处理单元进行轮询处理，与前面并发服务器相比，客户端增加不会造成系统并行处理单元的增加，而处理能力与CPU和内存速度有直接关系\n\n上述所有模型都有Demo\n\n代码在 [GitHub 上](https://github.com/zheng-ji/Server-Model)\n","source":"_posts/2013-08-28-fu-wu-qi-she-ji-mo-xing.markdown","raw":"---\nlayout: post\ntitle: \"服务器设计模型\"\ndate: 2012-03-17 20:37\ncomments: true\ncategories: Server\n---\n>服务端编程的挑战很美\nSocket编程的服务器模型类型:\n\n* 循环服务器模型\n* 并发服务器模型\n* IO复用服务器模型\n\n+  循环服务器模型:\n    使用循环方法去逐个处理客户端连接和请求\n\n+ 并发服务器的简单模型:\n使用进程处理客户端的连接和请求\n\n+ 并发服务器的TCP分类:\n\n使用了进程池或者线程池的进行客户端请求处理的框架和方法，并按照accept处理情况进行不同状态的划分\n*单客户端单进程，统一accept()\n*单客户端单进程，统一accept()\n*单客户端单线程，各线程独自accept(),使用互斥锁\n*并发服务模型使用IO复用:\n\n使用同一处理模块监视多个客户端链接并进行处理.在系统开始的时候，建立多个不同工作类型的处理单元，例如处理连接单元，处理业务单元等。在客户端来的时候，将客户端的连接放在一个状态池中，对所有客户端的连接状态在一个处理单元进行轮询处理，与前面并发服务器相比，客户端增加不会造成系统并行处理单元的增加，而处理能力与CPU和内存速度有直接关系\n\n上述所有模型都有Demo\n\n代码在 [GitHub 上](https://github.com/zheng-ji/Server-Model)\n","slug":"2013-08-28-fu-wu-qi-she-ji-mo-xing","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd820007nctjn4ielrbb","content":"<blockquote>\n<p>服务端编程的挑战很美<br>Socket编程的服务器模型类型:</p>\n</blockquote>\n<ul>\n<li>循环服务器模型</li>\n<li>并发服务器模型</li>\n<li>IO复用服务器模型</li>\n</ul>\n<ul>\n<li><p>循环服务器模型:<br> 使用循环方法去逐个处理客户端连接和请求</p>\n</li>\n<li><p>并发服务器的简单模型:<br>使用进程处理客户端的连接和请求</p>\n</li>\n<li><p>并发服务器的TCP分类:</p>\n</li>\n</ul>\n<p>使用了进程池或者线程池的进行客户端请求处理的框架和方法，并按照accept处理情况进行不同状态的划分<br><em>单客户端单进程，统一accept()\n</em>单客户端单进程，统一accept()<br><em>单客户端单线程，各线程独自accept(),使用互斥锁\n</em>并发服务模型使用IO复用:</p>\n<p>使用同一处理模块监视多个客户端链接并进行处理.在系统开始的时候，建立多个不同工作类型的处理单元，例如处理连接单元，处理业务单元等。在客户端来的时候，将客户端的连接放在一个状态池中，对所有客户端的连接状态在一个处理单元进行轮询处理，与前面并发服务器相比，客户端增加不会造成系统并行处理单元的增加，而处理能力与CPU和内存速度有直接关系</p>\n<p>上述所有模型都有Demo</p>\n<p>代码在 <a href=\"https://github.com/zheng-ji/Server-Model\" target=\"_blank\" rel=\"noopener\">GitHub 上</a></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>服务端编程的挑战很美<br>Socket编程的服务器模型类型:</p>\n</blockquote>\n<ul>\n<li>循环服务器模型</li>\n<li>并发服务器模型</li>\n<li>IO复用服务器模型</li>\n</ul>\n<ul>\n<li><p>循环服务器模型:<br> 使用循环方法去逐个处理客户端连接和请求</p>\n</li>\n<li><p>并发服务器的简单模型:<br>使用进程处理客户端的连接和请求</p>\n</li>\n<li><p>并发服务器的TCP分类:</p>\n</li>\n</ul>\n<p>使用了进程池或者线程池的进行客户端请求处理的框架和方法，并按照accept处理情况进行不同状态的划分<br><em>单客户端单进程，统一accept()\n</em>单客户端单进程，统一accept()<br><em>单客户端单线程，各线程独自accept(),使用互斥锁\n</em>并发服务模型使用IO复用:</p>\n<p>使用同一处理模块监视多个客户端链接并进行处理.在系统开始的时候，建立多个不同工作类型的处理单元，例如处理连接单元，处理业务单元等。在客户端来的时候，将客户端的连接放在一个状态池中，对所有客户端的连接状态在一个处理单元进行轮询处理，与前面并发服务器相比，客户端增加不会造成系统并行处理单元的增加，而处理能力与CPU和内存速度有直接关系</p>\n<p>上述所有模型都有Demo</p>\n<p>代码在 <a href=\"https://github.com/zheng-ji/Server-Model\" target=\"_blank\" rel=\"noopener\">GitHub 上</a></p>\n"},{"layout":"post","title":"Nginx 模块开发","date":"2013-02-17T06:04:00.000Z","comments":1,"description":"nginx 模块开发","_content":"写这篇文章的时候，参考[链接](http://blog.codinglabs.org/articles/intro-of-nginx-module-development.html)，特此鸣谢\n\n#### 为何需要Ngnix 模块：\n\n>对于一些访问量特别大，业务逻辑也相对简单的Web调用来说，通过一个nginx module来实现是一种比较好的优化方法。实现一个nginx module实际上比较简单。（@TimYang）\n\n#### Nginx 配置结构了解\nNginx的配置文件是以block的形式组织的，一个block通常使用大括号“{}”表示。block分为几个层级，整个配置文件为main层级，这 是最大的层级；在main层级下可以有event、http等层级，而http中又会有server block，server block中可以包含location block\n\n#### Nginx模块工作原理概述\nNginx本身做的工作实际很少，当它接到一个HTTP请求时，它仅仅是通过查找配置文件将此次请求映射到一个location block，而此location中所配置的各个指令则会启动不同的模块去完成工作，因此模块可以看做Nginx真正的劳动工作者。通常一个 location中的指令会涉及一个handler模块和多个filter模块（当然，多个location可以复用同一个模块）。handler模块负 责处理请求，完成响应内容的生成，而filter模块对响应内容进行处理。因此Nginx模块开发分为handler开发和filter开发\n\n####展示一个简单的Nginx模块开发全过程\n我们开发一个叫echo的handler模块，这个模块功能非常简单，它接收“echo”指令，指令可指定一个字符串参数，模块会输出这个字符串作为HTTP响应。例如，做如下配置：\n\n```\nlocation /echo {\n    echo \"hello nginx\";\n}\n```\n\n首先我们需要一个结构用于存储从配置文件中读进来的相关指令参数，即模块配置信息结构。根据Nginx模块开发规则这个结构的命名规则为ngx_http_[module-name]_[main|srv|loc]_conf_t\n\n实现这个功能需要三步：\n+ 读入配置文件中echo指令及其参数；\n+ 进行HTTP包装（添加HTTP头等工作）；\n+ 将结果返回给客户端。\n\n#### Nginx模块的安装\nNginx不支持动态链接模块，所以安装模块需要将模块代码与Nginx源代码进行重新编译。安装模块的步骤如下：\n\n+ 编写模块config文件，这个文件需要放在和模块源代码文件放在同一目录下。文件内容如下：\n\n```\nngx_addon_name=模块完整名称\nHTTP_MODULES=”$HTTP_MODULES 模块完整名称”\nNGX_ADDON_SRCS=”$NGX_ADDON_SRCS $ngx_addon_dir/源代码文件名”\n```\n\n+ 进入Nginx源代码，使用下面命令编译安装\n\n```\n./configure --prefix=安装目录 --add-module=模块源代码文件目录\nmake\nmake install\n```\n\n这样就完成安装了，例如，我的源代码文件放在/home/zj/tmp/ngx/ngx_http_echo下，我的config文件为：\n\n```\nngx_addon_name=ngx_http_echo_module\nHTTP_MODULES=\"$HTTP_MODULES ngx_http_echo_module\"\nNGX_ADDON_SRCS=\"$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_echo_module.c\"\n```\n\n#### 编译安装命令为：\n\n```\n./configure --prefix=/usr/local/nginx --add-module=/home/zj/tmp/ngx/ngx_http_echo\nmake\nsudo make install\n```\n\n这样echo模块就被安装在我的Nginx上了，下面测试一下，修改配置文件，增加以下一项配置：\n\n```\nlocation /echo {\n    echo \"This is my first nginx module!!!\";\n}\n```\n\n然后用curl测试一下：\n\n```\ncurl -i http://localhost/echo\n```\n","source":"_posts/2013-08-28-nginxmo-kuai-kai-fa.markdown","raw":"---\nlayout: post\ntitle: \"Nginx 模块开发\"\ndate: 2013-02-17 14:04\ncomments: true\ncategories: Server\ndescription: nginx 模块开发\n---\n写这篇文章的时候，参考[链接](http://blog.codinglabs.org/articles/intro-of-nginx-module-development.html)，特此鸣谢\n\n#### 为何需要Ngnix 模块：\n\n>对于一些访问量特别大，业务逻辑也相对简单的Web调用来说，通过一个nginx module来实现是一种比较好的优化方法。实现一个nginx module实际上比较简单。（@TimYang）\n\n#### Nginx 配置结构了解\nNginx的配置文件是以block的形式组织的，一个block通常使用大括号“{}”表示。block分为几个层级，整个配置文件为main层级，这 是最大的层级；在main层级下可以有event、http等层级，而http中又会有server block，server block中可以包含location block\n\n#### Nginx模块工作原理概述\nNginx本身做的工作实际很少，当它接到一个HTTP请求时，它仅仅是通过查找配置文件将此次请求映射到一个location block，而此location中所配置的各个指令则会启动不同的模块去完成工作，因此模块可以看做Nginx真正的劳动工作者。通常一个 location中的指令会涉及一个handler模块和多个filter模块（当然，多个location可以复用同一个模块）。handler模块负 责处理请求，完成响应内容的生成，而filter模块对响应内容进行处理。因此Nginx模块开发分为handler开发和filter开发\n\n####展示一个简单的Nginx模块开发全过程\n我们开发一个叫echo的handler模块，这个模块功能非常简单，它接收“echo”指令，指令可指定一个字符串参数，模块会输出这个字符串作为HTTP响应。例如，做如下配置：\n\n```\nlocation /echo {\n    echo \"hello nginx\";\n}\n```\n\n首先我们需要一个结构用于存储从配置文件中读进来的相关指令参数，即模块配置信息结构。根据Nginx模块开发规则这个结构的命名规则为ngx_http_[module-name]_[main|srv|loc]_conf_t\n\n实现这个功能需要三步：\n+ 读入配置文件中echo指令及其参数；\n+ 进行HTTP包装（添加HTTP头等工作）；\n+ 将结果返回给客户端。\n\n#### Nginx模块的安装\nNginx不支持动态链接模块，所以安装模块需要将模块代码与Nginx源代码进行重新编译。安装模块的步骤如下：\n\n+ 编写模块config文件，这个文件需要放在和模块源代码文件放在同一目录下。文件内容如下：\n\n```\nngx_addon_name=模块完整名称\nHTTP_MODULES=”$HTTP_MODULES 模块完整名称”\nNGX_ADDON_SRCS=”$NGX_ADDON_SRCS $ngx_addon_dir/源代码文件名”\n```\n\n+ 进入Nginx源代码，使用下面命令编译安装\n\n```\n./configure --prefix=安装目录 --add-module=模块源代码文件目录\nmake\nmake install\n```\n\n这样就完成安装了，例如，我的源代码文件放在/home/zj/tmp/ngx/ngx_http_echo下，我的config文件为：\n\n```\nngx_addon_name=ngx_http_echo_module\nHTTP_MODULES=\"$HTTP_MODULES ngx_http_echo_module\"\nNGX_ADDON_SRCS=\"$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_echo_module.c\"\n```\n\n#### 编译安装命令为：\n\n```\n./configure --prefix=/usr/local/nginx --add-module=/home/zj/tmp/ngx/ngx_http_echo\nmake\nsudo make install\n```\n\n这样echo模块就被安装在我的Nginx上了，下面测试一下，修改配置文件，增加以下一项配置：\n\n```\nlocation /echo {\n    echo \"This is my first nginx module!!!\";\n}\n```\n\n然后用curl测试一下：\n\n```\ncurl -i http://localhost/echo\n```\n","slug":"2013-08-28-nginxmo-kuai-kai-fa","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd830009nctjl44xz8ui","content":"<p>写这篇文章的时候，参考<a href=\"http://blog.codinglabs.org/articles/intro-of-nginx-module-development.html\" target=\"_blank\" rel=\"noopener\">链接</a>，特此鸣谢</p>\n<h4 id=\"为何需要Ngnix-模块：\"><a href=\"#为何需要Ngnix-模块：\" class=\"headerlink\" title=\"为何需要Ngnix 模块：\"></a>为何需要Ngnix 模块：</h4><blockquote>\n<p>对于一些访问量特别大，业务逻辑也相对简单的Web调用来说，通过一个nginx module来实现是一种比较好的优化方法。实现一个nginx module实际上比较简单。（@TimYang）</p>\n</blockquote>\n<h4 id=\"Nginx-配置结构了解\"><a href=\"#Nginx-配置结构了解\" class=\"headerlink\" title=\"Nginx 配置结构了解\"></a>Nginx 配置结构了解</h4><p>Nginx的配置文件是以block的形式组织的，一个block通常使用大括号“{}”表示。block分为几个层级，整个配置文件为main层级，这 是最大的层级；在main层级下可以有event、http等层级，而http中又会有server block，server block中可以包含location block</p>\n<h4 id=\"Nginx模块工作原理概述\"><a href=\"#Nginx模块工作原理概述\" class=\"headerlink\" title=\"Nginx模块工作原理概述\"></a>Nginx模块工作原理概述</h4><p>Nginx本身做的工作实际很少，当它接到一个HTTP请求时，它仅仅是通过查找配置文件将此次请求映射到一个location block，而此location中所配置的各个指令则会启动不同的模块去完成工作，因此模块可以看做Nginx真正的劳动工作者。通常一个 location中的指令会涉及一个handler模块和多个filter模块（当然，多个location可以复用同一个模块）。handler模块负 责处理请求，完成响应内容的生成，而filter模块对响应内容进行处理。因此Nginx模块开发分为handler开发和filter开发</p>\n<p>####展示一个简单的Nginx模块开发全过程<br>我们开发一个叫echo的handler模块，这个模块功能非常简单，它接收“echo”指令，指令可指定一个字符串参数，模块会输出这个字符串作为HTTP响应。例如，做如下配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /echo &#123;</span><br><span class=\"line\">    echo &quot;hello nginx&quot;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先我们需要一个结构用于存储从配置文件中读进来的相关指令参数，即模块配置信息结构。根据Nginx模块开发规则这个结构的命名规则为ngx_http_[module-name]_[main|srv|loc]_conf_t</p>\n<p>实现这个功能需要三步：</p>\n<ul>\n<li>读入配置文件中echo指令及其参数；</li>\n<li>进行HTTP包装（添加HTTP头等工作）；</li>\n<li>将结果返回给客户端。</li>\n</ul>\n<h4 id=\"Nginx模块的安装\"><a href=\"#Nginx模块的安装\" class=\"headerlink\" title=\"Nginx模块的安装\"></a>Nginx模块的安装</h4><p>Nginx不支持动态链接模块，所以安装模块需要将模块代码与Nginx源代码进行重新编译。安装模块的步骤如下：</p>\n<ul>\n<li>编写模块config文件，这个文件需要放在和模块源代码文件放在同一目录下。文件内容如下：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ngx_addon_name=模块完整名称</span><br><span class=\"line\">HTTP_MODULES=”$HTTP_MODULES 模块完整名称”</span><br><span class=\"line\">NGX_ADDON_SRCS=”$NGX_ADDON_SRCS $ngx_addon_dir/源代码文件名”</span><br></pre></td></tr></table></figure>\n<ul>\n<li>进入Nginx源代码，使用下面命令编译安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --prefix=安装目录 --add-module=模块源代码文件目录</span><br><span class=\"line\">make</span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<p>这样就完成安装了，例如，我的源代码文件放在/home/zj/tmp/ngx/ngx_http_echo下，我的config文件为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ngx_addon_name=ngx_http_echo_module</span><br><span class=\"line\">HTTP_MODULES=&quot;$HTTP_MODULES ngx_http_echo_module&quot;</span><br><span class=\"line\">NGX_ADDON_SRCS=&quot;$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_echo_module.c&quot;</span><br></pre></td></tr></table></figure>\n<h4 id=\"编译安装命令为：\"><a href=\"#编译安装命令为：\" class=\"headerlink\" title=\"编译安装命令为：\"></a>编译安装命令为：</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --prefix=/usr/local/nginx --add-module=/home/zj/tmp/ngx/ngx_http_echo</span><br><span class=\"line\">make</span><br><span class=\"line\">sudo make install</span><br></pre></td></tr></table></figure>\n<p>这样echo模块就被安装在我的Nginx上了，下面测试一下，修改配置文件，增加以下一项配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /echo &#123;</span><br><span class=\"line\">    echo &quot;This is my first nginx module!!!&quot;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>然后用curl测试一下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -i http://localhost/echo</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>写这篇文章的时候，参考<a href=\"http://blog.codinglabs.org/articles/intro-of-nginx-module-development.html\" target=\"_blank\" rel=\"noopener\">链接</a>，特此鸣谢</p>\n<h4 id=\"为何需要Ngnix-模块：\"><a href=\"#为何需要Ngnix-模块：\" class=\"headerlink\" title=\"为何需要Ngnix 模块：\"></a>为何需要Ngnix 模块：</h4><blockquote>\n<p>对于一些访问量特别大，业务逻辑也相对简单的Web调用来说，通过一个nginx module来实现是一种比较好的优化方法。实现一个nginx module实际上比较简单。（@TimYang）</p>\n</blockquote>\n<h4 id=\"Nginx-配置结构了解\"><a href=\"#Nginx-配置结构了解\" class=\"headerlink\" title=\"Nginx 配置结构了解\"></a>Nginx 配置结构了解</h4><p>Nginx的配置文件是以block的形式组织的，一个block通常使用大括号“{}”表示。block分为几个层级，整个配置文件为main层级，这 是最大的层级；在main层级下可以有event、http等层级，而http中又会有server block，server block中可以包含location block</p>\n<h4 id=\"Nginx模块工作原理概述\"><a href=\"#Nginx模块工作原理概述\" class=\"headerlink\" title=\"Nginx模块工作原理概述\"></a>Nginx模块工作原理概述</h4><p>Nginx本身做的工作实际很少，当它接到一个HTTP请求时，它仅仅是通过查找配置文件将此次请求映射到一个location block，而此location中所配置的各个指令则会启动不同的模块去完成工作，因此模块可以看做Nginx真正的劳动工作者。通常一个 location中的指令会涉及一个handler模块和多个filter模块（当然，多个location可以复用同一个模块）。handler模块负 责处理请求，完成响应内容的生成，而filter模块对响应内容进行处理。因此Nginx模块开发分为handler开发和filter开发</p>\n<p>####展示一个简单的Nginx模块开发全过程<br>我们开发一个叫echo的handler模块，这个模块功能非常简单，它接收“echo”指令，指令可指定一个字符串参数，模块会输出这个字符串作为HTTP响应。例如，做如下配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /echo &#123;</span><br><span class=\"line\">    echo &quot;hello nginx&quot;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先我们需要一个结构用于存储从配置文件中读进来的相关指令参数，即模块配置信息结构。根据Nginx模块开发规则这个结构的命名规则为ngx_http_[module-name]_[main|srv|loc]_conf_t</p>\n<p>实现这个功能需要三步：</p>\n<ul>\n<li>读入配置文件中echo指令及其参数；</li>\n<li>进行HTTP包装（添加HTTP头等工作）；</li>\n<li>将结果返回给客户端。</li>\n</ul>\n<h4 id=\"Nginx模块的安装\"><a href=\"#Nginx模块的安装\" class=\"headerlink\" title=\"Nginx模块的安装\"></a>Nginx模块的安装</h4><p>Nginx不支持动态链接模块，所以安装模块需要将模块代码与Nginx源代码进行重新编译。安装模块的步骤如下：</p>\n<ul>\n<li>编写模块config文件，这个文件需要放在和模块源代码文件放在同一目录下。文件内容如下：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ngx_addon_name=模块完整名称</span><br><span class=\"line\">HTTP_MODULES=”$HTTP_MODULES 模块完整名称”</span><br><span class=\"line\">NGX_ADDON_SRCS=”$NGX_ADDON_SRCS $ngx_addon_dir/源代码文件名”</span><br></pre></td></tr></table></figure>\n<ul>\n<li>进入Nginx源代码，使用下面命令编译安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --prefix=安装目录 --add-module=模块源代码文件目录</span><br><span class=\"line\">make</span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<p>这样就完成安装了，例如，我的源代码文件放在/home/zj/tmp/ngx/ngx_http_echo下，我的config文件为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ngx_addon_name=ngx_http_echo_module</span><br><span class=\"line\">HTTP_MODULES=&quot;$HTTP_MODULES ngx_http_echo_module&quot;</span><br><span class=\"line\">NGX_ADDON_SRCS=&quot;$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_echo_module.c&quot;</span><br></pre></td></tr></table></figure>\n<h4 id=\"编译安装命令为：\"><a href=\"#编译安装命令为：\" class=\"headerlink\" title=\"编译安装命令为：\"></a>编译安装命令为：</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --prefix=/usr/local/nginx --add-module=/home/zj/tmp/ngx/ngx_http_echo</span><br><span class=\"line\">make</span><br><span class=\"line\">sudo make install</span><br></pre></td></tr></table></figure>\n<p>这样echo模块就被安装在我的Nginx上了，下面测试一下，修改配置文件，增加以下一项配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /echo &#123;</span><br><span class=\"line\">    echo &quot;This is my first nginx module!!!&quot;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>然后用curl测试一下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -i http://localhost/echo</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Thread Pool in Python","date":"2012-12-27T05:40:00.000Z","comments":1,"_content":"#### python的创建多线程的方法\n使用线程有两种模式：\n+ 一种是创建线程要执行的函数，把这个函数传递进Thread对象里，让它来执行；\n+ 一种是直接从Thread继承，创建一个新的class，把线程执行的代码放到这个新的 class里。\n\n```python\nimport string, threading, time\n \ndef thread_main(a):\n        global count, mutex\n            # 获得线程名\n            threadname = threading.currentThread().getName()\n \n    for x in xrange(0, int(a)):\n                # 取得锁\n                mutex.acquire()\n        count = count + 1\n                # 释放锁\n                mutex.release()\n        print threadname, x, count\n                time.sleep(1)\n \ndef main(num):\n    global count, mutex\n    threads = []\n         \n    count = 1\n    # 创建一个锁\n    mutex = threading.Lock()\n    # 先创建线程对象\n    for x in xrange(0, num):\n        threads.append(threading.Thread(target=thread_main, args=(10,)))\n    # 启动所有线程\n    for t in threads:\n        t.start()\n    # 主线程中等待所有子线程退出\n    for t in threads:\n        t.join() \nif __name__ == '__main__':\n    num = 4\n    # 创建4个线程\n    main(4)\n```\n方法二\n\n```python\nimport threading\nimport time\n \nclass Test(threading.Thread):\n    def __init__(self, num):\n        threading.Thread.__init__(self)\n        self._run_num = num\n\n    def run(self):\n        global count, mutex\n        threadname = threading.currentThread().getName()\n\n    for x in xrange(0, int(self._run_num)):\n        mutex.acquire()\n        count = count + 1\n        mutex.release()\n        print threadname, x, count\n        time.sleep(1)\n\nif __name__ == '__main__':\n    global count, mutex\n    threads = []\n    num = 4\n    count = 1\n    # 创建锁\n    mutex = threading.Lock()\n    # 创建线程对象\n    for x in xrange(0, num):\n        threads.append(Test(10))\n    # 启动线程\n    for t in threads:\n        t.start()\n    # 等待子线程结束\n    for t in threads:\n        t.join()\n```\n#### 队列同步\nPython的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步\n\n#### 线程池原理：\n我们把任务放进队列中去，然后开N个线程，每个线程都去队列中取一个任务，执行完了之后告诉系统说我执行完了，然后接着去队列中取下一个任务，直至队列中所有任务取空，退出线程.\n\n```python\nimport time\nimport threading\nimport Queue\n \nclass Worker(threading.Thread):\n    def __init__(self, name, queue):\n        threading.Thread.__init__(self)\n        self.queue = queue\n        self.start()\n    def run(self):\n        # 著名的死循环，保证接着跑下一个任务\n        while True:\n        # 队列为空则退出线程\n        if self.queue.empty():\n            break\n        # 获取一个项目\n        foo = self.queue.get()\n        # 延时1S模拟你要做的事情\n        time.sleep(1)\n        print self.getName(),':', foo\n        # 告诉系统说任务完成\n        self.queue.task_done()\n \nqueue = Queue.Queue()\n \n# 加入100个任务队列\nfor i in range(100):\n    queue.put(i)\n             \n# 开10个线程\nfor i in range(10):\n    threadName = 'Thread' + str(i)\n    Worker(threadName, queue)\n# 所有线程执行完毕后关闭\nqueue.join()\n```\n\n\n","source":"_posts/2013-08-28-thread-pool-in-python.markdown","raw":"---\nlayout: post\ntitle: \"Thread Pool in Python\"\ndate: 2012-12-27 13:40\ncomments: true\ncategories: Programe\n---\n#### python的创建多线程的方法\n使用线程有两种模式：\n+ 一种是创建线程要执行的函数，把这个函数传递进Thread对象里，让它来执行；\n+ 一种是直接从Thread继承，创建一个新的class，把线程执行的代码放到这个新的 class里。\n\n```python\nimport string, threading, time\n \ndef thread_main(a):\n        global count, mutex\n            # 获得线程名\n            threadname = threading.currentThread().getName()\n \n    for x in xrange(0, int(a)):\n                # 取得锁\n                mutex.acquire()\n        count = count + 1\n                # 释放锁\n                mutex.release()\n        print threadname, x, count\n                time.sleep(1)\n \ndef main(num):\n    global count, mutex\n    threads = []\n         \n    count = 1\n    # 创建一个锁\n    mutex = threading.Lock()\n    # 先创建线程对象\n    for x in xrange(0, num):\n        threads.append(threading.Thread(target=thread_main, args=(10,)))\n    # 启动所有线程\n    for t in threads:\n        t.start()\n    # 主线程中等待所有子线程退出\n    for t in threads:\n        t.join() \nif __name__ == '__main__':\n    num = 4\n    # 创建4个线程\n    main(4)\n```\n方法二\n\n```python\nimport threading\nimport time\n \nclass Test(threading.Thread):\n    def __init__(self, num):\n        threading.Thread.__init__(self)\n        self._run_num = num\n\n    def run(self):\n        global count, mutex\n        threadname = threading.currentThread().getName()\n\n    for x in xrange(0, int(self._run_num)):\n        mutex.acquire()\n        count = count + 1\n        mutex.release()\n        print threadname, x, count\n        time.sleep(1)\n\nif __name__ == '__main__':\n    global count, mutex\n    threads = []\n    num = 4\n    count = 1\n    # 创建锁\n    mutex = threading.Lock()\n    # 创建线程对象\n    for x in xrange(0, num):\n        threads.append(Test(10))\n    # 启动线程\n    for t in threads:\n        t.start()\n    # 等待子线程结束\n    for t in threads:\n        t.join()\n```\n#### 队列同步\nPython的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步\n\n#### 线程池原理：\n我们把任务放进队列中去，然后开N个线程，每个线程都去队列中取一个任务，执行完了之后告诉系统说我执行完了，然后接着去队列中取下一个任务，直至队列中所有任务取空，退出线程.\n\n```python\nimport time\nimport threading\nimport Queue\n \nclass Worker(threading.Thread):\n    def __init__(self, name, queue):\n        threading.Thread.__init__(self)\n        self.queue = queue\n        self.start()\n    def run(self):\n        # 著名的死循环，保证接着跑下一个任务\n        while True:\n        # 队列为空则退出线程\n        if self.queue.empty():\n            break\n        # 获取一个项目\n        foo = self.queue.get()\n        # 延时1S模拟你要做的事情\n        time.sleep(1)\n        print self.getName(),':', foo\n        # 告诉系统说任务完成\n        self.queue.task_done()\n \nqueue = Queue.Queue()\n \n# 加入100个任务队列\nfor i in range(100):\n    queue.put(i)\n             \n# 开10个线程\nfor i in range(10):\n    threadName = 'Thread' + str(i)\n    Worker(threadName, queue)\n# 所有线程执行完毕后关闭\nqueue.join()\n```\n\n\n","slug":"2013-08-28-thread-pool-in-python","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd85000anctjkwhp974g","content":"<h4 id=\"python的创建多线程的方法\"><a href=\"#python的创建多线程的方法\" class=\"headerlink\" title=\"python的创建多线程的方法\"></a>python的创建多线程的方法</h4><p>使用线程有两种模式：</p>\n<ul>\n<li>一种是创建线程要执行的函数，把这个函数传递进Thread对象里，让它来执行；</li>\n<li>一种是直接从Thread继承，创建一个新的class，把线程执行的代码放到这个新的 class里。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> string, threading, time</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">thread_main</span><span class=\"params\">(a)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">global</span> count, mutex</span><br><span class=\"line\">            <span class=\"comment\"># 获得线程名</span></span><br><span class=\"line\">            threadname = threading.currentThread().getName()</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> xrange(<span class=\"number\">0</span>, int(a)):</span><br><span class=\"line\">                <span class=\"comment\"># 取得锁</span></span><br><span class=\"line\">                mutex.acquire()</span><br><span class=\"line\">        count = count + <span class=\"number\">1</span></span><br><span class=\"line\">                <span class=\"comment\"># 释放锁</span></span><br><span class=\"line\">                mutex.release()</span><br><span class=\"line\">        <span class=\"keyword\">print</span> threadname, x, count</span><br><span class=\"line\">                time.sleep(<span class=\"number\">1</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">(num)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">global</span> count, mutex</span><br><span class=\"line\">    threads = []</span><br><span class=\"line\">         </span><br><span class=\"line\">    count = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\"># 创建一个锁</span></span><br><span class=\"line\">    mutex = threading.Lock()</span><br><span class=\"line\">    <span class=\"comment\"># 先创建线程对象</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> xrange(<span class=\"number\">0</span>, num):</span><br><span class=\"line\">        threads.append(threading.Thread(target=thread_main, args=(<span class=\"number\">10</span>,)))</span><br><span class=\"line\">    <span class=\"comment\"># 启动所有线程</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> threads:</span><br><span class=\"line\">        t.start()</span><br><span class=\"line\">    <span class=\"comment\"># 主线程中等待所有子线程退出</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> threads:</span><br><span class=\"line\">        t.join() </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    num = <span class=\"number\">4</span></span><br><span class=\"line\">    <span class=\"comment\"># 创建4个线程</span></span><br><span class=\"line\">    main(<span class=\"number\">4</span>)</span><br></pre></td></tr></table></figure>\n<p>方法二</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> threading</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Test</span><span class=\"params\">(threading.Thread)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, num)</span>:</span></span><br><span class=\"line\">        threading.Thread.__init__(self)</span><br><span class=\"line\">        self._run_num = num</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">global</span> count, mutex</span><br><span class=\"line\">        threadname = threading.currentThread().getName()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> xrange(<span class=\"number\">0</span>, int(self._run_num)):</span><br><span class=\"line\">        mutex.acquire()</span><br><span class=\"line\">        count = count + <span class=\"number\">1</span></span><br><span class=\"line\">        mutex.release()</span><br><span class=\"line\">        <span class=\"keyword\">print</span> threadname, x, count</span><br><span class=\"line\">        time.sleep(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">global</span> count, mutex</span><br><span class=\"line\">    threads = []</span><br><span class=\"line\">    num = <span class=\"number\">4</span></span><br><span class=\"line\">    count = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\"># 创建锁</span></span><br><span class=\"line\">    mutex = threading.Lock()</span><br><span class=\"line\">    <span class=\"comment\"># 创建线程对象</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> xrange(<span class=\"number\">0</span>, num):</span><br><span class=\"line\">        threads.append(Test(<span class=\"number\">10</span>))</span><br><span class=\"line\">    <span class=\"comment\"># 启动线程</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> threads:</span><br><span class=\"line\">        t.start()</span><br><span class=\"line\">    <span class=\"comment\"># 等待子线程结束</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> threads:</span><br><span class=\"line\">        t.join()</span><br></pre></td></tr></table></figure>\n<h4 id=\"队列同步\"><a href=\"#队列同步\" class=\"headerlink\" title=\"队列同步\"></a>队列同步</h4><p>Python的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步</p>\n<h4 id=\"线程池原理：\"><a href=\"#线程池原理：\" class=\"headerlink\" title=\"线程池原理：\"></a>线程池原理：</h4><p>我们把任务放进队列中去，然后开N个线程，每个线程都去队列中取一个任务，执行完了之后告诉系统说我执行完了，然后接着去队列中取下一个任务，直至队列中所有任务取空，退出线程.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> threading</span><br><span class=\"line\"><span class=\"keyword\">import</span> Queue</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Worker</span><span class=\"params\">(threading.Thread)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, name, queue)</span>:</span></span><br><span class=\"line\">        threading.Thread.__init__(self)</span><br><span class=\"line\">        self.queue = queue</span><br><span class=\"line\">        self.start()</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># 著名的死循环，保证接着跑下一个任务</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 队列为空则退出线程</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.queue.empty():</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        <span class=\"comment\"># 获取一个项目</span></span><br><span class=\"line\">        foo = self.queue.get()</span><br><span class=\"line\">        <span class=\"comment\"># 延时1S模拟你要做的事情</span></span><br><span class=\"line\">        time.sleep(<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">print</span> self.getName(),<span class=\"string\">':'</span>, foo</span><br><span class=\"line\">        <span class=\"comment\"># 告诉系统说任务完成</span></span><br><span class=\"line\">        self.queue.task_done()</span><br><span class=\"line\"> </span><br><span class=\"line\">queue = Queue.Queue()</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 加入100个任务队列</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>):</span><br><span class=\"line\">    queue.put(i)</span><br><span class=\"line\">             </span><br><span class=\"line\"><span class=\"comment\"># 开10个线程</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>):</span><br><span class=\"line\">    threadName = <span class=\"string\">'Thread'</span> + str(i)</span><br><span class=\"line\">    Worker(threadName, queue)</span><br><span class=\"line\"><span class=\"comment\"># 所有线程执行完毕后关闭</span></span><br><span class=\"line\">queue.join()</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"python的创建多线程的方法\"><a href=\"#python的创建多线程的方法\" class=\"headerlink\" title=\"python的创建多线程的方法\"></a>python的创建多线程的方法</h4><p>使用线程有两种模式：</p>\n<ul>\n<li>一种是创建线程要执行的函数，把这个函数传递进Thread对象里，让它来执行；</li>\n<li>一种是直接从Thread继承，创建一个新的class，把线程执行的代码放到这个新的 class里。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> string, threading, time</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">thread_main</span><span class=\"params\">(a)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">global</span> count, mutex</span><br><span class=\"line\">            <span class=\"comment\"># 获得线程名</span></span><br><span class=\"line\">            threadname = threading.currentThread().getName()</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> xrange(<span class=\"number\">0</span>, int(a)):</span><br><span class=\"line\">                <span class=\"comment\"># 取得锁</span></span><br><span class=\"line\">                mutex.acquire()</span><br><span class=\"line\">        count = count + <span class=\"number\">1</span></span><br><span class=\"line\">                <span class=\"comment\"># 释放锁</span></span><br><span class=\"line\">                mutex.release()</span><br><span class=\"line\">        <span class=\"keyword\">print</span> threadname, x, count</span><br><span class=\"line\">                time.sleep(<span class=\"number\">1</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">(num)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">global</span> count, mutex</span><br><span class=\"line\">    threads = []</span><br><span class=\"line\">         </span><br><span class=\"line\">    count = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\"># 创建一个锁</span></span><br><span class=\"line\">    mutex = threading.Lock()</span><br><span class=\"line\">    <span class=\"comment\"># 先创建线程对象</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> xrange(<span class=\"number\">0</span>, num):</span><br><span class=\"line\">        threads.append(threading.Thread(target=thread_main, args=(<span class=\"number\">10</span>,)))</span><br><span class=\"line\">    <span class=\"comment\"># 启动所有线程</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> threads:</span><br><span class=\"line\">        t.start()</span><br><span class=\"line\">    <span class=\"comment\"># 主线程中等待所有子线程退出</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> threads:</span><br><span class=\"line\">        t.join() </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    num = <span class=\"number\">4</span></span><br><span class=\"line\">    <span class=\"comment\"># 创建4个线程</span></span><br><span class=\"line\">    main(<span class=\"number\">4</span>)</span><br></pre></td></tr></table></figure>\n<p>方法二</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> threading</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Test</span><span class=\"params\">(threading.Thread)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, num)</span>:</span></span><br><span class=\"line\">        threading.Thread.__init__(self)</span><br><span class=\"line\">        self._run_num = num</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">global</span> count, mutex</span><br><span class=\"line\">        threadname = threading.currentThread().getName()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> xrange(<span class=\"number\">0</span>, int(self._run_num)):</span><br><span class=\"line\">        mutex.acquire()</span><br><span class=\"line\">        count = count + <span class=\"number\">1</span></span><br><span class=\"line\">        mutex.release()</span><br><span class=\"line\">        <span class=\"keyword\">print</span> threadname, x, count</span><br><span class=\"line\">        time.sleep(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"keyword\">global</span> count, mutex</span><br><span class=\"line\">    threads = []</span><br><span class=\"line\">    num = <span class=\"number\">4</span></span><br><span class=\"line\">    count = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\"># 创建锁</span></span><br><span class=\"line\">    mutex = threading.Lock()</span><br><span class=\"line\">    <span class=\"comment\"># 创建线程对象</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> xrange(<span class=\"number\">0</span>, num):</span><br><span class=\"line\">        threads.append(Test(<span class=\"number\">10</span>))</span><br><span class=\"line\">    <span class=\"comment\"># 启动线程</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> threads:</span><br><span class=\"line\">        t.start()</span><br><span class=\"line\">    <span class=\"comment\"># 等待子线程结束</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> threads:</span><br><span class=\"line\">        t.join()</span><br></pre></td></tr></table></figure>\n<h4 id=\"队列同步\"><a href=\"#队列同步\" class=\"headerlink\" title=\"队列同步\"></a>队列同步</h4><p>Python的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步</p>\n<h4 id=\"线程池原理：\"><a href=\"#线程池原理：\" class=\"headerlink\" title=\"线程池原理：\"></a>线程池原理：</h4><p>我们把任务放进队列中去，然后开N个线程，每个线程都去队列中取一个任务，执行完了之后告诉系统说我执行完了，然后接着去队列中取下一个任务，直至队列中所有任务取空，退出线程.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> threading</span><br><span class=\"line\"><span class=\"keyword\">import</span> Queue</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Worker</span><span class=\"params\">(threading.Thread)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, name, queue)</span>:</span></span><br><span class=\"line\">        threading.Thread.__init__(self)</span><br><span class=\"line\">        self.queue = queue</span><br><span class=\"line\">        self.start()</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># 著名的死循环，保证接着跑下一个任务</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 队列为空则退出线程</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.queue.empty():</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        <span class=\"comment\"># 获取一个项目</span></span><br><span class=\"line\">        foo = self.queue.get()</span><br><span class=\"line\">        <span class=\"comment\"># 延时1S模拟你要做的事情</span></span><br><span class=\"line\">        time.sleep(<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">print</span> self.getName(),<span class=\"string\">':'</span>, foo</span><br><span class=\"line\">        <span class=\"comment\"># 告诉系统说任务完成</span></span><br><span class=\"line\">        self.queue.task_done()</span><br><span class=\"line\"> </span><br><span class=\"line\">queue = Queue.Queue()</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 加入100个任务队列</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>):</span><br><span class=\"line\">    queue.put(i)</span><br><span class=\"line\">             </span><br><span class=\"line\"><span class=\"comment\"># 开10个线程</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>):</span><br><span class=\"line\">    threadName = <span class=\"string\">'Thread'</span> + str(i)</span><br><span class=\"line\">    Worker(threadName, queue)</span><br><span class=\"line\"><span class=\"comment\"># 所有线程执行完毕后关闭</span></span><br><span class=\"line\">queue.join()</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"在路上","date":"2013-02-12T06:00:00.000Z","comments":1,"_content":"过去的一年里，我很刻意在锻炼一些不足的东西，即便如今还是无法和很多我崇拜的朋友那样成熟，但还是深切感受到成长带有一些痛。\n\n大学的我读了计算机。生长环境的原因，到进入大学才真正接触电脑.不夸张的说，我只会开机。从小一直倔强且自觉的人，顿时感觉自己是个loser。但是我还是很努力的去上课，学习，模仿我的同学，那些我看起来很有“天赋”的人，每个独特的个体有不同的经历，就像有些人初中已经在玩Linux， 有的高中玩信息竞赛，真的有无比的羡慕。你可以想象那时候的我就是一个白痴，什么都不懂，所幸的是，我不放弃，于是在努力学习,厚脸皮的取经，跟上老师的步伐。别人花1个小时，好吧，那我就花10个小时。幸运的是我认识到一些很好的同学，他们之间有些人在我心中占有很重的分量。我是一个感恩的人，当我有能力，也会延续这份恩情，给予同样需要帮助的人。就这样我貌似很白痴地拿下了大学的第一个国家奖学金，但是我不开心，因为，我讨厌成为没有安全感，这种安全感是需要我有足够的编程能力来支撑。而那时的我，可能只是个课业任务完成的比较认真的学生。而对于计算机这样一个动手能力极强的学科，我深深觉得还远远不够。说实话很郁闷。我也觉得很奇怪，为什么一个在高中可以担任篮球队长，一个可以面对做口语翻译欣然接受的人会如此沉默寡言。以至于大家误解我太过低调,囧rz，人什么都可以改变的，当你知道你的路在什么地方的时候。\n\n这期间我养成了每天晚上环大学内环慢跑的习惯，这一坚持便是3年。起初的原因是想调节自己的情绪，后来也就成为一种习惯，庆幸的是，我没有像别人一样沉溺于恶习。纵然我相信天道酬勤，也因起步太慢和方法不对，迟迟找不到感觉，焦虑失望的心必然是存在的，跑步帮助我调节。于是我就找我认为厉害的朋友聊天，遗憾的是，站在高处的他们终究只是习惯了自己的思维，没有站在“弱势群体”的角度思考他们的痛。于是，郁闷还在继续，但我没有停下探索与步伐，这期间我还是在企望某个曙光的到临。那种只能意会不可言传的感觉。I hope Change Coming!\n\n大二下的时候和班里的几位同学组了一个团队“叫神马团队”，渐渐接受各种项目的锻炼，是的，聪明的你会发现这是一个契机，我觉得这是开启心智模式的一个序幕。我本着不懂就更要努力的心态，与团队一起在成长，后来我也成了队长。和一些优秀的人在一起能让你更加优秀，的确是的。我开始用了Vim ，学会了GoogleReader ,掌握了各种提高效率的工具（evernote…），开始无尽的折腾，各种系统，各种好玩的技术。也慢慢找到自己想要的方向，我无限迷恋Unix编程艺术。Geek的血液已经开始流淌于我的信仰里。努力变得有方向和满足感了。迷茫也还是有的。\n\n这期间广泛的阅读让我视野大开，CoolShell,Tinyfool,云风的blog，TimYang的后端日志，DBANote….各种我崇拜的人，他们关于技术学习，以及其他相关文章让我流连忘返。这是我希望成为的人。我也开始广泛的接触经典阅读，可以看看我的豆瓣阅读。我发现我找到了那道曙光，这次我继续坚持。大四的时候，我的成绩是2/280,说实话，从大三起我已经开始逃课了，去做各种自己喜欢的事情。我承认还是有很多东西现阶段理解不了，但也会选择性地接受，有机会继续深究，做有心人。是的， 我开始挑战各种各样的技术难题，自信上来了。点滴感悟之中，也就发现了只会技术远远不够。\n\n因为家里某些原因，我放弃保送上海交大，说出来真的需要勇气，我也知道很多人会对我不理解，当我敢于对别人云淡风轻的提起之时，这背后已经是多次失眠哈哈。看来内心需要修炼。我发现和我一起成长的那帮牛逼的高中同学，他们高等学历的身份多多少少让我感受到了压力，但既然选择，那就承担吧.像一个男人一样去面对。现在的我比学生生涯的任何时候都具有强烈的求职欲望和学习能力，我更加知道自己要成为什么样的人。不谦虚的说，我比以前任何时候那个考过全县第一名的我更要强大，心智模式的打开，在我看来才是教育最重要的目的，让我看到了思维的转变。很可悲的是还是有很多人没有找到这样的意识。感谢读计算机这专业以及一路上遇到的人，让我追求独立思考的精神。\n\n今天听了tiny4voice的一篇文章《如何自学和成长》，我发现有很强劲的共鸣。是的，人不应该限制自己，勇敢的去挑战各种可能。就像我曾经去摆地摊：） 我也慢慢发现如果以后有机会，一定要对那些后来人更加地友善，正如曾经帮助过我的人，生活中，有的人，认为他们已经懂的东西很习以为常，然后以站着说话不腰疼的感受，于是说出来的话就很打击这些很渴望进步的学习者的内心，直至现在，我一直被这样的人伤害过，还好我懂得如何提炼更有效的信息，自我判断，只是当你有一天也走到了他们的位置，对他们态度好一些，但如果能感性点会更好。同理心可以让这个如此残酷的世界变得有那么一点人情味。\n\n我希望接下来的日子里，与我的朋友们一起共勉，每一个看我博客的人，我知道你们会是谁，你们真的很棒，感恩与你们同在，无论怎样，开心是最佳选择 :-) 。听到一句话很想与大家分享\n>岂能尽如人意，但求无愧于心，让我们把所有的不好叫做经历。 \n","source":"_posts/2013-08-28-zai-lu-shang.markdown","raw":"---\nlayout: post\ntitle: \"在路上\"\ndate: 2013-02-12 14:00\ncomments: true\ncategories: Life\n---\n过去的一年里，我很刻意在锻炼一些不足的东西，即便如今还是无法和很多我崇拜的朋友那样成熟，但还是深切感受到成长带有一些痛。\n\n大学的我读了计算机。生长环境的原因，到进入大学才真正接触电脑.不夸张的说，我只会开机。从小一直倔强且自觉的人，顿时感觉自己是个loser。但是我还是很努力的去上课，学习，模仿我的同学，那些我看起来很有“天赋”的人，每个独特的个体有不同的经历，就像有些人初中已经在玩Linux， 有的高中玩信息竞赛，真的有无比的羡慕。你可以想象那时候的我就是一个白痴，什么都不懂，所幸的是，我不放弃，于是在努力学习,厚脸皮的取经，跟上老师的步伐。别人花1个小时，好吧，那我就花10个小时。幸运的是我认识到一些很好的同学，他们之间有些人在我心中占有很重的分量。我是一个感恩的人，当我有能力，也会延续这份恩情，给予同样需要帮助的人。就这样我貌似很白痴地拿下了大学的第一个国家奖学金，但是我不开心，因为，我讨厌成为没有安全感，这种安全感是需要我有足够的编程能力来支撑。而那时的我，可能只是个课业任务完成的比较认真的学生。而对于计算机这样一个动手能力极强的学科，我深深觉得还远远不够。说实话很郁闷。我也觉得很奇怪，为什么一个在高中可以担任篮球队长，一个可以面对做口语翻译欣然接受的人会如此沉默寡言。以至于大家误解我太过低调,囧rz，人什么都可以改变的，当你知道你的路在什么地方的时候。\n\n这期间我养成了每天晚上环大学内环慢跑的习惯，这一坚持便是3年。起初的原因是想调节自己的情绪，后来也就成为一种习惯，庆幸的是，我没有像别人一样沉溺于恶习。纵然我相信天道酬勤，也因起步太慢和方法不对，迟迟找不到感觉，焦虑失望的心必然是存在的，跑步帮助我调节。于是我就找我认为厉害的朋友聊天，遗憾的是，站在高处的他们终究只是习惯了自己的思维，没有站在“弱势群体”的角度思考他们的痛。于是，郁闷还在继续，但我没有停下探索与步伐，这期间我还是在企望某个曙光的到临。那种只能意会不可言传的感觉。I hope Change Coming!\n\n大二下的时候和班里的几位同学组了一个团队“叫神马团队”，渐渐接受各种项目的锻炼，是的，聪明的你会发现这是一个契机，我觉得这是开启心智模式的一个序幕。我本着不懂就更要努力的心态，与团队一起在成长，后来我也成了队长。和一些优秀的人在一起能让你更加优秀，的确是的。我开始用了Vim ，学会了GoogleReader ,掌握了各种提高效率的工具（evernote…），开始无尽的折腾，各种系统，各种好玩的技术。也慢慢找到自己想要的方向，我无限迷恋Unix编程艺术。Geek的血液已经开始流淌于我的信仰里。努力变得有方向和满足感了。迷茫也还是有的。\n\n这期间广泛的阅读让我视野大开，CoolShell,Tinyfool,云风的blog，TimYang的后端日志，DBANote….各种我崇拜的人，他们关于技术学习，以及其他相关文章让我流连忘返。这是我希望成为的人。我也开始广泛的接触经典阅读，可以看看我的豆瓣阅读。我发现我找到了那道曙光，这次我继续坚持。大四的时候，我的成绩是2/280,说实话，从大三起我已经开始逃课了，去做各种自己喜欢的事情。我承认还是有很多东西现阶段理解不了，但也会选择性地接受，有机会继续深究，做有心人。是的， 我开始挑战各种各样的技术难题，自信上来了。点滴感悟之中，也就发现了只会技术远远不够。\n\n因为家里某些原因，我放弃保送上海交大，说出来真的需要勇气，我也知道很多人会对我不理解，当我敢于对别人云淡风轻的提起之时，这背后已经是多次失眠哈哈。看来内心需要修炼。我发现和我一起成长的那帮牛逼的高中同学，他们高等学历的身份多多少少让我感受到了压力，但既然选择，那就承担吧.像一个男人一样去面对。现在的我比学生生涯的任何时候都具有强烈的求职欲望和学习能力，我更加知道自己要成为什么样的人。不谦虚的说，我比以前任何时候那个考过全县第一名的我更要强大，心智模式的打开，在我看来才是教育最重要的目的，让我看到了思维的转变。很可悲的是还是有很多人没有找到这样的意识。感谢读计算机这专业以及一路上遇到的人，让我追求独立思考的精神。\n\n今天听了tiny4voice的一篇文章《如何自学和成长》，我发现有很强劲的共鸣。是的，人不应该限制自己，勇敢的去挑战各种可能。就像我曾经去摆地摊：） 我也慢慢发现如果以后有机会，一定要对那些后来人更加地友善，正如曾经帮助过我的人，生活中，有的人，认为他们已经懂的东西很习以为常，然后以站着说话不腰疼的感受，于是说出来的话就很打击这些很渴望进步的学习者的内心，直至现在，我一直被这样的人伤害过，还好我懂得如何提炼更有效的信息，自我判断，只是当你有一天也走到了他们的位置，对他们态度好一些，但如果能感性点会更好。同理心可以让这个如此残酷的世界变得有那么一点人情味。\n\n我希望接下来的日子里，与我的朋友们一起共勉，每一个看我博客的人，我知道你们会是谁，你们真的很棒，感恩与你们同在，无论怎样，开心是最佳选择 :-) 。听到一句话很想与大家分享\n>岂能尽如人意，但求无愧于心，让我们把所有的不好叫做经历。 \n","slug":"2013-08-28-zai-lu-shang","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd87000dnctjljmt75ep","content":"<p>过去的一年里，我很刻意在锻炼一些不足的东西，即便如今还是无法和很多我崇拜的朋友那样成熟，但还是深切感受到成长带有一些痛。</p>\n<p>大学的我读了计算机。生长环境的原因，到进入大学才真正接触电脑.不夸张的说，我只会开机。从小一直倔强且自觉的人，顿时感觉自己是个loser。但是我还是很努力的去上课，学习，模仿我的同学，那些我看起来很有“天赋”的人，每个独特的个体有不同的经历，就像有些人初中已经在玩Linux， 有的高中玩信息竞赛，真的有无比的羡慕。你可以想象那时候的我就是一个白痴，什么都不懂，所幸的是，我不放弃，于是在努力学习,厚脸皮的取经，跟上老师的步伐。别人花1个小时，好吧，那我就花10个小时。幸运的是我认识到一些很好的同学，他们之间有些人在我心中占有很重的分量。我是一个感恩的人，当我有能力，也会延续这份恩情，给予同样需要帮助的人。就这样我貌似很白痴地拿下了大学的第一个国家奖学金，但是我不开心，因为，我讨厌成为没有安全感，这种安全感是需要我有足够的编程能力来支撑。而那时的我，可能只是个课业任务完成的比较认真的学生。而对于计算机这样一个动手能力极强的学科，我深深觉得还远远不够。说实话很郁闷。我也觉得很奇怪，为什么一个在高中可以担任篮球队长，一个可以面对做口语翻译欣然接受的人会如此沉默寡言。以至于大家误解我太过低调,囧rz，人什么都可以改变的，当你知道你的路在什么地方的时候。</p>\n<p>这期间我养成了每天晚上环大学内环慢跑的习惯，这一坚持便是3年。起初的原因是想调节自己的情绪，后来也就成为一种习惯，庆幸的是，我没有像别人一样沉溺于恶习。纵然我相信天道酬勤，也因起步太慢和方法不对，迟迟找不到感觉，焦虑失望的心必然是存在的，跑步帮助我调节。于是我就找我认为厉害的朋友聊天，遗憾的是，站在高处的他们终究只是习惯了自己的思维，没有站在“弱势群体”的角度思考他们的痛。于是，郁闷还在继续，但我没有停下探索与步伐，这期间我还是在企望某个曙光的到临。那种只能意会不可言传的感觉。I hope Change Coming!</p>\n<p>大二下的时候和班里的几位同学组了一个团队“叫神马团队”，渐渐接受各种项目的锻炼，是的，聪明的你会发现这是一个契机，我觉得这是开启心智模式的一个序幕。我本着不懂就更要努力的心态，与团队一起在成长，后来我也成了队长。和一些优秀的人在一起能让你更加优秀，的确是的。我开始用了Vim ，学会了GoogleReader ,掌握了各种提高效率的工具（evernote…），开始无尽的折腾，各种系统，各种好玩的技术。也慢慢找到自己想要的方向，我无限迷恋Unix编程艺术。Geek的血液已经开始流淌于我的信仰里。努力变得有方向和满足感了。迷茫也还是有的。</p>\n<p>这期间广泛的阅读让我视野大开，CoolShell,Tinyfool,云风的blog，TimYang的后端日志，DBANote….各种我崇拜的人，他们关于技术学习，以及其他相关文章让我流连忘返。这是我希望成为的人。我也开始广泛的接触经典阅读，可以看看我的豆瓣阅读。我发现我找到了那道曙光，这次我继续坚持。大四的时候，我的成绩是2/280,说实话，从大三起我已经开始逃课了，去做各种自己喜欢的事情。我承认还是有很多东西现阶段理解不了，但也会选择性地接受，有机会继续深究，做有心人。是的， 我开始挑战各种各样的技术难题，自信上来了。点滴感悟之中，也就发现了只会技术远远不够。</p>\n<p>因为家里某些原因，我放弃保送上海交大，说出来真的需要勇气，我也知道很多人会对我不理解，当我敢于对别人云淡风轻的提起之时，这背后已经是多次失眠哈哈。看来内心需要修炼。我发现和我一起成长的那帮牛逼的高中同学，他们高等学历的身份多多少少让我感受到了压力，但既然选择，那就承担吧.像一个男人一样去面对。现在的我比学生生涯的任何时候都具有强烈的求职欲望和学习能力，我更加知道自己要成为什么样的人。不谦虚的说，我比以前任何时候那个考过全县第一名的我更要强大，心智模式的打开，在我看来才是教育最重要的目的，让我看到了思维的转变。很可悲的是还是有很多人没有找到这样的意识。感谢读计算机这专业以及一路上遇到的人，让我追求独立思考的精神。</p>\n<p>今天听了tiny4voice的一篇文章《如何自学和成长》，我发现有很强劲的共鸣。是的，人不应该限制自己，勇敢的去挑战各种可能。就像我曾经去摆地摊：） 我也慢慢发现如果以后有机会，一定要对那些后来人更加地友善，正如曾经帮助过我的人，生活中，有的人，认为他们已经懂的东西很习以为常，然后以站着说话不腰疼的感受，于是说出来的话就很打击这些很渴望进步的学习者的内心，直至现在，我一直被这样的人伤害过，还好我懂得如何提炼更有效的信息，自我判断，只是当你有一天也走到了他们的位置，对他们态度好一些，但如果能感性点会更好。同理心可以让这个如此残酷的世界变得有那么一点人情味。</p>\n<p>我希望接下来的日子里，与我的朋友们一起共勉，每一个看我博客的人，我知道你们会是谁，你们真的很棒，感恩与你们同在，无论怎样，开心是最佳选择 :-) 。听到一句话很想与大家分享</p>\n<blockquote>\n<p>岂能尽如人意，但求无愧于心，让我们把所有的不好叫做经历。 </p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p>过去的一年里，我很刻意在锻炼一些不足的东西，即便如今还是无法和很多我崇拜的朋友那样成熟，但还是深切感受到成长带有一些痛。</p>\n<p>大学的我读了计算机。生长环境的原因，到进入大学才真正接触电脑.不夸张的说，我只会开机。从小一直倔强且自觉的人，顿时感觉自己是个loser。但是我还是很努力的去上课，学习，模仿我的同学，那些我看起来很有“天赋”的人，每个独特的个体有不同的经历，就像有些人初中已经在玩Linux， 有的高中玩信息竞赛，真的有无比的羡慕。你可以想象那时候的我就是一个白痴，什么都不懂，所幸的是，我不放弃，于是在努力学习,厚脸皮的取经，跟上老师的步伐。别人花1个小时，好吧，那我就花10个小时。幸运的是我认识到一些很好的同学，他们之间有些人在我心中占有很重的分量。我是一个感恩的人，当我有能力，也会延续这份恩情，给予同样需要帮助的人。就这样我貌似很白痴地拿下了大学的第一个国家奖学金，但是我不开心，因为，我讨厌成为没有安全感，这种安全感是需要我有足够的编程能力来支撑。而那时的我，可能只是个课业任务完成的比较认真的学生。而对于计算机这样一个动手能力极强的学科，我深深觉得还远远不够。说实话很郁闷。我也觉得很奇怪，为什么一个在高中可以担任篮球队长，一个可以面对做口语翻译欣然接受的人会如此沉默寡言。以至于大家误解我太过低调,囧rz，人什么都可以改变的，当你知道你的路在什么地方的时候。</p>\n<p>这期间我养成了每天晚上环大学内环慢跑的习惯，这一坚持便是3年。起初的原因是想调节自己的情绪，后来也就成为一种习惯，庆幸的是，我没有像别人一样沉溺于恶习。纵然我相信天道酬勤，也因起步太慢和方法不对，迟迟找不到感觉，焦虑失望的心必然是存在的，跑步帮助我调节。于是我就找我认为厉害的朋友聊天，遗憾的是，站在高处的他们终究只是习惯了自己的思维，没有站在“弱势群体”的角度思考他们的痛。于是，郁闷还在继续，但我没有停下探索与步伐，这期间我还是在企望某个曙光的到临。那种只能意会不可言传的感觉。I hope Change Coming!</p>\n<p>大二下的时候和班里的几位同学组了一个团队“叫神马团队”，渐渐接受各种项目的锻炼，是的，聪明的你会发现这是一个契机，我觉得这是开启心智模式的一个序幕。我本着不懂就更要努力的心态，与团队一起在成长，后来我也成了队长。和一些优秀的人在一起能让你更加优秀，的确是的。我开始用了Vim ，学会了GoogleReader ,掌握了各种提高效率的工具（evernote…），开始无尽的折腾，各种系统，各种好玩的技术。也慢慢找到自己想要的方向，我无限迷恋Unix编程艺术。Geek的血液已经开始流淌于我的信仰里。努力变得有方向和满足感了。迷茫也还是有的。</p>\n<p>这期间广泛的阅读让我视野大开，CoolShell,Tinyfool,云风的blog，TimYang的后端日志，DBANote….各种我崇拜的人，他们关于技术学习，以及其他相关文章让我流连忘返。这是我希望成为的人。我也开始广泛的接触经典阅读，可以看看我的豆瓣阅读。我发现我找到了那道曙光，这次我继续坚持。大四的时候，我的成绩是2/280,说实话，从大三起我已经开始逃课了，去做各种自己喜欢的事情。我承认还是有很多东西现阶段理解不了，但也会选择性地接受，有机会继续深究，做有心人。是的， 我开始挑战各种各样的技术难题，自信上来了。点滴感悟之中，也就发现了只会技术远远不够。</p>\n<p>因为家里某些原因，我放弃保送上海交大，说出来真的需要勇气，我也知道很多人会对我不理解，当我敢于对别人云淡风轻的提起之时，这背后已经是多次失眠哈哈。看来内心需要修炼。我发现和我一起成长的那帮牛逼的高中同学，他们高等学历的身份多多少少让我感受到了压力，但既然选择，那就承担吧.像一个男人一样去面对。现在的我比学生生涯的任何时候都具有强烈的求职欲望和学习能力，我更加知道自己要成为什么样的人。不谦虚的说，我比以前任何时候那个考过全县第一名的我更要强大，心智模式的打开，在我看来才是教育最重要的目的，让我看到了思维的转变。很可悲的是还是有很多人没有找到这样的意识。感谢读计算机这专业以及一路上遇到的人，让我追求独立思考的精神。</p>\n<p>今天听了tiny4voice的一篇文章《如何自学和成长》，我发现有很强劲的共鸣。是的，人不应该限制自己，勇敢的去挑战各种可能。就像我曾经去摆地摊：） 我也慢慢发现如果以后有机会，一定要对那些后来人更加地友善，正如曾经帮助过我的人，生活中，有的人，认为他们已经懂的东西很习以为常，然后以站着说话不腰疼的感受，于是说出来的话就很打击这些很渴望进步的学习者的内心，直至现在，我一直被这样的人伤害过，还好我懂得如何提炼更有效的信息，自我判断，只是当你有一天也走到了他们的位置，对他们态度好一些，但如果能感性点会更好。同理心可以让这个如此残酷的世界变得有那么一点人情味。</p>\n<p>我希望接下来的日子里，与我的朋友们一起共勉，每一个看我博客的人，我知道你们会是谁，你们真的很棒，感恩与你们同在，无论怎样，开心是最佳选择 :-) 。听到一句话很想与大家分享</p>\n<blockquote>\n<p>岂能尽如人意，但求无愧于心，让我们把所有的不好叫做经历。 </p>\n</blockquote>\n"},{"layout":"post","title":"折腾 libevent","date":"2012-03-22T12:25:00.000Z","comments":1,"_content":"### 好奇折腾libevent\n\n原理介绍转自[IBM developworks](www.ibm.com/developerworks/cn/aix/library/au-libev/)\n\n处理多个连接有许多不同的传统方法，但是在处理大量连接时它们往往会产生问题，因为它们使用的内存或 CPU 太多，或者达到了某个操作系统限制。\n\n网络连接使用的主要方法如下：\n\n+ 循环：\n\n早期系统使用简单的循环选择解决方案，即循环遍历打开的网络连接的列表，判断是否有要读取的数据。这种方法既缓慢（尤其是随着连接数量增加越来越慢),又低效（因为在处理当前连接时其他连接可能正在发送请求并等待响应）。在系统循环遍历每个连接时，其他连接不得不等待。如果有100 个连接，其中只有一个有数据，那么仍然必须处理其他 99 个连接，才能轮到真正需要处理的连接。\n\n+ poll、epoll 和变体：\n\n这是对循环方法的改进，它用一个结构保存要监视的每个连接的数组，当在网络套接字上发现数据时，通过回调机制调用处理函数。poll 的问题是这个结构会非常大，在列表中添加新的网络连接时，修改结构会增加负载并影响性能。\n选择：\n\n+ select() 函数调用使用一个静态结构，它事先被硬编码为相当小的数量（1024 个连接），因此不适用于非常大的部署。\n\n上面的所有解决方案都用简单的循环等待并处理请求，然后把请求分派给另一个函数以处理实际的网络交互。关键在于循环和网络套接字需要大量管理代码，这样才能监听、更新和控制不同的连接和接口。\n\nlibevent 库实际上没有更换 select()、poll() 或其他机制的基础。而是使用对于每个平台最高效的高性能解决方案在实现外加上一个包装器。为了实际处理每个请求，libevent 库提供一种事件机制，它作为底层网络后端的包装器。事件系统让为连接添加处理函数变得非常简便，同时降低了底层 I/O 复杂性。这是 libevent 系统的核心。\n\n创建 libevent 服务器的基本方法是:\n\n* 注册当发生某一操作（比如接受来自客户端的连接）时应该执行的函数，然后调用主事件循环 event_dispatch()。\n\n* 执行过程的控制现在由 libevent 系统处理。注册事件和将调用的函数之后，事件系统开始自治；\n\n* 在应用程序运行时，可以在事件队列中添加（注册）或删除（取消注册）事件。事件注册非常方便，可以通过它添加新事件以处理新打开的连接，从而构建灵活的网络处理系统。\n\n流程：\n\n```\nevent_set() //函数创建新的事件结构\nevent_add() //在事件队列机制中添加事件；\nevent_dispatch() // 启动事件队列系统，开始监听（并接受）请求。\n```\n\n### Tips\n    \nTips:编译过程中需要 -levent\n用libevent库写的EchoServer：代码[链接](https://github.com/zheng-ji/ToyCollection/tree/master/libevent)\n\n","source":"_posts/2013-08-28-zhe-teng-libevent.markdown","raw":"---\nlayout: post\ntitle: \"折腾 libevent\"\ndate: 2012-03-22 20:25\ncomments: true\ncategories: NetWork\n---\n### 好奇折腾libevent\n\n原理介绍转自[IBM developworks](www.ibm.com/developerworks/cn/aix/library/au-libev/)\n\n处理多个连接有许多不同的传统方法，但是在处理大量连接时它们往往会产生问题，因为它们使用的内存或 CPU 太多，或者达到了某个操作系统限制。\n\n网络连接使用的主要方法如下：\n\n+ 循环：\n\n早期系统使用简单的循环选择解决方案，即循环遍历打开的网络连接的列表，判断是否有要读取的数据。这种方法既缓慢（尤其是随着连接数量增加越来越慢),又低效（因为在处理当前连接时其他连接可能正在发送请求并等待响应）。在系统循环遍历每个连接时，其他连接不得不等待。如果有100 个连接，其中只有一个有数据，那么仍然必须处理其他 99 个连接，才能轮到真正需要处理的连接。\n\n+ poll、epoll 和变体：\n\n这是对循环方法的改进，它用一个结构保存要监视的每个连接的数组，当在网络套接字上发现数据时，通过回调机制调用处理函数。poll 的问题是这个结构会非常大，在列表中添加新的网络连接时，修改结构会增加负载并影响性能。\n选择：\n\n+ select() 函数调用使用一个静态结构，它事先被硬编码为相当小的数量（1024 个连接），因此不适用于非常大的部署。\n\n上面的所有解决方案都用简单的循环等待并处理请求，然后把请求分派给另一个函数以处理实际的网络交互。关键在于循环和网络套接字需要大量管理代码，这样才能监听、更新和控制不同的连接和接口。\n\nlibevent 库实际上没有更换 select()、poll() 或其他机制的基础。而是使用对于每个平台最高效的高性能解决方案在实现外加上一个包装器。为了实际处理每个请求，libevent 库提供一种事件机制，它作为底层网络后端的包装器。事件系统让为连接添加处理函数变得非常简便，同时降低了底层 I/O 复杂性。这是 libevent 系统的核心。\n\n创建 libevent 服务器的基本方法是:\n\n* 注册当发生某一操作（比如接受来自客户端的连接）时应该执行的函数，然后调用主事件循环 event_dispatch()。\n\n* 执行过程的控制现在由 libevent 系统处理。注册事件和将调用的函数之后，事件系统开始自治；\n\n* 在应用程序运行时，可以在事件队列中添加（注册）或删除（取消注册）事件。事件注册非常方便，可以通过它添加新事件以处理新打开的连接，从而构建灵活的网络处理系统。\n\n流程：\n\n```\nevent_set() //函数创建新的事件结构\nevent_add() //在事件队列机制中添加事件；\nevent_dispatch() // 启动事件队列系统，开始监听（并接受）请求。\n```\n\n### Tips\n    \nTips:编译过程中需要 -levent\n用libevent库写的EchoServer：代码[链接](https://github.com/zheng-ji/ToyCollection/tree/master/libevent)\n\n","slug":"2013-08-28-zhe-teng-libevent","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd89000fnctj03gam2le","content":"<h3 id=\"好奇折腾libevent\"><a href=\"#好奇折腾libevent\" class=\"headerlink\" title=\"好奇折腾libevent\"></a>好奇折腾libevent</h3><p>原理介绍转自<a href=\"www.ibm.com/developerworks/cn/aix/library/au-libev/\">IBM developworks</a></p>\n<p>处理多个连接有许多不同的传统方法，但是在处理大量连接时它们往往会产生问题，因为它们使用的内存或 CPU 太多，或者达到了某个操作系统限制。</p>\n<p>网络连接使用的主要方法如下：</p>\n<ul>\n<li>循环：</li>\n</ul>\n<p>早期系统使用简单的循环选择解决方案，即循环遍历打开的网络连接的列表，判断是否有要读取的数据。这种方法既缓慢（尤其是随着连接数量增加越来越慢),又低效（因为在处理当前连接时其他连接可能正在发送请求并等待响应）。在系统循环遍历每个连接时，其他连接不得不等待。如果有100 个连接，其中只有一个有数据，那么仍然必须处理其他 99 个连接，才能轮到真正需要处理的连接。</p>\n<ul>\n<li>poll、epoll 和变体：</li>\n</ul>\n<p>这是对循环方法的改进，它用一个结构保存要监视的每个连接的数组，当在网络套接字上发现数据时，通过回调机制调用处理函数。poll 的问题是这个结构会非常大，在列表中添加新的网络连接时，修改结构会增加负载并影响性能。<br>选择：</p>\n<ul>\n<li>select() 函数调用使用一个静态结构，它事先被硬编码为相当小的数量（1024 个连接），因此不适用于非常大的部署。</li>\n</ul>\n<p>上面的所有解决方案都用简单的循环等待并处理请求，然后把请求分派给另一个函数以处理实际的网络交互。关键在于循环和网络套接字需要大量管理代码，这样才能监听、更新和控制不同的连接和接口。</p>\n<p>libevent 库实际上没有更换 select()、poll() 或其他机制的基础。而是使用对于每个平台最高效的高性能解决方案在实现外加上一个包装器。为了实际处理每个请求，libevent 库提供一种事件机制，它作为底层网络后端的包装器。事件系统让为连接添加处理函数变得非常简便，同时降低了底层 I/O 复杂性。这是 libevent 系统的核心。</p>\n<p>创建 libevent 服务器的基本方法是:</p>\n<ul>\n<li><p>注册当发生某一操作（比如接受来自客户端的连接）时应该执行的函数，然后调用主事件循环 event_dispatch()。</p>\n</li>\n<li><p>执行过程的控制现在由 libevent 系统处理。注册事件和将调用的函数之后，事件系统开始自治；</p>\n</li>\n<li><p>在应用程序运行时，可以在事件队列中添加（注册）或删除（取消注册）事件。事件注册非常方便，可以通过它添加新事件以处理新打开的连接，从而构建灵活的网络处理系统。</p>\n</li>\n</ul>\n<p>流程：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">event_set() //函数创建新的事件结构</span><br><span class=\"line\">event_add() //在事件队列机制中添加事件；</span><br><span class=\"line\">event_dispatch() // 启动事件队列系统，开始监听（并接受）请求。</span><br></pre></td></tr></table></figure>\n<h3 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips\"></a>Tips</h3><p>Tips:编译过程中需要 -levent<br>用libevent库写的EchoServer：代码<a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/libevent\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"好奇折腾libevent\"><a href=\"#好奇折腾libevent\" class=\"headerlink\" title=\"好奇折腾libevent\"></a>好奇折腾libevent</h3><p>原理介绍转自<a href=\"www.ibm.com/developerworks/cn/aix/library/au-libev/\">IBM developworks</a></p>\n<p>处理多个连接有许多不同的传统方法，但是在处理大量连接时它们往往会产生问题，因为它们使用的内存或 CPU 太多，或者达到了某个操作系统限制。</p>\n<p>网络连接使用的主要方法如下：</p>\n<ul>\n<li>循环：</li>\n</ul>\n<p>早期系统使用简单的循环选择解决方案，即循环遍历打开的网络连接的列表，判断是否有要读取的数据。这种方法既缓慢（尤其是随着连接数量增加越来越慢),又低效（因为在处理当前连接时其他连接可能正在发送请求并等待响应）。在系统循环遍历每个连接时，其他连接不得不等待。如果有100 个连接，其中只有一个有数据，那么仍然必须处理其他 99 个连接，才能轮到真正需要处理的连接。</p>\n<ul>\n<li>poll、epoll 和变体：</li>\n</ul>\n<p>这是对循环方法的改进，它用一个结构保存要监视的每个连接的数组，当在网络套接字上发现数据时，通过回调机制调用处理函数。poll 的问题是这个结构会非常大，在列表中添加新的网络连接时，修改结构会增加负载并影响性能。<br>选择：</p>\n<ul>\n<li>select() 函数调用使用一个静态结构，它事先被硬编码为相当小的数量（1024 个连接），因此不适用于非常大的部署。</li>\n</ul>\n<p>上面的所有解决方案都用简单的循环等待并处理请求，然后把请求分派给另一个函数以处理实际的网络交互。关键在于循环和网络套接字需要大量管理代码，这样才能监听、更新和控制不同的连接和接口。</p>\n<p>libevent 库实际上没有更换 select()、poll() 或其他机制的基础。而是使用对于每个平台最高效的高性能解决方案在实现外加上一个包装器。为了实际处理每个请求，libevent 库提供一种事件机制，它作为底层网络后端的包装器。事件系统让为连接添加处理函数变得非常简便，同时降低了底层 I/O 复杂性。这是 libevent 系统的核心。</p>\n<p>创建 libevent 服务器的基本方法是:</p>\n<ul>\n<li><p>注册当发生某一操作（比如接受来自客户端的连接）时应该执行的函数，然后调用主事件循环 event_dispatch()。</p>\n</li>\n<li><p>执行过程的控制现在由 libevent 系统处理。注册事件和将调用的函数之后，事件系统开始自治；</p>\n</li>\n<li><p>在应用程序运行时，可以在事件队列中添加（注册）或删除（取消注册）事件。事件注册非常方便，可以通过它添加新事件以处理新打开的连接，从而构建灵活的网络处理系统。</p>\n</li>\n</ul>\n<p>流程：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">event_set() //函数创建新的事件结构</span><br><span class=\"line\">event_add() //在事件队列机制中添加事件；</span><br><span class=\"line\">event_dispatch() // 启动事件队列系统，开始监听（并接受）请求。</span><br></pre></td></tr></table></figure>\n<h3 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips\"></a>Tips</h3><p>Tips:编译过程中需要 -levent<br>用libevent库写的EchoServer：代码<a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/libevent\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n"},{"layout":"post","title":"C++与Python的混合编程","date":"2013-06-08T15:42:00.000Z","comments":1,"_content":"#### python拓展编写\nC++编写python的拓展。提高程序运行效率\n我理解的一般流程:\n* 编写自己的业务逻辑代码本例子如\n\n```\nstring add(int a,int b)\n```\n\n* 包装为python函数，用于解析python传进来的参数\n\n```c\nPyObject* wrap_add(PyObject* self,PyObject* args);\n//解析参数\nPyArg_ParseTuple(args,\"i|i\",&a,&b);\n//构建返回值\nPy_BuildValue(\"s\",add(a,b).c_str());\n```\n\n* 编写映射函数\n\n```c\nstatic PyMethodDef bintMethods[] =\n{\n        {\"add\", wrap_add, METH_VARARGS, \"For add\"},\n            {NULL, NULL,0,NULL}\n}\n```\n\n*.模块初始化函数\n\n```c\nvoid initbint() {\n    PyObject* m;\n    m = Py_InitModule(\"bint\", bintMethods);\n}\n\n```\n\n如下\n\n```c    \n#include \"BigNum.h\"\n#include <python2.7/Python.h>\n#include <iostream>\n\nstring add(int a,int b) {\n    Bint num1(a);\n    Bint num2(b);\n    Bint ans = num1 + num2;\n    return Bint::write(ans);\n}\n\nstring multiple(int a,int b) {\n    Bint num1(a);\n    Bint num2(b);\n    Bint ans = num1 * num2;\n    return Bint::write(ans);\n}\n\nPyObject* wrap_add(PyObject* self,PyObject* args) {\n    int a,b;\n    if (!PyArg_ParseTuple(args,\"i|i\",&a,&b))\n        return NULL;\n    return Py_BuildValue(\"s\",add(a,b).c_str());\n}\n\nPyObject* wrap_mul(PyObject* self,PyObject* args) {\n    int a,b;\n    if (!PyArg_ParseTuple(args,\"i|i\",&a,&b))\n        return NULL;\n    return Py_BuildValue(\"s\",multiple(a,b).c_str());\n}\n\nstatic PyMethodDef bintMethods[] =\n{\n    {\"add\", wrap_add, METH_VARARGS, \"For add\"},\n    {\"mul\", wrap_mul, METH_VARARGS, \"For mul\"},\n    {NULL, NULL,0,NULL}\n};\n\nextern \"C\"              //不加会导致找不到initbint\nvoid initbint() {\n    PyObject* m;\n    m = Py_InitModule(\"bint\", bintMethods);\n}\n```\n\n编译成动态链接库\n\n```\nall:\n    g++ -fPIC -shared BigNum.cpp -o Bint.so\nclean:\n    rm -rf bint.so\n```\n\n```python           \nimport bint\nbint.mul(4000000,5000000)\n```\n\nGitHub上有[源码](http://innerbrilliant.sinaapp.com/?p=515)\n\n### C++调用Python\n\npython的开发效率之高是毋庸置疑的，C++/C的语言性能之快也是让人羡慕的。这一次，鱼和熊掌是可以兼得的 ：），混合编程，使得我们可以取之所长，游走在C与python之间。很多游戏开发中使用python来实现战斗脚本。\n* 初始化调用\nPy_Initialize();\n\n* PyObject* PyImport_ImportModule (char *name)\n一般都是通过(pmod = PyImport_ImportModule (\"zhengji.app_context\")先来\n加载一个模块（py脚本),得到一个PyObject *pmod对象,失败返回NULL类型\n\n* 获取某个方法或者类，PyObject * o是pmod\nPyObject* PyObject_GetAttrString (PyObject *o, char *attr_name)\n \n*调用该方法 callable_object是第二步返回的指针\nPyObject* PyObject_CallFunction (PyObject *callable_object, char *format, ...)\n \n* 将PyObject* 返回char*\nchar* PyString_AsString (PyObject *string)\n \n* 结束初始化\nPy_Finalize();\n\n下面是script.py的内容\n\n```python\n#!/usr/bin/python\n# Filename: script.py\nclass Student:\n    def SetName(self,name):\n        self._name = name\n    def PrintName(self):\n        print self._name\n    def hello():\n        print \"Hello World\\n\"\n    def world(name):\n        print \"name\" \n```\n\n#### C++调用Script.py\n\n```c\n#include <python2.7/Python.h>\n#include <iostream>\n#include <string>\n\nint main () {\n\n    //使用python之前，要调用Py_Initialize();这个函数进行初始化\n    Py_Initialize();\n\n    PyRun_SimpleString(\"import sys\");\n    PyRun_SimpleString(\"sys.path.append('./')\");\n\n    PyObject * pModule = NULL;\n    PyObject * pFunc = NULL;\n    PyObject * pClass = NULL;\n    PyObject * pInstance = NULL;\n\n    //这里是要调用的文件名\n    pModule = PyImport_ImportModule(\"script\");\n    //这里是要调用的函数名\n    pFunc= PyObject_GetAttrString(pModule, \"hello\");\n    //调用函数\n    PyEval_CallObject(pFunc, NULL);\n    Py_DECREF(pFunc); \n\n    pFunc = PyObject_GetAttrString(pModule, \"world\");\n    PyObject_CallFunction(pFunc, \"s\", \"zhengji\");\n    Py_DECREF(pFunc); \n\n    //测试调用python的类\n    pClass = PyObject_GetAttrString(pModule, \"Student\");\n    if (!pClass) {\n        printf(\"Can't find Student class.\\n\");\n        return -1;\n    }\n    pInstance = PyInstance_New(pClass, NULL, NULL);\n    if (!pInstance) {\n        printf(\"Can't create Student instance.\\n\");\n        return -1;\n    }\n    PyObject_CallMethod(pInstance, \"SetName\", \"s\",\"my family\");\n    PyObject_CallMethod(pInstance, \"PrintName\",NULL,NULL);\n    //调用Py_Finalize，这个根Py_Initialize相对应的。\n    Py_Finalize();\n    return 0;\n}\n```\n\n编译C++代码\n\n```\ng++ zj.cpp -o zj -lpython2.7\n```\n\n输出结果\n\n```\nzj@hp:~/tmp/CcalPy$ ./zj\nHello World\nname\nmy family\n```\n\n","source":"_posts/2013-08-29-c-plus-plus-yu-pythonde-hun-he-bian-cheng-pythontuo-zhan-bian-xie.markdown","raw":"---\nlayout: post\ntitle: \"C++与Python的混合编程\"\ndate: 2013-06-08 23:42\ncomments: true\ncategories: Programe\n---\n#### python拓展编写\nC++编写python的拓展。提高程序运行效率\n我理解的一般流程:\n* 编写自己的业务逻辑代码本例子如\n\n```\nstring add(int a,int b)\n```\n\n* 包装为python函数，用于解析python传进来的参数\n\n```c\nPyObject* wrap_add(PyObject* self,PyObject* args);\n//解析参数\nPyArg_ParseTuple(args,\"i|i\",&a,&b);\n//构建返回值\nPy_BuildValue(\"s\",add(a,b).c_str());\n```\n\n* 编写映射函数\n\n```c\nstatic PyMethodDef bintMethods[] =\n{\n        {\"add\", wrap_add, METH_VARARGS, \"For add\"},\n            {NULL, NULL,0,NULL}\n}\n```\n\n*.模块初始化函数\n\n```c\nvoid initbint() {\n    PyObject* m;\n    m = Py_InitModule(\"bint\", bintMethods);\n}\n\n```\n\n如下\n\n```c    \n#include \"BigNum.h\"\n#include <python2.7/Python.h>\n#include <iostream>\n\nstring add(int a,int b) {\n    Bint num1(a);\n    Bint num2(b);\n    Bint ans = num1 + num2;\n    return Bint::write(ans);\n}\n\nstring multiple(int a,int b) {\n    Bint num1(a);\n    Bint num2(b);\n    Bint ans = num1 * num2;\n    return Bint::write(ans);\n}\n\nPyObject* wrap_add(PyObject* self,PyObject* args) {\n    int a,b;\n    if (!PyArg_ParseTuple(args,\"i|i\",&a,&b))\n        return NULL;\n    return Py_BuildValue(\"s\",add(a,b).c_str());\n}\n\nPyObject* wrap_mul(PyObject* self,PyObject* args) {\n    int a,b;\n    if (!PyArg_ParseTuple(args,\"i|i\",&a,&b))\n        return NULL;\n    return Py_BuildValue(\"s\",multiple(a,b).c_str());\n}\n\nstatic PyMethodDef bintMethods[] =\n{\n    {\"add\", wrap_add, METH_VARARGS, \"For add\"},\n    {\"mul\", wrap_mul, METH_VARARGS, \"For mul\"},\n    {NULL, NULL,0,NULL}\n};\n\nextern \"C\"              //不加会导致找不到initbint\nvoid initbint() {\n    PyObject* m;\n    m = Py_InitModule(\"bint\", bintMethods);\n}\n```\n\n编译成动态链接库\n\n```\nall:\n    g++ -fPIC -shared BigNum.cpp -o Bint.so\nclean:\n    rm -rf bint.so\n```\n\n```python           \nimport bint\nbint.mul(4000000,5000000)\n```\n\nGitHub上有[源码](http://innerbrilliant.sinaapp.com/?p=515)\n\n### C++调用Python\n\npython的开发效率之高是毋庸置疑的，C++/C的语言性能之快也是让人羡慕的。这一次，鱼和熊掌是可以兼得的 ：），混合编程，使得我们可以取之所长，游走在C与python之间。很多游戏开发中使用python来实现战斗脚本。\n* 初始化调用\nPy_Initialize();\n\n* PyObject* PyImport_ImportModule (char *name)\n一般都是通过(pmod = PyImport_ImportModule (\"zhengji.app_context\")先来\n加载一个模块（py脚本),得到一个PyObject *pmod对象,失败返回NULL类型\n\n* 获取某个方法或者类，PyObject * o是pmod\nPyObject* PyObject_GetAttrString (PyObject *o, char *attr_name)\n \n*调用该方法 callable_object是第二步返回的指针\nPyObject* PyObject_CallFunction (PyObject *callable_object, char *format, ...)\n \n* 将PyObject* 返回char*\nchar* PyString_AsString (PyObject *string)\n \n* 结束初始化\nPy_Finalize();\n\n下面是script.py的内容\n\n```python\n#!/usr/bin/python\n# Filename: script.py\nclass Student:\n    def SetName(self,name):\n        self._name = name\n    def PrintName(self):\n        print self._name\n    def hello():\n        print \"Hello World\\n\"\n    def world(name):\n        print \"name\" \n```\n\n#### C++调用Script.py\n\n```c\n#include <python2.7/Python.h>\n#include <iostream>\n#include <string>\n\nint main () {\n\n    //使用python之前，要调用Py_Initialize();这个函数进行初始化\n    Py_Initialize();\n\n    PyRun_SimpleString(\"import sys\");\n    PyRun_SimpleString(\"sys.path.append('./')\");\n\n    PyObject * pModule = NULL;\n    PyObject * pFunc = NULL;\n    PyObject * pClass = NULL;\n    PyObject * pInstance = NULL;\n\n    //这里是要调用的文件名\n    pModule = PyImport_ImportModule(\"script\");\n    //这里是要调用的函数名\n    pFunc= PyObject_GetAttrString(pModule, \"hello\");\n    //调用函数\n    PyEval_CallObject(pFunc, NULL);\n    Py_DECREF(pFunc); \n\n    pFunc = PyObject_GetAttrString(pModule, \"world\");\n    PyObject_CallFunction(pFunc, \"s\", \"zhengji\");\n    Py_DECREF(pFunc); \n\n    //测试调用python的类\n    pClass = PyObject_GetAttrString(pModule, \"Student\");\n    if (!pClass) {\n        printf(\"Can't find Student class.\\n\");\n        return -1;\n    }\n    pInstance = PyInstance_New(pClass, NULL, NULL);\n    if (!pInstance) {\n        printf(\"Can't create Student instance.\\n\");\n        return -1;\n    }\n    PyObject_CallMethod(pInstance, \"SetName\", \"s\",\"my family\");\n    PyObject_CallMethod(pInstance, \"PrintName\",NULL,NULL);\n    //调用Py_Finalize，这个根Py_Initialize相对应的。\n    Py_Finalize();\n    return 0;\n}\n```\n\n编译C++代码\n\n```\ng++ zj.cpp -o zj -lpython2.7\n```\n\n输出结果\n\n```\nzj@hp:~/tmp/CcalPy$ ./zj\nHello World\nname\nmy family\n```\n\n","slug":"2013-08-29-c-plus-plus-yu-pythonde-hun-he-bian-cheng-pythontuo-zhan-bian-xie","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8b000inctjb033fsxj","content":"<h4 id=\"python拓展编写\"><a href=\"#python拓展编写\" class=\"headerlink\" title=\"python拓展编写\"></a>python拓展编写</h4><p>C++编写python的拓展。提高程序运行效率<br>我理解的一般流程:</p>\n<ul>\n<li>编写自己的业务逻辑代码本例子如</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">string add(int a,int b)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>包装为python函数，用于解析python传进来的参数</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyObject* <span class=\"title\">wrap_add</span><span class=\"params\">(PyObject* self,PyObject* args)</span></span>;</span><br><span class=\"line\"><span class=\"comment\">//解析参数</span></span><br><span class=\"line\">PyArg_ParseTuple(args,<span class=\"string\">\"i|i\"</span>,&amp;a,&amp;b);</span><br><span class=\"line\"><span class=\"comment\">//构建返回值</span></span><br><span class=\"line\">Py_BuildValue(<span class=\"string\">\"s\"</span>,add(a,b).c_str());</span><br></pre></td></tr></table></figure>\n<ul>\n<li>编写映射函数</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyMethodDef bintMethods[] =</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        &#123;<span class=\"string\">\"add\"</span>, wrap_add, METH_VARARGS, <span class=\"string\">\"For add\"</span>&#125;,</span><br><span class=\"line\">            &#123;<span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>,<span class=\"number\">0</span>,<span class=\"literal\">NULL</span>&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>*.模块初始化函数</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">initbint</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    PyObject* m;</span><br><span class=\"line\">    m = Py_InitModule(<span class=\"string\">\"bint\"</span>, bintMethods);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如下</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"BigNum.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;python2.7/Python.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">add</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\">Bint <span class=\"title\">num1</span><span class=\"params\">(a)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">Bint <span class=\"title\">num2</span><span class=\"params\">(b)</span></span>;</span><br><span class=\"line\">    Bint ans = num1 + num2;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Bint::write(ans);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">multiple</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\">Bint <span class=\"title\">num1</span><span class=\"params\">(a)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">Bint <span class=\"title\">num2</span><span class=\"params\">(b)</span></span>;</span><br><span class=\"line\">    Bint ans = num1 * num2;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Bint::write(ans);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">PyObject* <span class=\"title\">wrap_add</span><span class=\"params\">(PyObject* self,PyObject* args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a,b;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!PyArg_ParseTuple(args,<span class=\"string\">\"i|i\"</span>,&amp;a,&amp;b))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Py_BuildValue(<span class=\"string\">\"s\"</span>,add(a,b).c_str());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">PyObject* <span class=\"title\">wrap_mul</span><span class=\"params\">(PyObject* self,PyObject* args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a,b;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!PyArg_ParseTuple(args,<span class=\"string\">\"i|i\"</span>,&amp;a,&amp;b))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Py_BuildValue(<span class=\"string\">\"s\"</span>,multiple(a,b).c_str());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> PyMethodDef bintMethods[] =</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &#123;<span class=\"string\">\"add\"</span>, wrap_add, METH_VARARGS, <span class=\"string\">\"For add\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"mul\"</span>, wrap_mul, METH_VARARGS, <span class=\"string\">\"For mul\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>,<span class=\"number\">0</span>,<span class=\"literal\">NULL</span>&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"string\">\"C\"</span>              <span class=\"comment\">//不加会导致找不到initbint</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">initbint</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    PyObject* m;</span><br><span class=\"line\">    m = Py_InitModule(<span class=\"string\">\"bint\"</span>, bintMethods);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>编译成动态链接库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">all:</span><br><span class=\"line\">    g++ -fPIC -shared BigNum.cpp -o Bint.so</span><br><span class=\"line\">clean:</span><br><span class=\"line\">    rm -rf bint.so</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> bint</span><br><span class=\"line\">bint.mul(<span class=\"number\">4000000</span>,<span class=\"number\">5000000</span>)</span><br></pre></td></tr></table></figure>\n<p>GitHub上有<a href=\"http://innerbrilliant.sinaapp.com/?p=515\" target=\"_blank\" rel=\"noopener\">源码</a></p>\n<h3 id=\"C-调用Python\"><a href=\"#C-调用Python\" class=\"headerlink\" title=\"C++调用Python\"></a>C++调用Python</h3><p>python的开发效率之高是毋庸置疑的，C++/C的语言性能之快也是让人羡慕的。这一次，鱼和熊掌是可以兼得的 ：），混合编程，使得我们可以取之所长，游走在C与python之间。很多游戏开发中使用python来实现战斗脚本。</p>\n<ul>\n<li><p>初始化调用<br>Py_Initialize();</p>\n</li>\n<li><p>PyObject<em> PyImport_ImportModule (char </em>name)<br>一般都是通过(pmod = PyImport_ImportModule (“zhengji.app_context”)先来<br>加载一个模块（py脚本),得到一个PyObject *pmod对象,失败返回NULL类型</p>\n</li>\n<li><p>获取某个方法或者类，PyObject <em> o是pmod<br>PyObject</em> PyObject_GetAttrString (PyObject <em>o, char </em>attr_name)</p>\n</li>\n</ul>\n<p><em>调用该方法 callable_object是第二步返回的指针<br>PyObject</em> PyObject_CallFunction (PyObject <em>callable_object, char </em>format, …)</p>\n<ul>\n<li><p>将PyObject<em> 返回char</em><br>char<em> PyString_AsString (PyObject </em>string)</p>\n</li>\n<li><p>结束初始化<br>Py_Finalize();</p>\n</li>\n</ul>\n<p>下面是script.py的内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/python</span></span><br><span class=\"line\"><span class=\"comment\"># Filename: script.py</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Student</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">SetName</span><span class=\"params\">(self,name)</span>:</span></span><br><span class=\"line\">        self._name = name</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">PrintName</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">print</span> self._name</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hello</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">\"Hello World\\n\"</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">world</span><span class=\"params\">(name)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">\"name\"</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"C-调用Script-py\"><a href=\"#C-调用Script-py\" class=\"headerlink\" title=\"C++调用Script.py\"></a>C++调用Script.py</h4><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;python2.7/Python.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span> <span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//使用python之前，要调用Py_Initialize();这个函数进行初始化</span></span><br><span class=\"line\">    Py_Initialize();</span><br><span class=\"line\"></span><br><span class=\"line\">    PyRun_SimpleString(<span class=\"string\">\"import sys\"</span>);</span><br><span class=\"line\">    PyRun_SimpleString(<span class=\"string\">\"sys.path.append('./')\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    PyObject * pModule = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    PyObject * pFunc = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    PyObject * pClass = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    PyObject * pInstance = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//这里是要调用的文件名</span></span><br><span class=\"line\">    pModule = PyImport_ImportModule(<span class=\"string\">\"script\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">//这里是要调用的函数名</span></span><br><span class=\"line\">    pFunc= PyObject_GetAttrString(pModule, <span class=\"string\">\"hello\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">//调用函数</span></span><br><span class=\"line\">    PyEval_CallObject(pFunc, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    Py_DECREF(pFunc); </span><br><span class=\"line\"></span><br><span class=\"line\">    pFunc = PyObject_GetAttrString(pModule, <span class=\"string\">\"world\"</span>);</span><br><span class=\"line\">    PyObject_CallFunction(pFunc, <span class=\"string\">\"s\"</span>, <span class=\"string\">\"zhengji\"</span>);</span><br><span class=\"line\">    Py_DECREF(pFunc); </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//测试调用python的类</span></span><br><span class=\"line\">    pClass = PyObject_GetAttrString(pModule, <span class=\"string\">\"Student\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!pClass) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"Can't find Student class.\\n\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    pInstance = PyInstance_New(pClass, <span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!pInstance) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"Can't create Student instance.\\n\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    PyObject_CallMethod(pInstance, <span class=\"string\">\"SetName\"</span>, <span class=\"string\">\"s\"</span>,<span class=\"string\">\"my family\"</span>);</span><br><span class=\"line\">    PyObject_CallMethod(pInstance, <span class=\"string\">\"PrintName\"</span>,<span class=\"literal\">NULL</span>,<span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"comment\">//调用Py_Finalize，这个根Py_Initialize相对应的。</span></span><br><span class=\"line\">    Py_Finalize();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>编译C++代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ zj.cpp -o zj -lpython2.7</span><br></pre></td></tr></table></figure>\n<p>输出结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@hp:~/tmp/CcalPy$ ./zj</span><br><span class=\"line\">Hello World</span><br><span class=\"line\">name</span><br><span class=\"line\">my family</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"python拓展编写\"><a href=\"#python拓展编写\" class=\"headerlink\" title=\"python拓展编写\"></a>python拓展编写</h4><p>C++编写python的拓展。提高程序运行效率<br>我理解的一般流程:</p>\n<ul>\n<li>编写自己的业务逻辑代码本例子如</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">string add(int a,int b)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>包装为python函数，用于解析python传进来的参数</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyObject* <span class=\"title\">wrap_add</span><span class=\"params\">(PyObject* self,PyObject* args)</span></span>;</span><br><span class=\"line\"><span class=\"comment\">//解析参数</span></span><br><span class=\"line\">PyArg_ParseTuple(args,<span class=\"string\">\"i|i\"</span>,&amp;a,&amp;b);</span><br><span class=\"line\"><span class=\"comment\">//构建返回值</span></span><br><span class=\"line\">Py_BuildValue(<span class=\"string\">\"s\"</span>,add(a,b).c_str());</span><br></pre></td></tr></table></figure>\n<ul>\n<li>编写映射函数</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyMethodDef bintMethods[] =</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        &#123;<span class=\"string\">\"add\"</span>, wrap_add, METH_VARARGS, <span class=\"string\">\"For add\"</span>&#125;,</span><br><span class=\"line\">            &#123;<span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>,<span class=\"number\">0</span>,<span class=\"literal\">NULL</span>&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>*.模块初始化函数</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">initbint</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    PyObject* m;</span><br><span class=\"line\">    m = Py_InitModule(<span class=\"string\">\"bint\"</span>, bintMethods);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如下</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"BigNum.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;python2.7/Python.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">add</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\">Bint <span class=\"title\">num1</span><span class=\"params\">(a)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">Bint <span class=\"title\">num2</span><span class=\"params\">(b)</span></span>;</span><br><span class=\"line\">    Bint ans = num1 + num2;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Bint::write(ans);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">multiple</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\">Bint <span class=\"title\">num1</span><span class=\"params\">(a)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">Bint <span class=\"title\">num2</span><span class=\"params\">(b)</span></span>;</span><br><span class=\"line\">    Bint ans = num1 * num2;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Bint::write(ans);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">PyObject* <span class=\"title\">wrap_add</span><span class=\"params\">(PyObject* self,PyObject* args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a,b;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!PyArg_ParseTuple(args,<span class=\"string\">\"i|i\"</span>,&amp;a,&amp;b))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Py_BuildValue(<span class=\"string\">\"s\"</span>,add(a,b).c_str());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">PyObject* <span class=\"title\">wrap_mul</span><span class=\"params\">(PyObject* self,PyObject* args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> a,b;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!PyArg_ParseTuple(args,<span class=\"string\">\"i|i\"</span>,&amp;a,&amp;b))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Py_BuildValue(<span class=\"string\">\"s\"</span>,multiple(a,b).c_str());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> PyMethodDef bintMethods[] =</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &#123;<span class=\"string\">\"add\"</span>, wrap_add, METH_VARARGS, <span class=\"string\">\"For add\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"mul\"</span>, wrap_mul, METH_VARARGS, <span class=\"string\">\"For mul\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>,<span class=\"number\">0</span>,<span class=\"literal\">NULL</span>&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"string\">\"C\"</span>              <span class=\"comment\">//不加会导致找不到initbint</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">initbint</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    PyObject* m;</span><br><span class=\"line\">    m = Py_InitModule(<span class=\"string\">\"bint\"</span>, bintMethods);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>编译成动态链接库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">all:</span><br><span class=\"line\">    g++ -fPIC -shared BigNum.cpp -o Bint.so</span><br><span class=\"line\">clean:</span><br><span class=\"line\">    rm -rf bint.so</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> bint</span><br><span class=\"line\">bint.mul(<span class=\"number\">4000000</span>,<span class=\"number\">5000000</span>)</span><br></pre></td></tr></table></figure>\n<p>GitHub上有<a href=\"http://innerbrilliant.sinaapp.com/?p=515\" target=\"_blank\" rel=\"noopener\">源码</a></p>\n<h3 id=\"C-调用Python\"><a href=\"#C-调用Python\" class=\"headerlink\" title=\"C++调用Python\"></a>C++调用Python</h3><p>python的开发效率之高是毋庸置疑的，C++/C的语言性能之快也是让人羡慕的。这一次，鱼和熊掌是可以兼得的 ：），混合编程，使得我们可以取之所长，游走在C与python之间。很多游戏开发中使用python来实现战斗脚本。</p>\n<ul>\n<li><p>初始化调用<br>Py_Initialize();</p>\n</li>\n<li><p>PyObject<em> PyImport_ImportModule (char </em>name)<br>一般都是通过(pmod = PyImport_ImportModule (“zhengji.app_context”)先来<br>加载一个模块（py脚本),得到一个PyObject *pmod对象,失败返回NULL类型</p>\n</li>\n<li><p>获取某个方法或者类，PyObject <em> o是pmod<br>PyObject</em> PyObject_GetAttrString (PyObject <em>o, char </em>attr_name)</p>\n</li>\n</ul>\n<p><em>调用该方法 callable_object是第二步返回的指针<br>PyObject</em> PyObject_CallFunction (PyObject <em>callable_object, char </em>format, …)</p>\n<ul>\n<li><p>将PyObject<em> 返回char</em><br>char<em> PyString_AsString (PyObject </em>string)</p>\n</li>\n<li><p>结束初始化<br>Py_Finalize();</p>\n</li>\n</ul>\n<p>下面是script.py的内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/python</span></span><br><span class=\"line\"><span class=\"comment\"># Filename: script.py</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Student</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">SetName</span><span class=\"params\">(self,name)</span>:</span></span><br><span class=\"line\">        self._name = name</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">PrintName</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">print</span> self._name</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hello</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">\"Hello World\\n\"</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">world</span><span class=\"params\">(name)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">\"name\"</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"C-调用Script-py\"><a href=\"#C-调用Script-py\" class=\"headerlink\" title=\"C++调用Script.py\"></a>C++调用Script.py</h4><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;python2.7/Python.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span> <span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//使用python之前，要调用Py_Initialize();这个函数进行初始化</span></span><br><span class=\"line\">    Py_Initialize();</span><br><span class=\"line\"></span><br><span class=\"line\">    PyRun_SimpleString(<span class=\"string\">\"import sys\"</span>);</span><br><span class=\"line\">    PyRun_SimpleString(<span class=\"string\">\"sys.path.append('./')\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    PyObject * pModule = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    PyObject * pFunc = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    PyObject * pClass = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    PyObject * pInstance = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//这里是要调用的文件名</span></span><br><span class=\"line\">    pModule = PyImport_ImportModule(<span class=\"string\">\"script\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">//这里是要调用的函数名</span></span><br><span class=\"line\">    pFunc= PyObject_GetAttrString(pModule, <span class=\"string\">\"hello\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">//调用函数</span></span><br><span class=\"line\">    PyEval_CallObject(pFunc, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    Py_DECREF(pFunc); </span><br><span class=\"line\"></span><br><span class=\"line\">    pFunc = PyObject_GetAttrString(pModule, <span class=\"string\">\"world\"</span>);</span><br><span class=\"line\">    PyObject_CallFunction(pFunc, <span class=\"string\">\"s\"</span>, <span class=\"string\">\"zhengji\"</span>);</span><br><span class=\"line\">    Py_DECREF(pFunc); </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//测试调用python的类</span></span><br><span class=\"line\">    pClass = PyObject_GetAttrString(pModule, <span class=\"string\">\"Student\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!pClass) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"Can't find Student class.\\n\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    pInstance = PyInstance_New(pClass, <span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!pInstance) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"Can't create Student instance.\\n\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    PyObject_CallMethod(pInstance, <span class=\"string\">\"SetName\"</span>, <span class=\"string\">\"s\"</span>,<span class=\"string\">\"my family\"</span>);</span><br><span class=\"line\">    PyObject_CallMethod(pInstance, <span class=\"string\">\"PrintName\"</span>,<span class=\"literal\">NULL</span>,<span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"comment\">//调用Py_Finalize，这个根Py_Initialize相对应的。</span></span><br><span class=\"line\">    Py_Finalize();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>编译C++代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ zj.cpp -o zj -lpython2.7</span><br></pre></td></tr></table></figure>\n<p>输出结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@hp:~/tmp/CcalPy$ ./zj</span><br><span class=\"line\">Hello World</span><br><span class=\"line\">name</span><br><span class=\"line\">my family</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"豆瓣喜爱文章下载器","date":"2013-06-12T15:31:00.000Z","comments":1,"_content":"收藏一些不错的文章\n\n在豆瓣阅读到一些好的文章，通常会点击加心喜爱。久而久之，就淡忘了，于是想把他们下载下来，用了一天的时间写了具有爬虫和分析功能的下载器。使用了BeautifulSoup,urllib模块.可以一次性抓取其他人的文章。\n\n使用方法：\n\n```python\nif __name__ == \"__main__\":\n    #用户名,可以写入douban ID\n    usrnames = [\"laiyonghao\",\"fenng\"]\n        for name in usrnames:\n                cwl = Crawler(name)\n        cwl.start()\n        parser = Parser(cwl)\n        parser.run()\n```\n>运行 python main.py\n\n结果 \n\n```\ntmp\n    ├── fenng\n    │   ├── Got talent?\n    │   ├── QCon Beijing 2013 乱记\n    │   ├── 北京生存指南\n    │   ├── 发现「讷客」\n    │   ├── 父亲谈创新\n    │   ├── 和菜头对豆瓣用户骂声的回应\n    │   ├── 胡扯两句\n    │   ├── 年会：公司人的新民俗\n    │   ├── 一个关于嘲笑的小故事\n    │   ├── 有些事，蹲在家里是永远实现不了的。\n    │   ├── 赞\n    │   └── 中国说唱教父--尹相杰&lt;转&gt;\n    └── laiyonghao\n        ├── Live Together, Hate Each Other\n        ├── 当初的愿望实现了么？\n        ├── 豆瓣阅读即将开售（已上线）\n        ├── 婚礼主题曲背后的故事\n        └── 科普也需严谨---对《数学之美》密码部分的评论\n```\n\n源代码[链接](https://github.com/zheng-ji/douban-likes-crawler.git)\nHappy Hacking : )\n\n\n","source":"_posts/2013-08-29-dou-ban-xi-ai-wen-zhang-xia-zai-qi.markdown","raw":"---\nlayout: post\ntitle: \"豆瓣喜爱文章下载器\"\ndate: 2013-06-12 23:31\ncomments: true\ncategories: Programe \n---\n收藏一些不错的文章\n\n在豆瓣阅读到一些好的文章，通常会点击加心喜爱。久而久之，就淡忘了，于是想把他们下载下来，用了一天的时间写了具有爬虫和分析功能的下载器。使用了BeautifulSoup,urllib模块.可以一次性抓取其他人的文章。\n\n使用方法：\n\n```python\nif __name__ == \"__main__\":\n    #用户名,可以写入douban ID\n    usrnames = [\"laiyonghao\",\"fenng\"]\n        for name in usrnames:\n                cwl = Crawler(name)\n        cwl.start()\n        parser = Parser(cwl)\n        parser.run()\n```\n>运行 python main.py\n\n结果 \n\n```\ntmp\n    ├── fenng\n    │   ├── Got talent?\n    │   ├── QCon Beijing 2013 乱记\n    │   ├── 北京生存指南\n    │   ├── 发现「讷客」\n    │   ├── 父亲谈创新\n    │   ├── 和菜头对豆瓣用户骂声的回应\n    │   ├── 胡扯两句\n    │   ├── 年会：公司人的新民俗\n    │   ├── 一个关于嘲笑的小故事\n    │   ├── 有些事，蹲在家里是永远实现不了的。\n    │   ├── 赞\n    │   └── 中国说唱教父--尹相杰&lt;转&gt;\n    └── laiyonghao\n        ├── Live Together, Hate Each Other\n        ├── 当初的愿望实现了么？\n        ├── 豆瓣阅读即将开售（已上线）\n        ├── 婚礼主题曲背后的故事\n        └── 科普也需严谨---对《数学之美》密码部分的评论\n```\n\n源代码[链接](https://github.com/zheng-ji/douban-likes-crawler.git)\nHappy Hacking : )\n\n\n","slug":"2013-08-29-dou-ban-xi-ai-wen-zhang-xia-zai-qi","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8d000knctjtwisrcjj","content":"<p>收藏一些不错的文章</p>\n<p>在豆瓣阅读到一些好的文章，通常会点击加心喜爱。久而久之，就淡忘了，于是想把他们下载下来，用了一天的时间写了具有爬虫和分析功能的下载器。使用了BeautifulSoup,urllib模块.可以一次性抓取其他人的文章。</p>\n<p>使用方法：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    <span class=\"comment\">#用户名,可以写入douban ID</span></span><br><span class=\"line\">    usrnames = [<span class=\"string\">\"laiyonghao\"</span>,<span class=\"string\">\"fenng\"</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> name <span class=\"keyword\">in</span> usrnames:</span><br><span class=\"line\">                cwl = Crawler(name)</span><br><span class=\"line\">        cwl.start()</span><br><span class=\"line\">        parser = Parser(cwl)</span><br><span class=\"line\">        parser.run()</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>运行 python main.py</p>\n</blockquote>\n<p>结果 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tmp</span><br><span class=\"line\">    ├── fenng</span><br><span class=\"line\">    │   ├── Got talent?</span><br><span class=\"line\">    │   ├── QCon Beijing 2013 乱记</span><br><span class=\"line\">    │   ├── 北京生存指南</span><br><span class=\"line\">    │   ├── 发现「讷客」</span><br><span class=\"line\">    │   ├── 父亲谈创新</span><br><span class=\"line\">    │   ├── 和菜头对豆瓣用户骂声的回应</span><br><span class=\"line\">    │   ├── 胡扯两句</span><br><span class=\"line\">    │   ├── 年会：公司人的新民俗</span><br><span class=\"line\">    │   ├── 一个关于嘲笑的小故事</span><br><span class=\"line\">    │   ├── 有些事，蹲在家里是永远实现不了的。</span><br><span class=\"line\">    │   ├── 赞</span><br><span class=\"line\">    │   └── 中国说唱教父--尹相杰&amp;lt;转&amp;gt;</span><br><span class=\"line\">    └── laiyonghao</span><br><span class=\"line\">        ├── Live Together, Hate Each Other</span><br><span class=\"line\">        ├── 当初的愿望实现了么？</span><br><span class=\"line\">        ├── 豆瓣阅读即将开售（已上线）</span><br><span class=\"line\">        ├── 婚礼主题曲背后的故事</span><br><span class=\"line\">        └── 科普也需严谨---对《数学之美》密码部分的评论</span><br></pre></td></tr></table></figure>\n<p>源代码<a href=\"https://github.com/zheng-ji/douban-likes-crawler.git\" target=\"_blank\" rel=\"noopener\">链接</a><br>Happy Hacking : )</p>\n","site":{"data":{}},"excerpt":"","more":"<p>收藏一些不错的文章</p>\n<p>在豆瓣阅读到一些好的文章，通常会点击加心喜爱。久而久之，就淡忘了，于是想把他们下载下来，用了一天的时间写了具有爬虫和分析功能的下载器。使用了BeautifulSoup,urllib模块.可以一次性抓取其他人的文章。</p>\n<p>使用方法：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    <span class=\"comment\">#用户名,可以写入douban ID</span></span><br><span class=\"line\">    usrnames = [<span class=\"string\">\"laiyonghao\"</span>,<span class=\"string\">\"fenng\"</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> name <span class=\"keyword\">in</span> usrnames:</span><br><span class=\"line\">                cwl = Crawler(name)</span><br><span class=\"line\">        cwl.start()</span><br><span class=\"line\">        parser = Parser(cwl)</span><br><span class=\"line\">        parser.run()</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>运行 python main.py</p>\n</blockquote>\n<p>结果 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tmp</span><br><span class=\"line\">    ├── fenng</span><br><span class=\"line\">    │   ├── Got talent?</span><br><span class=\"line\">    │   ├── QCon Beijing 2013 乱记</span><br><span class=\"line\">    │   ├── 北京生存指南</span><br><span class=\"line\">    │   ├── 发现「讷客」</span><br><span class=\"line\">    │   ├── 父亲谈创新</span><br><span class=\"line\">    │   ├── 和菜头对豆瓣用户骂声的回应</span><br><span class=\"line\">    │   ├── 胡扯两句</span><br><span class=\"line\">    │   ├── 年会：公司人的新民俗</span><br><span class=\"line\">    │   ├── 一个关于嘲笑的小故事</span><br><span class=\"line\">    │   ├── 有些事，蹲在家里是永远实现不了的。</span><br><span class=\"line\">    │   ├── 赞</span><br><span class=\"line\">    │   └── 中国说唱教父--尹相杰&amp;lt;转&amp;gt;</span><br><span class=\"line\">    └── laiyonghao</span><br><span class=\"line\">        ├── Live Together, Hate Each Other</span><br><span class=\"line\">        ├── 当初的愿望实现了么？</span><br><span class=\"line\">        ├── 豆瓣阅读即将开售（已上线）</span><br><span class=\"line\">        ├── 婚礼主题曲背后的故事</span><br><span class=\"line\">        └── 科普也需严谨---对《数学之美》密码部分的评论</span><br></pre></td></tr></table></figure>\n<p>源代码<a href=\"https://github.com/zheng-ji/douban-likes-crawler.git\" target=\"_blank\" rel=\"noopener\">链接</a><br>Happy Hacking : )</p>\n"},{"layout":"post","title":"返回值的透彻理解","date":"2013-04-20T15:06:00.000Z","comments":1,"_content":"在读《C++编程关键路径》的时候，看到有一章讲的很好。于是分享开来：\n\n```c\nvoid swap(int a, int b) {\n    int tmp;\n    tmp = a;\n    a = b;\n    b = tmp;\n}\nint get_ini(int a) {\n    int  i = i + a;\n    return i;\n}\n\nchar * get_memory0() {\n    char * p = (char *) malloc(sizeof(char ) * 20);\n    strcpy(p,\"hello world\");\n    return p;\n}\n\nchar * get_memory1() {\n    char * p = \"hello world\";\n    return p;\n}\n\nchar * get_memory2() {\n    char p[] = \"hello world\";\n    return p;\n}\n\nint main(int argc,char * argv[]){\n    int x = 4,y = 3;\n    swap(x,y);\n    int z = x - y;\n    printf(\"z = %d\\n\",z);//问题1\n\n    z = get_ini(z);\n    printf(\"z = %d\\n\",z);//问题2\n\n    char * c0 = get_memory0();//问题3\n    printf(\"c0 = %s\\n\",co);\n\n    char * c1 = get_memory1();//问题4\n    printf(\"c1 = %s\\n\",c1);\n\n    char * c2 = get_memory2();//问题5\n    printf(\"c1 = %s\\n\",c2);\n}\n```\n\n#### 问题1：\na,b没有发生交换，所有函数会在程序运行的时候程序栈上分配一块存储区，这块栈的函数存储区随函数开始而开始，随着函数结束而结束，函数结束后， 这块存储区自动释放，以供其他用途，栈的默认大小是1M,swap(int a, int b)是一个参数传值的函数，函数内部的a,b是参数int a 和 int b的局部拷贝，所以a，b实际可以看成局部变量，他们的值由int a ,int b实参复制而来，只在函数内部有效，当函数体内的a,b离开函数作用域时候，a,b变量就销毁了.函数实参值没有发生改变。\n\n#### 问题2：\n返回值i是一个局部变量，函数的返回参数怎么可能是局部变量？函数的返回值由传值和传址两种，传值会在返回处生成一个临时对象，\n用于存放局部变量i的一份拷贝。临时对象没有名称。虽然i被销毁了，但是他的拷贝仍然存在。并在函数返回处赋值给z.c0 = “hello world”\n\n#### 问题3：\n程序运行期间堆的内存一直都在。返回的p是会被销毁，但是在返回处有p的拷贝对象，指向堆的地址。c1 = “hello world”\n\n#### 问题4:\n常量存储区：”hello world”在程序运行期间都在\n\n#### 问题5：\np[]不是指针，是一个数组变量，函数返回时左值拷贝只想的是局部变量的p[12]的首地址，当局部数组p[12]离开作用域后会自动销毁，\n这时，函数返回的左值，拷贝指向的是一个被销毁的局部变量地址。所以c2 = 未知\n\n","source":"_posts/2013-08-29-fan-hui-zhi-de-tou-che-li-jie.markdown","raw":"---\nlayout: post\ntitle: \"返回值的透彻理解\"\ndate: 2013-04-20 23:06\ncomments: true\ncategories: Programe\n---\n在读《C++编程关键路径》的时候，看到有一章讲的很好。于是分享开来：\n\n```c\nvoid swap(int a, int b) {\n    int tmp;\n    tmp = a;\n    a = b;\n    b = tmp;\n}\nint get_ini(int a) {\n    int  i = i + a;\n    return i;\n}\n\nchar * get_memory0() {\n    char * p = (char *) malloc(sizeof(char ) * 20);\n    strcpy(p,\"hello world\");\n    return p;\n}\n\nchar * get_memory1() {\n    char * p = \"hello world\";\n    return p;\n}\n\nchar * get_memory2() {\n    char p[] = \"hello world\";\n    return p;\n}\n\nint main(int argc,char * argv[]){\n    int x = 4,y = 3;\n    swap(x,y);\n    int z = x - y;\n    printf(\"z = %d\\n\",z);//问题1\n\n    z = get_ini(z);\n    printf(\"z = %d\\n\",z);//问题2\n\n    char * c0 = get_memory0();//问题3\n    printf(\"c0 = %s\\n\",co);\n\n    char * c1 = get_memory1();//问题4\n    printf(\"c1 = %s\\n\",c1);\n\n    char * c2 = get_memory2();//问题5\n    printf(\"c1 = %s\\n\",c2);\n}\n```\n\n#### 问题1：\na,b没有发生交换，所有函数会在程序运行的时候程序栈上分配一块存储区，这块栈的函数存储区随函数开始而开始，随着函数结束而结束，函数结束后， 这块存储区自动释放，以供其他用途，栈的默认大小是1M,swap(int a, int b)是一个参数传值的函数，函数内部的a,b是参数int a 和 int b的局部拷贝，所以a，b实际可以看成局部变量，他们的值由int a ,int b实参复制而来，只在函数内部有效，当函数体内的a,b离开函数作用域时候，a,b变量就销毁了.函数实参值没有发生改变。\n\n#### 问题2：\n返回值i是一个局部变量，函数的返回参数怎么可能是局部变量？函数的返回值由传值和传址两种，传值会在返回处生成一个临时对象，\n用于存放局部变量i的一份拷贝。临时对象没有名称。虽然i被销毁了，但是他的拷贝仍然存在。并在函数返回处赋值给z.c0 = “hello world”\n\n#### 问题3：\n程序运行期间堆的内存一直都在。返回的p是会被销毁，但是在返回处有p的拷贝对象，指向堆的地址。c1 = “hello world”\n\n#### 问题4:\n常量存储区：”hello world”在程序运行期间都在\n\n#### 问题5：\np[]不是指针，是一个数组变量，函数返回时左值拷贝只想的是局部变量的p[12]的首地址，当局部数组p[12]离开作用域后会自动销毁，\n这时，函数返回的左值，拷贝指向的是一个被销毁的局部变量地址。所以c2 = 未知\n\n","slug":"2013-08-29-fan-hui-zhi-de-tou-che-li-jie","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8f000nnctjifkzbyrt","content":"<p>在读《C++编程关键路径》的时候，看到有一章讲的很好。于是分享开来：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> tmp;</span><br><span class=\"line\">    tmp = a;</span><br><span class=\"line\">    a = b;</span><br><span class=\"line\">    b = tmp;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">get_ini</span><span class=\"params\">(<span class=\"keyword\">int</span> a)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span>  i = i + a;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> * <span class=\"title\">get_memory0</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> * p = (<span class=\"keyword\">char</span> *) <span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">char</span> ) * <span class=\"number\">20</span>);</span><br><span class=\"line\">    <span class=\"built_in\">strcpy</span>(p,<span class=\"string\">\"hello world\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> * <span class=\"title\">get_memory1</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> * p = <span class=\"string\">\"hello world\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> * <span class=\"title\">get_memory2</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> p[] = <span class=\"string\">\"hello world\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc,<span class=\"keyword\">char</span> * argv[])</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> x = <span class=\"number\">4</span>,y = <span class=\"number\">3</span>;</span><br><span class=\"line\">    swap(x,y);</span><br><span class=\"line\">    <span class=\"keyword\">int</span> z = x - y;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"z = %d\\n\"</span>,z);<span class=\"comment\">//问题1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    z = get_ini(z);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"z = %d\\n\"</span>,z);<span class=\"comment\">//问题2</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">char</span> * c0 = get_memory0();<span class=\"comment\">//问题3</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"c0 = %s\\n\"</span>,co);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">char</span> * c1 = get_memory1();<span class=\"comment\">//问题4</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"c1 = %s\\n\"</span>,c1);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">char</span> * c2 = get_memory2();<span class=\"comment\">//问题5</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"c1 = %s\\n\"</span>,c2);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"问题1：\"><a href=\"#问题1：\" class=\"headerlink\" title=\"问题1：\"></a>问题1：</h4><p>a,b没有发生交换，所有函数会在程序运行的时候程序栈上分配一块存储区，这块栈的函数存储区随函数开始而开始，随着函数结束而结束，函数结束后， 这块存储区自动释放，以供其他用途，栈的默认大小是1M,swap(int a, int b)是一个参数传值的函数，函数内部的a,b是参数int a 和 int b的局部拷贝，所以a，b实际可以看成局部变量，他们的值由int a ,int b实参复制而来，只在函数内部有效，当函数体内的a,b离开函数作用域时候，a,b变量就销毁了.函数实参值没有发生改变。</p>\n<h4 id=\"问题2：\"><a href=\"#问题2：\" class=\"headerlink\" title=\"问题2：\"></a>问题2：</h4><p>返回值i是一个局部变量，函数的返回参数怎么可能是局部变量？函数的返回值由传值和传址两种，传值会在返回处生成一个临时对象，<br>用于存放局部变量i的一份拷贝。临时对象没有名称。虽然i被销毁了，但是他的拷贝仍然存在。并在函数返回处赋值给z.c0 = “hello world”</p>\n<h4 id=\"问题3：\"><a href=\"#问题3：\" class=\"headerlink\" title=\"问题3：\"></a>问题3：</h4><p>程序运行期间堆的内存一直都在。返回的p是会被销毁，但是在返回处有p的拷贝对象，指向堆的地址。c1 = “hello world”</p>\n<h4 id=\"问题4\"><a href=\"#问题4\" class=\"headerlink\" title=\"问题4:\"></a>问题4:</h4><p>常量存储区：”hello world”在程序运行期间都在</p>\n<h4 id=\"问题5：\"><a href=\"#问题5：\" class=\"headerlink\" title=\"问题5：\"></a>问题5：</h4><p>p[]不是指针，是一个数组变量，函数返回时左值拷贝只想的是局部变量的p[12]的首地址，当局部数组p[12]离开作用域后会自动销毁，<br>这时，函数返回的左值，拷贝指向的是一个被销毁的局部变量地址。所以c2 = 未知</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在读《C++编程关键路径》的时候，看到有一章讲的很好。于是分享开来：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> tmp;</span><br><span class=\"line\">    tmp = a;</span><br><span class=\"line\">    a = b;</span><br><span class=\"line\">    b = tmp;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">get_ini</span><span class=\"params\">(<span class=\"keyword\">int</span> a)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span>  i = i + a;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> i;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> * <span class=\"title\">get_memory0</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> * p = (<span class=\"keyword\">char</span> *) <span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">char</span> ) * <span class=\"number\">20</span>);</span><br><span class=\"line\">    <span class=\"built_in\">strcpy</span>(p,<span class=\"string\">\"hello world\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> * <span class=\"title\">get_memory1</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> * p = <span class=\"string\">\"hello world\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> * <span class=\"title\">get_memory2</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> p[] = <span class=\"string\">\"hello world\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc,<span class=\"keyword\">char</span> * argv[])</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> x = <span class=\"number\">4</span>,y = <span class=\"number\">3</span>;</span><br><span class=\"line\">    swap(x,y);</span><br><span class=\"line\">    <span class=\"keyword\">int</span> z = x - y;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"z = %d\\n\"</span>,z);<span class=\"comment\">//问题1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    z = get_ini(z);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"z = %d\\n\"</span>,z);<span class=\"comment\">//问题2</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">char</span> * c0 = get_memory0();<span class=\"comment\">//问题3</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"c0 = %s\\n\"</span>,co);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">char</span> * c1 = get_memory1();<span class=\"comment\">//问题4</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"c1 = %s\\n\"</span>,c1);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">char</span> * c2 = get_memory2();<span class=\"comment\">//问题5</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"c1 = %s\\n\"</span>,c2);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"问题1：\"><a href=\"#问题1：\" class=\"headerlink\" title=\"问题1：\"></a>问题1：</h4><p>a,b没有发生交换，所有函数会在程序运行的时候程序栈上分配一块存储区，这块栈的函数存储区随函数开始而开始，随着函数结束而结束，函数结束后， 这块存储区自动释放，以供其他用途，栈的默认大小是1M,swap(int a, int b)是一个参数传值的函数，函数内部的a,b是参数int a 和 int b的局部拷贝，所以a，b实际可以看成局部变量，他们的值由int a ,int b实参复制而来，只在函数内部有效，当函数体内的a,b离开函数作用域时候，a,b变量就销毁了.函数实参值没有发生改变。</p>\n<h4 id=\"问题2：\"><a href=\"#问题2：\" class=\"headerlink\" title=\"问题2：\"></a>问题2：</h4><p>返回值i是一个局部变量，函数的返回参数怎么可能是局部变量？函数的返回值由传值和传址两种，传值会在返回处生成一个临时对象，<br>用于存放局部变量i的一份拷贝。临时对象没有名称。虽然i被销毁了，但是他的拷贝仍然存在。并在函数返回处赋值给z.c0 = “hello world”</p>\n<h4 id=\"问题3：\"><a href=\"#问题3：\" class=\"headerlink\" title=\"问题3：\"></a>问题3：</h4><p>程序运行期间堆的内存一直都在。返回的p是会被销毁，但是在返回处有p的拷贝对象，指向堆的地址。c1 = “hello world”</p>\n<h4 id=\"问题4\"><a href=\"#问题4\" class=\"headerlink\" title=\"问题4:\"></a>问题4:</h4><p>常量存储区：”hello world”在程序运行期间都在</p>\n<h4 id=\"问题5：\"><a href=\"#问题5：\" class=\"headerlink\" title=\"问题5：\"></a>问题5：</h4><p>p[]不是指针，是一个数组变量，函数返回时左值拷贝只想的是局部变量的p[12]的首地址，当局部数组p[12]离开作用域后会自动销毁，<br>这时，函数返回的左值，拷贝指向的是一个被销毁的局部变量地址。所以c2 = 未知</p>\n"},{"layout":"post","title":"Google C++ Style","date":"2013-05-11T15:12:00.000Z","comments":1,"_content":"阅读完《Google C++ Style》记录些小要点，很多开源代码都是按照这个规则编码，在了解这些原则之后，个人感觉阅读开源代码应该会省很多力气。\n\n* 有头文件都应该使用 #define 防止头文件被多重包含, 命名格式当是: ___H__\n* 能用前置声明的地方尽量不使用 #include\n前置声明是为了降低编译依赖，防止修改一个头文件引发多米诺效应; 举例说明: 如果头文件中用到类 File, 但不需要访问 File 类的声明, 头文件中只需前置声明 class File; 而无须 #include “file/base/file.h”.\n\n* 只有当函数只有 10 行甚至更少时才将其定义为内联函数.\n当函数被声明为内联函数之后, 编译器会将其内联展开, 而不是按通常的函数调用机制进行调用.优点:当函数体比较小的时候, 内联该函数可以令目标代码更加高效. 对于存取函数以及其它函数体比较短, 性能关键的函数\n\n* 义函数时, 参数顺序依次为: 输入参数, 然后是输出参数。\n标准化函数参数顺序可以提高可读性和易维护性\n\n* 造函数体中进行初始化操作\n如果对象需要进行有意义的 (non-trivial) 初始化, 考虑使用明确的 Init() 方法并 (或) 增加一个成员标记用于指示对象是否已经初始化成功.\n\n* 单个参数的构造函数使用 C++ 关键字 explicit.\n    大部分类并不需要可拷贝, 也不需要一个拷贝构造函数或重载赋值运算符. 不幸的是, 如果你不主动声明它们, 编译器会为你自动生成, 而且是 public 的.可以考虑在类的 private: 中添加拷贝构造函数和赋值操作的空实现, 只有声明, 没有定义. 由于这些空函数声明为 private, 当其他代码试图使用它们的时候, 编译器将报错. 方便起见, 我们可以使用 DISALLOW_COPY_AND_ASSIGN 宏:\n\n```\n\n#define DISALLOW_COPY_AND_ASSIGN(TypeName) \\\n    TypeName(const TypeName&); \\\nvoid operator=(const TypeName&)\nclass Foo {\n    public:\n        Foo(int f);\n        ~Foo();\n\n    private:\n        DISALLOW_COPY_AND_ASSIGN(Foo);\n};\n```\n\n* 仅当只有数据时使用 struct, 其它一概使用 class.\n* 编写简短函数\n如果函数超过 40 行, 可以思索一下能不能在不影响程序结构的前提下对其进行分割.\n\n* 存取控制\n\n将所有数据成员声明为 private, 并根据需要提供相应的存取函数. 例如, 某个名为 foo_ 的变量, 其取值函数是 foo(). 还可能需要一个赋值函数 set_foo().一般在头文件中把存取函数定义成内联函数.\n* 声明顺序\n\n在类中使用特定的声明顺序: public: 在 private: 之前, 成员函数在数据成员 (变量) 前;\n\n通常是：\n+ public -> protected -> private;\n+ typedefs 和枚举\n+ 常量\n+ 构造函数\n+ 析构函数\n+ 成员函数, 含静态成员函数\n+ 数据成员, 含静态数据成员\n+ 类型转换\n\n使用 C++ 的类型转换, 如 static_cast<>(). 不要使用 int y = (int)x 或 int y = int(x) 等转换方式;\n不要使用 C 风格类型转换. 而应该使用 C++ 风格.\n* 对于迭代器和其他模板对象使用前缀形式 (++i) 的自增, 自减运算符.\n\n不考虑返回值的话, 前置自增 (++i) 通常要比后置自增 (i++) 效率更高. 因为后置自增 (或自减) 需要对表达式的值 i 进行一次拷贝. 如果 i 是迭代器或其他非数值类型, 拷贝的代价是比较大的.\n* 尽可能用 sizeof(varname) 代替 sizeof(type).\n","source":"_posts/2013-08-29-google-c-plus-plus-style.markdown","raw":"---\nlayout: post\ntitle: \"Google C++ Style\"\ndate: 2013-05-11 23:12\ncomments: true\ncategories: Programe\n---\n阅读完《Google C++ Style》记录些小要点，很多开源代码都是按照这个规则编码，在了解这些原则之后，个人感觉阅读开源代码应该会省很多力气。\n\n* 有头文件都应该使用 #define 防止头文件被多重包含, 命名格式当是: ___H__\n* 能用前置声明的地方尽量不使用 #include\n前置声明是为了降低编译依赖，防止修改一个头文件引发多米诺效应; 举例说明: 如果头文件中用到类 File, 但不需要访问 File 类的声明, 头文件中只需前置声明 class File; 而无须 #include “file/base/file.h”.\n\n* 只有当函数只有 10 行甚至更少时才将其定义为内联函数.\n当函数被声明为内联函数之后, 编译器会将其内联展开, 而不是按通常的函数调用机制进行调用.优点:当函数体比较小的时候, 内联该函数可以令目标代码更加高效. 对于存取函数以及其它函数体比较短, 性能关键的函数\n\n* 义函数时, 参数顺序依次为: 输入参数, 然后是输出参数。\n标准化函数参数顺序可以提高可读性和易维护性\n\n* 造函数体中进行初始化操作\n如果对象需要进行有意义的 (non-trivial) 初始化, 考虑使用明确的 Init() 方法并 (或) 增加一个成员标记用于指示对象是否已经初始化成功.\n\n* 单个参数的构造函数使用 C++ 关键字 explicit.\n    大部分类并不需要可拷贝, 也不需要一个拷贝构造函数或重载赋值运算符. 不幸的是, 如果你不主动声明它们, 编译器会为你自动生成, 而且是 public 的.可以考虑在类的 private: 中添加拷贝构造函数和赋值操作的空实现, 只有声明, 没有定义. 由于这些空函数声明为 private, 当其他代码试图使用它们的时候, 编译器将报错. 方便起见, 我们可以使用 DISALLOW_COPY_AND_ASSIGN 宏:\n\n```\n\n#define DISALLOW_COPY_AND_ASSIGN(TypeName) \\\n    TypeName(const TypeName&); \\\nvoid operator=(const TypeName&)\nclass Foo {\n    public:\n        Foo(int f);\n        ~Foo();\n\n    private:\n        DISALLOW_COPY_AND_ASSIGN(Foo);\n};\n```\n\n* 仅当只有数据时使用 struct, 其它一概使用 class.\n* 编写简短函数\n如果函数超过 40 行, 可以思索一下能不能在不影响程序结构的前提下对其进行分割.\n\n* 存取控制\n\n将所有数据成员声明为 private, 并根据需要提供相应的存取函数. 例如, 某个名为 foo_ 的变量, 其取值函数是 foo(). 还可能需要一个赋值函数 set_foo().一般在头文件中把存取函数定义成内联函数.\n* 声明顺序\n\n在类中使用特定的声明顺序: public: 在 private: 之前, 成员函数在数据成员 (变量) 前;\n\n通常是：\n+ public -> protected -> private;\n+ typedefs 和枚举\n+ 常量\n+ 构造函数\n+ 析构函数\n+ 成员函数, 含静态成员函数\n+ 数据成员, 含静态数据成员\n+ 类型转换\n\n使用 C++ 的类型转换, 如 static_cast<>(). 不要使用 int y = (int)x 或 int y = int(x) 等转换方式;\n不要使用 C 风格类型转换. 而应该使用 C++ 风格.\n* 对于迭代器和其他模板对象使用前缀形式 (++i) 的自增, 自减运算符.\n\n不考虑返回值的话, 前置自增 (++i) 通常要比后置自增 (i++) 效率更高. 因为后置自增 (或自减) 需要对表达式的值 i 进行一次拷贝. 如果 i 是迭代器或其他非数值类型, 拷贝的代价是比较大的.\n* 尽可能用 sizeof(varname) 代替 sizeof(type).\n","slug":"2013-08-29-google-c-plus-plus-style","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8g000pnctjjmu4ssic","content":"<p>阅读完《Google C++ Style》记录些小要点，很多开源代码都是按照这个规则编码，在了解这些原则之后，个人感觉阅读开源代码应该会省很多力气。</p>\n<ul>\n<li>有头文件都应该使用 #define 防止头文件被多重包含, 命名格式当是: <strong>_H</strong></li>\n<li><p>能用前置声明的地方尽量不使用 #include<br>前置声明是为了降低编译依赖，防止修改一个头文件引发多米诺效应; 举例说明: 如果头文件中用到类 File, 但不需要访问 File 类的声明, 头文件中只需前置声明 class File; 而无须 #include “file/base/file.h”.</p>\n</li>\n<li><p>只有当函数只有 10 行甚至更少时才将其定义为内联函数.<br>当函数被声明为内联函数之后, 编译器会将其内联展开, 而不是按通常的函数调用机制进行调用.优点:当函数体比较小的时候, 内联该函数可以令目标代码更加高效. 对于存取函数以及其它函数体比较短, 性能关键的函数</p>\n</li>\n<li><p>义函数时, 参数顺序依次为: 输入参数, 然后是输出参数。<br>标准化函数参数顺序可以提高可读性和易维护性</p>\n</li>\n<li><p>造函数体中进行初始化操作<br>如果对象需要进行有意义的 (non-trivial) 初始化, 考虑使用明确的 Init() 方法并 (或) 增加一个成员标记用于指示对象是否已经初始化成功.</p>\n</li>\n<li><p>单个参数的构造函数使用 C++ 关键字 explicit.<br>  大部分类并不需要可拷贝, 也不需要一个拷贝构造函数或重载赋值运算符. 不幸的是, 如果你不主动声明它们, 编译器会为你自动生成, 而且是 public 的.可以考虑在类的 private: 中添加拷贝构造函数和赋值操作的空实现, 只有声明, 没有定义. 由于这些空函数声明为 private, 当其他代码试图使用它们的时候, 编译器将报错. 方便起见, 我们可以使用 DISALLOW_COPY_AND_ASSIGN 宏:</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">#define DISALLOW_COPY_AND_ASSIGN(TypeName) \\</span><br><span class=\"line\">    TypeName(const TypeName&amp;); \\</span><br><span class=\"line\">void operator=(const TypeName&amp;)</span><br><span class=\"line\">class Foo &#123;</span><br><span class=\"line\">    public:</span><br><span class=\"line\">        Foo(int f);</span><br><span class=\"line\">        ~Foo();</span><br><span class=\"line\"></span><br><span class=\"line\">    private:</span><br><span class=\"line\">        DISALLOW_COPY_AND_ASSIGN(Foo);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>仅当只有数据时使用 struct, 其它一概使用 class.</li>\n<li><p>编写简短函数<br>如果函数超过 40 行, 可以思索一下能不能在不影响程序结构的前提下对其进行分割.</p>\n</li>\n<li><p>存取控制</p>\n</li>\n</ul>\n<p>将所有数据成员声明为 private, 并根据需要提供相应的存取函数. 例如, 某个名为 foo_ 的变量, 其取值函数是 foo(). 还可能需要一个赋值函数 set_foo().一般在头文件中把存取函数定义成内联函数.</p>\n<ul>\n<li>声明顺序</li>\n</ul>\n<p>在类中使用特定的声明顺序: public: 在 private: 之前, 成员函数在数据成员 (变量) 前;</p>\n<p>通常是：</p>\n<ul>\n<li>public -&gt; protected -&gt; private;</li>\n<li>typedefs 和枚举</li>\n<li>常量</li>\n<li>构造函数</li>\n<li>析构函数</li>\n<li>成员函数, 含静态成员函数</li>\n<li>数据成员, 含静态数据成员</li>\n<li>类型转换</li>\n</ul>\n<p>使用 C++ 的类型转换, 如 static_cast&lt;&gt;(). 不要使用 int y = (int)x 或 int y = int(x) 等转换方式;<br>不要使用 C 风格类型转换. 而应该使用 C++ 风格.</p>\n<ul>\n<li>对于迭代器和其他模板对象使用前缀形式 (++i) 的自增, 自减运算符.</li>\n</ul>\n<p>不考虑返回值的话, 前置自增 (++i) 通常要比后置自增 (i++) 效率更高. 因为后置自增 (或自减) 需要对表达式的值 i 进行一次拷贝. 如果 i 是迭代器或其他非数值类型, 拷贝的代价是比较大的.</p>\n<ul>\n<li>尽可能用 sizeof(varname) 代替 sizeof(type).</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>阅读完《Google C++ Style》记录些小要点，很多开源代码都是按照这个规则编码，在了解这些原则之后，个人感觉阅读开源代码应该会省很多力气。</p>\n<ul>\n<li>有头文件都应该使用 #define 防止头文件被多重包含, 命名格式当是: <strong>_H</strong></li>\n<li><p>能用前置声明的地方尽量不使用 #include<br>前置声明是为了降低编译依赖，防止修改一个头文件引发多米诺效应; 举例说明: 如果头文件中用到类 File, 但不需要访问 File 类的声明, 头文件中只需前置声明 class File; 而无须 #include “file/base/file.h”.</p>\n</li>\n<li><p>只有当函数只有 10 行甚至更少时才将其定义为内联函数.<br>当函数被声明为内联函数之后, 编译器会将其内联展开, 而不是按通常的函数调用机制进行调用.优点:当函数体比较小的时候, 内联该函数可以令目标代码更加高效. 对于存取函数以及其它函数体比较短, 性能关键的函数</p>\n</li>\n<li><p>义函数时, 参数顺序依次为: 输入参数, 然后是输出参数。<br>标准化函数参数顺序可以提高可读性和易维护性</p>\n</li>\n<li><p>造函数体中进行初始化操作<br>如果对象需要进行有意义的 (non-trivial) 初始化, 考虑使用明确的 Init() 方法并 (或) 增加一个成员标记用于指示对象是否已经初始化成功.</p>\n</li>\n<li><p>单个参数的构造函数使用 C++ 关键字 explicit.<br>  大部分类并不需要可拷贝, 也不需要一个拷贝构造函数或重载赋值运算符. 不幸的是, 如果你不主动声明它们, 编译器会为你自动生成, 而且是 public 的.可以考虑在类的 private: 中添加拷贝构造函数和赋值操作的空实现, 只有声明, 没有定义. 由于这些空函数声明为 private, 当其他代码试图使用它们的时候, 编译器将报错. 方便起见, 我们可以使用 DISALLOW_COPY_AND_ASSIGN 宏:</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">#define DISALLOW_COPY_AND_ASSIGN(TypeName) \\</span><br><span class=\"line\">    TypeName(const TypeName&amp;); \\</span><br><span class=\"line\">void operator=(const TypeName&amp;)</span><br><span class=\"line\">class Foo &#123;</span><br><span class=\"line\">    public:</span><br><span class=\"line\">        Foo(int f);</span><br><span class=\"line\">        ~Foo();</span><br><span class=\"line\"></span><br><span class=\"line\">    private:</span><br><span class=\"line\">        DISALLOW_COPY_AND_ASSIGN(Foo);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>仅当只有数据时使用 struct, 其它一概使用 class.</li>\n<li><p>编写简短函数<br>如果函数超过 40 行, 可以思索一下能不能在不影响程序结构的前提下对其进行分割.</p>\n</li>\n<li><p>存取控制</p>\n</li>\n</ul>\n<p>将所有数据成员声明为 private, 并根据需要提供相应的存取函数. 例如, 某个名为 foo_ 的变量, 其取值函数是 foo(). 还可能需要一个赋值函数 set_foo().一般在头文件中把存取函数定义成内联函数.</p>\n<ul>\n<li>声明顺序</li>\n</ul>\n<p>在类中使用特定的声明顺序: public: 在 private: 之前, 成员函数在数据成员 (变量) 前;</p>\n<p>通常是：</p>\n<ul>\n<li>public -&gt; protected -&gt; private;</li>\n<li>typedefs 和枚举</li>\n<li>常量</li>\n<li>构造函数</li>\n<li>析构函数</li>\n<li>成员函数, 含静态成员函数</li>\n<li>数据成员, 含静态数据成员</li>\n<li>类型转换</li>\n</ul>\n<p>使用 C++ 的类型转换, 如 static_cast&lt;&gt;(). 不要使用 int y = (int)x 或 int y = int(x) 等转换方式;<br>不要使用 C 风格类型转换. 而应该使用 C++ 风格.</p>\n<ul>\n<li>对于迭代器和其他模板对象使用前缀形式 (++i) 的自增, 自减运算符.</li>\n</ul>\n<p>不考虑返回值的话, 前置自增 (++i) 通常要比后置自增 (i++) 效率更高. 因为后置自增 (或自减) 需要对表达式的值 i 进行一次拷贝. 如果 i 是迭代器或其他非数值类型, 拷贝的代价是比较大的.</p>\n<ul>\n<li>尽可能用 sizeof(varname) 代替 sizeof(type).</li>\n</ul>\n"},{"layout":"post","title":"回顾 ZeroMQ","date":"2013-06-29T15:25:00.000Z","comments":1,"_content":"今日在整理曾经的学习笔记，看到了ZeroMQ，号称史上最快消息内核。曾经在一创业公司用其开发过一些[后端服务](https://github.com/zheng-ji/log2aws)。当时用Go语言实现 源代码,使用的便是[gozmq库](https://github.com/alecthomas/gozmq).这个消息通信框架库的文章有很多，比较著名的当属[一淘](www.searchtb.com/2012/08/zeromq-primer.html)的，（技术文章这样写，的确是让读者舒服 ：））还有官方文档\n\n#### 优点：\n* 高度封装。\n它处于会话层之上，应用层之下，你不需要自己写一行的socket函数调用就能完成复杂的网络通信工作。\n\n* 点对点的消息传输上。\n传统的消息队列都需要一个消息服务器来存储转发消息。而ZeroMQ则把侧重点放在了点对点的消息传输上。ZeroMQ能缓存消息，但是是在发送端缓存。ZeroMQ里有水位设置的相关接口来控制缓存量。当然，ZeroMQ也支持传统的消息队列（通过zmq_device来实现）。这样使得客户端在重启的时候可以重新发送上次未发送成功的消息\n\n* 灵活的收发模式。\nREQ-REP 请求响应模式，PUSH-PULL： 推拉模式， PUB-SUB： 发布订阅模式 等。 其中任何一方都可以作为服务端\n\n* 以统一接口支持多种底层通信方式\n支持线程间通信，进程间通信，跨主机通信，假如你想把本机多进程的软件放到跨主机的环境里去执行，通常要将IPC接口用套接字重写一遍。非常麻烦。而有了ZeroMQ就方便多了，只要把通信协议从”ipc:///xxx”改为”tcp://*.*.*.*:****”就可以了，其他代码通通不需要改，如果这个是从配置文件里读的话，那么程序就完全不要动了，直接复制到其他机器上就可以了。\n\n* 异步高效。\nZeroMQ为了高性能的消息发送而服务的，它发送消息是异步模式，通过单独出一个IO线程来实现，要把资源释放函数交给ZeroMQ让ZeroMQ发完消息自己释放，所以消息发送调用之后不要立刻释放相关资源。\n\n\n","source":"_posts/2013-08-29-hui-gu-zeromq.markdown","raw":"---\nlayout: post\ntitle: \"回顾 ZeroMQ\"\ndate: 2013-06-29 23:25\ncomments: true\ncategories: NetWork Server \n---\n今日在整理曾经的学习笔记，看到了ZeroMQ，号称史上最快消息内核。曾经在一创业公司用其开发过一些[后端服务](https://github.com/zheng-ji/log2aws)。当时用Go语言实现 源代码,使用的便是[gozmq库](https://github.com/alecthomas/gozmq).这个消息通信框架库的文章有很多，比较著名的当属[一淘](www.searchtb.com/2012/08/zeromq-primer.html)的，（技术文章这样写，的确是让读者舒服 ：））还有官方文档\n\n#### 优点：\n* 高度封装。\n它处于会话层之上，应用层之下，你不需要自己写一行的socket函数调用就能完成复杂的网络通信工作。\n\n* 点对点的消息传输上。\n传统的消息队列都需要一个消息服务器来存储转发消息。而ZeroMQ则把侧重点放在了点对点的消息传输上。ZeroMQ能缓存消息，但是是在发送端缓存。ZeroMQ里有水位设置的相关接口来控制缓存量。当然，ZeroMQ也支持传统的消息队列（通过zmq_device来实现）。这样使得客户端在重启的时候可以重新发送上次未发送成功的消息\n\n* 灵活的收发模式。\nREQ-REP 请求响应模式，PUSH-PULL： 推拉模式， PUB-SUB： 发布订阅模式 等。 其中任何一方都可以作为服务端\n\n* 以统一接口支持多种底层通信方式\n支持线程间通信，进程间通信，跨主机通信，假如你想把本机多进程的软件放到跨主机的环境里去执行，通常要将IPC接口用套接字重写一遍。非常麻烦。而有了ZeroMQ就方便多了，只要把通信协议从”ipc:///xxx”改为”tcp://*.*.*.*:****”就可以了，其他代码通通不需要改，如果这个是从配置文件里读的话，那么程序就完全不要动了，直接复制到其他机器上就可以了。\n\n* 异步高效。\nZeroMQ为了高性能的消息发送而服务的，它发送消息是异步模式，通过单独出一个IO线程来实现，要把资源释放函数交给ZeroMQ让ZeroMQ发完消息自己释放，所以消息发送调用之后不要立刻释放相关资源。\n\n\n","slug":"2013-08-29-hui-gu-zeromq","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8h000snctj6a4c4ehe","content":"<p>今日在整理曾经的学习笔记，看到了ZeroMQ，号称史上最快消息内核。曾经在一创业公司用其开发过一些<a href=\"https://github.com/zheng-ji/log2aws\" target=\"_blank\" rel=\"noopener\">后端服务</a>。当时用Go语言实现 源代码,使用的便是<a href=\"https://github.com/alecthomas/gozmq\" target=\"_blank\" rel=\"noopener\">gozmq库</a>.这个消息通信框架库的文章有很多，比较著名的当属<a href=\"www.searchtb.com/2012/08/zeromq-primer.html\">一淘</a>的，（技术文章这样写，的确是让读者舒服 ：））还有官方文档</p>\n<h4 id=\"优点：\"><a href=\"#优点：\" class=\"headerlink\" title=\"优点：\"></a>优点：</h4><ul>\n<li><p>高度封装。<br>它处于会话层之上，应用层之下，你不需要自己写一行的socket函数调用就能完成复杂的网络通信工作。</p>\n</li>\n<li><p>点对点的消息传输上。<br>传统的消息队列都需要一个消息服务器来存储转发消息。而ZeroMQ则把侧重点放在了点对点的消息传输上。ZeroMQ能缓存消息，但是是在发送端缓存。ZeroMQ里有水位设置的相关接口来控制缓存量。当然，ZeroMQ也支持传统的消息队列（通过zmq_device来实现）。这样使得客户端在重启的时候可以重新发送上次未发送成功的消息</p>\n</li>\n<li><p>灵活的收发模式。<br>REQ-REP 请求响应模式，PUSH-PULL： 推拉模式， PUB-SUB： 发布订阅模式 等。 其中任何一方都可以作为服务端</p>\n</li>\n<li><p>以统一接口支持多种底层通信方式<br>支持线程间通信，进程间通信，跨主机通信，假如你想把本机多进程的软件放到跨主机的环境里去执行，通常要将IPC接口用套接字重写一遍。非常麻烦。而有了ZeroMQ就方便多了，只要把通信协议从”ipc:///xxx”改为”tcp://<em>.</em>.<em>.</em>:<em>**</em>”就可以了，其他代码通通不需要改，如果这个是从配置文件里读的话，那么程序就完全不要动了，直接复制到其他机器上就可以了。</p>\n</li>\n<li><p>异步高效。<br>ZeroMQ为了高性能的消息发送而服务的，它发送消息是异步模式，通过单独出一个IO线程来实现，要把资源释放函数交给ZeroMQ让ZeroMQ发完消息自己释放，所以消息发送调用之后不要立刻释放相关资源。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>今日在整理曾经的学习笔记，看到了ZeroMQ，号称史上最快消息内核。曾经在一创业公司用其开发过一些<a href=\"https://github.com/zheng-ji/log2aws\" target=\"_blank\" rel=\"noopener\">后端服务</a>。当时用Go语言实现 源代码,使用的便是<a href=\"https://github.com/alecthomas/gozmq\" target=\"_blank\" rel=\"noopener\">gozmq库</a>.这个消息通信框架库的文章有很多，比较著名的当属<a href=\"www.searchtb.com/2012/08/zeromq-primer.html\">一淘</a>的，（技术文章这样写，的确是让读者舒服 ：））还有官方文档</p>\n<h4 id=\"优点：\"><a href=\"#优点：\" class=\"headerlink\" title=\"优点：\"></a>优点：</h4><ul>\n<li><p>高度封装。<br>它处于会话层之上，应用层之下，你不需要自己写一行的socket函数调用就能完成复杂的网络通信工作。</p>\n</li>\n<li><p>点对点的消息传输上。<br>传统的消息队列都需要一个消息服务器来存储转发消息。而ZeroMQ则把侧重点放在了点对点的消息传输上。ZeroMQ能缓存消息，但是是在发送端缓存。ZeroMQ里有水位设置的相关接口来控制缓存量。当然，ZeroMQ也支持传统的消息队列（通过zmq_device来实现）。这样使得客户端在重启的时候可以重新发送上次未发送成功的消息</p>\n</li>\n<li><p>灵活的收发模式。<br>REQ-REP 请求响应模式，PUSH-PULL： 推拉模式， PUB-SUB： 发布订阅模式 等。 其中任何一方都可以作为服务端</p>\n</li>\n<li><p>以统一接口支持多种底层通信方式<br>支持线程间通信，进程间通信，跨主机通信，假如你想把本机多进程的软件放到跨主机的环境里去执行，通常要将IPC接口用套接字重写一遍。非常麻烦。而有了ZeroMQ就方便多了，只要把通信协议从”ipc:///xxx”改为”tcp://<em>.</em>.<em>.</em>:<em>**</em>”就可以了，其他代码通通不需要改，如果这个是从配置文件里读的话，那么程序就完全不要动了，直接复制到其他机器上就可以了。</p>\n</li>\n<li><p>异步高效。<br>ZeroMQ为了高性能的消息发送而服务的，它发送消息是异步模式，通过单独出一个IO线程来实现，要把资源释放函数交给ZeroMQ让ZeroMQ发完消息自己释放，所以消息发送调用之后不要立刻释放相关资源。</p>\n</li>\n</ul>\n"},{"layout":"post","title":"Unix Domain Socket – IPC通信机制","date":"2013-06-17T15:52:00.000Z","comments":1,"_content":"#### 什么是Unix Domain Socket\n基于socket的框架上发展出一种IPC机制，就是UNIX Domain Socket。虽然网络socket也可用于同一台主机的进程间通讯（通过loopback地址127.0.0.1），但是UNIX Domain Socket用于IPC更有效率：\n\n* 不需要经过网络协议栈\n* 不需要打包拆包、计算校验和、维护序号和应答等\n\n只是将应用层数据从一个进程拷贝到另一个进程。这是因为，IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的。UNIX Domain Socket也提供面向流和面向数据包两种API接口，类似于TCP和UDP，但是面向消息的UNIX Domain Socket也是可靠的，消息既不会丢失也不会顺序错乱。\n\n#### 应用\n\nUNIX Domain Socket是全双工的，API接口语义丰富，相比其它IPC机制有明显的优越性，目前已成为使用最广泛的IPC机制，比如X Window服务器和GUI程序之间就是通过UNIX Domain Socket通讯的。\n\nNginx通过unix:/socket与fastcgi连接，提升性能,比tcp socket要高效\n+ 在nginx.conf中修改配置为：\n\n```\nfastcgi_pass unix:/tmp/php-cgi.sock;\n#fastcgi_pass 127.0.0.1:9000;\n```\n\n+ 在php-fpm.conf中修改配置为：\n\n```\n/tmp/php-cgi.sock\n```\n\n通信过程\n\n{% img /images/2013/08/ipc_unix_socket-300x300.png %}\n\n用Unix domain socket写的Demo\n\n使用UNIX Domain Socket的过程和网络socket十分相似，也要先调用socket()创建一个socket文件描述符，address family指定为AF_UNIX，type可以选择SOCK_DGRAM或SOCK_STREAM，protocol参数仍然指定为0即可。通常是指定/tmp/目录下的一个文件作为通信路径\n\n源码demo[链接](https://github.com/zheng-ji/ToyCollection/tree/master/unix-sock)\n\n","source":"_posts/2013-08-29-unix-domain-socket-ipctong-xin-ji-zhi.markdown","raw":"---\nlayout: post\ntitle: \"Unix Domain Socket – IPC通信机制\"\ndate: 2013-06-17 23:52\ncomments: true\ncategories: NetWork\n---\n#### 什么是Unix Domain Socket\n基于socket的框架上发展出一种IPC机制，就是UNIX Domain Socket。虽然网络socket也可用于同一台主机的进程间通讯（通过loopback地址127.0.0.1），但是UNIX Domain Socket用于IPC更有效率：\n\n* 不需要经过网络协议栈\n* 不需要打包拆包、计算校验和、维护序号和应答等\n\n只是将应用层数据从一个进程拷贝到另一个进程。这是因为，IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的。UNIX Domain Socket也提供面向流和面向数据包两种API接口，类似于TCP和UDP，但是面向消息的UNIX Domain Socket也是可靠的，消息既不会丢失也不会顺序错乱。\n\n#### 应用\n\nUNIX Domain Socket是全双工的，API接口语义丰富，相比其它IPC机制有明显的优越性，目前已成为使用最广泛的IPC机制，比如X Window服务器和GUI程序之间就是通过UNIX Domain Socket通讯的。\n\nNginx通过unix:/socket与fastcgi连接，提升性能,比tcp socket要高效\n+ 在nginx.conf中修改配置为：\n\n```\nfastcgi_pass unix:/tmp/php-cgi.sock;\n#fastcgi_pass 127.0.0.1:9000;\n```\n\n+ 在php-fpm.conf中修改配置为：\n\n```\n/tmp/php-cgi.sock\n```\n\n通信过程\n\n{% img /images/2013/08/ipc_unix_socket-300x300.png %}\n\n用Unix domain socket写的Demo\n\n使用UNIX Domain Socket的过程和网络socket十分相似，也要先调用socket()创建一个socket文件描述符，address family指定为AF_UNIX，type可以选择SOCK_DGRAM或SOCK_STREAM，protocol参数仍然指定为0即可。通常是指定/tmp/目录下的一个文件作为通信路径\n\n源码demo[链接](https://github.com/zheng-ji/ToyCollection/tree/master/unix-sock)\n\n","slug":"2013-08-29-unix-domain-socket-ipctong-xin-ji-zhi","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8i000tnctjm668omms","content":"<h4 id=\"什么是Unix-Domain-Socket\"><a href=\"#什么是Unix-Domain-Socket\" class=\"headerlink\" title=\"什么是Unix Domain Socket\"></a>什么是Unix Domain Socket</h4><p>基于socket的框架上发展出一种IPC机制，就是UNIX Domain Socket。虽然网络socket也可用于同一台主机的进程间通讯（通过loopback地址127.0.0.1），但是UNIX Domain Socket用于IPC更有效率：</p>\n<ul>\n<li>不需要经过网络协议栈</li>\n<li>不需要打包拆包、计算校验和、维护序号和应答等</li>\n</ul>\n<p>只是将应用层数据从一个进程拷贝到另一个进程。这是因为，IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的。UNIX Domain Socket也提供面向流和面向数据包两种API接口，类似于TCP和UDP，但是面向消息的UNIX Domain Socket也是可靠的，消息既不会丢失也不会顺序错乱。</p>\n<h4 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h4><p>UNIX Domain Socket是全双工的，API接口语义丰富，相比其它IPC机制有明显的优越性，目前已成为使用最广泛的IPC机制，比如X Window服务器和GUI程序之间就是通过UNIX Domain Socket通讯的。</p>\n<p>Nginx通过unix:/socket与fastcgi连接，提升性能,比tcp socket要高效</p>\n<ul>\n<li>在nginx.conf中修改配置为：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fastcgi_pass unix:/tmp/php-cgi.sock;</span><br><span class=\"line\">#fastcgi_pass 127.0.0.1:9000;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>在php-fpm.conf中修改配置为：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/tmp/php-cgi.sock</span><br></pre></td></tr></table></figure>\n<p>通信过程</p>\n<img src=\"/images/2013/08/ipc_unix_socket-300x300.png\">\n<p>用Unix domain socket写的Demo</p>\n<p>使用UNIX Domain Socket的过程和网络socket十分相似，也要先调用socket()创建一个socket文件描述符，address family指定为AF_UNIX，type可以选择SOCK_DGRAM或SOCK_STREAM，protocol参数仍然指定为0即可。通常是指定/tmp/目录下的一个文件作为通信路径</p>\n<p>源码demo<a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/unix-sock\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"什么是Unix-Domain-Socket\"><a href=\"#什么是Unix-Domain-Socket\" class=\"headerlink\" title=\"什么是Unix Domain Socket\"></a>什么是Unix Domain Socket</h4><p>基于socket的框架上发展出一种IPC机制，就是UNIX Domain Socket。虽然网络socket也可用于同一台主机的进程间通讯（通过loopback地址127.0.0.1），但是UNIX Domain Socket用于IPC更有效率：</p>\n<ul>\n<li>不需要经过网络协议栈</li>\n<li>不需要打包拆包、计算校验和、维护序号和应答等</li>\n</ul>\n<p>只是将应用层数据从一个进程拷贝到另一个进程。这是因为，IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的。UNIX Domain Socket也提供面向流和面向数据包两种API接口，类似于TCP和UDP，但是面向消息的UNIX Domain Socket也是可靠的，消息既不会丢失也不会顺序错乱。</p>\n<h4 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h4><p>UNIX Domain Socket是全双工的，API接口语义丰富，相比其它IPC机制有明显的优越性，目前已成为使用最广泛的IPC机制，比如X Window服务器和GUI程序之间就是通过UNIX Domain Socket通讯的。</p>\n<p>Nginx通过unix:/socket与fastcgi连接，提升性能,比tcp socket要高效</p>\n<ul>\n<li>在nginx.conf中修改配置为：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fastcgi_pass unix:/tmp/php-cgi.sock;</span><br><span class=\"line\">#fastcgi_pass 127.0.0.1:9000;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>在php-fpm.conf中修改配置为：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/tmp/php-cgi.sock</span><br></pre></td></tr></table></figure>\n<p>通信过程</p>\n<img src=\"/images/2013/08/ipc_unix_socket-300x300.png\">\n<p>用Unix domain socket写的Demo</p>\n<p>使用UNIX Domain Socket的过程和网络socket十分相似，也要先调用socket()创建一个socket文件描述符，address family指定为AF_UNIX，type可以选择SOCK_DGRAM或SOCK_STREAM，protocol参数仍然指定为0即可。通常是指定/tmp/目录下的一个文件作为通信路径</p>\n<p>源码demo<a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/unix-sock\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n"},{"layout":"post","title":"修葺小博","date":"2013-05-30T15:20:00.000Z","comments":1,"_content":"#### 关于博客\n\n大二那年从《暗时间》里，看到刘未鹏说“写博客很重要”，之后便开始建站写文章，Fenng君说到的文案的力量也让我深思技术人员必须要有好的文笔。一篇文章，能否做到干练，条理分明，甚至排版清晰，都是很考验人的。以后文章不能令自己满意，（就像自己开发的产品你都不喜欢使用）绝不能发表。\n\n今天好好地修理一翻博客，顿觉从建博至今，写了很多垃圾文章，甚发觉以前很幼稚（包括想法与文字），本想删除劣迹，但这些文章终究是自己一步步成长的印记，所以让它们保留着。折腾了一天wp源码（修改css代码，添加一些有用的插件）还是很欢乐的。得益于广泛阅读和折腾，技术的广度是够的，但深度却明显不足。后续宁愿慢点也要做深度思考，尽可能写出博文。\n\n#### 关于技术\n\n以后这个博客记录的更多会是后端开发的感悟，来源于自己浓厚的兴趣使然，喜欢服务端编程。虽然我在TX没有机会接触这样的开发（多少有些遗憾吧，但我希望去大公司开拓眼界，以后真的能做这样的工作，故不能放弃积累）。全凭一腔热血和毅力折腾，我所做的方法是，查看前人的技术成长，自己给自己提需求(比较傻)。偶有所得便会放上Github。诚如我所言，深度思考，学过的理要尽可能实现出来。宁愿慢点以获得真正的收获！\n\n如今已不再觉得学习某些技术会很厉害，真正具备的是思考，学习的能力。这都离不开扎实的基础！欣喜的是，我发现只要你去尝试并坚持努力，这些都可以提高的。\n\n接触到身边很多程序员：\"CopyCat,重复劳动，眼界狭隘，缺乏思考\"，内心感到难受。@ruitao说过；”不可能要求这世界所有人都有一样的想法，他们已经被磨去了棱角。“ （PS：@ruitao是一个Geek&&工具控,我的偶像：））。所幸的是我可以自我修炼，信息的畅通大大降低了学习门槛，一直欣赏一种人，知道自己需要什么并坚持想法的去学习，不为了所谓“外部评价”。很感恩认识到一些爱好技术，追求效率的朋友，和志同道合的人分享是件很幸福的事.\n\n#### 致将要逝去的大学时光\n\n这个月与好友们泡在一起，俺学会了lol，虽然绝对菜B，但仍能感受到大伙在一起的狂欢激情。这些日子，我尽可能地尝试以前想做的事情，比如弹起吉他。感觉人生又完满了一点。认识多了几个热爱搞技术的朋友，能和他们一起侃共同的话题真的很爽。或许因为大家都有不安分的心以及共同的愿景吧。\n转入正题：leveldb的内存设计思想\n\n在研究leveldb的源代码，觉得他的内存池实现很收启发。学习leveldb的内存设计思想。\n\n如果是频繁的申请内存，不连续，会造成内存碎片。但Leveldb采用了内存池的概念，一次性申请4M的内存。下次读取的内存小于内存池的容量，直接获取，否则，重新申请内存块：\n* 如果申请的字节数，bytes >= 1M，则申请内存为 bytes的块,避免内存块浪费\n* 如果申请的字节数，bytes <= 1M，则申请内存为 4M 的块\nGithub [源码](https://github.com/zheng-ji/ToyCollection/tree/master/Level_memo)\n","source":"_posts/2013-08-29-xiu-qi-xiao-bo.markdown","raw":"---\nlayout: post\ntitle: \"修葺小博\"\ndate: 2013-05-30 23:20\ncomments: true\ncategories: Life\n---\n#### 关于博客\n\n大二那年从《暗时间》里，看到刘未鹏说“写博客很重要”，之后便开始建站写文章，Fenng君说到的文案的力量也让我深思技术人员必须要有好的文笔。一篇文章，能否做到干练，条理分明，甚至排版清晰，都是很考验人的。以后文章不能令自己满意，（就像自己开发的产品你都不喜欢使用）绝不能发表。\n\n今天好好地修理一翻博客，顿觉从建博至今，写了很多垃圾文章，甚发觉以前很幼稚（包括想法与文字），本想删除劣迹，但这些文章终究是自己一步步成长的印记，所以让它们保留着。折腾了一天wp源码（修改css代码，添加一些有用的插件）还是很欢乐的。得益于广泛阅读和折腾，技术的广度是够的，但深度却明显不足。后续宁愿慢点也要做深度思考，尽可能写出博文。\n\n#### 关于技术\n\n以后这个博客记录的更多会是后端开发的感悟，来源于自己浓厚的兴趣使然，喜欢服务端编程。虽然我在TX没有机会接触这样的开发（多少有些遗憾吧，但我希望去大公司开拓眼界，以后真的能做这样的工作，故不能放弃积累）。全凭一腔热血和毅力折腾，我所做的方法是，查看前人的技术成长，自己给自己提需求(比较傻)。偶有所得便会放上Github。诚如我所言，深度思考，学过的理要尽可能实现出来。宁愿慢点以获得真正的收获！\n\n如今已不再觉得学习某些技术会很厉害，真正具备的是思考，学习的能力。这都离不开扎实的基础！欣喜的是，我发现只要你去尝试并坚持努力，这些都可以提高的。\n\n接触到身边很多程序员：\"CopyCat,重复劳动，眼界狭隘，缺乏思考\"，内心感到难受。@ruitao说过；”不可能要求这世界所有人都有一样的想法，他们已经被磨去了棱角。“ （PS：@ruitao是一个Geek&&工具控,我的偶像：））。所幸的是我可以自我修炼，信息的畅通大大降低了学习门槛，一直欣赏一种人，知道自己需要什么并坚持想法的去学习，不为了所谓“外部评价”。很感恩认识到一些爱好技术，追求效率的朋友，和志同道合的人分享是件很幸福的事.\n\n#### 致将要逝去的大学时光\n\n这个月与好友们泡在一起，俺学会了lol，虽然绝对菜B，但仍能感受到大伙在一起的狂欢激情。这些日子，我尽可能地尝试以前想做的事情，比如弹起吉他。感觉人生又完满了一点。认识多了几个热爱搞技术的朋友，能和他们一起侃共同的话题真的很爽。或许因为大家都有不安分的心以及共同的愿景吧。\n转入正题：leveldb的内存设计思想\n\n在研究leveldb的源代码，觉得他的内存池实现很收启发。学习leveldb的内存设计思想。\n\n如果是频繁的申请内存，不连续，会造成内存碎片。但Leveldb采用了内存池的概念，一次性申请4M的内存。下次读取的内存小于内存池的容量，直接获取，否则，重新申请内存块：\n* 如果申请的字节数，bytes >= 1M，则申请内存为 bytes的块,避免内存块浪费\n* 如果申请的字节数，bytes <= 1M，则申请内存为 4M 的块\nGithub [源码](https://github.com/zheng-ji/ToyCollection/tree/master/Level_memo)\n","slug":"2013-08-29-xiu-qi-xiao-bo","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8j000vnctjhf66mq92","content":"<h4 id=\"关于博客\"><a href=\"#关于博客\" class=\"headerlink\" title=\"关于博客\"></a>关于博客</h4><p>大二那年从《暗时间》里，看到刘未鹏说“写博客很重要”，之后便开始建站写文章，Fenng君说到的文案的力量也让我深思技术人员必须要有好的文笔。一篇文章，能否做到干练，条理分明，甚至排版清晰，都是很考验人的。以后文章不能令自己满意，（就像自己开发的产品你都不喜欢使用）绝不能发表。</p>\n<p>今天好好地修理一翻博客，顿觉从建博至今，写了很多垃圾文章，甚发觉以前很幼稚（包括想法与文字），本想删除劣迹，但这些文章终究是自己一步步成长的印记，所以让它们保留着。折腾了一天wp源码（修改css代码，添加一些有用的插件）还是很欢乐的。得益于广泛阅读和折腾，技术的广度是够的，但深度却明显不足。后续宁愿慢点也要做深度思考，尽可能写出博文。</p>\n<h4 id=\"关于技术\"><a href=\"#关于技术\" class=\"headerlink\" title=\"关于技术\"></a>关于技术</h4><p>以后这个博客记录的更多会是后端开发的感悟，来源于自己浓厚的兴趣使然，喜欢服务端编程。虽然我在TX没有机会接触这样的开发（多少有些遗憾吧，但我希望去大公司开拓眼界，以后真的能做这样的工作，故不能放弃积累）。全凭一腔热血和毅力折腾，我所做的方法是，查看前人的技术成长，自己给自己提需求(比较傻)。偶有所得便会放上Github。诚如我所言，深度思考，学过的理要尽可能实现出来。宁愿慢点以获得真正的收获！</p>\n<p>如今已不再觉得学习某些技术会很厉害，真正具备的是思考，学习的能力。这都离不开扎实的基础！欣喜的是，我发现只要你去尝试并坚持努力，这些都可以提高的。</p>\n<p>接触到身边很多程序员：”CopyCat,重复劳动，眼界狭隘，缺乏思考”，内心感到难受。@ruitao说过；”不可能要求这世界所有人都有一样的想法，他们已经被磨去了棱角。“ （PS：@ruitao是一个Geek&amp;&amp;工具控,我的偶像：））。所幸的是我可以自我修炼，信息的畅通大大降低了学习门槛，一直欣赏一种人，知道自己需要什么并坚持想法的去学习，不为了所谓“外部评价”。很感恩认识到一些爱好技术，追求效率的朋友，和志同道合的人分享是件很幸福的事.</p>\n<h4 id=\"致将要逝去的大学时光\"><a href=\"#致将要逝去的大学时光\" class=\"headerlink\" title=\"致将要逝去的大学时光\"></a>致将要逝去的大学时光</h4><p>这个月与好友们泡在一起，俺学会了lol，虽然绝对菜B，但仍能感受到大伙在一起的狂欢激情。这些日子，我尽可能地尝试以前想做的事情，比如弹起吉他。感觉人生又完满了一点。认识多了几个热爱搞技术的朋友，能和他们一起侃共同的话题真的很爽。或许因为大家都有不安分的心以及共同的愿景吧。<br>转入正题：leveldb的内存设计思想</p>\n<p>在研究leveldb的源代码，觉得他的内存池实现很收启发。学习leveldb的内存设计思想。</p>\n<p>如果是频繁的申请内存，不连续，会造成内存碎片。但Leveldb采用了内存池的概念，一次性申请4M的内存。下次读取的内存小于内存池的容量，直接获取，否则，重新申请内存块：</p>\n<ul>\n<li>如果申请的字节数，bytes &gt;= 1M，则申请内存为 bytes的块,避免内存块浪费</li>\n<li>如果申请的字节数，bytes &lt;= 1M，则申请内存为 4M 的块<br>Github <a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/Level_memo\" target=\"_blank\" rel=\"noopener\">源码</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"关于博客\"><a href=\"#关于博客\" class=\"headerlink\" title=\"关于博客\"></a>关于博客</h4><p>大二那年从《暗时间》里，看到刘未鹏说“写博客很重要”，之后便开始建站写文章，Fenng君说到的文案的力量也让我深思技术人员必须要有好的文笔。一篇文章，能否做到干练，条理分明，甚至排版清晰，都是很考验人的。以后文章不能令自己满意，（就像自己开发的产品你都不喜欢使用）绝不能发表。</p>\n<p>今天好好地修理一翻博客，顿觉从建博至今，写了很多垃圾文章，甚发觉以前很幼稚（包括想法与文字），本想删除劣迹，但这些文章终究是自己一步步成长的印记，所以让它们保留着。折腾了一天wp源码（修改css代码，添加一些有用的插件）还是很欢乐的。得益于广泛阅读和折腾，技术的广度是够的，但深度却明显不足。后续宁愿慢点也要做深度思考，尽可能写出博文。</p>\n<h4 id=\"关于技术\"><a href=\"#关于技术\" class=\"headerlink\" title=\"关于技术\"></a>关于技术</h4><p>以后这个博客记录的更多会是后端开发的感悟，来源于自己浓厚的兴趣使然，喜欢服务端编程。虽然我在TX没有机会接触这样的开发（多少有些遗憾吧，但我希望去大公司开拓眼界，以后真的能做这样的工作，故不能放弃积累）。全凭一腔热血和毅力折腾，我所做的方法是，查看前人的技术成长，自己给自己提需求(比较傻)。偶有所得便会放上Github。诚如我所言，深度思考，学过的理要尽可能实现出来。宁愿慢点以获得真正的收获！</p>\n<p>如今已不再觉得学习某些技术会很厉害，真正具备的是思考，学习的能力。这都离不开扎实的基础！欣喜的是，我发现只要你去尝试并坚持努力，这些都可以提高的。</p>\n<p>接触到身边很多程序员：”CopyCat,重复劳动，眼界狭隘，缺乏思考”，内心感到难受。@ruitao说过；”不可能要求这世界所有人都有一样的想法，他们已经被磨去了棱角。“ （PS：@ruitao是一个Geek&amp;&amp;工具控,我的偶像：））。所幸的是我可以自我修炼，信息的畅通大大降低了学习门槛，一直欣赏一种人，知道自己需要什么并坚持想法的去学习，不为了所谓“外部评价”。很感恩认识到一些爱好技术，追求效率的朋友，和志同道合的人分享是件很幸福的事.</p>\n<h4 id=\"致将要逝去的大学时光\"><a href=\"#致将要逝去的大学时光\" class=\"headerlink\" title=\"致将要逝去的大学时光\"></a>致将要逝去的大学时光</h4><p>这个月与好友们泡在一起，俺学会了lol，虽然绝对菜B，但仍能感受到大伙在一起的狂欢激情。这些日子，我尽可能地尝试以前想做的事情，比如弹起吉他。感觉人生又完满了一点。认识多了几个热爱搞技术的朋友，能和他们一起侃共同的话题真的很爽。或许因为大家都有不安分的心以及共同的愿景吧。<br>转入正题：leveldb的内存设计思想</p>\n<p>在研究leveldb的源代码，觉得他的内存池实现很收启发。学习leveldb的内存设计思想。</p>\n<p>如果是频繁的申请内存，不连续，会造成内存碎片。但Leveldb采用了内存池的概念，一次性申请4M的内存。下次读取的内存小于内存池的容量，直接获取，否则，重新申请内存块：</p>\n<ul>\n<li>如果申请的字节数，bytes &gt;= 1M，则申请内存为 bytes的块,避免内存块浪费</li>\n<li>如果申请的字节数，bytes &lt;= 1M，则申请内存为 4M 的块<br>Github <a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/Level_memo\" target=\"_blank\" rel=\"noopener\">源码</a></li>\n</ul>\n"},{"layout":"post","title":"分布式处理框架-Gearman","date":"2013-06-19T16:00:00.000Z","comments":1,"_content":"近日折腾Gearman.有兴趣可以参考阅读[这个](http://www.gearman.org/),[这个](http://pythonhosted.org/gearman/)，还有[这个](http://www.s135.com/dips/)\n\n官方说法：\n\n>Gearman provides a generic application framework to farm out work to other machines or processes that are better suited to do the work. It allows you to do work in parallel, to load balance processing, and to call functions between languages. It can be used in a variety of applications, from high-availability web sites to the transport of database replication events. In other words, it is the nervous system for how distributed processing communicates. \n\nGearman是一个提供机器与进程之间相互协作的通信框架。可以让你并行处理作业以及负载均衡，提供不同的语言接口使得不同语言可以互相协作。用处很广泛，从web站点到数据库Replication事件。换句话说，是一个分布式的通讯框架\n\n#### 特点\n\n+ 开源：\n    多语言支持：Gearman支持的语言种类非常丰富。让我们能够用一种语言来编写Worker程序，但是用另外一种语言编写Client程序。\n\n+ 灵活：不必拘泥于固定的形式。您可以采用你希望的任何形式，例如 Map/Reduce。\n\n+ 快速：Gearman的协议非常简单，并且有一个用C语言实现的，经过优化的服务器，保证应用的负载在非常低的水平。\n\n+ 可植入：因为Gearman非常小巧、灵活置入到现有的任何系统中。\n\n+ 无单点故障：Gearman可扩展系统，可以避免系统的失败。\n\n#### 场景\n听上去很诱惑的样子了。试想下：\n我们的服务器有IO读写密集型，存储密集型，CPU使用不频繁，内存使用不频繁。如果我们能根据业务充分调动起各个服务器的特点。实现服务器的最大价值。Gearman可以登上舞台 ：）\n\n图解工作流\n{% img /images/2013/08/gearman.png %}\n\n#### Gearman 有三个角色\n+ Job Server:中央调度，消息中心，负载均衡\n+ Client：发起Job,可由任何语言编写\n+ Worker：负责执行Job，执行业务流\n\n实操安装Gearman（以ubuntu为例子）,默认的端口4730\n\n```\nsudo apt-get install gearman\n```\n\n安装python-gearman\n\n```\nsudo apt-get install python-gearman\n```\n\n用python编写\nworker代码\n\n```\n#worker.py\nimport os\nimport gearman\nimport math \n \nclass CustomGearmanWorker(gearman.GearmanWorker):\n   def on_job_execute(self, current_job):\n          return super(CustomGearmanWorker, self).on_job_execute(current_job)\ndef task_callback(gearman_worker, job):\n    print job.data\n    return job.data + \" has received\" \n                   \nnew_worker = CustomGearmanWorker(['127.0.0.1:4730'])\nnew_worker.register_task(\"ping\", task_callback)\nnew_worker.work()\n```\n\nclient代码\n\n```python\n#!/usr/bin/env python2.7\n# -*- coding: utf-8 -*-\n# # file: client.py\nfrom gearman import GearmanClient\nnew_client = GearmanClient(['127.0.0.1:4730'])\ncurrent_request = new_client.submit_job('ping', 'foo')\nnew_result = current_request.result\nprint new_resul\n```\n\n结果\n\n```\nfoo has received\n```\n\n用Go测试下\n\n```\n#gearman的Go库,内有example\ngo get https://github.com/mikespook/gearman-go\n```\n\nHappy Hacking!\n","source":"_posts/2013-08-30-fen-bu-shi-chu-li-kuang-jia-gearman.markdown","raw":"---\nlayout: post\ntitle: \"分布式处理框架-Gearman\"\ndate: 2013-06-20 00:00\ncomments: true\ncategories: Server \n---\n近日折腾Gearman.有兴趣可以参考阅读[这个](http://www.gearman.org/),[这个](http://pythonhosted.org/gearman/)，还有[这个](http://www.s135.com/dips/)\n\n官方说法：\n\n>Gearman provides a generic application framework to farm out work to other machines or processes that are better suited to do the work. It allows you to do work in parallel, to load balance processing, and to call functions between languages. It can be used in a variety of applications, from high-availability web sites to the transport of database replication events. In other words, it is the nervous system for how distributed processing communicates. \n\nGearman是一个提供机器与进程之间相互协作的通信框架。可以让你并行处理作业以及负载均衡，提供不同的语言接口使得不同语言可以互相协作。用处很广泛，从web站点到数据库Replication事件。换句话说，是一个分布式的通讯框架\n\n#### 特点\n\n+ 开源：\n    多语言支持：Gearman支持的语言种类非常丰富。让我们能够用一种语言来编写Worker程序，但是用另外一种语言编写Client程序。\n\n+ 灵活：不必拘泥于固定的形式。您可以采用你希望的任何形式，例如 Map/Reduce。\n\n+ 快速：Gearman的协议非常简单，并且有一个用C语言实现的，经过优化的服务器，保证应用的负载在非常低的水平。\n\n+ 可植入：因为Gearman非常小巧、灵活置入到现有的任何系统中。\n\n+ 无单点故障：Gearman可扩展系统，可以避免系统的失败。\n\n#### 场景\n听上去很诱惑的样子了。试想下：\n我们的服务器有IO读写密集型，存储密集型，CPU使用不频繁，内存使用不频繁。如果我们能根据业务充分调动起各个服务器的特点。实现服务器的最大价值。Gearman可以登上舞台 ：）\n\n图解工作流\n{% img /images/2013/08/gearman.png %}\n\n#### Gearman 有三个角色\n+ Job Server:中央调度，消息中心，负载均衡\n+ Client：发起Job,可由任何语言编写\n+ Worker：负责执行Job，执行业务流\n\n实操安装Gearman（以ubuntu为例子）,默认的端口4730\n\n```\nsudo apt-get install gearman\n```\n\n安装python-gearman\n\n```\nsudo apt-get install python-gearman\n```\n\n用python编写\nworker代码\n\n```\n#worker.py\nimport os\nimport gearman\nimport math \n \nclass CustomGearmanWorker(gearman.GearmanWorker):\n   def on_job_execute(self, current_job):\n          return super(CustomGearmanWorker, self).on_job_execute(current_job)\ndef task_callback(gearman_worker, job):\n    print job.data\n    return job.data + \" has received\" \n                   \nnew_worker = CustomGearmanWorker(['127.0.0.1:4730'])\nnew_worker.register_task(\"ping\", task_callback)\nnew_worker.work()\n```\n\nclient代码\n\n```python\n#!/usr/bin/env python2.7\n# -*- coding: utf-8 -*-\n# # file: client.py\nfrom gearman import GearmanClient\nnew_client = GearmanClient(['127.0.0.1:4730'])\ncurrent_request = new_client.submit_job('ping', 'foo')\nnew_result = current_request.result\nprint new_resul\n```\n\n结果\n\n```\nfoo has received\n```\n\n用Go测试下\n\n```\n#gearman的Go库,内有example\ngo get https://github.com/mikespook/gearman-go\n```\n\nHappy Hacking!\n","slug":"2013-08-30-fen-bu-shi-chu-li-kuang-jia-gearman","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8l000ynctj4hgranwb","content":"<p>近日折腾Gearman.有兴趣可以参考阅读<a href=\"http://www.gearman.org/\" target=\"_blank\" rel=\"noopener\">这个</a>,<a href=\"http://pythonhosted.org/gearman/\" target=\"_blank\" rel=\"noopener\">这个</a>，还有<a href=\"http://www.s135.com/dips/\" target=\"_blank\" rel=\"noopener\">这个</a></p>\n<p>官方说法：</p>\n<blockquote>\n<p>Gearman provides a generic application framework to farm out work to other machines or processes that are better suited to do the work. It allows you to do work in parallel, to load balance processing, and to call functions between languages. It can be used in a variety of applications, from high-availability web sites to the transport of database replication events. In other words, it is the nervous system for how distributed processing communicates. </p>\n</blockquote>\n<p>Gearman是一个提供机器与进程之间相互协作的通信框架。可以让你并行处理作业以及负载均衡，提供不同的语言接口使得不同语言可以互相协作。用处很广泛，从web站点到数据库Replication事件。换句话说，是一个分布式的通讯框架</p>\n<h4 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h4><ul>\n<li><p>开源：<br>  多语言支持：Gearman支持的语言种类非常丰富。让我们能够用一种语言来编写Worker程序，但是用另外一种语言编写Client程序。</p>\n</li>\n<li><p>灵活：不必拘泥于固定的形式。您可以采用你希望的任何形式，例如 Map/Reduce。</p>\n</li>\n<li><p>快速：Gearman的协议非常简单，并且有一个用C语言实现的，经过优化的服务器，保证应用的负载在非常低的水平。</p>\n</li>\n<li><p>可植入：因为Gearman非常小巧、灵活置入到现有的任何系统中。</p>\n</li>\n<li><p>无单点故障：Gearman可扩展系统，可以避免系统的失败。</p>\n</li>\n</ul>\n<h4 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a>场景</h4><p>听上去很诱惑的样子了。试想下：<br>我们的服务器有IO读写密集型，存储密集型，CPU使用不频繁，内存使用不频繁。如果我们能根据业务充分调动起各个服务器的特点。实现服务器的最大价值。Gearman可以登上舞台 ：）</p>\n<p>图解工作流<br><img src=\"/images/2013/08/gearman.png\"></p>\n<h4 id=\"Gearman-有三个角色\"><a href=\"#Gearman-有三个角色\" class=\"headerlink\" title=\"Gearman 有三个角色\"></a>Gearman 有三个角色</h4><ul>\n<li>Job Server:中央调度，消息中心，负载均衡</li>\n<li>Client：发起Job,可由任何语言编写</li>\n<li>Worker：负责执行Job，执行业务流</li>\n</ul>\n<p>实操安装Gearman（以ubuntu为例子）,默认的端口4730</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install gearman</span><br></pre></td></tr></table></figure>\n<p>安装python-gearman</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install python-gearman</span><br></pre></td></tr></table></figure>\n<p>用python编写<br>worker代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#worker.py</span><br><span class=\"line\">import os</span><br><span class=\"line\">import gearman</span><br><span class=\"line\">import math </span><br><span class=\"line\"> </span><br><span class=\"line\">class CustomGearmanWorker(gearman.GearmanWorker):</span><br><span class=\"line\">   def on_job_execute(self, current_job):</span><br><span class=\"line\">          return super(CustomGearmanWorker, self).on_job_execute(current_job)</span><br><span class=\"line\">def task_callback(gearman_worker, job):</span><br><span class=\"line\">    print job.data</span><br><span class=\"line\">    return job.data + &quot; has received&quot; </span><br><span class=\"line\">                   </span><br><span class=\"line\">new_worker = CustomGearmanWorker([&apos;127.0.0.1:4730&apos;])</span><br><span class=\"line\">new_worker.register_task(&quot;ping&quot;, task_callback)</span><br><span class=\"line\">new_worker.work()</span><br></pre></td></tr></table></figure>\n<p>client代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python2.7</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># # file: client.py</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> gearman <span class=\"keyword\">import</span> GearmanClient</span><br><span class=\"line\">new_client = GearmanClient([<span class=\"string\">'127.0.0.1:4730'</span>])</span><br><span class=\"line\">current_request = new_client.submit_job(<span class=\"string\">'ping'</span>, <span class=\"string\">'foo'</span>)</span><br><span class=\"line\">new_result = current_request.result</span><br><span class=\"line\"><span class=\"keyword\">print</span> new_resul</span><br></pre></td></tr></table></figure>\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo has received</span><br></pre></td></tr></table></figure>\n<p>用Go测试下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#gearman的Go库,内有example</span><br><span class=\"line\">go get https://github.com/mikespook/gearman-go</span><br></pre></td></tr></table></figure>\n<p>Happy Hacking!</p>\n","site":{"data":{}},"excerpt":"","more":"<p>近日折腾Gearman.有兴趣可以参考阅读<a href=\"http://www.gearman.org/\" target=\"_blank\" rel=\"noopener\">这个</a>,<a href=\"http://pythonhosted.org/gearman/\" target=\"_blank\" rel=\"noopener\">这个</a>，还有<a href=\"http://www.s135.com/dips/\" target=\"_blank\" rel=\"noopener\">这个</a></p>\n<p>官方说法：</p>\n<blockquote>\n<p>Gearman provides a generic application framework to farm out work to other machines or processes that are better suited to do the work. It allows you to do work in parallel, to load balance processing, and to call functions between languages. It can be used in a variety of applications, from high-availability web sites to the transport of database replication events. In other words, it is the nervous system for how distributed processing communicates. </p>\n</blockquote>\n<p>Gearman是一个提供机器与进程之间相互协作的通信框架。可以让你并行处理作业以及负载均衡，提供不同的语言接口使得不同语言可以互相协作。用处很广泛，从web站点到数据库Replication事件。换句话说，是一个分布式的通讯框架</p>\n<h4 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h4><ul>\n<li><p>开源：<br>  多语言支持：Gearman支持的语言种类非常丰富。让我们能够用一种语言来编写Worker程序，但是用另外一种语言编写Client程序。</p>\n</li>\n<li><p>灵活：不必拘泥于固定的形式。您可以采用你希望的任何形式，例如 Map/Reduce。</p>\n</li>\n<li><p>快速：Gearman的协议非常简单，并且有一个用C语言实现的，经过优化的服务器，保证应用的负载在非常低的水平。</p>\n</li>\n<li><p>可植入：因为Gearman非常小巧、灵活置入到现有的任何系统中。</p>\n</li>\n<li><p>无单点故障：Gearman可扩展系统，可以避免系统的失败。</p>\n</li>\n</ul>\n<h4 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a>场景</h4><p>听上去很诱惑的样子了。试想下：<br>我们的服务器有IO读写密集型，存储密集型，CPU使用不频繁，内存使用不频繁。如果我们能根据业务充分调动起各个服务器的特点。实现服务器的最大价值。Gearman可以登上舞台 ：）</p>\n<p>图解工作流<br><img src=\"/images/2013/08/gearman.png\"></p>\n<h4 id=\"Gearman-有三个角色\"><a href=\"#Gearman-有三个角色\" class=\"headerlink\" title=\"Gearman 有三个角色\"></a>Gearman 有三个角色</h4><ul>\n<li>Job Server:中央调度，消息中心，负载均衡</li>\n<li>Client：发起Job,可由任何语言编写</li>\n<li>Worker：负责执行Job，执行业务流</li>\n</ul>\n<p>实操安装Gearman（以ubuntu为例子）,默认的端口4730</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install gearman</span><br></pre></td></tr></table></figure>\n<p>安装python-gearman</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install python-gearman</span><br></pre></td></tr></table></figure>\n<p>用python编写<br>worker代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#worker.py</span><br><span class=\"line\">import os</span><br><span class=\"line\">import gearman</span><br><span class=\"line\">import math </span><br><span class=\"line\"> </span><br><span class=\"line\">class CustomGearmanWorker(gearman.GearmanWorker):</span><br><span class=\"line\">   def on_job_execute(self, current_job):</span><br><span class=\"line\">          return super(CustomGearmanWorker, self).on_job_execute(current_job)</span><br><span class=\"line\">def task_callback(gearman_worker, job):</span><br><span class=\"line\">    print job.data</span><br><span class=\"line\">    return job.data + &quot; has received&quot; </span><br><span class=\"line\">                   </span><br><span class=\"line\">new_worker = CustomGearmanWorker([&apos;127.0.0.1:4730&apos;])</span><br><span class=\"line\">new_worker.register_task(&quot;ping&quot;, task_callback)</span><br><span class=\"line\">new_worker.work()</span><br></pre></td></tr></table></figure>\n<p>client代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python2.7</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># # file: client.py</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> gearman <span class=\"keyword\">import</span> GearmanClient</span><br><span class=\"line\">new_client = GearmanClient([<span class=\"string\">'127.0.0.1:4730'</span>])</span><br><span class=\"line\">current_request = new_client.submit_job(<span class=\"string\">'ping'</span>, <span class=\"string\">'foo'</span>)</span><br><span class=\"line\">new_result = current_request.result</span><br><span class=\"line\"><span class=\"keyword\">print</span> new_resul</span><br></pre></td></tr></table></figure>\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foo has received</span><br></pre></td></tr></table></figure>\n<p>用Go测试下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#gearman的Go库,内有example</span><br><span class=\"line\">go get https://github.com/mikespook/gearman-go</span><br></pre></td></tr></table></figure>\n<p>Happy Hacking!</p>\n"},{"layout":"post","title":"封培之旅","date":"2013-07-15T11:32:00.000Z","comments":1,"_content":"作为新入职的员工，参加了公司为期10天的封闭培训，此文记下这些日子的一些感悟。 因为 “思绪来地快，去地也快” by 云风。\n\n#### 遇到的人\n\n因为缘分，我和其他6位同学组成了小组（肆无忌惮组），其中一位是武大的博士（windsunwang），一位是来广研微信的华工师兄(xiaochunguo)，有趣的是我们曾在网易面试的时候相遇，一位广研邮箱的中大师姐（vinajiang），琳琅天上的美术设计师（Mzt，鬼斧神功的画技，我们称之为大师），还有QQ空间的南大愤青，（杰哥），华科运维女（hazel）,大家一起完成每一天的任务，默契也在合作中慢慢养成。感受到了windsunwang的博学和严谨，xiaochunguo的冷静，Mzt的艺术家气息，vinajiang的细腻，hazel的积极。当然还少不了杰哥这个SB :) ，他说他封闭培训的收获就是大师学会画蜗牛，囧。在大伙身上感受到了久违的集体温暖\n\n我的室友：litten是位小清新的SNG前端工程师，毕业于华中科大，litten有想法也有激情，人很文静，很好相处，因为有着很多共同话题，每天晚上因为聊得太晚而导致早上起床很累。这样的日子，想必我今后会怀念这位短暂的室友吧。\n\n我们“班”里有很多个性鲜明的人，有的很主动高调，属于喜欢当领导的人，有的是很有实力的低调派，在需要的时候总是会一语惊人，腾讯的确是聚集了很多优秀的人才，大家的知识储备以及视野和专业度都很高。特别是两位产品经理。独特的视角和条理分明的逻辑，以及优秀的口才，让我钦佩。唯一有些遗憾的是，搞技术的人多少感觉不出。或许没有深入了解吧。\n\n#### 看到的事\n\n封闭培训讲了不少所谓的职场课程，尽管我认为有些厚黑，但在职场的确需要适应，调整心态去接受吧少年。《体验式培训课》，以及《互联网行业发展》让我获益匪浅。“目标，计划，确认，执行”（Target Plan Chect Action）的指导方针应该是我们需要具备的思维方式。合作，沟通，领导在团队极其重要,特别是团队的规模到了一定的规模。主动的人总是应势站出来承担了责任，积极的热情，敬业的态度使得他们成为了耀眼的角色。培训过程中还是克服不少羞涩，拿起了话筒，在队友需要我的时候挺身而出，但总归还是不能像某些同学一样很老练地去表达。只要你细心观察，便能吸收到周围同学的正能量，比如博士跟我讲问卷设计的时候，深切感受到真正做过研究的人，他们严谨的逻辑思维让你觉得是如此的靠谱。\n#### 震撼的产品体验报告会\n\n我们做的是QQ空间的产品体验报告，最终只是得到了阳光普照奖。这次活动我细心观摩了真正的产品经理，或者有用心的同学是如何做这个Presentation的，其中一组同学的体验报告包涵了竟品分析，用户调研，原型设计，同时也用了很炫的展示手法，毫无悬念的拿走了第一名。用心做事的人是应该值得尊敬的。\n\n很多时候我们会感觉做产品其实只是耍耍花样，看到很多天花乱缀的文章为了一个小按钮而大书特书，有点没必要。如今看来，如果把握每一个需求，隐形要求你有丰富的知识储备，大量的用于调研（Custom Engagement）.如果你想你的方案令他人信服，你需要组织资源，撰写有料的报告，甚至做一个小Demo,如果可能的话做自些小测试。这些同学让我看到了很赞的能力。\n\n说到这里，我也看到了我们班有位微信的产品经理，在我与之交谈的过程中，由心的欣赏。除去淡定的临场发言的实力，更具闪光点的是其洞察力与组织能力，在谈及百度发展历程，以及产品发展定位，都能信手拈来，有理有据，中肯的道出个中要害，想必其阅读量很大。反思自己，虽然很多资料我也阅读过，但没有去总结形成自己的思想，只是在他人提及之后才恍然大悟。虽然我不是做产品的，“我只是了解了解就够了？”抱有这样的想法是可以么？如果程序员只是停留在代码中自娱自乐，没有思考产品，用户的东西，我想多半是没有灵魂的吧。以后要真的去沉淀才是。\n\n感觉腾讯能发展成今天这样子，的确是有其伟大之处。至少是招到了不少优秀的同学，曾经有人说腾讯是一个消耗人才的地方，不可否认大公司因流程体制都有通病，但我感受到，只有用心，通过不同的方式，可以开阔视野，如果你用心并去努力，还是能收获到。学习的涵义也应该慢慢变得多元化（沟通，情绪，产品），而不仅仅只是单一的技术。\n\n结尾想引用这次封陪之旅一位老师的话 “坚持是最好的美德” ：） 。问题很多，耐心勇敢去做你能尽到的改变吧,别泄气哈。\n\n","source":"_posts/2013-08-30-feng-pei-zhi-lu.markdown","raw":"---\nlayout: post\ntitle: \"封培之旅\"\ndate: 2013-07-15 19:32\ncomments: true\ncategories: Life\n---\n作为新入职的员工，参加了公司为期10天的封闭培训，此文记下这些日子的一些感悟。 因为 “思绪来地快，去地也快” by 云风。\n\n#### 遇到的人\n\n因为缘分，我和其他6位同学组成了小组（肆无忌惮组），其中一位是武大的博士（windsunwang），一位是来广研微信的华工师兄(xiaochunguo)，有趣的是我们曾在网易面试的时候相遇，一位广研邮箱的中大师姐（vinajiang），琳琅天上的美术设计师（Mzt，鬼斧神功的画技，我们称之为大师），还有QQ空间的南大愤青，（杰哥），华科运维女（hazel）,大家一起完成每一天的任务，默契也在合作中慢慢养成。感受到了windsunwang的博学和严谨，xiaochunguo的冷静，Mzt的艺术家气息，vinajiang的细腻，hazel的积极。当然还少不了杰哥这个SB :) ，他说他封闭培训的收获就是大师学会画蜗牛，囧。在大伙身上感受到了久违的集体温暖\n\n我的室友：litten是位小清新的SNG前端工程师，毕业于华中科大，litten有想法也有激情，人很文静，很好相处，因为有着很多共同话题，每天晚上因为聊得太晚而导致早上起床很累。这样的日子，想必我今后会怀念这位短暂的室友吧。\n\n我们“班”里有很多个性鲜明的人，有的很主动高调，属于喜欢当领导的人，有的是很有实力的低调派，在需要的时候总是会一语惊人，腾讯的确是聚集了很多优秀的人才，大家的知识储备以及视野和专业度都很高。特别是两位产品经理。独特的视角和条理分明的逻辑，以及优秀的口才，让我钦佩。唯一有些遗憾的是，搞技术的人多少感觉不出。或许没有深入了解吧。\n\n#### 看到的事\n\n封闭培训讲了不少所谓的职场课程，尽管我认为有些厚黑，但在职场的确需要适应，调整心态去接受吧少年。《体验式培训课》，以及《互联网行业发展》让我获益匪浅。“目标，计划，确认，执行”（Target Plan Chect Action）的指导方针应该是我们需要具备的思维方式。合作，沟通，领导在团队极其重要,特别是团队的规模到了一定的规模。主动的人总是应势站出来承担了责任，积极的热情，敬业的态度使得他们成为了耀眼的角色。培训过程中还是克服不少羞涩，拿起了话筒，在队友需要我的时候挺身而出，但总归还是不能像某些同学一样很老练地去表达。只要你细心观察，便能吸收到周围同学的正能量，比如博士跟我讲问卷设计的时候，深切感受到真正做过研究的人，他们严谨的逻辑思维让你觉得是如此的靠谱。\n#### 震撼的产品体验报告会\n\n我们做的是QQ空间的产品体验报告，最终只是得到了阳光普照奖。这次活动我细心观摩了真正的产品经理，或者有用心的同学是如何做这个Presentation的，其中一组同学的体验报告包涵了竟品分析，用户调研，原型设计，同时也用了很炫的展示手法，毫无悬念的拿走了第一名。用心做事的人是应该值得尊敬的。\n\n很多时候我们会感觉做产品其实只是耍耍花样，看到很多天花乱缀的文章为了一个小按钮而大书特书，有点没必要。如今看来，如果把握每一个需求，隐形要求你有丰富的知识储备，大量的用于调研（Custom Engagement）.如果你想你的方案令他人信服，你需要组织资源，撰写有料的报告，甚至做一个小Demo,如果可能的话做自些小测试。这些同学让我看到了很赞的能力。\n\n说到这里，我也看到了我们班有位微信的产品经理，在我与之交谈的过程中，由心的欣赏。除去淡定的临场发言的实力，更具闪光点的是其洞察力与组织能力，在谈及百度发展历程，以及产品发展定位，都能信手拈来，有理有据，中肯的道出个中要害，想必其阅读量很大。反思自己，虽然很多资料我也阅读过，但没有去总结形成自己的思想，只是在他人提及之后才恍然大悟。虽然我不是做产品的，“我只是了解了解就够了？”抱有这样的想法是可以么？如果程序员只是停留在代码中自娱自乐，没有思考产品，用户的东西，我想多半是没有灵魂的吧。以后要真的去沉淀才是。\n\n感觉腾讯能发展成今天这样子，的确是有其伟大之处。至少是招到了不少优秀的同学，曾经有人说腾讯是一个消耗人才的地方，不可否认大公司因流程体制都有通病，但我感受到，只有用心，通过不同的方式，可以开阔视野，如果你用心并去努力，还是能收获到。学习的涵义也应该慢慢变得多元化（沟通，情绪，产品），而不仅仅只是单一的技术。\n\n结尾想引用这次封陪之旅一位老师的话 “坚持是最好的美德” ：） 。问题很多，耐心勇敢去做你能尽到的改变吧,别泄气哈。\n\n","slug":"2013-08-30-feng-pei-zhi-lu","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8m0010nctjdjsjqseg","content":"<p>作为新入职的员工，参加了公司为期10天的封闭培训，此文记下这些日子的一些感悟。 因为 “思绪来地快，去地也快” by 云风。</p>\n<h4 id=\"遇到的人\"><a href=\"#遇到的人\" class=\"headerlink\" title=\"遇到的人\"></a>遇到的人</h4><p>因为缘分，我和其他6位同学组成了小组（肆无忌惮组），其中一位是武大的博士（windsunwang），一位是来广研微信的华工师兄(xiaochunguo)，有趣的是我们曾在网易面试的时候相遇，一位广研邮箱的中大师姐（vinajiang），琳琅天上的美术设计师（Mzt，鬼斧神功的画技，我们称之为大师），还有QQ空间的南大愤青，（杰哥），华科运维女（hazel）,大家一起完成每一天的任务，默契也在合作中慢慢养成。感受到了windsunwang的博学和严谨，xiaochunguo的冷静，Mzt的艺术家气息，vinajiang的细腻，hazel的积极。当然还少不了杰哥这个SB :) ，他说他封闭培训的收获就是大师学会画蜗牛，囧。在大伙身上感受到了久违的集体温暖</p>\n<p>我的室友：litten是位小清新的SNG前端工程师，毕业于华中科大，litten有想法也有激情，人很文静，很好相处，因为有着很多共同话题，每天晚上因为聊得太晚而导致早上起床很累。这样的日子，想必我今后会怀念这位短暂的室友吧。</p>\n<p>我们“班”里有很多个性鲜明的人，有的很主动高调，属于喜欢当领导的人，有的是很有实力的低调派，在需要的时候总是会一语惊人，腾讯的确是聚集了很多优秀的人才，大家的知识储备以及视野和专业度都很高。特别是两位产品经理。独特的视角和条理分明的逻辑，以及优秀的口才，让我钦佩。唯一有些遗憾的是，搞技术的人多少感觉不出。或许没有深入了解吧。</p>\n<h4 id=\"看到的事\"><a href=\"#看到的事\" class=\"headerlink\" title=\"看到的事\"></a>看到的事</h4><p>封闭培训讲了不少所谓的职场课程，尽管我认为有些厚黑，但在职场的确需要适应，调整心态去接受吧少年。《体验式培训课》，以及《互联网行业发展》让我获益匪浅。“目标，计划，确认，执行”（Target Plan Chect Action）的指导方针应该是我们需要具备的思维方式。合作，沟通，领导在团队极其重要,特别是团队的规模到了一定的规模。主动的人总是应势站出来承担了责任，积极的热情，敬业的态度使得他们成为了耀眼的角色。培训过程中还是克服不少羞涩，拿起了话筒，在队友需要我的时候挺身而出，但总归还是不能像某些同学一样很老练地去表达。只要你细心观察，便能吸收到周围同学的正能量，比如博士跟我讲问卷设计的时候，深切感受到真正做过研究的人，他们严谨的逻辑思维让你觉得是如此的靠谱。</p>\n<h4 id=\"震撼的产品体验报告会\"><a href=\"#震撼的产品体验报告会\" class=\"headerlink\" title=\"震撼的产品体验报告会\"></a>震撼的产品体验报告会</h4><p>我们做的是QQ空间的产品体验报告，最终只是得到了阳光普照奖。这次活动我细心观摩了真正的产品经理，或者有用心的同学是如何做这个Presentation的，其中一组同学的体验报告包涵了竟品分析，用户调研，原型设计，同时也用了很炫的展示手法，毫无悬念的拿走了第一名。用心做事的人是应该值得尊敬的。</p>\n<p>很多时候我们会感觉做产品其实只是耍耍花样，看到很多天花乱缀的文章为了一个小按钮而大书特书，有点没必要。如今看来，如果把握每一个需求，隐形要求你有丰富的知识储备，大量的用于调研（Custom Engagement）.如果你想你的方案令他人信服，你需要组织资源，撰写有料的报告，甚至做一个小Demo,如果可能的话做自些小测试。这些同学让我看到了很赞的能力。</p>\n<p>说到这里，我也看到了我们班有位微信的产品经理，在我与之交谈的过程中，由心的欣赏。除去淡定的临场发言的实力，更具闪光点的是其洞察力与组织能力，在谈及百度发展历程，以及产品发展定位，都能信手拈来，有理有据，中肯的道出个中要害，想必其阅读量很大。反思自己，虽然很多资料我也阅读过，但没有去总结形成自己的思想，只是在他人提及之后才恍然大悟。虽然我不是做产品的，“我只是了解了解就够了？”抱有这样的想法是可以么？如果程序员只是停留在代码中自娱自乐，没有思考产品，用户的东西，我想多半是没有灵魂的吧。以后要真的去沉淀才是。</p>\n<p>感觉腾讯能发展成今天这样子，的确是有其伟大之处。至少是招到了不少优秀的同学，曾经有人说腾讯是一个消耗人才的地方，不可否认大公司因流程体制都有通病，但我感受到，只有用心，通过不同的方式，可以开阔视野，如果你用心并去努力，还是能收获到。学习的涵义也应该慢慢变得多元化（沟通，情绪，产品），而不仅仅只是单一的技术。</p>\n<p>结尾想引用这次封陪之旅一位老师的话 “坚持是最好的美德” ：） 。问题很多，耐心勇敢去做你能尽到的改变吧,别泄气哈。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>作为新入职的员工，参加了公司为期10天的封闭培训，此文记下这些日子的一些感悟。 因为 “思绪来地快，去地也快” by 云风。</p>\n<h4 id=\"遇到的人\"><a href=\"#遇到的人\" class=\"headerlink\" title=\"遇到的人\"></a>遇到的人</h4><p>因为缘分，我和其他6位同学组成了小组（肆无忌惮组），其中一位是武大的博士（windsunwang），一位是来广研微信的华工师兄(xiaochunguo)，有趣的是我们曾在网易面试的时候相遇，一位广研邮箱的中大师姐（vinajiang），琳琅天上的美术设计师（Mzt，鬼斧神功的画技，我们称之为大师），还有QQ空间的南大愤青，（杰哥），华科运维女（hazel）,大家一起完成每一天的任务，默契也在合作中慢慢养成。感受到了windsunwang的博学和严谨，xiaochunguo的冷静，Mzt的艺术家气息，vinajiang的细腻，hazel的积极。当然还少不了杰哥这个SB :) ，他说他封闭培训的收获就是大师学会画蜗牛，囧。在大伙身上感受到了久违的集体温暖</p>\n<p>我的室友：litten是位小清新的SNG前端工程师，毕业于华中科大，litten有想法也有激情，人很文静，很好相处，因为有着很多共同话题，每天晚上因为聊得太晚而导致早上起床很累。这样的日子，想必我今后会怀念这位短暂的室友吧。</p>\n<p>我们“班”里有很多个性鲜明的人，有的很主动高调，属于喜欢当领导的人，有的是很有实力的低调派，在需要的时候总是会一语惊人，腾讯的确是聚集了很多优秀的人才，大家的知识储备以及视野和专业度都很高。特别是两位产品经理。独特的视角和条理分明的逻辑，以及优秀的口才，让我钦佩。唯一有些遗憾的是，搞技术的人多少感觉不出。或许没有深入了解吧。</p>\n<h4 id=\"看到的事\"><a href=\"#看到的事\" class=\"headerlink\" title=\"看到的事\"></a>看到的事</h4><p>封闭培训讲了不少所谓的职场课程，尽管我认为有些厚黑，但在职场的确需要适应，调整心态去接受吧少年。《体验式培训课》，以及《互联网行业发展》让我获益匪浅。“目标，计划，确认，执行”（Target Plan Chect Action）的指导方针应该是我们需要具备的思维方式。合作，沟通，领导在团队极其重要,特别是团队的规模到了一定的规模。主动的人总是应势站出来承担了责任，积极的热情，敬业的态度使得他们成为了耀眼的角色。培训过程中还是克服不少羞涩，拿起了话筒，在队友需要我的时候挺身而出，但总归还是不能像某些同学一样很老练地去表达。只要你细心观察，便能吸收到周围同学的正能量，比如博士跟我讲问卷设计的时候，深切感受到真正做过研究的人，他们严谨的逻辑思维让你觉得是如此的靠谱。</p>\n<h4 id=\"震撼的产品体验报告会\"><a href=\"#震撼的产品体验报告会\" class=\"headerlink\" title=\"震撼的产品体验报告会\"></a>震撼的产品体验报告会</h4><p>我们做的是QQ空间的产品体验报告，最终只是得到了阳光普照奖。这次活动我细心观摩了真正的产品经理，或者有用心的同学是如何做这个Presentation的，其中一组同学的体验报告包涵了竟品分析，用户调研，原型设计，同时也用了很炫的展示手法，毫无悬念的拿走了第一名。用心做事的人是应该值得尊敬的。</p>\n<p>很多时候我们会感觉做产品其实只是耍耍花样，看到很多天花乱缀的文章为了一个小按钮而大书特书，有点没必要。如今看来，如果把握每一个需求，隐形要求你有丰富的知识储备，大量的用于调研（Custom Engagement）.如果你想你的方案令他人信服，你需要组织资源，撰写有料的报告，甚至做一个小Demo,如果可能的话做自些小测试。这些同学让我看到了很赞的能力。</p>\n<p>说到这里，我也看到了我们班有位微信的产品经理，在我与之交谈的过程中，由心的欣赏。除去淡定的临场发言的实力，更具闪光点的是其洞察力与组织能力，在谈及百度发展历程，以及产品发展定位，都能信手拈来，有理有据，中肯的道出个中要害，想必其阅读量很大。反思自己，虽然很多资料我也阅读过，但没有去总结形成自己的思想，只是在他人提及之后才恍然大悟。虽然我不是做产品的，“我只是了解了解就够了？”抱有这样的想法是可以么？如果程序员只是停留在代码中自娱自乐，没有思考产品，用户的东西，我想多半是没有灵魂的吧。以后要真的去沉淀才是。</p>\n<p>感觉腾讯能发展成今天这样子，的确是有其伟大之处。至少是招到了不少优秀的同学，曾经有人说腾讯是一个消耗人才的地方，不可否认大公司因流程体制都有通病，但我感受到，只有用心，通过不同的方式，可以开阔视野，如果你用心并去努力，还是能收获到。学习的涵义也应该慢慢变得多元化（沟通，情绪，产品），而不仅仅只是单一的技术。</p>\n<p>结尾想引用这次封陪之旅一位老师的话 “坚持是最好的美德” ：） 。问题很多，耐心勇敢去做你能尽到的改变吧,别泄气哈。</p>\n"},{"layout":"post","title":"竟然也用到了Oracle","date":"2013-08-16T12:25:00.000Z","comments":1,"_content":"\n#### Oracle初印象\n\n曾经阿里的去O化搞得满城风雨，，随后很多企业也开始跟风去除Oracle，让Oracle这样的企业都为之咳嗽了一阵子。有兴趣的朋友可以看看王坚博士的文章。作为一个开源软件热爱者，首先接触到的一定是Mysql， 随后才是MongoDB,Redis,LevelDb。无论如何是怎么也想不到会去接触Oracle，就像我再也没有机会也不会去使用3.5英寸软盘的样子,因为这样会让我感觉到世界在倒退。\n\n先知言：”存在即合理”。也就为以后的遇见埋下伏笔。果然，由于历史原因，庞大的业务体系下，我终于还是遇见了它，带着对伟大数据库敬仰的心探索了一把。说实话，当你习惯了简单的Mysql之类的思维之后，接触Oracle就有点纠结了。我愿意称其为接触另一种新思维方式。没有比这更值得鼓舞人心的动力了 ：）\n\n{% img /images/2013/08/oracle.png %}\n\n我做的事情是在游戏数据操作中做一个抽象的操作类。涉及框架代码的改造，这过程有点DT。我从事的工作大部分是C++开发这过程着实feel到了“生命太短，远离C++” 涉及到多重继承，虚析构函数，同个父类冲突，属性可见性,抽象类可用。Debug 了两天。还好有GDB这种家伙。\nOracle查询流程\n\n简单描述下普通的Oracle建立连接以及查询的顺序,使用的是OCCI （Oracle的C++接口）:\n\n```\n//创建enviroment变量\nEnvironment *env = Environment::createEnvironment( Environment::DEFAULT);\n//创建连接\nConnection *conn = env->createConnection( userName, password, connectString);\n//创建 查询描述符\nStatement *stmt = conn->createStatement( \"SELECT blobcol FROM mytable\");\n//执行查询，返回结果集\nResultSet *rs = stmt->executeQuery();\n//关闭查询，环境变量\nstmt->closeResultSet(rs);\nconn->terminateStatement(stmt);\nenv->terminateConnection(conn);\nEnvironment::terminateEnvironment(env);\n```\n\n蛋蛋的疼\n\n期间遇到了Oracle 好多奇形怪状的问题。尽管如此，我喜欢这样折腾自己 :) 是不是有点变态。\n\n+ 创建环境变量类指明多线程使用。该任务需要多线程执行的，如果不特别声明多线程执行，如果不特别指明的话会奔溃，我纠结了一天就是因为没有指明这个常量。这在Mysql是没有见到的吧\n+ 连接管理。Oracle的连接关闭很重要。查询任务完成后要及时关闭连接。如果不关闭连接和环境句柄，程序就会有很大的潜在bug,程序执行期间也会奔溃。这过程中自己写了连接管理模块。特别处理了多线程处理时的构造与析构。\n\n以下是连接管理类的代码\n\n```            \n#include<string.h>\nusing namespace oracle::occi;\nclass COraclconn\n{\n    public :\n\n        COraclconn (const std::string & user, const std:: string& password,\n                const std:: string& dbname)\n        {\n            m_status = false;\n            env = NULL;\n            conn = NULL;\n            stmt = NULL;\n            env = Environment::createEnvironment( Environment::THREADED_MUTEXED);\n            if (! env)\n            {\n                env = NULL;\n                return;\n            }\n            conn = env-> createConnection(user, password, dbname);\n            if (! conn)\n            {\n                conn = NULL;\n                return;\n            }\n            m_status = true;\n        }\n\n        ~COraclconn ()\n        {\n            if ( conn && stmt)\n                conn-> terminateStatement( stmt);\n            if ( env && conn)\n                env-> terminateConnection( conn);\n            if ( env)\n                Environment:: terminateEnvironment( env);\n        }\n        Statement * getstmt( const string& sql)\n        {\n            if (! m_status)\n                return NULL;\n            if ( stmt)\n            {\n                conn-> terminateStatement( stmt);\n                stmt = NULL;\n\n            }\n            stmt = conn-> createStatement(sql);\n            if (! stmt)\n            {\n                stmt = NULL;\n                m_status = false;\n            }\n            return stmt;\n\n        }\n    protected :\n        bool m_status;\n        Environment *env ;\n        Connection *conn ;\n        Statement *stmt ;\n};\n```\n\n还好我做的是封装SQL，对于其诡异的语法可以不用涉及到。相信每个热爱技术的人儿碰到写相对非业务的代码会感到充实愉快的吧。\n\nHappy Hacking ：）\n\n","source":"_posts/2013-08-30-jing-ran-ye-yong-dao-liao-oracle.markdown","raw":"---\nlayout: post\ntitle: \"竟然也用到了Oracle\"\ndate: 2013-08-16 20:25\ncomments: true\ncategories: DataBase\n---\n\n#### Oracle初印象\n\n曾经阿里的去O化搞得满城风雨，，随后很多企业也开始跟风去除Oracle，让Oracle这样的企业都为之咳嗽了一阵子。有兴趣的朋友可以看看王坚博士的文章。作为一个开源软件热爱者，首先接触到的一定是Mysql， 随后才是MongoDB,Redis,LevelDb。无论如何是怎么也想不到会去接触Oracle，就像我再也没有机会也不会去使用3.5英寸软盘的样子,因为这样会让我感觉到世界在倒退。\n\n先知言：”存在即合理”。也就为以后的遇见埋下伏笔。果然，由于历史原因，庞大的业务体系下，我终于还是遇见了它，带着对伟大数据库敬仰的心探索了一把。说实话，当你习惯了简单的Mysql之类的思维之后，接触Oracle就有点纠结了。我愿意称其为接触另一种新思维方式。没有比这更值得鼓舞人心的动力了 ：）\n\n{% img /images/2013/08/oracle.png %}\n\n我做的事情是在游戏数据操作中做一个抽象的操作类。涉及框架代码的改造，这过程有点DT。我从事的工作大部分是C++开发这过程着实feel到了“生命太短，远离C++” 涉及到多重继承，虚析构函数，同个父类冲突，属性可见性,抽象类可用。Debug 了两天。还好有GDB这种家伙。\nOracle查询流程\n\n简单描述下普通的Oracle建立连接以及查询的顺序,使用的是OCCI （Oracle的C++接口）:\n\n```\n//创建enviroment变量\nEnvironment *env = Environment::createEnvironment( Environment::DEFAULT);\n//创建连接\nConnection *conn = env->createConnection( userName, password, connectString);\n//创建 查询描述符\nStatement *stmt = conn->createStatement( \"SELECT blobcol FROM mytable\");\n//执行查询，返回结果集\nResultSet *rs = stmt->executeQuery();\n//关闭查询，环境变量\nstmt->closeResultSet(rs);\nconn->terminateStatement(stmt);\nenv->terminateConnection(conn);\nEnvironment::terminateEnvironment(env);\n```\n\n蛋蛋的疼\n\n期间遇到了Oracle 好多奇形怪状的问题。尽管如此，我喜欢这样折腾自己 :) 是不是有点变态。\n\n+ 创建环境变量类指明多线程使用。该任务需要多线程执行的，如果不特别声明多线程执行，如果不特别指明的话会奔溃，我纠结了一天就是因为没有指明这个常量。这在Mysql是没有见到的吧\n+ 连接管理。Oracle的连接关闭很重要。查询任务完成后要及时关闭连接。如果不关闭连接和环境句柄，程序就会有很大的潜在bug,程序执行期间也会奔溃。这过程中自己写了连接管理模块。特别处理了多线程处理时的构造与析构。\n\n以下是连接管理类的代码\n\n```            \n#include<string.h>\nusing namespace oracle::occi;\nclass COraclconn\n{\n    public :\n\n        COraclconn (const std::string & user, const std:: string& password,\n                const std:: string& dbname)\n        {\n            m_status = false;\n            env = NULL;\n            conn = NULL;\n            stmt = NULL;\n            env = Environment::createEnvironment( Environment::THREADED_MUTEXED);\n            if (! env)\n            {\n                env = NULL;\n                return;\n            }\n            conn = env-> createConnection(user, password, dbname);\n            if (! conn)\n            {\n                conn = NULL;\n                return;\n            }\n            m_status = true;\n        }\n\n        ~COraclconn ()\n        {\n            if ( conn && stmt)\n                conn-> terminateStatement( stmt);\n            if ( env && conn)\n                env-> terminateConnection( conn);\n            if ( env)\n                Environment:: terminateEnvironment( env);\n        }\n        Statement * getstmt( const string& sql)\n        {\n            if (! m_status)\n                return NULL;\n            if ( stmt)\n            {\n                conn-> terminateStatement( stmt);\n                stmt = NULL;\n\n            }\n            stmt = conn-> createStatement(sql);\n            if (! stmt)\n            {\n                stmt = NULL;\n                m_status = false;\n            }\n            return stmt;\n\n        }\n    protected :\n        bool m_status;\n        Environment *env ;\n        Connection *conn ;\n        Statement *stmt ;\n};\n```\n\n还好我做的是封装SQL，对于其诡异的语法可以不用涉及到。相信每个热爱技术的人儿碰到写相对非业务的代码会感到充实愉快的吧。\n\nHappy Hacking ：）\n\n","slug":"2013-08-30-jing-ran-ye-yong-dao-liao-oracle","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8n0013nctjkilz2o5u","content":"<h4 id=\"Oracle初印象\"><a href=\"#Oracle初印象\" class=\"headerlink\" title=\"Oracle初印象\"></a>Oracle初印象</h4><p>曾经阿里的去O化搞得满城风雨，，随后很多企业也开始跟风去除Oracle，让Oracle这样的企业都为之咳嗽了一阵子。有兴趣的朋友可以看看王坚博士的文章。作为一个开源软件热爱者，首先接触到的一定是Mysql， 随后才是MongoDB,Redis,LevelDb。无论如何是怎么也想不到会去接触Oracle，就像我再也没有机会也不会去使用3.5英寸软盘的样子,因为这样会让我感觉到世界在倒退。</p>\n<p>先知言：”存在即合理”。也就为以后的遇见埋下伏笔。果然，由于历史原因，庞大的业务体系下，我终于还是遇见了它，带着对伟大数据库敬仰的心探索了一把。说实话，当你习惯了简单的Mysql之类的思维之后，接触Oracle就有点纠结了。我愿意称其为接触另一种新思维方式。没有比这更值得鼓舞人心的动力了 ：）</p>\n<img src=\"/images/2013/08/oracle.png\">\n<p>我做的事情是在游戏数据操作中做一个抽象的操作类。涉及框架代码的改造，这过程有点DT。我从事的工作大部分是C++开发这过程着实feel到了“生命太短，远离C++” 涉及到多重继承，虚析构函数，同个父类冲突，属性可见性,抽象类可用。Debug 了两天。还好有GDB这种家伙。<br>Oracle查询流程</p>\n<p>简单描述下普通的Oracle建立连接以及查询的顺序,使用的是OCCI （Oracle的C++接口）:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//创建enviroment变量</span><br><span class=\"line\">Environment *env = Environment::createEnvironment( Environment::DEFAULT);</span><br><span class=\"line\">//创建连接</span><br><span class=\"line\">Connection *conn = env-&gt;createConnection( userName, password, connectString);</span><br><span class=\"line\">//创建 查询描述符</span><br><span class=\"line\">Statement *stmt = conn-&gt;createStatement( &quot;SELECT blobcol FROM mytable&quot;);</span><br><span class=\"line\">//执行查询，返回结果集</span><br><span class=\"line\">ResultSet *rs = stmt-&gt;executeQuery();</span><br><span class=\"line\">//关闭查询，环境变量</span><br><span class=\"line\">stmt-&gt;closeResultSet(rs);</span><br><span class=\"line\">conn-&gt;terminateStatement(stmt);</span><br><span class=\"line\">env-&gt;terminateConnection(conn);</span><br><span class=\"line\">Environment::terminateEnvironment(env);</span><br></pre></td></tr></table></figure>\n<p>蛋蛋的疼</p>\n<p>期间遇到了Oracle 好多奇形怪状的问题。尽管如此，我喜欢这样折腾自己 :) 是不是有点变态。</p>\n<ul>\n<li>创建环境变量类指明多线程使用。该任务需要多线程执行的，如果不特别声明多线程执行，如果不特别指明的话会奔溃，我纠结了一天就是因为没有指明这个常量。这在Mysql是没有见到的吧</li>\n<li>连接管理。Oracle的连接关闭很重要。查询任务完成后要及时关闭连接。如果不关闭连接和环境句柄，程序就会有很大的潜在bug,程序执行期间也会奔溃。这过程中自己写了连接管理模块。特别处理了多线程处理时的构造与析构。</li>\n</ul>\n<p>以下是连接管理类的代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include&lt;string.h&gt;</span><br><span class=\"line\">using namespace oracle::occi;</span><br><span class=\"line\">class COraclconn</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    public :</span><br><span class=\"line\"></span><br><span class=\"line\">        COraclconn (const std::string &amp; user, const std:: string&amp; password,</span><br><span class=\"line\">                const std:: string&amp; dbname)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            m_status = false;</span><br><span class=\"line\">            env = NULL;</span><br><span class=\"line\">            conn = NULL;</span><br><span class=\"line\">            stmt = NULL;</span><br><span class=\"line\">            env = Environment::createEnvironment( Environment::THREADED_MUTEXED);</span><br><span class=\"line\">            if (! env)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                env = NULL;</span><br><span class=\"line\">                return;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            conn = env-&gt; createConnection(user, password, dbname);</span><br><span class=\"line\">            if (! conn)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                conn = NULL;</span><br><span class=\"line\">                return;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            m_status = true;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        ~COraclconn ()</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            if ( conn &amp;&amp; stmt)</span><br><span class=\"line\">                conn-&gt; terminateStatement( stmt);</span><br><span class=\"line\">            if ( env &amp;&amp; conn)</span><br><span class=\"line\">                env-&gt; terminateConnection( conn);</span><br><span class=\"line\">            if ( env)</span><br><span class=\"line\">                Environment:: terminateEnvironment( env);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Statement * getstmt( const string&amp; sql)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            if (! m_status)</span><br><span class=\"line\">                return NULL;</span><br><span class=\"line\">            if ( stmt)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                conn-&gt; terminateStatement( stmt);</span><br><span class=\"line\">                stmt = NULL;</span><br><span class=\"line\"></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            stmt = conn-&gt; createStatement(sql);</span><br><span class=\"line\">            if (! stmt)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                stmt = NULL;</span><br><span class=\"line\">                m_status = false;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            return stmt;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    protected :</span><br><span class=\"line\">        bool m_status;</span><br><span class=\"line\">        Environment *env ;</span><br><span class=\"line\">        Connection *conn ;</span><br><span class=\"line\">        Statement *stmt ;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>还好我做的是封装SQL，对于其诡异的语法可以不用涉及到。相信每个热爱技术的人儿碰到写相对非业务的代码会感到充实愉快的吧。</p>\n<p>Happy Hacking ：）</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"Oracle初印象\"><a href=\"#Oracle初印象\" class=\"headerlink\" title=\"Oracle初印象\"></a>Oracle初印象</h4><p>曾经阿里的去O化搞得满城风雨，，随后很多企业也开始跟风去除Oracle，让Oracle这样的企业都为之咳嗽了一阵子。有兴趣的朋友可以看看王坚博士的文章。作为一个开源软件热爱者，首先接触到的一定是Mysql， 随后才是MongoDB,Redis,LevelDb。无论如何是怎么也想不到会去接触Oracle，就像我再也没有机会也不会去使用3.5英寸软盘的样子,因为这样会让我感觉到世界在倒退。</p>\n<p>先知言：”存在即合理”。也就为以后的遇见埋下伏笔。果然，由于历史原因，庞大的业务体系下，我终于还是遇见了它，带着对伟大数据库敬仰的心探索了一把。说实话，当你习惯了简单的Mysql之类的思维之后，接触Oracle就有点纠结了。我愿意称其为接触另一种新思维方式。没有比这更值得鼓舞人心的动力了 ：）</p>\n<img src=\"/images/2013/08/oracle.png\">\n<p>我做的事情是在游戏数据操作中做一个抽象的操作类。涉及框架代码的改造，这过程有点DT。我从事的工作大部分是C++开发这过程着实feel到了“生命太短，远离C++” 涉及到多重继承，虚析构函数，同个父类冲突，属性可见性,抽象类可用。Debug 了两天。还好有GDB这种家伙。<br>Oracle查询流程</p>\n<p>简单描述下普通的Oracle建立连接以及查询的顺序,使用的是OCCI （Oracle的C++接口）:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//创建enviroment变量</span><br><span class=\"line\">Environment *env = Environment::createEnvironment( Environment::DEFAULT);</span><br><span class=\"line\">//创建连接</span><br><span class=\"line\">Connection *conn = env-&gt;createConnection( userName, password, connectString);</span><br><span class=\"line\">//创建 查询描述符</span><br><span class=\"line\">Statement *stmt = conn-&gt;createStatement( &quot;SELECT blobcol FROM mytable&quot;);</span><br><span class=\"line\">//执行查询，返回结果集</span><br><span class=\"line\">ResultSet *rs = stmt-&gt;executeQuery();</span><br><span class=\"line\">//关闭查询，环境变量</span><br><span class=\"line\">stmt-&gt;closeResultSet(rs);</span><br><span class=\"line\">conn-&gt;terminateStatement(stmt);</span><br><span class=\"line\">env-&gt;terminateConnection(conn);</span><br><span class=\"line\">Environment::terminateEnvironment(env);</span><br></pre></td></tr></table></figure>\n<p>蛋蛋的疼</p>\n<p>期间遇到了Oracle 好多奇形怪状的问题。尽管如此，我喜欢这样折腾自己 :) 是不是有点变态。</p>\n<ul>\n<li>创建环境变量类指明多线程使用。该任务需要多线程执行的，如果不特别声明多线程执行，如果不特别指明的话会奔溃，我纠结了一天就是因为没有指明这个常量。这在Mysql是没有见到的吧</li>\n<li>连接管理。Oracle的连接关闭很重要。查询任务完成后要及时关闭连接。如果不关闭连接和环境句柄，程序就会有很大的潜在bug,程序执行期间也会奔溃。这过程中自己写了连接管理模块。特别处理了多线程处理时的构造与析构。</li>\n</ul>\n<p>以下是连接管理类的代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include&lt;string.h&gt;</span><br><span class=\"line\">using namespace oracle::occi;</span><br><span class=\"line\">class COraclconn</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    public :</span><br><span class=\"line\"></span><br><span class=\"line\">        COraclconn (const std::string &amp; user, const std:: string&amp; password,</span><br><span class=\"line\">                const std:: string&amp; dbname)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            m_status = false;</span><br><span class=\"line\">            env = NULL;</span><br><span class=\"line\">            conn = NULL;</span><br><span class=\"line\">            stmt = NULL;</span><br><span class=\"line\">            env = Environment::createEnvironment( Environment::THREADED_MUTEXED);</span><br><span class=\"line\">            if (! env)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                env = NULL;</span><br><span class=\"line\">                return;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            conn = env-&gt; createConnection(user, password, dbname);</span><br><span class=\"line\">            if (! conn)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                conn = NULL;</span><br><span class=\"line\">                return;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            m_status = true;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        ~COraclconn ()</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            if ( conn &amp;&amp; stmt)</span><br><span class=\"line\">                conn-&gt; terminateStatement( stmt);</span><br><span class=\"line\">            if ( env &amp;&amp; conn)</span><br><span class=\"line\">                env-&gt; terminateConnection( conn);</span><br><span class=\"line\">            if ( env)</span><br><span class=\"line\">                Environment:: terminateEnvironment( env);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Statement * getstmt( const string&amp; sql)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            if (! m_status)</span><br><span class=\"line\">                return NULL;</span><br><span class=\"line\">            if ( stmt)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                conn-&gt; terminateStatement( stmt);</span><br><span class=\"line\">                stmt = NULL;</span><br><span class=\"line\"></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            stmt = conn-&gt; createStatement(sql);</span><br><span class=\"line\">            if (! stmt)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                stmt = NULL;</span><br><span class=\"line\">                m_status = false;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            return stmt;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    protected :</span><br><span class=\"line\">        bool m_status;</span><br><span class=\"line\">        Environment *env ;</span><br><span class=\"line\">        Connection *conn ;</span><br><span class=\"line\">        Statement *stmt ;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>还好我做的是封装SQL，对于其诡异的语法可以不用涉及到。相信每个热爱技术的人儿碰到写相对非业务的代码会感到充实愉快的吧。</p>\n<p>Happy Hacking ：）</p>\n"},{"layout":"post","title":"nginx+lua应对在线状态服务","date":"2013-09-12T15:12:00.000Z","comments":1,"description":"nginx lua","_content":"\n几天前在@ideawu的博客上看到了其一篇文章中讲到的技术题.\n[《在线状态服务在网站系统中的应用》](http://www.ideawu.net/blog/archives/732.html) 。于是内心折腾的火焰便熊熊燃烧起来，连续几天晚上折腾到凌晨1点。感谢@agentzh 春哥与阿里巴巴的技术贡献,让我可以安心睡觉 :) \n\n在线状态服务这样的场景在互联网应用上比比皆是\n\n* 聊天系统中同时在线的人数\n* 游戏中同时在线玩家等\n\n文中所言,现实的在线状态应用场景是:\n网页中用JavaScript启动一个定时器, 定期报告在线状态, 也就是向在线状态服务器发送心跳包.对某个同时在线100万人, 每天1亿PV的网站来说, 在线状态服务器一天接收到的心跳包大概是10亿个, 也即每秒10000个请求(10000qps).要实现这样的在线状态服务器, 也是一个挑战.\n \n好了，我当时真的很兴奋，感觉自己像接到了任务，立马打起了鸡血研究. 脑海中涌现出来的直觉是，使用tornado + Redis，这样的高并发组合应对这样的场景应该是无压力的，但是因为这样的事情我做过，想挑战自己非舒适的区域，挖掘新的知识大陆。\n我们一直都说，没有经过打磨的想法一般都是廉价的。后来我想到的是Ngnix这样的服务器来抗如此高的请求，那么我们就自己写个拓展，查询内存数据库，这里我选择用redis来做kv内存数据库，\n\n文中谈到的自己设计精巧的kv数据库，甚至用C++写针对性的http服务，来提升通用服务器的性能。曾经写过一个KV数据库，其性能真的是渣渣。[源码链接](https://github.com/zheng-ji/KvDb)。欢迎吐槽.\n一直以来听闻春哥的nginx lua模块拓展，可以为nginx定制业务。想想以前用c语言实现，简直就是痛苦,这一次可以使用lua，甚为欢悦，没有什么比探索新东西带来的乐趣更令人振奋了\n\n首先要有lua的运行环境。他是一种胶水粘合剂 ：） 还必须安装**luajit**\n\n```\n#设置环境变量，后续安装需要\nshell> export LUAJIT_LIB=/usr/local/lib\nshell> export LUAJIT_INC=/usr/local/include/luajit-<VERSION>\n```\n\n#### 需要安装的nginx 插件\n\n```\nngx_devel_kit https://github.com/simpl/ngx_devel_kit\nset-misc-nginx-module https://github.com/agentzh/set-misc-nginx-module\nmemc-nginx-module https://github.com/agentzh/memc-nginx-module \nlua-nginx-module https://github.com/chaoslawful/lua-nginx-module\n```\n\n#### 下载之后，安装nginx插件\n                 \n```\n./configure --prefix=/path/to/nginx_src --add-module=/path/to/ngx_devel_kit --add-module=set-misc-nginx-module \\\n--add-module=/path/to/lua-nginx-module -add-module=ngx_devel_kit \nmake \nmake install\n```\n\nnginx.conf 文件                 \n\n```\nlocation /echo {  \n    default_type 'text/plain';  \n    echo 'hello echo';  \n}  \n\nlocation /lua {  \n    default_type 'text/plain';  \n    content_by_lua 'ngx.say(\"hello, lua\")';  \n}  \n```\n\n也许你会遇到一些麻烦,执行如下命令\n\n```\nshell> echo \"/usr/local/lib\" > /etc/ld.so.conf.d/usr_local_lib.conf\nshell> ldconfig\n```\n\n重启服务器之后，应该就可以看到hello,lua :) (到这里仅仅是开始，折腾了有点久)\n \n### 好了，来完成ideawu的作业 ：）\n\n>在线状态服务, 是这样的一个服务, 它维护了网站当前的在线用户列表, 接受其它模块的查询. 是实现统计网站同时在线人数, 维护在线用户列表等功能的基础服务. 在Facebook的聊天系统中, 在线状态是为聊天系统服务的, 所以在线状态是一种”强”在线, 也即用户保持着和Comet服务器的连接, 可随时接受服务器推送(push)的消息.在高并发请求的情况下如何完成该需求呢\n\n使用 Lua 脚本语言操作 Redis。这里使用 content_by_lua_file （nginx_lua_module 模块具有）来引入 Lua 脚本文件。\nagentzh 提供了一个很方便的开发包，如下：[lua-resty-redis](https://github.com/agentzh/lua-resty-redis.git)\n\n该包中，有一个 lib 目录，将 lib 目录下的文件和子目录拷贝至目录 /home/zj/soft/data/www/lua/\n在 Nginx 配置文件中，需要加一行代码，以便引入 redis.lua。\n注：加在 http 段里。\n\n```\nlua_package_path \"/home/zj/soft/data/www/lua//?.lua;;\";  \n```\n\n为了使得 lua 脚本的修改能及时生效，需要加入一行代码，如下：注：在 server 段里，加入代码，如果不加此代码或者设置为 on 时，则需要重启 Nginx。 不过nginx 会报警\n\n```\nlua_code_cache off;  \n```\n\nnginx.conf 里\n\n```\nlocation /getolNum {\n    content_by_lua_file /conf/online.lua;  \n} \n```\n\n##### online.lua 源码\n\n```lua\nlocal redis = require \"redis\"\nlocal cache = redis.new()\n\nlocal ok, err = cache.connect(cache, '127.0.0.1', '6379')\nif not ok then\n    ngx.say(\"failed to connect:\", err)\n    return\nend\n\ncache:set_timeout(30000)\nargs = ngx.req.get_uri_args()\nuser = args[\"user\"]\n--设置用户 3 min 过期\ncache:setex(user,180,23)\n\nlocal res,err = cache:keys('*')\n\n--count res num\ncount = 0\nfor _ in pairs(res) do\n    count = count + 1\nend\nngx.say(count)\nlocal ok, err = cache:close()\n```\n\n结果\n\n```\ncurl localhost/getOlnum?user=zj\n返回：1\ncurl localhost/getOlnum?user=zhengji\n返回：2\n```\n\nHappy Hacking :)\n \n\n\n\n\n\n\n\n\n","source":"_posts/2013-09-12-nginx-plus-luaying-dui-zai-xian-zhuang-tai-fu-wu.markdown","raw":"---\nlayout: post\ntitle: \"nginx+lua应对在线状态服务\"\ndate: 2013-09-12 23:12\ncomments: true\ncategories: Server\ndescription: nginx lua\n---\n\n几天前在@ideawu的博客上看到了其一篇文章中讲到的技术题.\n[《在线状态服务在网站系统中的应用》](http://www.ideawu.net/blog/archives/732.html) 。于是内心折腾的火焰便熊熊燃烧起来，连续几天晚上折腾到凌晨1点。感谢@agentzh 春哥与阿里巴巴的技术贡献,让我可以安心睡觉 :) \n\n在线状态服务这样的场景在互联网应用上比比皆是\n\n* 聊天系统中同时在线的人数\n* 游戏中同时在线玩家等\n\n文中所言,现实的在线状态应用场景是:\n网页中用JavaScript启动一个定时器, 定期报告在线状态, 也就是向在线状态服务器发送心跳包.对某个同时在线100万人, 每天1亿PV的网站来说, 在线状态服务器一天接收到的心跳包大概是10亿个, 也即每秒10000个请求(10000qps).要实现这样的在线状态服务器, 也是一个挑战.\n \n好了，我当时真的很兴奋，感觉自己像接到了任务，立马打起了鸡血研究. 脑海中涌现出来的直觉是，使用tornado + Redis，这样的高并发组合应对这样的场景应该是无压力的，但是因为这样的事情我做过，想挑战自己非舒适的区域，挖掘新的知识大陆。\n我们一直都说，没有经过打磨的想法一般都是廉价的。后来我想到的是Ngnix这样的服务器来抗如此高的请求，那么我们就自己写个拓展，查询内存数据库，这里我选择用redis来做kv内存数据库，\n\n文中谈到的自己设计精巧的kv数据库，甚至用C++写针对性的http服务，来提升通用服务器的性能。曾经写过一个KV数据库，其性能真的是渣渣。[源码链接](https://github.com/zheng-ji/KvDb)。欢迎吐槽.\n一直以来听闻春哥的nginx lua模块拓展，可以为nginx定制业务。想想以前用c语言实现，简直就是痛苦,这一次可以使用lua，甚为欢悦，没有什么比探索新东西带来的乐趣更令人振奋了\n\n首先要有lua的运行环境。他是一种胶水粘合剂 ：） 还必须安装**luajit**\n\n```\n#设置环境变量，后续安装需要\nshell> export LUAJIT_LIB=/usr/local/lib\nshell> export LUAJIT_INC=/usr/local/include/luajit-<VERSION>\n```\n\n#### 需要安装的nginx 插件\n\n```\nngx_devel_kit https://github.com/simpl/ngx_devel_kit\nset-misc-nginx-module https://github.com/agentzh/set-misc-nginx-module\nmemc-nginx-module https://github.com/agentzh/memc-nginx-module \nlua-nginx-module https://github.com/chaoslawful/lua-nginx-module\n```\n\n#### 下载之后，安装nginx插件\n                 \n```\n./configure --prefix=/path/to/nginx_src --add-module=/path/to/ngx_devel_kit --add-module=set-misc-nginx-module \\\n--add-module=/path/to/lua-nginx-module -add-module=ngx_devel_kit \nmake \nmake install\n```\n\nnginx.conf 文件                 \n\n```\nlocation /echo {  \n    default_type 'text/plain';  \n    echo 'hello echo';  \n}  \n\nlocation /lua {  \n    default_type 'text/plain';  \n    content_by_lua 'ngx.say(\"hello, lua\")';  \n}  \n```\n\n也许你会遇到一些麻烦,执行如下命令\n\n```\nshell> echo \"/usr/local/lib\" > /etc/ld.so.conf.d/usr_local_lib.conf\nshell> ldconfig\n```\n\n重启服务器之后，应该就可以看到hello,lua :) (到这里仅仅是开始，折腾了有点久)\n \n### 好了，来完成ideawu的作业 ：）\n\n>在线状态服务, 是这样的一个服务, 它维护了网站当前的在线用户列表, 接受其它模块的查询. 是实现统计网站同时在线人数, 维护在线用户列表等功能的基础服务. 在Facebook的聊天系统中, 在线状态是为聊天系统服务的, 所以在线状态是一种”强”在线, 也即用户保持着和Comet服务器的连接, 可随时接受服务器推送(push)的消息.在高并发请求的情况下如何完成该需求呢\n\n使用 Lua 脚本语言操作 Redis。这里使用 content_by_lua_file （nginx_lua_module 模块具有）来引入 Lua 脚本文件。\nagentzh 提供了一个很方便的开发包，如下：[lua-resty-redis](https://github.com/agentzh/lua-resty-redis.git)\n\n该包中，有一个 lib 目录，将 lib 目录下的文件和子目录拷贝至目录 /home/zj/soft/data/www/lua/\n在 Nginx 配置文件中，需要加一行代码，以便引入 redis.lua。\n注：加在 http 段里。\n\n```\nlua_package_path \"/home/zj/soft/data/www/lua//?.lua;;\";  \n```\n\n为了使得 lua 脚本的修改能及时生效，需要加入一行代码，如下：注：在 server 段里，加入代码，如果不加此代码或者设置为 on 时，则需要重启 Nginx。 不过nginx 会报警\n\n```\nlua_code_cache off;  \n```\n\nnginx.conf 里\n\n```\nlocation /getolNum {\n    content_by_lua_file /conf/online.lua;  \n} \n```\n\n##### online.lua 源码\n\n```lua\nlocal redis = require \"redis\"\nlocal cache = redis.new()\n\nlocal ok, err = cache.connect(cache, '127.0.0.1', '6379')\nif not ok then\n    ngx.say(\"failed to connect:\", err)\n    return\nend\n\ncache:set_timeout(30000)\nargs = ngx.req.get_uri_args()\nuser = args[\"user\"]\n--设置用户 3 min 过期\ncache:setex(user,180,23)\n\nlocal res,err = cache:keys('*')\n\n--count res num\ncount = 0\nfor _ in pairs(res) do\n    count = count + 1\nend\nngx.say(count)\nlocal ok, err = cache:close()\n```\n\n结果\n\n```\ncurl localhost/getOlnum?user=zj\n返回：1\ncurl localhost/getOlnum?user=zhengji\n返回：2\n```\n\nHappy Hacking :)\n \n\n\n\n\n\n\n\n\n","slug":"2013-09-12-nginx-plus-luaying-dui-zai-xian-zhuang-tai-fu-wu","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8o0015nctjejy94i8m","content":"<p>几天前在@ideawu的博客上看到了其一篇文章中讲到的技术题.<br><a href=\"http://www.ideawu.net/blog/archives/732.html\" target=\"_blank\" rel=\"noopener\">《在线状态服务在网站系统中的应用》</a> 。于是内心折腾的火焰便熊熊燃烧起来，连续几天晚上折腾到凌晨1点。感谢@agentzh 春哥与阿里巴巴的技术贡献,让我可以安心睡觉 :) </p>\n<p>在线状态服务这样的场景在互联网应用上比比皆是</p>\n<ul>\n<li>聊天系统中同时在线的人数</li>\n<li>游戏中同时在线玩家等</li>\n</ul>\n<p>文中所言,现实的在线状态应用场景是:<br>网页中用JavaScript启动一个定时器, 定期报告在线状态, 也就是向在线状态服务器发送心跳包.对某个同时在线100万人, 每天1亿PV的网站来说, 在线状态服务器一天接收到的心跳包大概是10亿个, 也即每秒10000个请求(10000qps).要实现这样的在线状态服务器, 也是一个挑战.</p>\n<p>好了，我当时真的很兴奋，感觉自己像接到了任务，立马打起了鸡血研究. 脑海中涌现出来的直觉是，使用tornado + Redis，这样的高并发组合应对这样的场景应该是无压力的，但是因为这样的事情我做过，想挑战自己非舒适的区域，挖掘新的知识大陆。<br>我们一直都说，没有经过打磨的想法一般都是廉价的。后来我想到的是Ngnix这样的服务器来抗如此高的请求，那么我们就自己写个拓展，查询内存数据库，这里我选择用redis来做kv内存数据库，</p>\n<p>文中谈到的自己设计精巧的kv数据库，甚至用C++写针对性的http服务，来提升通用服务器的性能。曾经写过一个KV数据库，其性能真的是渣渣。<a href=\"https://github.com/zheng-ji/KvDb\" target=\"_blank\" rel=\"noopener\">源码链接</a>。欢迎吐槽.<br>一直以来听闻春哥的nginx lua模块拓展，可以为nginx定制业务。想想以前用c语言实现，简直就是痛苦,这一次可以使用lua，甚为欢悦，没有什么比探索新东西带来的乐趣更令人振奋了</p>\n<p>首先要有lua的运行环境。他是一种胶水粘合剂 ：） 还必须安装<strong>luajit</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#设置环境变量，后续安装需要</span><br><span class=\"line\">shell&gt; export LUAJIT_LIB=/usr/local/lib</span><br><span class=\"line\">shell&gt; export LUAJIT_INC=/usr/local/include/luajit-&lt;VERSION&gt;</span><br></pre></td></tr></table></figure>\n<h4 id=\"需要安装的nginx-插件\"><a href=\"#需要安装的nginx-插件\" class=\"headerlink\" title=\"需要安装的nginx 插件\"></a>需要安装的nginx 插件</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ngx_devel_kit https://github.com/simpl/ngx_devel_kit</span><br><span class=\"line\">set-misc-nginx-module https://github.com/agentzh/set-misc-nginx-module</span><br><span class=\"line\">memc-nginx-module https://github.com/agentzh/memc-nginx-module </span><br><span class=\"line\">lua-nginx-module https://github.com/chaoslawful/lua-nginx-module</span><br></pre></td></tr></table></figure>\n<h4 id=\"下载之后，安装nginx插件\"><a href=\"#下载之后，安装nginx插件\" class=\"headerlink\" title=\"下载之后，安装nginx插件\"></a>下载之后，安装nginx插件</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --prefix=/path/to/nginx_src --add-module=/path/to/ngx_devel_kit --add-module=set-misc-nginx-module \\</span><br><span class=\"line\">--add-module=/path/to/lua-nginx-module -add-module=ngx_devel_kit </span><br><span class=\"line\">make </span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<p>nginx.conf 文件                 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /echo &#123;  </span><br><span class=\"line\">    default_type &apos;text/plain&apos;;  </span><br><span class=\"line\">    echo &apos;hello echo&apos;;  </span><br><span class=\"line\">&#125;  </span><br><span class=\"line\"></span><br><span class=\"line\">location /lua &#123;  </span><br><span class=\"line\">    default_type &apos;text/plain&apos;;  </span><br><span class=\"line\">    content_by_lua &apos;ngx.say(&quot;hello, lua&quot;)&apos;;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>也许你会遇到一些麻烦,执行如下命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shell&gt; echo &quot;/usr/local/lib&quot; &gt; /etc/ld.so.conf.d/usr_local_lib.conf</span><br><span class=\"line\">shell&gt; ldconfig</span><br></pre></td></tr></table></figure>\n<p>重启服务器之后，应该就可以看到hello,lua :) (到这里仅仅是开始，折腾了有点久)</p>\n<h3 id=\"好了，来完成ideawu的作业-：）\"><a href=\"#好了，来完成ideawu的作业-：）\" class=\"headerlink\" title=\"好了，来完成ideawu的作业 ：）\"></a>好了，来完成ideawu的作业 ：）</h3><blockquote>\n<p>在线状态服务, 是这样的一个服务, 它维护了网站当前的在线用户列表, 接受其它模块的查询. 是实现统计网站同时在线人数, 维护在线用户列表等功能的基础服务. 在Facebook的聊天系统中, 在线状态是为聊天系统服务的, 所以在线状态是一种”强”在线, 也即用户保持着和Comet服务器的连接, 可随时接受服务器推送(push)的消息.在高并发请求的情况下如何完成该需求呢</p>\n</blockquote>\n<p>使用 Lua 脚本语言操作 Redis。这里使用 content_by_lua_file （nginx_lua_module 模块具有）来引入 Lua 脚本文件。<br>agentzh 提供了一个很方便的开发包，如下：<a href=\"https://github.com/agentzh/lua-resty-redis.git\" target=\"_blank\" rel=\"noopener\">lua-resty-redis</a></p>\n<p>该包中，有一个 lib 目录，将 lib 目录下的文件和子目录拷贝至目录 /home/zj/soft/data/www/lua/<br>在 Nginx 配置文件中，需要加一行代码，以便引入 redis.lua。<br>注：加在 http 段里。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lua_package_path &quot;/home/zj/soft/data/www/lua//?.lua;;&quot;;</span><br></pre></td></tr></table></figure>\n<p>为了使得 lua 脚本的修改能及时生效，需要加入一行代码，如下：注：在 server 段里，加入代码，如果不加此代码或者设置为 on 时，则需要重启 Nginx。 不过nginx 会报警</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lua_code_cache off;</span><br></pre></td></tr></table></figure>\n<p>nginx.conf 里</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /getolNum &#123;</span><br><span class=\"line\">    content_by_lua_file /conf/online.lua;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"online-lua-源码\"><a href=\"#online-lua-源码\" class=\"headerlink\" title=\"online.lua 源码\"></a>online.lua 源码</h5><figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">local</span> redis = <span class=\"built_in\">require</span> <span class=\"string\">\"redis\"</span></span><br><span class=\"line\"><span class=\"keyword\">local</span> cache = redis.new()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">local</span> ok, err = cache.connect(cache, <span class=\"string\">'127.0.0.1'</span>, <span class=\"string\">'6379'</span>)</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> ok <span class=\"keyword\">then</span></span><br><span class=\"line\">    ngx.say(<span class=\"string\">\"failed to connect:\"</span>, err)</span><br><span class=\"line\">    <span class=\"keyword\">return</span></span><br><span class=\"line\"><span class=\"keyword\">end</span></span><br><span class=\"line\"></span><br><span class=\"line\">cache:set_timeout(<span class=\"number\">30000</span>)</span><br><span class=\"line\">args = ngx.req.get_uri_args()</span><br><span class=\"line\">user = args[<span class=\"string\">\"user\"</span>]</span><br><span class=\"line\"><span class=\"comment\">--设置用户 3 min 过期</span></span><br><span class=\"line\">cache:setex(user,<span class=\"number\">180</span>,<span class=\"number\">23</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">local</span> res,err = cache:keys(<span class=\"string\">'*'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">--count res num</span></span><br><span class=\"line\">count = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">pairs</span>(res) <span class=\"keyword\">do</span></span><br><span class=\"line\">    count = count + <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"keyword\">end</span></span><br><span class=\"line\">ngx.say(count)</span><br><span class=\"line\"><span class=\"keyword\">local</span> ok, err = cache:<span class=\"built_in\">close</span>()</span><br></pre></td></tr></table></figure>\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost/getOlnum?user=zj</span><br><span class=\"line\">返回：1</span><br><span class=\"line\">curl localhost/getOlnum?user=zhengji</span><br><span class=\"line\">返回：2</span><br></pre></td></tr></table></figure>\n<p>Happy Hacking :)</p>\n","site":{"data":{}},"excerpt":"","more":"<p>几天前在@ideawu的博客上看到了其一篇文章中讲到的技术题.<br><a href=\"http://www.ideawu.net/blog/archives/732.html\" target=\"_blank\" rel=\"noopener\">《在线状态服务在网站系统中的应用》</a> 。于是内心折腾的火焰便熊熊燃烧起来，连续几天晚上折腾到凌晨1点。感谢@agentzh 春哥与阿里巴巴的技术贡献,让我可以安心睡觉 :) </p>\n<p>在线状态服务这样的场景在互联网应用上比比皆是</p>\n<ul>\n<li>聊天系统中同时在线的人数</li>\n<li>游戏中同时在线玩家等</li>\n</ul>\n<p>文中所言,现实的在线状态应用场景是:<br>网页中用JavaScript启动一个定时器, 定期报告在线状态, 也就是向在线状态服务器发送心跳包.对某个同时在线100万人, 每天1亿PV的网站来说, 在线状态服务器一天接收到的心跳包大概是10亿个, 也即每秒10000个请求(10000qps).要实现这样的在线状态服务器, 也是一个挑战.</p>\n<p>好了，我当时真的很兴奋，感觉自己像接到了任务，立马打起了鸡血研究. 脑海中涌现出来的直觉是，使用tornado + Redis，这样的高并发组合应对这样的场景应该是无压力的，但是因为这样的事情我做过，想挑战自己非舒适的区域，挖掘新的知识大陆。<br>我们一直都说，没有经过打磨的想法一般都是廉价的。后来我想到的是Ngnix这样的服务器来抗如此高的请求，那么我们就自己写个拓展，查询内存数据库，这里我选择用redis来做kv内存数据库，</p>\n<p>文中谈到的自己设计精巧的kv数据库，甚至用C++写针对性的http服务，来提升通用服务器的性能。曾经写过一个KV数据库，其性能真的是渣渣。<a href=\"https://github.com/zheng-ji/KvDb\" target=\"_blank\" rel=\"noopener\">源码链接</a>。欢迎吐槽.<br>一直以来听闻春哥的nginx lua模块拓展，可以为nginx定制业务。想想以前用c语言实现，简直就是痛苦,这一次可以使用lua，甚为欢悦，没有什么比探索新东西带来的乐趣更令人振奋了</p>\n<p>首先要有lua的运行环境。他是一种胶水粘合剂 ：） 还必须安装<strong>luajit</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#设置环境变量，后续安装需要</span><br><span class=\"line\">shell&gt; export LUAJIT_LIB=/usr/local/lib</span><br><span class=\"line\">shell&gt; export LUAJIT_INC=/usr/local/include/luajit-&lt;VERSION&gt;</span><br></pre></td></tr></table></figure>\n<h4 id=\"需要安装的nginx-插件\"><a href=\"#需要安装的nginx-插件\" class=\"headerlink\" title=\"需要安装的nginx 插件\"></a>需要安装的nginx 插件</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ngx_devel_kit https://github.com/simpl/ngx_devel_kit</span><br><span class=\"line\">set-misc-nginx-module https://github.com/agentzh/set-misc-nginx-module</span><br><span class=\"line\">memc-nginx-module https://github.com/agentzh/memc-nginx-module </span><br><span class=\"line\">lua-nginx-module https://github.com/chaoslawful/lua-nginx-module</span><br></pre></td></tr></table></figure>\n<h4 id=\"下载之后，安装nginx插件\"><a href=\"#下载之后，安装nginx插件\" class=\"headerlink\" title=\"下载之后，安装nginx插件\"></a>下载之后，安装nginx插件</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --prefix=/path/to/nginx_src --add-module=/path/to/ngx_devel_kit --add-module=set-misc-nginx-module \\</span><br><span class=\"line\">--add-module=/path/to/lua-nginx-module -add-module=ngx_devel_kit </span><br><span class=\"line\">make </span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<p>nginx.conf 文件                 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /echo &#123;  </span><br><span class=\"line\">    default_type &apos;text/plain&apos;;  </span><br><span class=\"line\">    echo &apos;hello echo&apos;;  </span><br><span class=\"line\">&#125;  </span><br><span class=\"line\"></span><br><span class=\"line\">location /lua &#123;  </span><br><span class=\"line\">    default_type &apos;text/plain&apos;;  </span><br><span class=\"line\">    content_by_lua &apos;ngx.say(&quot;hello, lua&quot;)&apos;;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>也许你会遇到一些麻烦,执行如下命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shell&gt; echo &quot;/usr/local/lib&quot; &gt; /etc/ld.so.conf.d/usr_local_lib.conf</span><br><span class=\"line\">shell&gt; ldconfig</span><br></pre></td></tr></table></figure>\n<p>重启服务器之后，应该就可以看到hello,lua :) (到这里仅仅是开始，折腾了有点久)</p>\n<h3 id=\"好了，来完成ideawu的作业-：）\"><a href=\"#好了，来完成ideawu的作业-：）\" class=\"headerlink\" title=\"好了，来完成ideawu的作业 ：）\"></a>好了，来完成ideawu的作业 ：）</h3><blockquote>\n<p>在线状态服务, 是这样的一个服务, 它维护了网站当前的在线用户列表, 接受其它模块的查询. 是实现统计网站同时在线人数, 维护在线用户列表等功能的基础服务. 在Facebook的聊天系统中, 在线状态是为聊天系统服务的, 所以在线状态是一种”强”在线, 也即用户保持着和Comet服务器的连接, 可随时接受服务器推送(push)的消息.在高并发请求的情况下如何完成该需求呢</p>\n</blockquote>\n<p>使用 Lua 脚本语言操作 Redis。这里使用 content_by_lua_file （nginx_lua_module 模块具有）来引入 Lua 脚本文件。<br>agentzh 提供了一个很方便的开发包，如下：<a href=\"https://github.com/agentzh/lua-resty-redis.git\" target=\"_blank\" rel=\"noopener\">lua-resty-redis</a></p>\n<p>该包中，有一个 lib 目录，将 lib 目录下的文件和子目录拷贝至目录 /home/zj/soft/data/www/lua/<br>在 Nginx 配置文件中，需要加一行代码，以便引入 redis.lua。<br>注：加在 http 段里。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lua_package_path &quot;/home/zj/soft/data/www/lua//?.lua;;&quot;;</span><br></pre></td></tr></table></figure>\n<p>为了使得 lua 脚本的修改能及时生效，需要加入一行代码，如下：注：在 server 段里，加入代码，如果不加此代码或者设置为 on 时，则需要重启 Nginx。 不过nginx 会报警</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lua_code_cache off;</span><br></pre></td></tr></table></figure>\n<p>nginx.conf 里</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /getolNum &#123;</span><br><span class=\"line\">    content_by_lua_file /conf/online.lua;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"online-lua-源码\"><a href=\"#online-lua-源码\" class=\"headerlink\" title=\"online.lua 源码\"></a>online.lua 源码</h5><figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">local</span> redis = <span class=\"built_in\">require</span> <span class=\"string\">\"redis\"</span></span><br><span class=\"line\"><span class=\"keyword\">local</span> cache = redis.new()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">local</span> ok, err = cache.connect(cache, <span class=\"string\">'127.0.0.1'</span>, <span class=\"string\">'6379'</span>)</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> ok <span class=\"keyword\">then</span></span><br><span class=\"line\">    ngx.say(<span class=\"string\">\"failed to connect:\"</span>, err)</span><br><span class=\"line\">    <span class=\"keyword\">return</span></span><br><span class=\"line\"><span class=\"keyword\">end</span></span><br><span class=\"line\"></span><br><span class=\"line\">cache:set_timeout(<span class=\"number\">30000</span>)</span><br><span class=\"line\">args = ngx.req.get_uri_args()</span><br><span class=\"line\">user = args[<span class=\"string\">\"user\"</span>]</span><br><span class=\"line\"><span class=\"comment\">--设置用户 3 min 过期</span></span><br><span class=\"line\">cache:setex(user,<span class=\"number\">180</span>,<span class=\"number\">23</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">local</span> res,err = cache:keys(<span class=\"string\">'*'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">--count res num</span></span><br><span class=\"line\">count = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">pairs</span>(res) <span class=\"keyword\">do</span></span><br><span class=\"line\">    count = count + <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"keyword\">end</span></span><br><span class=\"line\">ngx.say(count)</span><br><span class=\"line\"><span class=\"keyword\">local</span> ok, err = cache:<span class=\"built_in\">close</span>()</span><br></pre></td></tr></table></figure>\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost/getOlnum?user=zj</span><br><span class=\"line\">返回：1</span><br><span class=\"line\">curl localhost/getOlnum?user=zhengji</span><br><span class=\"line\">返回：2</span><br></pre></td></tr></table></figure>\n<p>Happy Hacking :)</p>\n"},{"layout":"post","title":"Jsonp解决跨域请求","date":"2013-09-15T13:50:00.000Z","comments":1,"_content":"\n昨天搞了一整天js,遇到了各种我从没遇到的问题,真心觉得前端工程师是很厉害的。想不出为什么会有人说所谓的前端“无技术含量”的源论.前端要考虑的东西实在是多，也有其架构设计。特别是js. 我用的是phonegap + jqtouch做移动App\n\n\n场景是：\n客户端使用Ajax技术向服务器发送请求，然后拉取数据\n\nServer端代码是php写的,\n\n```php\n$arr = array(\n        'user'=>'123',\n        'friends' => 234\n        )\necho json_encode($arr);\n```\n\njs代码,使用jquery发起get 请求,文件路径E:/mytest/test.html\n\n```javascript\n$(function(){\n    url = \"http://127.0.0.1/test.php\"\n    $.get(url,funtion(result) {\n        alert(result);\n    })\n);\n```\n\n看过jquery文档之后，我以为这样会返回我要的数据，真是图样图森破，chrome的控制台返回：不是同一个源，不允许跨域发请求。 \n\n#####什么是跨域请求\n简单来说：a.com 域名下的js无法操作b.com或是c.a.com域名下的对象,上述场景中，http://127.0.0.1/test.php 和 E：/mytest/test.html本身就不属于同一个域下，因此不能访问。浏览器本身有同源策略，当初设计是出于安全考虑，百度给出了解释是：\n>　同源策略，它是由Netscape提出的一个著名的安全策略。现在所有支持JavaScript 的浏览器都会使用这个策略。所谓同源是指，域名，协议，端口相同。当一个浏览器的两个tab页中分别打开来 百度和谷歌的页面当一个百度浏览器执行一个脚本的时候会检查这个脚本是属于哪个页面的，即检查是否同源，只有和百度同源的脚本才会被执行。\n\n我最后是通过查阅资料,采用jsonp的方式解决\n\n#####什么是jsonp\n>　JSONP是JSON with Padding的略称。它是一个非官方的协议，它允许在服务器端集成Script tags返回至客户端，通过javascript callback的形式实现跨域访问（这仅仅是JSONP简单的实现形式） - 百度\n\n因此最后的Server端代码是php写的\n\n```python\n$arr = array(\n        'user'=>'123',\n        'friends' => 234\n        )\n$callback = $_GET['callback']; //新加\necho $callback.json_encode($arr);\n```\n\njs代码,请求的时候，加入一个参数callback,通过javascripte callback形式调用服务器的scrpt tags的返回值\n\n```javascript\n$(function(){\n    url = \"http://127.0.0.1/test.php?callback=?\"\n    $.get(url,funtion(result) {\n        alert(result);\n    }));\n```\n\n调用成功\n这个东西纠结我大半天。但是有收获的 ：）\n\n\n\n\n\n","source":"_posts/2013-09-15-jsonpjie-jue-kua-yu-qing-qiu.markdown","raw":"---\nlayout: post\ntitle: \"Jsonp解决跨域请求\"\ndate: 2013-09-15 21:50\ncomments: true\ncategories: NetWork\n---\n\n昨天搞了一整天js,遇到了各种我从没遇到的问题,真心觉得前端工程师是很厉害的。想不出为什么会有人说所谓的前端“无技术含量”的源论.前端要考虑的东西实在是多，也有其架构设计。特别是js. 我用的是phonegap + jqtouch做移动App\n\n\n场景是：\n客户端使用Ajax技术向服务器发送请求，然后拉取数据\n\nServer端代码是php写的,\n\n```php\n$arr = array(\n        'user'=>'123',\n        'friends' => 234\n        )\necho json_encode($arr);\n```\n\njs代码,使用jquery发起get 请求,文件路径E:/mytest/test.html\n\n```javascript\n$(function(){\n    url = \"http://127.0.0.1/test.php\"\n    $.get(url,funtion(result) {\n        alert(result);\n    })\n);\n```\n\n看过jquery文档之后，我以为这样会返回我要的数据，真是图样图森破，chrome的控制台返回：不是同一个源，不允许跨域发请求。 \n\n#####什么是跨域请求\n简单来说：a.com 域名下的js无法操作b.com或是c.a.com域名下的对象,上述场景中，http://127.0.0.1/test.php 和 E：/mytest/test.html本身就不属于同一个域下，因此不能访问。浏览器本身有同源策略，当初设计是出于安全考虑，百度给出了解释是：\n>　同源策略，它是由Netscape提出的一个著名的安全策略。现在所有支持JavaScript 的浏览器都会使用这个策略。所谓同源是指，域名，协议，端口相同。当一个浏览器的两个tab页中分别打开来 百度和谷歌的页面当一个百度浏览器执行一个脚本的时候会检查这个脚本是属于哪个页面的，即检查是否同源，只有和百度同源的脚本才会被执行。\n\n我最后是通过查阅资料,采用jsonp的方式解决\n\n#####什么是jsonp\n>　JSONP是JSON with Padding的略称。它是一个非官方的协议，它允许在服务器端集成Script tags返回至客户端，通过javascript callback的形式实现跨域访问（这仅仅是JSONP简单的实现形式） - 百度\n\n因此最后的Server端代码是php写的\n\n```python\n$arr = array(\n        'user'=>'123',\n        'friends' => 234\n        )\n$callback = $_GET['callback']; //新加\necho $callback.json_encode($arr);\n```\n\njs代码,请求的时候，加入一个参数callback,通过javascripte callback形式调用服务器的scrpt tags的返回值\n\n```javascript\n$(function(){\n    url = \"http://127.0.0.1/test.php?callback=?\"\n    $.get(url,funtion(result) {\n        alert(result);\n    }));\n```\n\n调用成功\n这个东西纠结我大半天。但是有收获的 ：）\n\n\n\n\n\n","slug":"2013-09-15-jsonpjie-jue-kua-yu-qing-qiu","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8p0018nctjff0vsloh","content":"<p>昨天搞了一整天js,遇到了各种我从没遇到的问题,真心觉得前端工程师是很厉害的。想不出为什么会有人说所谓的前端“无技术含量”的源论.前端要考虑的东西实在是多，也有其架构设计。特别是js. 我用的是phonegap + jqtouch做移动App</p>\n<p>场景是：<br>客户端使用Ajax技术向服务器发送请求，然后拉取数据</p>\n<p>Server端代码是php写的,</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$arr = <span class=\"keyword\">array</span>(</span><br><span class=\"line\">        <span class=\"string\">'user'</span>=&gt;<span class=\"string\">'123'</span>,</span><br><span class=\"line\">        <span class=\"string\">'friends'</span> =&gt; <span class=\"number\">234</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"><span class=\"keyword\">echo</span> json_encode($arr);</span><br></pre></td></tr></table></figure>\n<p>js代码,使用jquery发起get 请求,文件路径E:/mytest/test.html</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    url = <span class=\"string\">\"http://127.0.0.1/test.php\"</span></span><br><span class=\"line\">    $.get(url,funtion(result) &#123;</span><br><span class=\"line\">        alert(result);</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<p>看过jquery文档之后，我以为这样会返回我要的数据，真是图样图森破，chrome的控制台返回：不是同一个源，不允许跨域发请求。 </p>\n<p>#####什么是跨域请求<br>简单来说：a.com 域名下的js无法操作b.com或是c.a.com域名下的对象,上述场景中，<a href=\"http://127.0.0.1/test.php\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1/test.php</a> 和 E：/mytest/test.html本身就不属于同一个域下，因此不能访问。浏览器本身有同源策略，当初设计是出于安全考虑，百度给出了解释是：</p>\n<blockquote>\n<p>　同源策略，它是由Netscape提出的一个著名的安全策略。现在所有支持JavaScript 的浏览器都会使用这个策略。所谓同源是指，域名，协议，端口相同。当一个浏览器的两个tab页中分别打开来 百度和谷歌的页面当一个百度浏览器执行一个脚本的时候会检查这个脚本是属于哪个页面的，即检查是否同源，只有和百度同源的脚本才会被执行。</p>\n</blockquote>\n<p>我最后是通过查阅资料,采用jsonp的方式解决</p>\n<p>#####什么是jsonp</p>\n<blockquote>\n<p>　JSONP是JSON with Padding的略称。它是一个非官方的协议，它允许在服务器端集成Script tags返回至客户端，通过javascript callback的形式实现跨域访问（这仅仅是JSONP简单的实现形式） - 百度</p>\n</blockquote>\n<p>因此最后的Server端代码是php写的</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$arr = array(</span><br><span class=\"line\">        'user'=&gt;'123',</span><br><span class=\"line\">        'friends' =&gt; 234</span><br><span class=\"line\">        )</span><br><span class=\"line\">$callback = $_GET[<span class=\"string\">'callback'</span>]; //新加</span><br><span class=\"line\">echo $callback.json_encode($arr);</span><br></pre></td></tr></table></figure>\n<p>js代码,请求的时候，加入一个参数callback,通过javascripte callback形式调用服务器的scrpt tags的返回值</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    url = <span class=\"string\">\"http://127.0.0.1/test.php?callback=?\"</span></span><br><span class=\"line\">    $.get(url,funtion(result) &#123;</span><br><span class=\"line\">        alert(result);</span><br><span class=\"line\">    &#125;));</span><br></pre></td></tr></table></figure>\n<p>调用成功<br>这个东西纠结我大半天。但是有收获的 ：）</p>\n","site":{"data":{}},"excerpt":"","more":"<p>昨天搞了一整天js,遇到了各种我从没遇到的问题,真心觉得前端工程师是很厉害的。想不出为什么会有人说所谓的前端“无技术含量”的源论.前端要考虑的东西实在是多，也有其架构设计。特别是js. 我用的是phonegap + jqtouch做移动App</p>\n<p>场景是：<br>客户端使用Ajax技术向服务器发送请求，然后拉取数据</p>\n<p>Server端代码是php写的,</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$arr = <span class=\"keyword\">array</span>(</span><br><span class=\"line\">        <span class=\"string\">'user'</span>=&gt;<span class=\"string\">'123'</span>,</span><br><span class=\"line\">        <span class=\"string\">'friends'</span> =&gt; <span class=\"number\">234</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"><span class=\"keyword\">echo</span> json_encode($arr);</span><br></pre></td></tr></table></figure>\n<p>js代码,使用jquery发起get 请求,文件路径E:/mytest/test.html</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    url = <span class=\"string\">\"http://127.0.0.1/test.php\"</span></span><br><span class=\"line\">    $.get(url,funtion(result) &#123;</span><br><span class=\"line\">        alert(result);</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<p>看过jquery文档之后，我以为这样会返回我要的数据，真是图样图森破，chrome的控制台返回：不是同一个源，不允许跨域发请求。 </p>\n<p>#####什么是跨域请求<br>简单来说：a.com 域名下的js无法操作b.com或是c.a.com域名下的对象,上述场景中，<a href=\"http://127.0.0.1/test.php\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1/test.php</a> 和 E：/mytest/test.html本身就不属于同一个域下，因此不能访问。浏览器本身有同源策略，当初设计是出于安全考虑，百度给出了解释是：</p>\n<blockquote>\n<p>　同源策略，它是由Netscape提出的一个著名的安全策略。现在所有支持JavaScript 的浏览器都会使用这个策略。所谓同源是指，域名，协议，端口相同。当一个浏览器的两个tab页中分别打开来 百度和谷歌的页面当一个百度浏览器执行一个脚本的时候会检查这个脚本是属于哪个页面的，即检查是否同源，只有和百度同源的脚本才会被执行。</p>\n</blockquote>\n<p>我最后是通过查阅资料,采用jsonp的方式解决</p>\n<p>#####什么是jsonp</p>\n<blockquote>\n<p>　JSONP是JSON with Padding的略称。它是一个非官方的协议，它允许在服务器端集成Script tags返回至客户端，通过javascript callback的形式实现跨域访问（这仅仅是JSONP简单的实现形式） - 百度</p>\n</blockquote>\n<p>因此最后的Server端代码是php写的</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$arr = array(</span><br><span class=\"line\">        'user'=&gt;'123',</span><br><span class=\"line\">        'friends' =&gt; 234</span><br><span class=\"line\">        )</span><br><span class=\"line\">$callback = $_GET[<span class=\"string\">'callback'</span>]; //新加</span><br><span class=\"line\">echo $callback.json_encode($arr);</span><br></pre></td></tr></table></figure>\n<p>js代码,请求的时候，加入一个参数callback,通过javascripte callback形式调用服务器的scrpt tags的返回值</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">    url = <span class=\"string\">\"http://127.0.0.1/test.php?callback=?\"</span></span><br><span class=\"line\">    $.get(url,funtion(result) &#123;</span><br><span class=\"line\">        alert(result);</span><br><span class=\"line\">    &#125;));</span><br></pre></td></tr></table></figure>\n<p>调用成功<br>这个东西纠结我大半天。但是有收获的 ：）</p>\n"},{"layout":"post","title":"leveldb本地存储引擎-精致的工具","date":"2013-09-21T01:42:00.000Z","comments":1,"_content":"\n leveldb是一个google实现的非常高效的kv数据库，能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LSM算法。 LevelDB 是单进程的服务，性能非常之高，在一台4个Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。@ideawu的ssdb就是基于Leveldb引擎开发的，看起来很NB的样子 \n\n它只是一个本地存储引擎:\n\n* k/v db library，提供持久化 \n* No Server \n* No cache \n于是它精巧。 \n\n>talk is cheap ,Show me the Code\n\n简单示范一下C++使用Leveldb ,要先下载leveldb源码编译[code](https://github.com/basho/leveldb)\n\n```python\n#include<iostream>  \n#include<string>  \n#include\"leveldb/db.h\"  \n\nusing namespace std;  \nusing namespace leveldb;  \n\nint main()  \n{  \n    DB *db;  \n    Options options;  \n    options.create_if_missing = true;  \n    Status s = DB::Open(options,\"/data/leveldb/lvd.db\",&db);  \n    if(!s.ok()){  \n        cerr << s.ToString() << endl;\n    }  \n    string key = \"name\",val = \"leveldb\";  \n    s = db->Put(WriteOptions(),key,val);  \n    if(!s.ok()){  \n        cerr << s.ToString() << endl; \n    }  \n    s = db->Get(ReadOptions(),key,&val);  \n    if(s.ok()){  \n        cout << key << \"=\" << val << endl;  \n        s = db->Put(leveldb::WriteOptions(),\"key2\",val);  \n        if(s.ok()){  \n            s = db->Delete(leveldb::WriteOptions(),key);  \n            if(!s.ok()){  \n                cerr << s.ToString() << endl;\n            }  \n        }  \n    }  \n                                                                                                                                    }  \n```\n\n编译方法\n\n```\ng++ testleveldb.cpp -o main -I./Include -l./ -lleveldb -lrt\n```\n\n执行./main 之后便可以看到,leveldb的存储文件\n\n```\nzj@hp:~/lvd.db$ tree\n.\n├── 000003.log\n├── CURRENT\n├── LOCK\n├── LOG\n├── MANIFEST-000002\n├── sst_0\n├── sst_1\n├── sst_2\n├── sst_3\n├── sst_4\n├── sst_5\n└── sst_6\n```\n\n很多语言都给予了binding,那么python 也不例外了 ：） [py-leveldb](https://github.com/rjpower/py-leveldb)  \n你需要先安装python-leveldb库\n\n```python\nimport leveldb\ndb = leveldb.LevelDB('./db')\ndb.Put('hello', 'world')\nprint db.Get('hello')\n```\n\n如果你也和我一样蛋疼，你会不会想会有Server可以调用呢，再看下一篇吧 ：）\n\n\n\n\n\n\n","source":"_posts/2013-09-21-leveldbben-di-cun-chu-yin-qing-jing-zhi-de-gong-ju.markdown","raw":"---\nlayout: post\ntitle: \"leveldb本地存储引擎-精致的工具\"\ndate: 2013-09-21 09:42\ncomments: true\ncategories: Server DataBase \n---\n\n leveldb是一个google实现的非常高效的kv数据库，能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LSM算法。 LevelDB 是单进程的服务，性能非常之高，在一台4个Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。@ideawu的ssdb就是基于Leveldb引擎开发的，看起来很NB的样子 \n\n它只是一个本地存储引擎:\n\n* k/v db library，提供持久化 \n* No Server \n* No cache \n于是它精巧。 \n\n>talk is cheap ,Show me the Code\n\n简单示范一下C++使用Leveldb ,要先下载leveldb源码编译[code](https://github.com/basho/leveldb)\n\n```python\n#include<iostream>  \n#include<string>  \n#include\"leveldb/db.h\"  \n\nusing namespace std;  \nusing namespace leveldb;  \n\nint main()  \n{  \n    DB *db;  \n    Options options;  \n    options.create_if_missing = true;  \n    Status s = DB::Open(options,\"/data/leveldb/lvd.db\",&db);  \n    if(!s.ok()){  \n        cerr << s.ToString() << endl;\n    }  \n    string key = \"name\",val = \"leveldb\";  \n    s = db->Put(WriteOptions(),key,val);  \n    if(!s.ok()){  \n        cerr << s.ToString() << endl; \n    }  \n    s = db->Get(ReadOptions(),key,&val);  \n    if(s.ok()){  \n        cout << key << \"=\" << val << endl;  \n        s = db->Put(leveldb::WriteOptions(),\"key2\",val);  \n        if(s.ok()){  \n            s = db->Delete(leveldb::WriteOptions(),key);  \n            if(!s.ok()){  \n                cerr << s.ToString() << endl;\n            }  \n        }  \n    }  \n                                                                                                                                    }  \n```\n\n编译方法\n\n```\ng++ testleveldb.cpp -o main -I./Include -l./ -lleveldb -lrt\n```\n\n执行./main 之后便可以看到,leveldb的存储文件\n\n```\nzj@hp:~/lvd.db$ tree\n.\n├── 000003.log\n├── CURRENT\n├── LOCK\n├── LOG\n├── MANIFEST-000002\n├── sst_0\n├── sst_1\n├── sst_2\n├── sst_3\n├── sst_4\n├── sst_5\n└── sst_6\n```\n\n很多语言都给予了binding,那么python 也不例外了 ：） [py-leveldb](https://github.com/rjpower/py-leveldb)  \n你需要先安装python-leveldb库\n\n```python\nimport leveldb\ndb = leveldb.LevelDB('./db')\ndb.Put('hello', 'world')\nprint db.Get('hello')\n```\n\n如果你也和我一样蛋疼，你会不会想会有Server可以调用呢，再看下一篇吧 ：）\n\n\n\n\n\n\n","slug":"2013-09-21-leveldbben-di-cun-chu-yin-qing-jing-zhi-de-gong-ju","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8q001anctjfimpo365","content":"<p> leveldb是一个google实现的非常高效的kv数据库，能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LSM算法。 LevelDB 是单进程的服务，性能非常之高，在一台4个Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。@ideawu的ssdb就是基于Leveldb引擎开发的，看起来很NB的样子 </p>\n<p>它只是一个本地存储引擎:</p>\n<ul>\n<li>k/v db library，提供持久化 </li>\n<li>No Server </li>\n<li>No cache<br>于是它精巧。 </li>\n</ul>\n<blockquote>\n<p>talk is cheap ,Show me the Code</p>\n</blockquote>\n<p>简单示范一下C++使用Leveldb ,要先下载leveldb源码编译<a href=\"https://github.com/basho/leveldb\" target=\"_blank\" rel=\"noopener\">code</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#include&lt;iostream&gt;  </span></span><br><span class=\"line\"><span class=\"comment\">#include&lt;string&gt;  </span></span><br><span class=\"line\"><span class=\"comment\">#include\"leveldb/db.h\"  </span></span><br><span class=\"line\"></span><br><span class=\"line\">using namespace std;  </span><br><span class=\"line\">using namespace leveldb;  </span><br><span class=\"line\"></span><br><span class=\"line\">int main()  </span><br><span class=\"line\">&#123;  </span><br><span class=\"line\">    DB *db;  </span><br><span class=\"line\">    Options options;  </span><br><span class=\"line\">    options.create_if_missing = true;  </span><br><span class=\"line\">    Status s = DB::Open(options,<span class=\"string\">\"/data/leveldb/lvd.db\"</span>,&amp;db);  </span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!s.ok())&#123;  </span><br><span class=\"line\">        cerr &lt;&lt; s.ToString() &lt;&lt; endl;</span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">    string key = <span class=\"string\">\"name\"</span>,val = <span class=\"string\">\"leveldb\"</span>;  </span><br><span class=\"line\">    s = db-&gt;Put(WriteOptions(),key,val);  </span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!s.ok())&#123;  </span><br><span class=\"line\">        cerr &lt;&lt; s.ToString() &lt;&lt; endl; </span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">    s = db-&gt;Get(ReadOptions(),key,&amp;val);  </span><br><span class=\"line\">    <span class=\"keyword\">if</span>(s.ok())&#123;  </span><br><span class=\"line\">        cout &lt;&lt; key &lt;&lt; <span class=\"string\">\"=\"</span> &lt;&lt; val &lt;&lt; endl;  </span><br><span class=\"line\">        s = db-&gt;Put(leveldb::WriteOptions(),\"key2\",val);  </span><br><span class=\"line\">        <span class=\"keyword\">if</span>(s.ok())&#123;  </span><br><span class=\"line\">            s = db-&gt;Delete(leveldb::WriteOptions(),key);  </span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!s.ok())&#123;  </span><br><span class=\"line\">                cerr &lt;&lt; s.ToString() &lt;&lt; endl;</span><br><span class=\"line\">            &#125;  </span><br><span class=\"line\">        &#125;  </span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">                                                                                                                                    &#125;</span><br></pre></td></tr></table></figure>\n<p>编译方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ testleveldb.cpp -o main -I./Include -l./ -lleveldb -lrt</span><br></pre></td></tr></table></figure>\n<p>执行./main 之后便可以看到,leveldb的存储文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@hp:~/lvd.db$ tree</span><br><span class=\"line\">.</span><br><span class=\"line\">├── 000003.log</span><br><span class=\"line\">├── CURRENT</span><br><span class=\"line\">├── LOCK</span><br><span class=\"line\">├── LOG</span><br><span class=\"line\">├── MANIFEST-000002</span><br><span class=\"line\">├── sst_0</span><br><span class=\"line\">├── sst_1</span><br><span class=\"line\">├── sst_2</span><br><span class=\"line\">├── sst_3</span><br><span class=\"line\">├── sst_4</span><br><span class=\"line\">├── sst_5</span><br><span class=\"line\">└── sst_6</span><br></pre></td></tr></table></figure>\n<p>很多语言都给予了binding,那么python 也不例外了 ：） <a href=\"https://github.com/rjpower/py-leveldb\" target=\"_blank\" rel=\"noopener\">py-leveldb</a><br>你需要先安装python-leveldb库</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> leveldb</span><br><span class=\"line\">db = leveldb.LevelDB(<span class=\"string\">'./db'</span>)</span><br><span class=\"line\">db.Put(<span class=\"string\">'hello'</span>, <span class=\"string\">'world'</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> db.Get(<span class=\"string\">'hello'</span>)</span><br></pre></td></tr></table></figure>\n<p>如果你也和我一样蛋疼，你会不会想会有Server可以调用呢，再看下一篇吧 ：）</p>\n","site":{"data":{}},"excerpt":"","more":"<p> leveldb是一个google实现的非常高效的kv数据库，能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LSM算法。 LevelDB 是单进程的服务，性能非常之高，在一台4个Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。@ideawu的ssdb就是基于Leveldb引擎开发的，看起来很NB的样子 </p>\n<p>它只是一个本地存储引擎:</p>\n<ul>\n<li>k/v db library，提供持久化 </li>\n<li>No Server </li>\n<li>No cache<br>于是它精巧。 </li>\n</ul>\n<blockquote>\n<p>talk is cheap ,Show me the Code</p>\n</blockquote>\n<p>简单示范一下C++使用Leveldb ,要先下载leveldb源码编译<a href=\"https://github.com/basho/leveldb\" target=\"_blank\" rel=\"noopener\">code</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#include&lt;iostream&gt;  </span></span><br><span class=\"line\"><span class=\"comment\">#include&lt;string&gt;  </span></span><br><span class=\"line\"><span class=\"comment\">#include\"leveldb/db.h\"  </span></span><br><span class=\"line\"></span><br><span class=\"line\">using namespace std;  </span><br><span class=\"line\">using namespace leveldb;  </span><br><span class=\"line\"></span><br><span class=\"line\">int main()  </span><br><span class=\"line\">&#123;  </span><br><span class=\"line\">    DB *db;  </span><br><span class=\"line\">    Options options;  </span><br><span class=\"line\">    options.create_if_missing = true;  </span><br><span class=\"line\">    Status s = DB::Open(options,<span class=\"string\">\"/data/leveldb/lvd.db\"</span>,&amp;db);  </span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!s.ok())&#123;  </span><br><span class=\"line\">        cerr &lt;&lt; s.ToString() &lt;&lt; endl;</span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">    string key = <span class=\"string\">\"name\"</span>,val = <span class=\"string\">\"leveldb\"</span>;  </span><br><span class=\"line\">    s = db-&gt;Put(WriteOptions(),key,val);  </span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!s.ok())&#123;  </span><br><span class=\"line\">        cerr &lt;&lt; s.ToString() &lt;&lt; endl; </span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">    s = db-&gt;Get(ReadOptions(),key,&amp;val);  </span><br><span class=\"line\">    <span class=\"keyword\">if</span>(s.ok())&#123;  </span><br><span class=\"line\">        cout &lt;&lt; key &lt;&lt; <span class=\"string\">\"=\"</span> &lt;&lt; val &lt;&lt; endl;  </span><br><span class=\"line\">        s = db-&gt;Put(leveldb::WriteOptions(),\"key2\",val);  </span><br><span class=\"line\">        <span class=\"keyword\">if</span>(s.ok())&#123;  </span><br><span class=\"line\">            s = db-&gt;Delete(leveldb::WriteOptions(),key);  </span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!s.ok())&#123;  </span><br><span class=\"line\">                cerr &lt;&lt; s.ToString() &lt;&lt; endl;</span><br><span class=\"line\">            &#125;  </span><br><span class=\"line\">        &#125;  </span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">                                                                                                                                    &#125;</span><br></pre></td></tr></table></figure>\n<p>编译方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ testleveldb.cpp -o main -I./Include -l./ -lleveldb -lrt</span><br></pre></td></tr></table></figure>\n<p>执行./main 之后便可以看到,leveldb的存储文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@hp:~/lvd.db$ tree</span><br><span class=\"line\">.</span><br><span class=\"line\">├── 000003.log</span><br><span class=\"line\">├── CURRENT</span><br><span class=\"line\">├── LOCK</span><br><span class=\"line\">├── LOG</span><br><span class=\"line\">├── MANIFEST-000002</span><br><span class=\"line\">├── sst_0</span><br><span class=\"line\">├── sst_1</span><br><span class=\"line\">├── sst_2</span><br><span class=\"line\">├── sst_3</span><br><span class=\"line\">├── sst_4</span><br><span class=\"line\">├── sst_5</span><br><span class=\"line\">└── sst_6</span><br></pre></td></tr></table></figure>\n<p>很多语言都给予了binding,那么python 也不例外了 ：） <a href=\"https://github.com/rjpower/py-leveldb\" target=\"_blank\" rel=\"noopener\">py-leveldb</a><br>你需要先安装python-leveldb库</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> leveldb</span><br><span class=\"line\">db = leveldb.LevelDB(<span class=\"string\">'./db'</span>)</span><br><span class=\"line\">db.Put(<span class=\"string\">'hello'</span>, <span class=\"string\">'world'</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> db.Get(<span class=\"string\">'hello'</span>)</span><br></pre></td></tr></table></figure>\n<p>如果你也和我一样蛋疼，你会不会想会有Server可以调用呢，再看下一篇吧 ：）</p>\n"},{"layout":"post","title":"单机玩Hadoop","date":"2013-09-22T10:11:00.000Z","comments":1,"_content":"以前在Amazon Web Service[AWS](http://aws.amazon.com/) 做过Hadoop 运算，处理业务逻辑，当时也曾在自己电脑做一个单一的节点模拟.在Tencent 有机会处理tencent 游戏的海量数据分析，这时候用到的是公司的TDW,也是基于Hadoop 的改造。大数据被炒的火热，特别是某些公司会把这些当作自我标榜更是让人恶心.本着折腾的信，把自己玩hadoop的过程写下来 ：）\n\n+ 创建hadoop用户组;\n\n```\nsudo addgroup hadoop\nsudo adduser -ingroup hadoop hadoop\n```\n\n给hadoop用户添加权限，编辑/etc/sudoers文件; 在root   ALL=(ALL:ALL)   ALL下\n\n```\nhadoop  ALL=(ALL:ALL) ALL\n```\n\n+ 在Ubuntu下安装JDK \n\n```\nsudo apt-add-repository ppa:flexiondotorg/java\nsudo apt-get update\nsudo apt-get install sun-java6-jre sun-java6-jdk sun-java6-plugin\n```\n如果你在第二条命令遇到错误:\n\n```\nW: GPG 错误：http://ppa.launchpad.net precise Release: 由于没有公钥，无法验证下列签名： NO_PUBKEY 2EA8F35793D8809A\n请执行\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 2EA8F35793D8809A  \n```\n\n编辑 sudo vi /etc/environment\n在其中添加如下两行：\n\n```\nJAVA_HOME=/usr/lib/jvm/java-6-sun\nCLASSPATH=.:/usr/lib/jvm/java-6-sun/lib\n```\n\n+ 安装ssh 服务\n\n```\nsudo apt-get install ssh openssh-server\n```\n\n首先要转换成hadoop用户，执行以下命令：\n\n```\nsu - hadoop\n```\n\n采用 rsa 方式 生成key\n\n```\nssh-keygen -t rsa -P \"\"\n```\n\n进入~/.ssh/目录下，将id_rsa.pub追加到authorized_keys授权文件中,使其无密码登录本机\n\n```\ncd ~/.ssh\ncat id_rsa.pub >> authorized_keys\n```\n\n+ 下载[hadoop](http://www.apache.org/dyn/closer.cgi/hadoop/common/),并安装\n\n```\nsudo cp hadoop-0.20.203.0rc1.tar.gz /usr/local/\n```\n\n解压hadoop-0.20.203.tar.gz；\n\n```\ncd /usr/local\nsudo tar -zxf hadoop-0.20.203.0rc1.tar.gz\n```\n\n将解压出的文件夹改名为hadoop;\n\n```\nsudo mv hadoop-0.20.203.0 hadoop\n```\n\n将该hadoop文件夹的属主用户设为hadoop，\n\n```\nsudo chown -R hadoop:hadoop hadoop\n```\n\n打开hadoop/conf/hadoop-env.sh文件;\n\n```\nsudo vi hadoop/conf/hadoop-env.sh\n```\n\n配置conf/hadoop-env.sh,配置本机jdk的路径;\n\n```\nexport JAVA_HOME=/usr/lib/jvm/java-6-sun/\nexport HADOOP_HOME=/usr/local/hadoop\nexport PATH=$PATH:/usr/local/hadoop/bin\n```\n\n记得source hadoop-env.sh \n\n编辑conf/core-site.xml文件;\n\n```\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<!-- Put site-specific property overrides in this file. -->\n<configuration>\n    <property>  \n        <name>fs.default.name</name>  \n        <value>hdfs://localhost:9000</value>   \n    </property>  \n</configuration>\n```\n\n编辑conf/mapred-site.xml文件;\n\n```\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<!-- Put site-specific property overrides in this file. -->\n<configuration>  \n     <property>   \n           <name>mapred.job.tracker</name>  \n            <value>localhost:9001</value>   \n      </property>  \n</configuration>\n```\n\n编辑conf/hdfs-site.xml文件;\n\n```\n<configuration>\n    <property>\n        <name>dfs.name.dir</name>\n        <value>/usr/local/hadoop/datalog1,/usr/local/hadoop/datalog2</value>\n    </property>\n    <property>\n        <name>dfs.data.dir</name>\n        <value>/usr/local/hadoop/data1,/usr/local/hadoop/data2</value>\n    </property>\n    <property>\n        <name>dfs.replication</name>\n        <value>2</value>\n    </property>\n</configuration>\n```\n\n+ 运行hadoop,并启动\n\n```\ncd /usr/local/hadoop/\nbin/hadoop namenode -format // 进入hadoop目录下，格式化hdfs文件系统\nbin/start-all.sh //启动脚本\n```\n\n检测hadoop是否启动成功\n\n```\nhadoop@hp:/usr/local/hadoop/bin$ sudo jps\n11822 DataNode\n12461 Jps\n11581 NameNode\n12157 JobTracker\n12064 SecondaryNameNode\n12377 TaskTracker\n```\n\n说明hadoop单机版环境配置好了\n此时访问[http://localhost:50030/](http://localhost:50030/),便可以看到管理界面\n{% img /images/2013/09/hadoop.png %}\n让我们来完成那篇著名论文的wordcounw吧\n\n创建输入文件夹,并挂载hdfs\n\n```\nhadoop@hp:/usr/local/hadoop$ mkdir input //创建输入文件夹\nhadoop@hp:/usr/local/hadoop$ cp conf/* input\nhadoop@hp:/usr/local/hadoop$ bin/hadoop fs -put input/ input\n```\n\n执行wordcount程序,输入为input，输出数据目录为output。,\n\n```\nbin/hadoop jar hadoop-examples-0.20.203.0.jar wordcount input output\n```\n\n出现了运行情况如下\n\n```\n13/09/22 17:59:40 INFO input.FileInputFormat: Total input paths to process : 15\n13/09/22 17:59:41 INFO mapred.JobClient: Running job: job_201309221738_0006\n13/09/22 17:59:42 INFO mapred.JobClient:  map 0% reduce 0%\n13/09/22 17:59:58 INFO mapred.JobClient:  map 13% reduce 0%\n13/09/22 18:00:07 INFO mapred.JobClient:  map 26% reduce 0%\n13/09/22 18:00:16 INFO mapred.JobClient:  map 40% reduce 8%\n13/09/22 18:00:22 INFO mapred.JobClient:  map 53% reduce 13%\n13/09/22 18:00:28 INFO mapred.JobClient:  map 66% reduce 13%\n13/09/22 18:00:31 INFO mapred.JobClient:  map 66% reduce 17%\n13/09/22 18:00:34 INFO mapred.JobClient:  map 80% reduce 17%\n13/09/22 18:00:37 INFO mapred.JobClient:  map 80% reduce 22%\n13/09/22 18:00:40 INFO mapred.JobClient:  map 93% reduce 22%\n13/09/22 18:00:46 INFO mapred.JobClient:  map 100% reduce 26%\n13/09/22 18:00:55 INFO mapred.JobClient:  map 100% reduce 100%\n13/09/22 18:01:00 INFO mapred.JobClient: Job complete: job_201309221738_0006\n13/09/22 18:01:00 INFO mapred.JobClient: Counters: 25\n13/09/22 18:01:00 INFO mapred.JobClient:   Job Counters \n```\n\n查看执行结果\n\n```\nhadoop@hp:/usr/local/hadoop$ bin/hadoop fs -cat output/*\n```\n\n截取部分结果现场\n\n```\nhadoop@hp:/usr/local/hadoop$ hadoop fs -cat output/*\n\"\". 4\n\"*\" 10\n\"alice,bob  10\n\"console\"   1\n\"hadoop.root.logger\".   1\n\"jks\".  4\n   79\n$HADOOP_BALANCER_OPTS\"   1\n$HADOOP_DATANODE_OPTS\"   1\n$HADOOP_HOME/conf/slaves 1\n$HADOOP_HOME/logs    1\n$HADOOP_JOBTRACKER_OPTS\" 1\n$HADOOP_NAMENODE_OPTS\"   1\n$HADOOP_SECONDARYNAMENODE_OPTS\"  1\n```\n\n停止hadoop\n\n```\nhadoop@hp:/usr/local/hadoop$ ./stop-all.sh \n```\n\nhadoop这只小象在单机可以这么玩\n\n\n","source":"_posts/2013-09-22-dan-ji-wan-hadoop.markdown","raw":"---\nlayout: post\ntitle: \"单机玩Hadoop\"\ndate: 2013-09-22 18:11\ncomments: true\ncategories: Server\n---\n以前在Amazon Web Service[AWS](http://aws.amazon.com/) 做过Hadoop 运算，处理业务逻辑，当时也曾在自己电脑做一个单一的节点模拟.在Tencent 有机会处理tencent 游戏的海量数据分析，这时候用到的是公司的TDW,也是基于Hadoop 的改造。大数据被炒的火热，特别是某些公司会把这些当作自我标榜更是让人恶心.本着折腾的信，把自己玩hadoop的过程写下来 ：）\n\n+ 创建hadoop用户组;\n\n```\nsudo addgroup hadoop\nsudo adduser -ingroup hadoop hadoop\n```\n\n给hadoop用户添加权限，编辑/etc/sudoers文件; 在root   ALL=(ALL:ALL)   ALL下\n\n```\nhadoop  ALL=(ALL:ALL) ALL\n```\n\n+ 在Ubuntu下安装JDK \n\n```\nsudo apt-add-repository ppa:flexiondotorg/java\nsudo apt-get update\nsudo apt-get install sun-java6-jre sun-java6-jdk sun-java6-plugin\n```\n如果你在第二条命令遇到错误:\n\n```\nW: GPG 错误：http://ppa.launchpad.net precise Release: 由于没有公钥，无法验证下列签名： NO_PUBKEY 2EA8F35793D8809A\n请执行\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 2EA8F35793D8809A  \n```\n\n编辑 sudo vi /etc/environment\n在其中添加如下两行：\n\n```\nJAVA_HOME=/usr/lib/jvm/java-6-sun\nCLASSPATH=.:/usr/lib/jvm/java-6-sun/lib\n```\n\n+ 安装ssh 服务\n\n```\nsudo apt-get install ssh openssh-server\n```\n\n首先要转换成hadoop用户，执行以下命令：\n\n```\nsu - hadoop\n```\n\n采用 rsa 方式 生成key\n\n```\nssh-keygen -t rsa -P \"\"\n```\n\n进入~/.ssh/目录下，将id_rsa.pub追加到authorized_keys授权文件中,使其无密码登录本机\n\n```\ncd ~/.ssh\ncat id_rsa.pub >> authorized_keys\n```\n\n+ 下载[hadoop](http://www.apache.org/dyn/closer.cgi/hadoop/common/),并安装\n\n```\nsudo cp hadoop-0.20.203.0rc1.tar.gz /usr/local/\n```\n\n解压hadoop-0.20.203.tar.gz；\n\n```\ncd /usr/local\nsudo tar -zxf hadoop-0.20.203.0rc1.tar.gz\n```\n\n将解压出的文件夹改名为hadoop;\n\n```\nsudo mv hadoop-0.20.203.0 hadoop\n```\n\n将该hadoop文件夹的属主用户设为hadoop，\n\n```\nsudo chown -R hadoop:hadoop hadoop\n```\n\n打开hadoop/conf/hadoop-env.sh文件;\n\n```\nsudo vi hadoop/conf/hadoop-env.sh\n```\n\n配置conf/hadoop-env.sh,配置本机jdk的路径;\n\n```\nexport JAVA_HOME=/usr/lib/jvm/java-6-sun/\nexport HADOOP_HOME=/usr/local/hadoop\nexport PATH=$PATH:/usr/local/hadoop/bin\n```\n\n记得source hadoop-env.sh \n\n编辑conf/core-site.xml文件;\n\n```\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<!-- Put site-specific property overrides in this file. -->\n<configuration>\n    <property>  \n        <name>fs.default.name</name>  \n        <value>hdfs://localhost:9000</value>   \n    </property>  \n</configuration>\n```\n\n编辑conf/mapred-site.xml文件;\n\n```\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<!-- Put site-specific property overrides in this file. -->\n<configuration>  \n     <property>   \n           <name>mapred.job.tracker</name>  \n            <value>localhost:9001</value>   \n      </property>  \n</configuration>\n```\n\n编辑conf/hdfs-site.xml文件;\n\n```\n<configuration>\n    <property>\n        <name>dfs.name.dir</name>\n        <value>/usr/local/hadoop/datalog1,/usr/local/hadoop/datalog2</value>\n    </property>\n    <property>\n        <name>dfs.data.dir</name>\n        <value>/usr/local/hadoop/data1,/usr/local/hadoop/data2</value>\n    </property>\n    <property>\n        <name>dfs.replication</name>\n        <value>2</value>\n    </property>\n</configuration>\n```\n\n+ 运行hadoop,并启动\n\n```\ncd /usr/local/hadoop/\nbin/hadoop namenode -format // 进入hadoop目录下，格式化hdfs文件系统\nbin/start-all.sh //启动脚本\n```\n\n检测hadoop是否启动成功\n\n```\nhadoop@hp:/usr/local/hadoop/bin$ sudo jps\n11822 DataNode\n12461 Jps\n11581 NameNode\n12157 JobTracker\n12064 SecondaryNameNode\n12377 TaskTracker\n```\n\n说明hadoop单机版环境配置好了\n此时访问[http://localhost:50030/](http://localhost:50030/),便可以看到管理界面\n{% img /images/2013/09/hadoop.png %}\n让我们来完成那篇著名论文的wordcounw吧\n\n创建输入文件夹,并挂载hdfs\n\n```\nhadoop@hp:/usr/local/hadoop$ mkdir input //创建输入文件夹\nhadoop@hp:/usr/local/hadoop$ cp conf/* input\nhadoop@hp:/usr/local/hadoop$ bin/hadoop fs -put input/ input\n```\n\n执行wordcount程序,输入为input，输出数据目录为output。,\n\n```\nbin/hadoop jar hadoop-examples-0.20.203.0.jar wordcount input output\n```\n\n出现了运行情况如下\n\n```\n13/09/22 17:59:40 INFO input.FileInputFormat: Total input paths to process : 15\n13/09/22 17:59:41 INFO mapred.JobClient: Running job: job_201309221738_0006\n13/09/22 17:59:42 INFO mapred.JobClient:  map 0% reduce 0%\n13/09/22 17:59:58 INFO mapred.JobClient:  map 13% reduce 0%\n13/09/22 18:00:07 INFO mapred.JobClient:  map 26% reduce 0%\n13/09/22 18:00:16 INFO mapred.JobClient:  map 40% reduce 8%\n13/09/22 18:00:22 INFO mapred.JobClient:  map 53% reduce 13%\n13/09/22 18:00:28 INFO mapred.JobClient:  map 66% reduce 13%\n13/09/22 18:00:31 INFO mapred.JobClient:  map 66% reduce 17%\n13/09/22 18:00:34 INFO mapred.JobClient:  map 80% reduce 17%\n13/09/22 18:00:37 INFO mapred.JobClient:  map 80% reduce 22%\n13/09/22 18:00:40 INFO mapred.JobClient:  map 93% reduce 22%\n13/09/22 18:00:46 INFO mapred.JobClient:  map 100% reduce 26%\n13/09/22 18:00:55 INFO mapred.JobClient:  map 100% reduce 100%\n13/09/22 18:01:00 INFO mapred.JobClient: Job complete: job_201309221738_0006\n13/09/22 18:01:00 INFO mapred.JobClient: Counters: 25\n13/09/22 18:01:00 INFO mapred.JobClient:   Job Counters \n```\n\n查看执行结果\n\n```\nhadoop@hp:/usr/local/hadoop$ bin/hadoop fs -cat output/*\n```\n\n截取部分结果现场\n\n```\nhadoop@hp:/usr/local/hadoop$ hadoop fs -cat output/*\n\"\". 4\n\"*\" 10\n\"alice,bob  10\n\"console\"   1\n\"hadoop.root.logger\".   1\n\"jks\".  4\n   79\n$HADOOP_BALANCER_OPTS\"   1\n$HADOOP_DATANODE_OPTS\"   1\n$HADOOP_HOME/conf/slaves 1\n$HADOOP_HOME/logs    1\n$HADOOP_JOBTRACKER_OPTS\" 1\n$HADOOP_NAMENODE_OPTS\"   1\n$HADOOP_SECONDARYNAMENODE_OPTS\"  1\n```\n\n停止hadoop\n\n```\nhadoop@hp:/usr/local/hadoop$ ./stop-all.sh \n```\n\nhadoop这只小象在单机可以这么玩\n\n\n","slug":"2013-09-22-dan-ji-wan-hadoop","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8r001dnctjutd4q9bv","content":"<p>以前在Amazon Web Service<a href=\"http://aws.amazon.com/\" target=\"_blank\" rel=\"noopener\">AWS</a> 做过Hadoop 运算，处理业务逻辑，当时也曾在自己电脑做一个单一的节点模拟.在Tencent 有机会处理tencent 游戏的海量数据分析，这时候用到的是公司的TDW,也是基于Hadoop 的改造。大数据被炒的火热，特别是某些公司会把这些当作自我标榜更是让人恶心.本着折腾的信，把自己玩hadoop的过程写下来 ：）</p>\n<ul>\n<li>创建hadoop用户组;</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo addgroup hadoop</span><br><span class=\"line\">sudo adduser -ingroup hadoop hadoop</span><br></pre></td></tr></table></figure>\n<p>给hadoop用户添加权限，编辑/etc/sudoers文件; 在root   ALL=(ALL:ALL)   ALL下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop  ALL=(ALL:ALL) ALL</span><br></pre></td></tr></table></figure>\n<ul>\n<li>在Ubuntu下安装JDK </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-add-repository ppa:flexiondotorg/java</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install sun-java6-jre sun-java6-jdk sun-java6-plugin</span><br></pre></td></tr></table></figure>\n<p>如果你在第二条命令遇到错误:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">W: GPG 错误：http://ppa.launchpad.net precise Release: 由于没有公钥，无法验证下列签名： NO_PUBKEY 2EA8F35793D8809A</span><br><span class=\"line\">请执行</span><br><span class=\"line\">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 2EA8F35793D8809A</span><br></pre></td></tr></table></figure>\n<p>编辑 sudo vi /etc/environment<br>在其中添加如下两行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_HOME=/usr/lib/jvm/java-6-sun</span><br><span class=\"line\">CLASSPATH=.:/usr/lib/jvm/java-6-sun/lib</span><br></pre></td></tr></table></figure>\n<ul>\n<li>安装ssh 服务</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install ssh openssh-server</span><br></pre></td></tr></table></figure>\n<p>首先要转换成hadoop用户，执行以下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">su - hadoop</span><br></pre></td></tr></table></figure>\n<p>采用 rsa 方式 生成key</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-keygen -t rsa -P &quot;&quot;</span><br></pre></td></tr></table></figure>\n<p>进入~/.ssh/目录下，将id_rsa.pub追加到authorized_keys授权文件中,使其无密码登录本机</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/.ssh</span><br><span class=\"line\">cat id_rsa.pub &gt;&gt; authorized_keys</span><br></pre></td></tr></table></figure>\n<ul>\n<li>下载<a href=\"http://www.apache.org/dyn/closer.cgi/hadoop/common/\" target=\"_blank\" rel=\"noopener\">hadoop</a>,并安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo cp hadoop-0.20.203.0rc1.tar.gz /usr/local/</span><br></pre></td></tr></table></figure>\n<p>解压hadoop-0.20.203.tar.gz；</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/local</span><br><span class=\"line\">sudo tar -zxf hadoop-0.20.203.0rc1.tar.gz</span><br></pre></td></tr></table></figure>\n<p>将解压出的文件夹改名为hadoop;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mv hadoop-0.20.203.0 hadoop</span><br></pre></td></tr></table></figure>\n<p>将该hadoop文件夹的属主用户设为hadoop，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo chown -R hadoop:hadoop hadoop</span><br></pre></td></tr></table></figure>\n<p>打开hadoop/conf/hadoop-env.sh文件;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo vi hadoop/conf/hadoop-env.sh</span><br></pre></td></tr></table></figure>\n<p>配置conf/hadoop-env.sh,配置本机jdk的路径;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export JAVA_HOME=/usr/lib/jvm/java-6-sun/</span><br><span class=\"line\">export HADOOP_HOME=/usr/local/hadoop</span><br><span class=\"line\">export PATH=$PATH:/usr/local/hadoop/bin</span><br></pre></td></tr></table></figure>\n<p>记得source hadoop-env.sh </p>\n<p>编辑conf/core-site.xml文件;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class=\"line\">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class=\"line\">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;property&gt;  </span><br><span class=\"line\">        &lt;name&gt;fs.default.name&lt;/name&gt;  </span><br><span class=\"line\">        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;   </span><br><span class=\"line\">    &lt;/property&gt;  </span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n<p>编辑conf/mapred-site.xml文件;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class=\"line\">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class=\"line\">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class=\"line\">&lt;configuration&gt;  </span><br><span class=\"line\">     &lt;property&gt;   </span><br><span class=\"line\">           &lt;name&gt;mapred.job.tracker&lt;/name&gt;  </span><br><span class=\"line\">            &lt;value&gt;localhost:9001&lt;/value&gt;   </span><br><span class=\"line\">      &lt;/property&gt;  </span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n<p>编辑conf/hdfs-site.xml文件;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">        &lt;name&gt;dfs.name.dir&lt;/name&gt;</span><br><span class=\"line\">        &lt;value&gt;/usr/local/hadoop/datalog1,/usr/local/hadoop/datalog2&lt;/value&gt;</span><br><span class=\"line\">    &lt;/property&gt;</span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">        &lt;name&gt;dfs.data.dir&lt;/name&gt;</span><br><span class=\"line\">        &lt;value&gt;/usr/local/hadoop/data1,/usr/local/hadoop/data2&lt;/value&gt;</span><br><span class=\"line\">    &lt;/property&gt;</span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class=\"line\">        &lt;value&gt;2&lt;/value&gt;</span><br><span class=\"line\">    &lt;/property&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>运行hadoop,并启动</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/local/hadoop/</span><br><span class=\"line\">bin/hadoop namenode -format // 进入hadoop目录下，格式化hdfs文件系统</span><br><span class=\"line\">bin/start-all.sh //启动脚本</span><br></pre></td></tr></table></figure>\n<p>检测hadoop是否启动成功</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop/bin$ sudo jps</span><br><span class=\"line\">11822 DataNode</span><br><span class=\"line\">12461 Jps</span><br><span class=\"line\">11581 NameNode</span><br><span class=\"line\">12157 JobTracker</span><br><span class=\"line\">12064 SecondaryNameNode</span><br><span class=\"line\">12377 TaskTracker</span><br></pre></td></tr></table></figure>\n<p>说明hadoop单机版环境配置好了<br>此时访问<a href=\"http://localhost:50030/\" target=\"_blank\" rel=\"noopener\">http://localhost:50030/</a>,便可以看到管理界面<br><img src=\"/images/2013/09/hadoop.png\"><br>让我们来完成那篇著名论文的wordcounw吧</p>\n<p>创建输入文件夹,并挂载hdfs</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop$ mkdir input //创建输入文件夹</span><br><span class=\"line\">hadoop@hp:/usr/local/hadoop$ cp conf/* input</span><br><span class=\"line\">hadoop@hp:/usr/local/hadoop$ bin/hadoop fs -put input/ input</span><br></pre></td></tr></table></figure>\n<p>执行wordcount程序,输入为input，输出数据目录为output。,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hadoop jar hadoop-examples-0.20.203.0.jar wordcount input output</span><br></pre></td></tr></table></figure>\n<p>出现了运行情况如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">13/09/22 17:59:40 INFO input.FileInputFormat: Total input paths to process : 15</span><br><span class=\"line\">13/09/22 17:59:41 INFO mapred.JobClient: Running job: job_201309221738_0006</span><br><span class=\"line\">13/09/22 17:59:42 INFO mapred.JobClient:  map 0% reduce 0%</span><br><span class=\"line\">13/09/22 17:59:58 INFO mapred.JobClient:  map 13% reduce 0%</span><br><span class=\"line\">13/09/22 18:00:07 INFO mapred.JobClient:  map 26% reduce 0%</span><br><span class=\"line\">13/09/22 18:00:16 INFO mapred.JobClient:  map 40% reduce 8%</span><br><span class=\"line\">13/09/22 18:00:22 INFO mapred.JobClient:  map 53% reduce 13%</span><br><span class=\"line\">13/09/22 18:00:28 INFO mapred.JobClient:  map 66% reduce 13%</span><br><span class=\"line\">13/09/22 18:00:31 INFO mapred.JobClient:  map 66% reduce 17%</span><br><span class=\"line\">13/09/22 18:00:34 INFO mapred.JobClient:  map 80% reduce 17%</span><br><span class=\"line\">13/09/22 18:00:37 INFO mapred.JobClient:  map 80% reduce 22%</span><br><span class=\"line\">13/09/22 18:00:40 INFO mapred.JobClient:  map 93% reduce 22%</span><br><span class=\"line\">13/09/22 18:00:46 INFO mapred.JobClient:  map 100% reduce 26%</span><br><span class=\"line\">13/09/22 18:00:55 INFO mapred.JobClient:  map 100% reduce 100%</span><br><span class=\"line\">13/09/22 18:01:00 INFO mapred.JobClient: Job complete: job_201309221738_0006</span><br><span class=\"line\">13/09/22 18:01:00 INFO mapred.JobClient: Counters: 25</span><br><span class=\"line\">13/09/22 18:01:00 INFO mapred.JobClient:   Job Counters</span><br></pre></td></tr></table></figure>\n<p>查看执行结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop$ bin/hadoop fs -cat output/*</span><br></pre></td></tr></table></figure>\n<p>截取部分结果现场</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop$ hadoop fs -cat output/*</span><br><span class=\"line\">&quot;&quot;. 4</span><br><span class=\"line\">&quot;*&quot; 10</span><br><span class=\"line\">&quot;alice,bob  10</span><br><span class=\"line\">&quot;console&quot;   1</span><br><span class=\"line\">&quot;hadoop.root.logger&quot;.   1</span><br><span class=\"line\">&quot;jks&quot;.  4</span><br><span class=\"line\">   79</span><br><span class=\"line\">$HADOOP_BALANCER_OPTS&quot;   1</span><br><span class=\"line\">$HADOOP_DATANODE_OPTS&quot;   1</span><br><span class=\"line\">$HADOOP_HOME/conf/slaves 1</span><br><span class=\"line\">$HADOOP_HOME/logs    1</span><br><span class=\"line\">$HADOOP_JOBTRACKER_OPTS&quot; 1</span><br><span class=\"line\">$HADOOP_NAMENODE_OPTS&quot;   1</span><br><span class=\"line\">$HADOOP_SECONDARYNAMENODE_OPTS&quot;  1</span><br></pre></td></tr></table></figure>\n<p>停止hadoop</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop$ ./stop-all.sh</span><br></pre></td></tr></table></figure>\n<p>hadoop这只小象在单机可以这么玩</p>\n","site":{"data":{}},"excerpt":"","more":"<p>以前在Amazon Web Service<a href=\"http://aws.amazon.com/\" target=\"_blank\" rel=\"noopener\">AWS</a> 做过Hadoop 运算，处理业务逻辑，当时也曾在自己电脑做一个单一的节点模拟.在Tencent 有机会处理tencent 游戏的海量数据分析，这时候用到的是公司的TDW,也是基于Hadoop 的改造。大数据被炒的火热，特别是某些公司会把这些当作自我标榜更是让人恶心.本着折腾的信，把自己玩hadoop的过程写下来 ：）</p>\n<ul>\n<li>创建hadoop用户组;</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo addgroup hadoop</span><br><span class=\"line\">sudo adduser -ingroup hadoop hadoop</span><br></pre></td></tr></table></figure>\n<p>给hadoop用户添加权限，编辑/etc/sudoers文件; 在root   ALL=(ALL:ALL)   ALL下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop  ALL=(ALL:ALL) ALL</span><br></pre></td></tr></table></figure>\n<ul>\n<li>在Ubuntu下安装JDK </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-add-repository ppa:flexiondotorg/java</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install sun-java6-jre sun-java6-jdk sun-java6-plugin</span><br></pre></td></tr></table></figure>\n<p>如果你在第二条命令遇到错误:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">W: GPG 错误：http://ppa.launchpad.net precise Release: 由于没有公钥，无法验证下列签名： NO_PUBKEY 2EA8F35793D8809A</span><br><span class=\"line\">请执行</span><br><span class=\"line\">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 2EA8F35793D8809A</span><br></pre></td></tr></table></figure>\n<p>编辑 sudo vi /etc/environment<br>在其中添加如下两行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_HOME=/usr/lib/jvm/java-6-sun</span><br><span class=\"line\">CLASSPATH=.:/usr/lib/jvm/java-6-sun/lib</span><br></pre></td></tr></table></figure>\n<ul>\n<li>安装ssh 服务</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install ssh openssh-server</span><br></pre></td></tr></table></figure>\n<p>首先要转换成hadoop用户，执行以下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">su - hadoop</span><br></pre></td></tr></table></figure>\n<p>采用 rsa 方式 生成key</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-keygen -t rsa -P &quot;&quot;</span><br></pre></td></tr></table></figure>\n<p>进入~/.ssh/目录下，将id_rsa.pub追加到authorized_keys授权文件中,使其无密码登录本机</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/.ssh</span><br><span class=\"line\">cat id_rsa.pub &gt;&gt; authorized_keys</span><br></pre></td></tr></table></figure>\n<ul>\n<li>下载<a href=\"http://www.apache.org/dyn/closer.cgi/hadoop/common/\" target=\"_blank\" rel=\"noopener\">hadoop</a>,并安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo cp hadoop-0.20.203.0rc1.tar.gz /usr/local/</span><br></pre></td></tr></table></figure>\n<p>解压hadoop-0.20.203.tar.gz；</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/local</span><br><span class=\"line\">sudo tar -zxf hadoop-0.20.203.0rc1.tar.gz</span><br></pre></td></tr></table></figure>\n<p>将解压出的文件夹改名为hadoop;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mv hadoop-0.20.203.0 hadoop</span><br></pre></td></tr></table></figure>\n<p>将该hadoop文件夹的属主用户设为hadoop，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo chown -R hadoop:hadoop hadoop</span><br></pre></td></tr></table></figure>\n<p>打开hadoop/conf/hadoop-env.sh文件;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo vi hadoop/conf/hadoop-env.sh</span><br></pre></td></tr></table></figure>\n<p>配置conf/hadoop-env.sh,配置本机jdk的路径;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export JAVA_HOME=/usr/lib/jvm/java-6-sun/</span><br><span class=\"line\">export HADOOP_HOME=/usr/local/hadoop</span><br><span class=\"line\">export PATH=$PATH:/usr/local/hadoop/bin</span><br></pre></td></tr></table></figure>\n<p>记得source hadoop-env.sh </p>\n<p>编辑conf/core-site.xml文件;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class=\"line\">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class=\"line\">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;property&gt;  </span><br><span class=\"line\">        &lt;name&gt;fs.default.name&lt;/name&gt;  </span><br><span class=\"line\">        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;   </span><br><span class=\"line\">    &lt;/property&gt;  </span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n<p>编辑conf/mapred-site.xml文件;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class=\"line\">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class=\"line\">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class=\"line\">&lt;configuration&gt;  </span><br><span class=\"line\">     &lt;property&gt;   </span><br><span class=\"line\">           &lt;name&gt;mapred.job.tracker&lt;/name&gt;  </span><br><span class=\"line\">            &lt;value&gt;localhost:9001&lt;/value&gt;   </span><br><span class=\"line\">      &lt;/property&gt;  </span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n<p>编辑conf/hdfs-site.xml文件;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">        &lt;name&gt;dfs.name.dir&lt;/name&gt;</span><br><span class=\"line\">        &lt;value&gt;/usr/local/hadoop/datalog1,/usr/local/hadoop/datalog2&lt;/value&gt;</span><br><span class=\"line\">    &lt;/property&gt;</span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">        &lt;name&gt;dfs.data.dir&lt;/name&gt;</span><br><span class=\"line\">        &lt;value&gt;/usr/local/hadoop/data1,/usr/local/hadoop/data2&lt;/value&gt;</span><br><span class=\"line\">    &lt;/property&gt;</span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class=\"line\">        &lt;value&gt;2&lt;/value&gt;</span><br><span class=\"line\">    &lt;/property&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>运行hadoop,并启动</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/local/hadoop/</span><br><span class=\"line\">bin/hadoop namenode -format // 进入hadoop目录下，格式化hdfs文件系统</span><br><span class=\"line\">bin/start-all.sh //启动脚本</span><br></pre></td></tr></table></figure>\n<p>检测hadoop是否启动成功</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop/bin$ sudo jps</span><br><span class=\"line\">11822 DataNode</span><br><span class=\"line\">12461 Jps</span><br><span class=\"line\">11581 NameNode</span><br><span class=\"line\">12157 JobTracker</span><br><span class=\"line\">12064 SecondaryNameNode</span><br><span class=\"line\">12377 TaskTracker</span><br></pre></td></tr></table></figure>\n<p>说明hadoop单机版环境配置好了<br>此时访问<a href=\"http://localhost:50030/\" target=\"_blank\" rel=\"noopener\">http://localhost:50030/</a>,便可以看到管理界面<br><img src=\"/images/2013/09/hadoop.png\"><br>让我们来完成那篇著名论文的wordcounw吧</p>\n<p>创建输入文件夹,并挂载hdfs</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop$ mkdir input //创建输入文件夹</span><br><span class=\"line\">hadoop@hp:/usr/local/hadoop$ cp conf/* input</span><br><span class=\"line\">hadoop@hp:/usr/local/hadoop$ bin/hadoop fs -put input/ input</span><br></pre></td></tr></table></figure>\n<p>执行wordcount程序,输入为input，输出数据目录为output。,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hadoop jar hadoop-examples-0.20.203.0.jar wordcount input output</span><br></pre></td></tr></table></figure>\n<p>出现了运行情况如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">13/09/22 17:59:40 INFO input.FileInputFormat: Total input paths to process : 15</span><br><span class=\"line\">13/09/22 17:59:41 INFO mapred.JobClient: Running job: job_201309221738_0006</span><br><span class=\"line\">13/09/22 17:59:42 INFO mapred.JobClient:  map 0% reduce 0%</span><br><span class=\"line\">13/09/22 17:59:58 INFO mapred.JobClient:  map 13% reduce 0%</span><br><span class=\"line\">13/09/22 18:00:07 INFO mapred.JobClient:  map 26% reduce 0%</span><br><span class=\"line\">13/09/22 18:00:16 INFO mapred.JobClient:  map 40% reduce 8%</span><br><span class=\"line\">13/09/22 18:00:22 INFO mapred.JobClient:  map 53% reduce 13%</span><br><span class=\"line\">13/09/22 18:00:28 INFO mapred.JobClient:  map 66% reduce 13%</span><br><span class=\"line\">13/09/22 18:00:31 INFO mapred.JobClient:  map 66% reduce 17%</span><br><span class=\"line\">13/09/22 18:00:34 INFO mapred.JobClient:  map 80% reduce 17%</span><br><span class=\"line\">13/09/22 18:00:37 INFO mapred.JobClient:  map 80% reduce 22%</span><br><span class=\"line\">13/09/22 18:00:40 INFO mapred.JobClient:  map 93% reduce 22%</span><br><span class=\"line\">13/09/22 18:00:46 INFO mapred.JobClient:  map 100% reduce 26%</span><br><span class=\"line\">13/09/22 18:00:55 INFO mapred.JobClient:  map 100% reduce 100%</span><br><span class=\"line\">13/09/22 18:01:00 INFO mapred.JobClient: Job complete: job_201309221738_0006</span><br><span class=\"line\">13/09/22 18:01:00 INFO mapred.JobClient: Counters: 25</span><br><span class=\"line\">13/09/22 18:01:00 INFO mapred.JobClient:   Job Counters</span><br></pre></td></tr></table></figure>\n<p>查看执行结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop$ bin/hadoop fs -cat output/*</span><br></pre></td></tr></table></figure>\n<p>截取部分结果现场</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop$ hadoop fs -cat output/*</span><br><span class=\"line\">&quot;&quot;. 4</span><br><span class=\"line\">&quot;*&quot; 10</span><br><span class=\"line\">&quot;alice,bob  10</span><br><span class=\"line\">&quot;console&quot;   1</span><br><span class=\"line\">&quot;hadoop.root.logger&quot;.   1</span><br><span class=\"line\">&quot;jks&quot;.  4</span><br><span class=\"line\">   79</span><br><span class=\"line\">$HADOOP_BALANCER_OPTS&quot;   1</span><br><span class=\"line\">$HADOOP_DATANODE_OPTS&quot;   1</span><br><span class=\"line\">$HADOOP_HOME/conf/slaves 1</span><br><span class=\"line\">$HADOOP_HOME/logs    1</span><br><span class=\"line\">$HADOOP_JOBTRACKER_OPTS&quot; 1</span><br><span class=\"line\">$HADOOP_NAMENODE_OPTS&quot;   1</span><br><span class=\"line\">$HADOOP_SECONDARYNAMENODE_OPTS&quot;  1</span><br></pre></td></tr></table></figure>\n<p>停止hadoop</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hadoop@hp:/usr/local/hadoop$ ./stop-all.sh</span><br></pre></td></tr></table></figure>\n<p>hadoop这只小象在单机可以这么玩</p>\n"},{"layout":"post","title":"Bash Shell 技巧小结","date":"2013-09-28T14:52:00.000Z","comments":1,"_content":"\n* 使用 shell 获取进程，并删除\n\n```\n#取得当前进程号\ncurrent_pid=$$\n#获得特定进程号并重定向到一个临时文件中\nps -aux|grep \"/usr/sbin/httpd\" | grep -v \"grep\"| awk '{print $2}' >/tmp/${current_pid}.txt\n#commands start\nfor pid in `cat /tmp/${current_pid}.txt`\ndo\n{\n    echo \"kill -9 $pid\"\n    kill -9 $pid\n}\ndone \nrm -f /tmp/${current_pid}.txt \n```\n\n* shell 的函数处理\n\n```\nfunc()\n{\n    echo $a $b $c\n    echo $1 $2 $3\n}\na=\"aaa\"\nb=\"bbb\"\nc=\"ccc\"\nfunc $a e f\n```\n\n函数传参是通过 funcname $para1 $para2 ...,函数内部是使用$1,$2,$3\n结果为：\n\n```\naaa bbb ccc\naaa e f \n```\n\n* 信号捕捉\ntrap可以使你在脚本中捕捉信号，命令形式为trap name signal(s)\n其中,name是捕捉到信号以后所采取的一系列操作。实际中，name一般是一个专门用来处理所捕捉信号的函数。name需要用双引号（“”）引起来。signal是待捕捉的信号。\n最常见的行动包括： 清除临时文件 忽略该信号(如trap \"\" 23) 询问用户是否终止该脚本进程\n\n```\ntrap 'exitprocess' 2　　　　#捕捉到信号２之后执行exitprocess function\nLOOP=0\nfunction exitprocess()\n{\n    echo \"You Just hit <CTRL-C>, at number $LOOP\"\n    echo \"I will now exit\"\n    exit 1\n}\nwhile : # 循环直到捕捉到信号（注意中间的空格） \ndo\n    LOOP=$LOOP+1\n    echo $LOOP\n    sleep 1\ndone \n```\n\n给一个文本，获取其中2000 ~ 3000 行怎么破？\n\n```\ncat data.txt | tail -n +2000 | head -n 1000 > result.txt\n```\n\n查找文件是否存在\n\n```\nfind /data -name hello.cpp \n```\n\n","source":"_posts/2013-09-28-shellji-qiao-xiao-jie.markdown","raw":"---\nlayout: post\ntitle: \"Bash Shell 技巧小结\"\ndate: 2013-09-28 22:52\ncomments: true\ncategories: Programe\n---\n\n* 使用 shell 获取进程，并删除\n\n```\n#取得当前进程号\ncurrent_pid=$$\n#获得特定进程号并重定向到一个临时文件中\nps -aux|grep \"/usr/sbin/httpd\" | grep -v \"grep\"| awk '{print $2}' >/tmp/${current_pid}.txt\n#commands start\nfor pid in `cat /tmp/${current_pid}.txt`\ndo\n{\n    echo \"kill -9 $pid\"\n    kill -9 $pid\n}\ndone \nrm -f /tmp/${current_pid}.txt \n```\n\n* shell 的函数处理\n\n```\nfunc()\n{\n    echo $a $b $c\n    echo $1 $2 $3\n}\na=\"aaa\"\nb=\"bbb\"\nc=\"ccc\"\nfunc $a e f\n```\n\n函数传参是通过 funcname $para1 $para2 ...,函数内部是使用$1,$2,$3\n结果为：\n\n```\naaa bbb ccc\naaa e f \n```\n\n* 信号捕捉\ntrap可以使你在脚本中捕捉信号，命令形式为trap name signal(s)\n其中,name是捕捉到信号以后所采取的一系列操作。实际中，name一般是一个专门用来处理所捕捉信号的函数。name需要用双引号（“”）引起来。signal是待捕捉的信号。\n最常见的行动包括： 清除临时文件 忽略该信号(如trap \"\" 23) 询问用户是否终止该脚本进程\n\n```\ntrap 'exitprocess' 2　　　　#捕捉到信号２之后执行exitprocess function\nLOOP=0\nfunction exitprocess()\n{\n    echo \"You Just hit <CTRL-C>, at number $LOOP\"\n    echo \"I will now exit\"\n    exit 1\n}\nwhile : # 循环直到捕捉到信号（注意中间的空格） \ndo\n    LOOP=$LOOP+1\n    echo $LOOP\n    sleep 1\ndone \n```\n\n给一个文本，获取其中2000 ~ 3000 行怎么破？\n\n```\ncat data.txt | tail -n +2000 | head -n 1000 > result.txt\n```\n\n查找文件是否存在\n\n```\nfind /data -name hello.cpp \n```\n\n","slug":"2013-09-28-shellji-qiao-xiao-jie","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8s001fnctjvejda5vu","content":"<ul>\n<li>使用 shell 获取进程，并删除</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#取得当前进程号</span><br><span class=\"line\">current_pid=$$</span><br><span class=\"line\">#获得特定进程号并重定向到一个临时文件中</span><br><span class=\"line\">ps -aux|grep &quot;/usr/sbin/httpd&quot; | grep -v &quot;grep&quot;| awk &apos;&#123;print $2&#125;&apos; &gt;/tmp/$&#123;current_pid&#125;.txt</span><br><span class=\"line\">#commands start</span><br><span class=\"line\">for pid in `cat /tmp/$&#123;current_pid&#125;.txt`</span><br><span class=\"line\">do</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    echo &quot;kill -9 $pid&quot;</span><br><span class=\"line\">    kill -9 $pid</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">done </span><br><span class=\"line\">rm -f /tmp/$&#123;current_pid&#125;.txt</span><br></pre></td></tr></table></figure>\n<ul>\n<li>shell 的函数处理</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    echo $a $b $c</span><br><span class=\"line\">    echo $1 $2 $3</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">a=&quot;aaa&quot;</span><br><span class=\"line\">b=&quot;bbb&quot;</span><br><span class=\"line\">c=&quot;ccc&quot;</span><br><span class=\"line\">func $a e f</span><br></pre></td></tr></table></figure>\n<p>函数传参是通过 funcname $para1 $para2 …,函数内部是使用$1,$2,$3<br>结果为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aaa bbb ccc</span><br><span class=\"line\">aaa e f</span><br></pre></td></tr></table></figure>\n<ul>\n<li>信号捕捉<br>trap可以使你在脚本中捕捉信号，命令形式为trap name signal(s)<br>其中,name是捕捉到信号以后所采取的一系列操作。实际中，name一般是一个专门用来处理所捕捉信号的函数。name需要用双引号（“”）引起来。signal是待捕捉的信号。<br>最常见的行动包括： 清除临时文件 忽略该信号(如trap “” 23) 询问用户是否终止该脚本进程</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trap &apos;exitprocess&apos; 2　　　　#捕捉到信号２之后执行exitprocess function</span><br><span class=\"line\">LOOP=0</span><br><span class=\"line\">function exitprocess()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    echo &quot;You Just hit &lt;CTRL-C&gt;, at number $LOOP&quot;</span><br><span class=\"line\">    echo &quot;I will now exit&quot;</span><br><span class=\"line\">    exit 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">while : # 循环直到捕捉到信号（注意中间的空格） </span><br><span class=\"line\">do</span><br><span class=\"line\">    LOOP=$LOOP+1</span><br><span class=\"line\">    echo $LOOP</span><br><span class=\"line\">    sleep 1</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>给一个文本，获取其中2000 ~ 3000 行怎么破？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat data.txt | tail -n +2000 | head -n 1000 &gt; result.txt</span><br></pre></td></tr></table></figure>\n<p>查找文件是否存在</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find /data -name hello.cpp</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>使用 shell 获取进程，并删除</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#取得当前进程号</span><br><span class=\"line\">current_pid=$$</span><br><span class=\"line\">#获得特定进程号并重定向到一个临时文件中</span><br><span class=\"line\">ps -aux|grep &quot;/usr/sbin/httpd&quot; | grep -v &quot;grep&quot;| awk &apos;&#123;print $2&#125;&apos; &gt;/tmp/$&#123;current_pid&#125;.txt</span><br><span class=\"line\">#commands start</span><br><span class=\"line\">for pid in `cat /tmp/$&#123;current_pid&#125;.txt`</span><br><span class=\"line\">do</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    echo &quot;kill -9 $pid&quot;</span><br><span class=\"line\">    kill -9 $pid</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">done </span><br><span class=\"line\">rm -f /tmp/$&#123;current_pid&#125;.txt</span><br></pre></td></tr></table></figure>\n<ul>\n<li>shell 的函数处理</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    echo $a $b $c</span><br><span class=\"line\">    echo $1 $2 $3</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">a=&quot;aaa&quot;</span><br><span class=\"line\">b=&quot;bbb&quot;</span><br><span class=\"line\">c=&quot;ccc&quot;</span><br><span class=\"line\">func $a e f</span><br></pre></td></tr></table></figure>\n<p>函数传参是通过 funcname $para1 $para2 …,函数内部是使用$1,$2,$3<br>结果为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aaa bbb ccc</span><br><span class=\"line\">aaa e f</span><br></pre></td></tr></table></figure>\n<ul>\n<li>信号捕捉<br>trap可以使你在脚本中捕捉信号，命令形式为trap name signal(s)<br>其中,name是捕捉到信号以后所采取的一系列操作。实际中，name一般是一个专门用来处理所捕捉信号的函数。name需要用双引号（“”）引起来。signal是待捕捉的信号。<br>最常见的行动包括： 清除临时文件 忽略该信号(如trap “” 23) 询问用户是否终止该脚本进程</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trap &apos;exitprocess&apos; 2　　　　#捕捉到信号２之后执行exitprocess function</span><br><span class=\"line\">LOOP=0</span><br><span class=\"line\">function exitprocess()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    echo &quot;You Just hit &lt;CTRL-C&gt;, at number $LOOP&quot;</span><br><span class=\"line\">    echo &quot;I will now exit&quot;</span><br><span class=\"line\">    exit 1</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">while : # 循环直到捕捉到信号（注意中间的空格） </span><br><span class=\"line\">do</span><br><span class=\"line\">    LOOP=$LOOP+1</span><br><span class=\"line\">    echo $LOOP</span><br><span class=\"line\">    sleep 1</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>给一个文本，获取其中2000 ~ 3000 行怎么破？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat data.txt | tail -n +2000 | head -n 1000 &gt; result.txt</span><br></pre></td></tr></table></figure>\n<p>查找文件是否存在</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find /data -name hello.cpp</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"ZeroRPC-基于ZMQ的RPC通讯库","date":"2013-09-29T12:56:00.000Z","comments":1,"_content":"[dotCloud](https://www.dotcloud.com/) 是一家具有伟大基因的公司,我认为的伟大是有着开源贡献的情怀，就像Amazon,Google等，而不是国内的某些巨头，虽然作为新兴的云服务提供商还不足以比肩巨头，致力于用技术解决公司的运营问题的同时也回馈社会，让我为之喝彩.我也有理由相信这样的公司会走的更远，因为他们有胸怀有远见，是否重视技术就更不言而喻了.\n\n这篇文章旨在介绍由**dotCloud**开源的[ZeroRpc](https://github.com/dotcloud/zerorpc-python),在dotcloud公司的基础服务得到很大应用，在阅读其manual之后更是被其简洁明了的使用方法所吸引 \n>ZeroRPC is a modern communication layer for distributed systems built on top of ZeroMQ,\n\n一直以来我一直喜欢python 的简洁，用过ZeroMQ做过网络通讯方面的编程，也使用RPC 做过远程过程调用，上次使用LevelDB的RPC是用python的[第三方库] (https://github.com/dotcloud/zerorpc-python)\n\n这次刚好在Github上面看到这样的好玩意，便想与大家分享,ZeroRpc不仅仅支持代码层面的调用，也支持CLi， 这种设计本身就很有弹性.赞！\n\n安装zerorpc\n\n```\nsudo pip install zerorpc \n```\n\n在还没开始看demo之前\n我们需要了解ZeroRpc是由三层架构组成：\n\n* 传输层是使用[ZMQ](http://www.zeromq.org/) 以及msgpack(http://msgpack.org/),基于ZeroMQ的分布式通讯层,通讯的数据被MsgPack 序列化过所以更快\n* 消息层,比较复杂,处理heartbeat, multiplexing, and events.\n* RPC层:处理请求,响应\n\n官方的[文档](http://zerorpc.dotcloud.com/)给出以下demo\n\n####server.py #####\n\n```python\nimport zerorpc\nclass HelloRPC(object):\n    def hello(self, name):\n        return \"Hello, %s\" % name\n\ns = zerorpc.Server(HelloRPC())\ns.bind(\"tcp://0.0.0.0:4242\")\ns.run()\n```\n\n####client.py\n\n```python\nimport zerorpc\n\nc = zerorpc.Client()\nc.connect(\"tcp://127.0.0.1:4242\")\nprint c.hello(\"RPC\")\n```\nclient也可用命令行代替\n\n```python\nzerorpc tcp://127.0.0.1:4242 hello RPC\n```\n\n够简明易懂了吧\n再来一个返回连续字节流的例子\n\n####server.py\n\n```python\nimport zerorpc\n\nclass StreamingRPC(object):\n    @zerorpc.stream\n    def streaming_range(self, fr, to, step):\n        return xrange(fr, to, step)\n\ns = zerorpc.Server(StreamingRPC())\ns.bind(\"tcp://0.0.0.0:4242\")\ns.run()\n```\n\n####client.py\n\n```python\nimport zerorpc\n\nc = zerorpc.Client()\nc.connect(\"tcp://127.0.0.1:4242\")\n\nfor item in c.streaming_range(10, 20, 2):\n    print item\n```\n\nclient也可用命令行代替,--json 表示头部是一个json对象\n\n```\nzerorpc tcp://127.0.0.1:4242 streaming_range 10 20 2 --json\n```\n\nHappy Hacking\n\n\n","source":"_posts/2013-09-29-zerorpcshi-ge-hao-dong-xi.markdown","raw":"---\nlayout: post\ntitle: \"ZeroRPC-基于ZMQ的RPC通讯库\"\ndate: 2013-09-29 20:56\ncomments: true\ncategories: Server NetWork\n---\n[dotCloud](https://www.dotcloud.com/) 是一家具有伟大基因的公司,我认为的伟大是有着开源贡献的情怀，就像Amazon,Google等，而不是国内的某些巨头，虽然作为新兴的云服务提供商还不足以比肩巨头，致力于用技术解决公司的运营问题的同时也回馈社会，让我为之喝彩.我也有理由相信这样的公司会走的更远，因为他们有胸怀有远见，是否重视技术就更不言而喻了.\n\n这篇文章旨在介绍由**dotCloud**开源的[ZeroRpc](https://github.com/dotcloud/zerorpc-python),在dotcloud公司的基础服务得到很大应用，在阅读其manual之后更是被其简洁明了的使用方法所吸引 \n>ZeroRPC is a modern communication layer for distributed systems built on top of ZeroMQ,\n\n一直以来我一直喜欢python 的简洁，用过ZeroMQ做过网络通讯方面的编程，也使用RPC 做过远程过程调用，上次使用LevelDB的RPC是用python的[第三方库] (https://github.com/dotcloud/zerorpc-python)\n\n这次刚好在Github上面看到这样的好玩意，便想与大家分享,ZeroRpc不仅仅支持代码层面的调用，也支持CLi， 这种设计本身就很有弹性.赞！\n\n安装zerorpc\n\n```\nsudo pip install zerorpc \n```\n\n在还没开始看demo之前\n我们需要了解ZeroRpc是由三层架构组成：\n\n* 传输层是使用[ZMQ](http://www.zeromq.org/) 以及msgpack(http://msgpack.org/),基于ZeroMQ的分布式通讯层,通讯的数据被MsgPack 序列化过所以更快\n* 消息层,比较复杂,处理heartbeat, multiplexing, and events.\n* RPC层:处理请求,响应\n\n官方的[文档](http://zerorpc.dotcloud.com/)给出以下demo\n\n####server.py #####\n\n```python\nimport zerorpc\nclass HelloRPC(object):\n    def hello(self, name):\n        return \"Hello, %s\" % name\n\ns = zerorpc.Server(HelloRPC())\ns.bind(\"tcp://0.0.0.0:4242\")\ns.run()\n```\n\n####client.py\n\n```python\nimport zerorpc\n\nc = zerorpc.Client()\nc.connect(\"tcp://127.0.0.1:4242\")\nprint c.hello(\"RPC\")\n```\nclient也可用命令行代替\n\n```python\nzerorpc tcp://127.0.0.1:4242 hello RPC\n```\n\n够简明易懂了吧\n再来一个返回连续字节流的例子\n\n####server.py\n\n```python\nimport zerorpc\n\nclass StreamingRPC(object):\n    @zerorpc.stream\n    def streaming_range(self, fr, to, step):\n        return xrange(fr, to, step)\n\ns = zerorpc.Server(StreamingRPC())\ns.bind(\"tcp://0.0.0.0:4242\")\ns.run()\n```\n\n####client.py\n\n```python\nimport zerorpc\n\nc = zerorpc.Client()\nc.connect(\"tcp://127.0.0.1:4242\")\n\nfor item in c.streaming_range(10, 20, 2):\n    print item\n```\n\nclient也可用命令行代替,--json 表示头部是一个json对象\n\n```\nzerorpc tcp://127.0.0.1:4242 streaming_range 10 20 2 --json\n```\n\nHappy Hacking\n\n\n","slug":"2013-09-29-zerorpcshi-ge-hao-dong-xi","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8t001inctjat3r6l68","content":"<p><a href=\"https://www.dotcloud.com/\" target=\"_blank\" rel=\"noopener\">dotCloud</a> 是一家具有伟大基因的公司,我认为的伟大是有着开源贡献的情怀，就像Amazon,Google等，而不是国内的某些巨头，虽然作为新兴的云服务提供商还不足以比肩巨头，致力于用技术解决公司的运营问题的同时也回馈社会，让我为之喝彩.我也有理由相信这样的公司会走的更远，因为他们有胸怀有远见，是否重视技术就更不言而喻了.</p>\n<p>这篇文章旨在介绍由<strong>dotCloud</strong>开源的<a href=\"https://github.com/dotcloud/zerorpc-python\" target=\"_blank\" rel=\"noopener\">ZeroRpc</a>,在dotcloud公司的基础服务得到很大应用，在阅读其manual之后更是被其简洁明了的使用方法所吸引 </p>\n<blockquote>\n<p>ZeroRPC is a modern communication layer for distributed systems built on top of ZeroMQ,</p>\n</blockquote>\n<p>一直以来我一直喜欢python 的简洁，用过ZeroMQ做过网络通讯方面的编程，也使用RPC 做过远程过程调用，上次使用LevelDB的RPC是用python的[第三方库] (<a href=\"https://github.com/dotcloud/zerorpc-python\" target=\"_blank\" rel=\"noopener\">https://github.com/dotcloud/zerorpc-python</a>)</p>\n<p>这次刚好在Github上面看到这样的好玩意，便想与大家分享,ZeroRpc不仅仅支持代码层面的调用，也支持CLi， 这种设计本身就很有弹性.赞！</p>\n<p>安装zerorpc</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip install zerorpc</span><br></pre></td></tr></table></figure>\n<p>在还没开始看demo之前<br>我们需要了解ZeroRpc是由三层架构组成：</p>\n<ul>\n<li>传输层是使用<a href=\"http://www.zeromq.org/\" target=\"_blank\" rel=\"noopener\">ZMQ</a> 以及msgpack(<a href=\"http://msgpack.org/),基于ZeroMQ的分布式通讯层,通讯的数据被MsgPack\" target=\"_blank\" rel=\"noopener\">http://msgpack.org/),基于ZeroMQ的分布式通讯层,通讯的数据被MsgPack</a> 序列化过所以更快</li>\n<li>消息层,比较复杂,处理heartbeat, multiplexing, and events.</li>\n<li>RPC层:处理请求,响应</li>\n</ul>\n<p>官方的<a href=\"http://zerorpc.dotcloud.com/\" target=\"_blank\" rel=\"noopener\">文档</a>给出以下demo</p>\n<p>####server.py #####</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> zerorpc</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HelloRPC</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hello</span><span class=\"params\">(self, name)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"Hello, %s\"</span> % name</span><br><span class=\"line\"></span><br><span class=\"line\">s = zerorpc.Server(HelloRPC())</span><br><span class=\"line\">s.bind(<span class=\"string\">\"tcp://0.0.0.0:4242\"</span>)</span><br><span class=\"line\">s.run()</span><br></pre></td></tr></table></figure>\n<p>####client.py</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> zerorpc</span><br><span class=\"line\"></span><br><span class=\"line\">c = zerorpc.Client()</span><br><span class=\"line\">c.connect(<span class=\"string\">\"tcp://127.0.0.1:4242\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> c.hello(<span class=\"string\">\"RPC\"</span>)</span><br></pre></td></tr></table></figure>\n<p>client也可用命令行代替</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zerorpc tcp://<span class=\"number\">127.0</span><span class=\"number\">.0</span><span class=\"number\">.1</span>:<span class=\"number\">4242</span> hello RPC</span><br></pre></td></tr></table></figure>\n<p>够简明易懂了吧<br>再来一个返回连续字节流的例子</p>\n<p>####server.py</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> zerorpc</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">StreamingRPC</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @zerorpc.stream</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">streaming_range</span><span class=\"params\">(self, fr, to, step)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> xrange(fr, to, step)</span><br><span class=\"line\"></span><br><span class=\"line\">s = zerorpc.Server(StreamingRPC())</span><br><span class=\"line\">s.bind(<span class=\"string\">\"tcp://0.0.0.0:4242\"</span>)</span><br><span class=\"line\">s.run()</span><br></pre></td></tr></table></figure>\n<p>####client.py</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> zerorpc</span><br><span class=\"line\"></span><br><span class=\"line\">c = zerorpc.Client()</span><br><span class=\"line\">c.connect(<span class=\"string\">\"tcp://127.0.0.1:4242\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> c.streaming_range(<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">2</span>):</span><br><span class=\"line\">    <span class=\"keyword\">print</span> item</span><br></pre></td></tr></table></figure>\n<p>client也可用命令行代替,–json 表示头部是一个json对象</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zerorpc tcp://127.0.0.1:4242 streaming_range 10 20 2 --json</span><br></pre></td></tr></table></figure>\n<p>Happy Hacking</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.dotcloud.com/\" target=\"_blank\" rel=\"noopener\">dotCloud</a> 是一家具有伟大基因的公司,我认为的伟大是有着开源贡献的情怀，就像Amazon,Google等，而不是国内的某些巨头，虽然作为新兴的云服务提供商还不足以比肩巨头，致力于用技术解决公司的运营问题的同时也回馈社会，让我为之喝彩.我也有理由相信这样的公司会走的更远，因为他们有胸怀有远见，是否重视技术就更不言而喻了.</p>\n<p>这篇文章旨在介绍由<strong>dotCloud</strong>开源的<a href=\"https://github.com/dotcloud/zerorpc-python\" target=\"_blank\" rel=\"noopener\">ZeroRpc</a>,在dotcloud公司的基础服务得到很大应用，在阅读其manual之后更是被其简洁明了的使用方法所吸引 </p>\n<blockquote>\n<p>ZeroRPC is a modern communication layer for distributed systems built on top of ZeroMQ,</p>\n</blockquote>\n<p>一直以来我一直喜欢python 的简洁，用过ZeroMQ做过网络通讯方面的编程，也使用RPC 做过远程过程调用，上次使用LevelDB的RPC是用python的[第三方库] (<a href=\"https://github.com/dotcloud/zerorpc-python\" target=\"_blank\" rel=\"noopener\">https://github.com/dotcloud/zerorpc-python</a>)</p>\n<p>这次刚好在Github上面看到这样的好玩意，便想与大家分享,ZeroRpc不仅仅支持代码层面的调用，也支持CLi， 这种设计本身就很有弹性.赞！</p>\n<p>安装zerorpc</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip install zerorpc</span><br></pre></td></tr></table></figure>\n<p>在还没开始看demo之前<br>我们需要了解ZeroRpc是由三层架构组成：</p>\n<ul>\n<li>传输层是使用<a href=\"http://www.zeromq.org/\" target=\"_blank\" rel=\"noopener\">ZMQ</a> 以及msgpack(<a href=\"http://msgpack.org/),基于ZeroMQ的分布式通讯层,通讯的数据被MsgPack\" target=\"_blank\" rel=\"noopener\">http://msgpack.org/),基于ZeroMQ的分布式通讯层,通讯的数据被MsgPack</a> 序列化过所以更快</li>\n<li>消息层,比较复杂,处理heartbeat, multiplexing, and events.</li>\n<li>RPC层:处理请求,响应</li>\n</ul>\n<p>官方的<a href=\"http://zerorpc.dotcloud.com/\" target=\"_blank\" rel=\"noopener\">文档</a>给出以下demo</p>\n<p>####server.py #####</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> zerorpc</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HelloRPC</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hello</span><span class=\"params\">(self, name)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"Hello, %s\"</span> % name</span><br><span class=\"line\"></span><br><span class=\"line\">s = zerorpc.Server(HelloRPC())</span><br><span class=\"line\">s.bind(<span class=\"string\">\"tcp://0.0.0.0:4242\"</span>)</span><br><span class=\"line\">s.run()</span><br></pre></td></tr></table></figure>\n<p>####client.py</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> zerorpc</span><br><span class=\"line\"></span><br><span class=\"line\">c = zerorpc.Client()</span><br><span class=\"line\">c.connect(<span class=\"string\">\"tcp://127.0.0.1:4242\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> c.hello(<span class=\"string\">\"RPC\"</span>)</span><br></pre></td></tr></table></figure>\n<p>client也可用命令行代替</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zerorpc tcp://<span class=\"number\">127.0</span><span class=\"number\">.0</span><span class=\"number\">.1</span>:<span class=\"number\">4242</span> hello RPC</span><br></pre></td></tr></table></figure>\n<p>够简明易懂了吧<br>再来一个返回连续字节流的例子</p>\n<p>####server.py</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> zerorpc</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">StreamingRPC</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\"><span class=\"meta\">    @zerorpc.stream</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">streaming_range</span><span class=\"params\">(self, fr, to, step)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> xrange(fr, to, step)</span><br><span class=\"line\"></span><br><span class=\"line\">s = zerorpc.Server(StreamingRPC())</span><br><span class=\"line\">s.bind(<span class=\"string\">\"tcp://0.0.0.0:4242\"</span>)</span><br><span class=\"line\">s.run()</span><br></pre></td></tr></table></figure>\n<p>####client.py</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> zerorpc</span><br><span class=\"line\"></span><br><span class=\"line\">c = zerorpc.Client()</span><br><span class=\"line\">c.connect(<span class=\"string\">\"tcp://127.0.0.1:4242\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> c.streaming_range(<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">2</span>):</span><br><span class=\"line\">    <span class=\"keyword\">print</span> item</span><br></pre></td></tr></table></figure>\n<p>client也可用命令行代替,–json 表示头部是一个json对象</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zerorpc tcp://127.0.0.1:4242 streaming_range 10 20 2 --json</span><br></pre></td></tr></table></figure>\n<p>Happy Hacking</p>\n"},{"layout":"post","title":"上善若水-想和这段生活谈谈","date":"2013-11-10T13:29:00.000Z","comments":1,"_content":"来深圳已经四个多月了，我不会扯淡地说些恍如隔日，白驹过隙之云，就我真实的感受而言，这些日子发生了很多事情，感觉经历了不少事情。关键字是： ***MiniGame比赛，后苑生活，吉他，折腾捣鼓***\n\n{% img /images/2013/10/Gitar.jpg %}\n{% img /images/2013/10/Violin.jpg %}\n\n本以为音乐会随着时光离我远去，原来它一直都在。小时候学过小提琴，后来因为羡慕同龄人可以一起踢球玩耍而渐渐荒废，每次面对房间里那把吉他心中不免有些愧疚，想拿起来练却因为种种原因作罢，归咎于我的无能吧。毕业前夕，邂逅吉他。开始新的音乐旅程.无数次的脱皮结茧也没有打消我的热情，疯狂爱上优美的弦音。虽不能说废寝忘食，却也可以每天自学一段时间，现在算是可以弹奏喜欢的歌曲。有一天当我教宿舍的朋友如何入门的时候，突然感觉自己已经在喜欢的路上走了一段距离。那时候看看手里的茧,听着手中指弹的发声，瞬间感动。这背后，是心性的变化。沉淀下来是可以做不少你曾经觉得甚是神奇的事情.\n\n***上善若水，水善利万物而不争。天下柔者莫过于水,而能攻者有莫过于水。***\n来深的这段时间里，我想这是我最大的收获。我喜欢这句话。\n\n心态的变化体现在对技术折腾上。曾经在时间，任务，压力面前我总是妥协倾向更快速解决问题。这样，知其然不知其所以然的祸根就埋下了，也伴有一些焦急，***“一件事情如果你说不好，十有八九你是做不好的”***。当然我依然改变不了捣鼓研究的热情，转变的是，我更愿意以一种好奇求问的心态，想想他们适合怎样的场景，在允许的情况下，我很乐意探其究竟。从细节中去发现美。曾以为会花费不少时间，如今看来，倒是在效率上给我带来了很大的提高，思维上也改造了不少 ：）.这几天疯狂地满足了折腾的欲望\n\n+ 折腾ArchLinux，\n+ 阅读完一本《MongoDb权威指南》\n+ 开发一个chrome插件,稍后会把经验分享给大家\n+ 博客做了改版，也顺带理清了octopress的框架,给他加了不少插件。\n\n捣鼓的热情，可以让人忘记时间甚至烦恼，沉浸在知识的海洋，也会为自己小小欣慰一把，这种小情绪怡然自得，如果你也是个不安分的人，相信你在此刻会有共鸣。\n \n提起工作，必须承认，离开有2年半感情的[Youmi](http://youmi.net)，它有我大学一半的青春与回忆，对我来说是一个不容易的事情，我爱那里的人，初创团队的KISS，让我感受到很强的工程师文化，i like it。那里有我的可敬的精神[偶像](http://sysrt.net)，但我希望我的人生多一些阅历，于是在毕业的岔口我来到了tx。选择没有对错，这一路总有不同的风景，\n \n在大公司，不可避免，我做的是螺丝钉般很琐碎的工作，很诚实地说，基本无技术上的锻炼,很长一段时间也将是。这一直是我内心一个心结。这对热爱技术的我，算是一种无奈吧。只能靠自己更高效地工作争取会宿舍去捣鼓消化技术的热情，真的很羡慕那些工程师味道浓厚，真正做事，创造价值的团队，每每在微博看到业界意见领袖（[@coolshell](http://coolshell.cn),[@Fenng](http://dbanotes.net)..）的团队，便会像阿Q一样自嘲下自己,也好，多些经历也是好事，这样我会更加鞭策着去努力。话说回来，无论光景怎么变，我能做的就是始终都不能放弃学习与积累。这个过程中本身就是一件很开心的事情。很欣喜的是这一路我并不孤单，[华亮](http://everet.org)和我也是一样在努力着。\n\n在平淡，甚至有点黯然失色的日子里，携安静的内心,还有吉他与代码，多一份坦然，多一份汗水，多一份坚持去面对生活，感悟生活，这是我对“上善若水”的理解。文字还是稚嫩，写这文章的心情是平静,不带偏激和情绪，我想和这段生活谈谈。\n\n","source":"_posts/2013-10-10-shui-de-xin-jing.markdown","raw":"---\nlayout: post\ntitle: \"上善若水-想和这段生活谈谈\"\ndate: 2013-11-10 21:29\ncomments: true\ncategories: Life\n---\n来深圳已经四个多月了，我不会扯淡地说些恍如隔日，白驹过隙之云，就我真实的感受而言，这些日子发生了很多事情，感觉经历了不少事情。关键字是： ***MiniGame比赛，后苑生活，吉他，折腾捣鼓***\n\n{% img /images/2013/10/Gitar.jpg %}\n{% img /images/2013/10/Violin.jpg %}\n\n本以为音乐会随着时光离我远去，原来它一直都在。小时候学过小提琴，后来因为羡慕同龄人可以一起踢球玩耍而渐渐荒废，每次面对房间里那把吉他心中不免有些愧疚，想拿起来练却因为种种原因作罢，归咎于我的无能吧。毕业前夕，邂逅吉他。开始新的音乐旅程.无数次的脱皮结茧也没有打消我的热情，疯狂爱上优美的弦音。虽不能说废寝忘食，却也可以每天自学一段时间，现在算是可以弹奏喜欢的歌曲。有一天当我教宿舍的朋友如何入门的时候，突然感觉自己已经在喜欢的路上走了一段距离。那时候看看手里的茧,听着手中指弹的发声，瞬间感动。这背后，是心性的变化。沉淀下来是可以做不少你曾经觉得甚是神奇的事情.\n\n***上善若水，水善利万物而不争。天下柔者莫过于水,而能攻者有莫过于水。***\n来深的这段时间里，我想这是我最大的收获。我喜欢这句话。\n\n心态的变化体现在对技术折腾上。曾经在时间，任务，压力面前我总是妥协倾向更快速解决问题。这样，知其然不知其所以然的祸根就埋下了，也伴有一些焦急，***“一件事情如果你说不好，十有八九你是做不好的”***。当然我依然改变不了捣鼓研究的热情，转变的是，我更愿意以一种好奇求问的心态，想想他们适合怎样的场景，在允许的情况下，我很乐意探其究竟。从细节中去发现美。曾以为会花费不少时间，如今看来，倒是在效率上给我带来了很大的提高，思维上也改造了不少 ：）.这几天疯狂地满足了折腾的欲望\n\n+ 折腾ArchLinux，\n+ 阅读完一本《MongoDb权威指南》\n+ 开发一个chrome插件,稍后会把经验分享给大家\n+ 博客做了改版，也顺带理清了octopress的框架,给他加了不少插件。\n\n捣鼓的热情，可以让人忘记时间甚至烦恼，沉浸在知识的海洋，也会为自己小小欣慰一把，这种小情绪怡然自得，如果你也是个不安分的人，相信你在此刻会有共鸣。\n \n提起工作，必须承认，离开有2年半感情的[Youmi](http://youmi.net)，它有我大学一半的青春与回忆，对我来说是一个不容易的事情，我爱那里的人，初创团队的KISS，让我感受到很强的工程师文化，i like it。那里有我的可敬的精神[偶像](http://sysrt.net)，但我希望我的人生多一些阅历，于是在毕业的岔口我来到了tx。选择没有对错，这一路总有不同的风景，\n \n在大公司，不可避免，我做的是螺丝钉般很琐碎的工作，很诚实地说，基本无技术上的锻炼,很长一段时间也将是。这一直是我内心一个心结。这对热爱技术的我，算是一种无奈吧。只能靠自己更高效地工作争取会宿舍去捣鼓消化技术的热情，真的很羡慕那些工程师味道浓厚，真正做事，创造价值的团队，每每在微博看到业界意见领袖（[@coolshell](http://coolshell.cn),[@Fenng](http://dbanotes.net)..）的团队，便会像阿Q一样自嘲下自己,也好，多些经历也是好事，这样我会更加鞭策着去努力。话说回来，无论光景怎么变，我能做的就是始终都不能放弃学习与积累。这个过程中本身就是一件很开心的事情。很欣喜的是这一路我并不孤单，[华亮](http://everet.org)和我也是一样在努力着。\n\n在平淡，甚至有点黯然失色的日子里，携安静的内心,还有吉他与代码，多一份坦然，多一份汗水，多一份坚持去面对生活，感悟生活，这是我对“上善若水”的理解。文字还是稚嫩，写这文章的心情是平静,不带偏激和情绪，我想和这段生活谈谈。\n\n","slug":"2013-10-10-shui-de-xin-jing","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8v001knctjsgoheo89","content":"<p>来深圳已经四个多月了，我不会扯淡地说些恍如隔日，白驹过隙之云，就我真实的感受而言，这些日子发生了很多事情，感觉经历了不少事情。关键字是： <strong><em>MiniGame比赛，后苑生活，吉他，折腾捣鼓</em></strong></p>\n<img src=\"/images/2013/10/Gitar.jpg\">\n<img src=\"/images/2013/10/Violin.jpg\">\n<p>本以为音乐会随着时光离我远去，原来它一直都在。小时候学过小提琴，后来因为羡慕同龄人可以一起踢球玩耍而渐渐荒废，每次面对房间里那把吉他心中不免有些愧疚，想拿起来练却因为种种原因作罢，归咎于我的无能吧。毕业前夕，邂逅吉他。开始新的音乐旅程.无数次的脱皮结茧也没有打消我的热情，疯狂爱上优美的弦音。虽不能说废寝忘食，却也可以每天自学一段时间，现在算是可以弹奏喜欢的歌曲。有一天当我教宿舍的朋友如何入门的时候，突然感觉自己已经在喜欢的路上走了一段距离。那时候看看手里的茧,听着手中指弹的发声，瞬间感动。这背后，是心性的变化。沉淀下来是可以做不少你曾经觉得甚是神奇的事情.</p>\n<p><strong><em>上善若水，水善利万物而不争。天下柔者莫过于水,而能攻者有莫过于水。</em></strong><br>来深的这段时间里，我想这是我最大的收获。我喜欢这句话。</p>\n<p>心态的变化体现在对技术折腾上。曾经在时间，任务，压力面前我总是妥协倾向更快速解决问题。这样，知其然不知其所以然的祸根就埋下了，也伴有一些焦急，<strong><em>“一件事情如果你说不好，十有八九你是做不好的”</em></strong>。当然我依然改变不了捣鼓研究的热情，转变的是，我更愿意以一种好奇求问的心态，想想他们适合怎样的场景，在允许的情况下，我很乐意探其究竟。从细节中去发现美。曾以为会花费不少时间，如今看来，倒是在效率上给我带来了很大的提高，思维上也改造了不少 ：）.这几天疯狂地满足了折腾的欲望</p>\n<ul>\n<li>折腾ArchLinux，</li>\n<li>阅读完一本《MongoDb权威指南》</li>\n<li>开发一个chrome插件,稍后会把经验分享给大家</li>\n<li>博客做了改版，也顺带理清了octopress的框架,给他加了不少插件。</li>\n</ul>\n<p>捣鼓的热情，可以让人忘记时间甚至烦恼，沉浸在知识的海洋，也会为自己小小欣慰一把，这种小情绪怡然自得，如果你也是个不安分的人，相信你在此刻会有共鸣。</p>\n<p>提起工作，必须承认，离开有2年半感情的<a href=\"http://youmi.net\" target=\"_blank\" rel=\"noopener\">Youmi</a>，它有我大学一半的青春与回忆，对我来说是一个不容易的事情，我爱那里的人，初创团队的KISS，让我感受到很强的工程师文化，i like it。那里有我的可敬的精神<a href=\"http://sysrt.net\" target=\"_blank\" rel=\"noopener\">偶像</a>，但我希望我的人生多一些阅历，于是在毕业的岔口我来到了tx。选择没有对错，这一路总有不同的风景，</p>\n<p>在大公司，不可避免，我做的是螺丝钉般很琐碎的工作，很诚实地说，基本无技术上的锻炼,很长一段时间也将是。这一直是我内心一个心结。这对热爱技术的我，算是一种无奈吧。只能靠自己更高效地工作争取会宿舍去捣鼓消化技术的热情，真的很羡慕那些工程师味道浓厚，真正做事，创造价值的团队，每每在微博看到业界意见领袖（<a href=\"http://coolshell.cn\" target=\"_blank\" rel=\"noopener\">@coolshell</a>,<a href=\"http://dbanotes.net\" target=\"_blank\" rel=\"noopener\">@Fenng</a>..）的团队，便会像阿Q一样自嘲下自己,也好，多些经历也是好事，这样我会更加鞭策着去努力。话说回来，无论光景怎么变，我能做的就是始终都不能放弃学习与积累。这个过程中本身就是一件很开心的事情。很欣喜的是这一路我并不孤单，<a href=\"http://everet.org\" target=\"_blank\" rel=\"noopener\">华亮</a>和我也是一样在努力着。</p>\n<p>在平淡，甚至有点黯然失色的日子里，携安静的内心,还有吉他与代码，多一份坦然，多一份汗水，多一份坚持去面对生活，感悟生活，这是我对“上善若水”的理解。文字还是稚嫩，写这文章的心情是平静,不带偏激和情绪，我想和这段生活谈谈。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>来深圳已经四个多月了，我不会扯淡地说些恍如隔日，白驹过隙之云，就我真实的感受而言，这些日子发生了很多事情，感觉经历了不少事情。关键字是： <strong><em>MiniGame比赛，后苑生活，吉他，折腾捣鼓</em></strong></p>\n<img src=\"/images/2013/10/Gitar.jpg\">\n<img src=\"/images/2013/10/Violin.jpg\">\n<p>本以为音乐会随着时光离我远去，原来它一直都在。小时候学过小提琴，后来因为羡慕同龄人可以一起踢球玩耍而渐渐荒废，每次面对房间里那把吉他心中不免有些愧疚，想拿起来练却因为种种原因作罢，归咎于我的无能吧。毕业前夕，邂逅吉他。开始新的音乐旅程.无数次的脱皮结茧也没有打消我的热情，疯狂爱上优美的弦音。虽不能说废寝忘食，却也可以每天自学一段时间，现在算是可以弹奏喜欢的歌曲。有一天当我教宿舍的朋友如何入门的时候，突然感觉自己已经在喜欢的路上走了一段距离。那时候看看手里的茧,听着手中指弹的发声，瞬间感动。这背后，是心性的变化。沉淀下来是可以做不少你曾经觉得甚是神奇的事情.</p>\n<p><strong><em>上善若水，水善利万物而不争。天下柔者莫过于水,而能攻者有莫过于水。</em></strong><br>来深的这段时间里，我想这是我最大的收获。我喜欢这句话。</p>\n<p>心态的变化体现在对技术折腾上。曾经在时间，任务，压力面前我总是妥协倾向更快速解决问题。这样，知其然不知其所以然的祸根就埋下了，也伴有一些焦急，<strong><em>“一件事情如果你说不好，十有八九你是做不好的”</em></strong>。当然我依然改变不了捣鼓研究的热情，转变的是，我更愿意以一种好奇求问的心态，想想他们适合怎样的场景，在允许的情况下，我很乐意探其究竟。从细节中去发现美。曾以为会花费不少时间，如今看来，倒是在效率上给我带来了很大的提高，思维上也改造了不少 ：）.这几天疯狂地满足了折腾的欲望</p>\n<ul>\n<li>折腾ArchLinux，</li>\n<li>阅读完一本《MongoDb权威指南》</li>\n<li>开发一个chrome插件,稍后会把经验分享给大家</li>\n<li>博客做了改版，也顺带理清了octopress的框架,给他加了不少插件。</li>\n</ul>\n<p>捣鼓的热情，可以让人忘记时间甚至烦恼，沉浸在知识的海洋，也会为自己小小欣慰一把，这种小情绪怡然自得，如果你也是个不安分的人，相信你在此刻会有共鸣。</p>\n<p>提起工作，必须承认，离开有2年半感情的<a href=\"http://youmi.net\" target=\"_blank\" rel=\"noopener\">Youmi</a>，它有我大学一半的青春与回忆，对我来说是一个不容易的事情，我爱那里的人，初创团队的KISS，让我感受到很强的工程师文化，i like it。那里有我的可敬的精神<a href=\"http://sysrt.net\" target=\"_blank\" rel=\"noopener\">偶像</a>，但我希望我的人生多一些阅历，于是在毕业的岔口我来到了tx。选择没有对错，这一路总有不同的风景，</p>\n<p>在大公司，不可避免，我做的是螺丝钉般很琐碎的工作，很诚实地说，基本无技术上的锻炼,很长一段时间也将是。这一直是我内心一个心结。这对热爱技术的我，算是一种无奈吧。只能靠自己更高效地工作争取会宿舍去捣鼓消化技术的热情，真的很羡慕那些工程师味道浓厚，真正做事，创造价值的团队，每每在微博看到业界意见领袖（<a href=\"http://coolshell.cn\" target=\"_blank\" rel=\"noopener\">@coolshell</a>,<a href=\"http://dbanotes.net\" target=\"_blank\" rel=\"noopener\">@Fenng</a>..）的团队，便会像阿Q一样自嘲下自己,也好，多些经历也是好事，这样我会更加鞭策着去努力。话说回来，无论光景怎么变，我能做的就是始终都不能放弃学习与积累。这个过程中本身就是一件很开心的事情。很欣喜的是这一路我并不孤单，<a href=\"http://everet.org\" target=\"_blank\" rel=\"noopener\">华亮</a>和我也是一样在努力着。</p>\n<p>在平淡，甚至有点黯然失色的日子里，携安静的内心,还有吉他与代码，多一份坦然，多一份汗水，多一份坚持去面对生活，感悟生活，这是我对“上善若水”的理解。文字还是稚嫩，写这文章的心情是平静,不带偏激和情绪，我想和这段生活谈谈。</p>\n"},{"layout":"post","title":"最近用到的 MySql 语句","date":"2013-12-05T15:01:00.000Z","comments":1,"keywords":"优化","description":"mysql优化","_content":"该文章没有什么创造性营养，也没有什么技术沉淀，各位看官轻轻带过，仅仅经验之谈，看过用过的人都会，简单的事情就平滑地带过。怎么让索然无味的文章更好地被他人深入阅读,要么就是实用，要么就是深刻，不扯淡, 直奔主题。\n\n### 查看表结构\n\n```\ndesc Tbl;\nshow create table Tbl;\nshow full fields table Tbl;\n```\n\n如果表有很多分区，导致很多打点刷屏，那么可以用\n\n```\ndesc Tbl/G;\n```\n\n表太多的话，我的场景是2000张表,:(\n\n```\nSHOW TABLES LIKE '%tb%';\n```\n\n####查询数据库的字符集\n\n```\nshow variables like '%character%';\n```\n\n####指定字符集直连\n\n```\nmysql -h10.145.135.234 -uoss -pxxx dbName --default-character-set=gbk;\n```\n\n####赋予权限\n\n```\nshow grants for 'xxx'@'xxx.xxx.xxx.xxx'\n```\n\n####如果想备份，或者复制表\n\n```\ncreate table newtb select * from oldtable\n```\n\n####修改表字段\n\n```\nalter tbA modify fieldA int(11) unsigned default '0'\n```\n\n####移除字段\n\n```\nalter table t2 drop column c;\n```\n\n####修改主键\n\n```\nalter table tbA drop primary key;\nAlter table tbA add primary key(dtStatDate,File2)\n```\n\n####查询当前数据库的查询进程,干掉挂起的query\n\n```\nshow processlist;\nkill pid\n```\n\n####直接在shell外部命令行执行:\n\n```\nmysql -h10.112.111.111 -uxxx -pxxxx dbname -Ns -e\"\nselect distinct(iUin) from TableA where dtEventTime >= '2013-05-05' \n\" > records.txt;\n```\n\n#### 排除重复记录\n\n```\nINSERT IGNORE into\nReplace Into 是为了让主键替换原有的记录\n```\n\n####load data infile语句\n从一个文本文件中以很高的速度读入一个表中。使用这个命令之前，mysqld进程（服务）必须已经在运行。为了安全原因，当读取位于服务器上的文本文件时，文件必须处于数据库目录或可被所有人读取。另外，为了对服务器上文件使用load data infile，在服务器主机上你必须有file的权限。\n\n```\nload data infile \"/home/Order txt\" into table Orders(Order_Number, Order_Date, Customer_ID) terminated by',';\n```\n\n#### mysqldump 中解决 报\"Access denied for user when using LOCK TABLES\"\n\n```\nmysqldump -udbuser -p dbname --skip-lock-tables > dbname.sql\n```\n\n####监控数据库磁盘增长量\n\n```\nuse information_schema;\n#库的大小\nselect concat(round(sum(DATA_LENGTH/1024/1024),2),'MB') as data  from TABLES where table_schema='db1';\n```\n\n####时间函数\n\n```\nFROM_UNIXTIME(iLoginTime,'%Y-%m-%d')\nunix_timestamp('2013-12-03');\nDate_SUB(OrderDate,INTERVAL 2 DAY)\nDate_ADD(OrderDate,INTERVAL 2 DAY)\ntimestampdiff(week,’2009-01-24′,’2009-06-20′);\n```\n\n####no exist,having\n适合做留存用户分析\n\n```\nSELECT distinct field1\nFROM table a\nwhere date <= 20130430 and\nnot exists (\n        SELECT field1 FROM table b where date>=20130501 and a.field1=b.field1\n)\n\n#举例子,可以计算第一次创建用户的人\nselect * from TbRole having min(CreateTime) between 'xxx' and 'xxx' \n```\n\n####mysql 逻辑运算,好像在编程的样子\n\n```\ncase condition1\nwhen result1 then 'xx'\nwhen result2 then 'xx'\nelse result1 then 'xx'\nend as 'xx'\n\nifnull(a,b) #如果a不为空的情况下执行a,否则执行b\nif(condition,a,b)#如果符合condition 执行a,否则执行b\n```\n\n####妙用group by \n可以在group by 里面做逻辑运算, 缩小逻辑范围\n\n```\nselect * From tableA group by (round(field1/100,0));\n```\n\n####格式化字符串类型\n\n```\nconcat('a','b')\n```\n\n####mysql的临时变量'@'\n以下sql是取各道具排前10的等级\n\n```\nselect * from (\n    select dtStatDate,iRoleLevel,iUserNum,\n    if(@templevel=a.iRoleLevel,@tno:=@tno+1,@tno:=1) as tno,@templevel:=a.iRoleLevel \n    from tbl_a , (SELECT @tno:= 0,@templevel:=null) tbl_b\n    order by a.iRoleLevel asc,a.iUserNum desc\n) c\nwhere tno<=10 order by iRoleLevel asc\n```\n\n####其他\nunion all 效率会比union高,因为union有去重功能,会耗时 \n","source":"_posts/2013-12-05-zui-jin-yong-dao-de-mysql.markdown","raw":"---\nlayout: post\ntitle: \"最近用到的 MySql 语句\"\ndate: 2013-12-05 23:01\ncomments: true\ncategories: DataBase\nkeywords: 优化\ndescription: mysql优化\n---\n该文章没有什么创造性营养，也没有什么技术沉淀，各位看官轻轻带过，仅仅经验之谈，看过用过的人都会，简单的事情就平滑地带过。怎么让索然无味的文章更好地被他人深入阅读,要么就是实用，要么就是深刻，不扯淡, 直奔主题。\n\n### 查看表结构\n\n```\ndesc Tbl;\nshow create table Tbl;\nshow full fields table Tbl;\n```\n\n如果表有很多分区，导致很多打点刷屏，那么可以用\n\n```\ndesc Tbl/G;\n```\n\n表太多的话，我的场景是2000张表,:(\n\n```\nSHOW TABLES LIKE '%tb%';\n```\n\n####查询数据库的字符集\n\n```\nshow variables like '%character%';\n```\n\n####指定字符集直连\n\n```\nmysql -h10.145.135.234 -uoss -pxxx dbName --default-character-set=gbk;\n```\n\n####赋予权限\n\n```\nshow grants for 'xxx'@'xxx.xxx.xxx.xxx'\n```\n\n####如果想备份，或者复制表\n\n```\ncreate table newtb select * from oldtable\n```\n\n####修改表字段\n\n```\nalter tbA modify fieldA int(11) unsigned default '0'\n```\n\n####移除字段\n\n```\nalter table t2 drop column c;\n```\n\n####修改主键\n\n```\nalter table tbA drop primary key;\nAlter table tbA add primary key(dtStatDate,File2)\n```\n\n####查询当前数据库的查询进程,干掉挂起的query\n\n```\nshow processlist;\nkill pid\n```\n\n####直接在shell外部命令行执行:\n\n```\nmysql -h10.112.111.111 -uxxx -pxxxx dbname -Ns -e\"\nselect distinct(iUin) from TableA where dtEventTime >= '2013-05-05' \n\" > records.txt;\n```\n\n#### 排除重复记录\n\n```\nINSERT IGNORE into\nReplace Into 是为了让主键替换原有的记录\n```\n\n####load data infile语句\n从一个文本文件中以很高的速度读入一个表中。使用这个命令之前，mysqld进程（服务）必须已经在运行。为了安全原因，当读取位于服务器上的文本文件时，文件必须处于数据库目录或可被所有人读取。另外，为了对服务器上文件使用load data infile，在服务器主机上你必须有file的权限。\n\n```\nload data infile \"/home/Order txt\" into table Orders(Order_Number, Order_Date, Customer_ID) terminated by',';\n```\n\n#### mysqldump 中解决 报\"Access denied for user when using LOCK TABLES\"\n\n```\nmysqldump -udbuser -p dbname --skip-lock-tables > dbname.sql\n```\n\n####监控数据库磁盘增长量\n\n```\nuse information_schema;\n#库的大小\nselect concat(round(sum(DATA_LENGTH/1024/1024),2),'MB') as data  from TABLES where table_schema='db1';\n```\n\n####时间函数\n\n```\nFROM_UNIXTIME(iLoginTime,'%Y-%m-%d')\nunix_timestamp('2013-12-03');\nDate_SUB(OrderDate,INTERVAL 2 DAY)\nDate_ADD(OrderDate,INTERVAL 2 DAY)\ntimestampdiff(week,’2009-01-24′,’2009-06-20′);\n```\n\n####no exist,having\n适合做留存用户分析\n\n```\nSELECT distinct field1\nFROM table a\nwhere date <= 20130430 and\nnot exists (\n        SELECT field1 FROM table b where date>=20130501 and a.field1=b.field1\n)\n\n#举例子,可以计算第一次创建用户的人\nselect * from TbRole having min(CreateTime) between 'xxx' and 'xxx' \n```\n\n####mysql 逻辑运算,好像在编程的样子\n\n```\ncase condition1\nwhen result1 then 'xx'\nwhen result2 then 'xx'\nelse result1 then 'xx'\nend as 'xx'\n\nifnull(a,b) #如果a不为空的情况下执行a,否则执行b\nif(condition,a,b)#如果符合condition 执行a,否则执行b\n```\n\n####妙用group by \n可以在group by 里面做逻辑运算, 缩小逻辑范围\n\n```\nselect * From tableA group by (round(field1/100,0));\n```\n\n####格式化字符串类型\n\n```\nconcat('a','b')\n```\n\n####mysql的临时变量'@'\n以下sql是取各道具排前10的等级\n\n```\nselect * from (\n    select dtStatDate,iRoleLevel,iUserNum,\n    if(@templevel=a.iRoleLevel,@tno:=@tno+1,@tno:=1) as tno,@templevel:=a.iRoleLevel \n    from tbl_a , (SELECT @tno:= 0,@templevel:=null) tbl_b\n    order by a.iRoleLevel asc,a.iUserNum desc\n) c\nwhere tno<=10 order by iRoleLevel asc\n```\n\n####其他\nunion all 效率会比union高,因为union有去重功能,会耗时 \n","slug":"2013-12-05-zui-jin-yong-dao-de-mysql","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8w001nnctjyv9t1372","content":"<p>该文章没有什么创造性营养，也没有什么技术沉淀，各位看官轻轻带过，仅仅经验之谈，看过用过的人都会，简单的事情就平滑地带过。怎么让索然无味的文章更好地被他人深入阅读,要么就是实用，要么就是深刻，不扯淡, 直奔主题。</p>\n<h3 id=\"查看表结构\"><a href=\"#查看表结构\" class=\"headerlink\" title=\"查看表结构\"></a>查看表结构</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">desc Tbl;</span><br><span class=\"line\">show create table Tbl;</span><br><span class=\"line\">show full fields table Tbl;</span><br></pre></td></tr></table></figure>\n<p>如果表有很多分区，导致很多打点刷屏，那么可以用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">desc Tbl/G;</span><br></pre></td></tr></table></figure>\n<p>表太多的话，我的场景是2000张表,:(</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SHOW TABLES LIKE &apos;%tb%&apos;;</span><br></pre></td></tr></table></figure>\n<p>####查询数据库的字符集</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show variables like &apos;%character%&apos;;</span><br></pre></td></tr></table></figure>\n<p>####指定字符集直连</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -h10.145.135.234 -uoss -pxxx dbName --default-character-set=gbk;</span><br></pre></td></tr></table></figure>\n<p>####赋予权限</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show grants for &apos;xxx&apos;@&apos;xxx.xxx.xxx.xxx&apos;</span><br></pre></td></tr></table></figure>\n<p>####如果想备份，或者复制表</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">create table newtb select * from oldtable</span><br></pre></td></tr></table></figure>\n<p>####修改表字段</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alter tbA modify fieldA int(11) unsigned default &apos;0&apos;</span><br></pre></td></tr></table></figure>\n<p>####移除字段</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alter table t2 drop column c;</span><br></pre></td></tr></table></figure>\n<p>####修改主键</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alter table tbA drop primary key;</span><br><span class=\"line\">Alter table tbA add primary key(dtStatDate,File2)</span><br></pre></td></tr></table></figure>\n<p>####查询当前数据库的查询进程,干掉挂起的query</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show processlist;</span><br><span class=\"line\">kill pid</span><br></pre></td></tr></table></figure>\n<p>####直接在shell外部命令行执行:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -h10.112.111.111 -uxxx -pxxxx dbname -Ns -e&quot;</span><br><span class=\"line\">select distinct(iUin) from TableA where dtEventTime &gt;= &apos;2013-05-05&apos; </span><br><span class=\"line\">&quot; &gt; records.txt;</span><br></pre></td></tr></table></figure>\n<h4 id=\"排除重复记录\"><a href=\"#排除重复记录\" class=\"headerlink\" title=\"排除重复记录\"></a>排除重复记录</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INSERT IGNORE into</span><br><span class=\"line\">Replace Into 是为了让主键替换原有的记录</span><br></pre></td></tr></table></figure>\n<p>####load data infile语句<br>从一个文本文件中以很高的速度读入一个表中。使用这个命令之前，mysqld进程（服务）必须已经在运行。为了安全原因，当读取位于服务器上的文本文件时，文件必须处于数据库目录或可被所有人读取。另外，为了对服务器上文件使用load data infile，在服务器主机上你必须有file的权限。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">load data infile &quot;/home/Order txt&quot; into table Orders(Order_Number, Order_Date, Customer_ID) terminated by&apos;,&apos;;</span><br></pre></td></tr></table></figure>\n<h4 id=\"mysqldump-中解决-报”Access-denied-for-user-when-using-LOCK-TABLES”\"><a href=\"#mysqldump-中解决-报”Access-denied-for-user-when-using-LOCK-TABLES”\" class=\"headerlink\" title=\"mysqldump 中解决 报”Access denied for user when using LOCK TABLES”\"></a>mysqldump 中解决 报”Access denied for user when using LOCK TABLES”</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqldump -udbuser -p dbname --skip-lock-tables &gt; dbname.sql</span><br></pre></td></tr></table></figure>\n<p>####监控数据库磁盘增长量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">use information_schema;</span><br><span class=\"line\">#库的大小</span><br><span class=\"line\">select concat(round(sum(DATA_LENGTH/1024/1024),2),&apos;MB&apos;) as data  from TABLES where table_schema=&apos;db1&apos;;</span><br></pre></td></tr></table></figure>\n<p>####时间函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM_UNIXTIME(iLoginTime,&apos;%Y-%m-%d&apos;)</span><br><span class=\"line\">unix_timestamp(&apos;2013-12-03&apos;);</span><br><span class=\"line\">Date_SUB(OrderDate,INTERVAL 2 DAY)</span><br><span class=\"line\">Date_ADD(OrderDate,INTERVAL 2 DAY)</span><br><span class=\"line\">timestampdiff(week,’2009-01-24′,’2009-06-20′);</span><br></pre></td></tr></table></figure>\n<p>####no exist,having<br>适合做留存用户分析</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT distinct field1</span><br><span class=\"line\">FROM table a</span><br><span class=\"line\">where date &lt;= 20130430 and</span><br><span class=\"line\">not exists (</span><br><span class=\"line\">        SELECT field1 FROM table b where date&gt;=20130501 and a.field1=b.field1</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">#举例子,可以计算第一次创建用户的人</span><br><span class=\"line\">select * from TbRole having min(CreateTime) between &apos;xxx&apos; and &apos;xxx&apos;</span><br></pre></td></tr></table></figure>\n<p>####mysql 逻辑运算,好像在编程的样子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case condition1</span><br><span class=\"line\">when result1 then &apos;xx&apos;</span><br><span class=\"line\">when result2 then &apos;xx&apos;</span><br><span class=\"line\">else result1 then &apos;xx&apos;</span><br><span class=\"line\">end as &apos;xx&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">ifnull(a,b) #如果a不为空的情况下执行a,否则执行b</span><br><span class=\"line\">if(condition,a,b)#如果符合condition 执行a,否则执行b</span><br></pre></td></tr></table></figure>\n<p>####妙用group by<br>可以在group by 里面做逻辑运算, 缩小逻辑范围</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * From tableA group by (round(field1/100,0));</span><br></pre></td></tr></table></figure>\n<p>####格式化字符串类型</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">concat(&apos;a&apos;,&apos;b&apos;)</span><br></pre></td></tr></table></figure>\n<p>####mysql的临时变量‘@’<br>以下sql是取各道具排前10的等级</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * from (</span><br><span class=\"line\">    select dtStatDate,iRoleLevel,iUserNum,</span><br><span class=\"line\">    if(@templevel=a.iRoleLevel,@tno:=@tno+1,@tno:=1) as tno,@templevel:=a.iRoleLevel </span><br><span class=\"line\">    from tbl_a , (SELECT @tno:= 0,@templevel:=null) tbl_b</span><br><span class=\"line\">    order by a.iRoleLevel asc,a.iUserNum desc</span><br><span class=\"line\">) c</span><br><span class=\"line\">where tno&lt;=10 order by iRoleLevel asc</span><br></pre></td></tr></table></figure>\n<p>####其他<br>union all 效率会比union高,因为union有去重功能,会耗时 </p>\n","site":{"data":{}},"excerpt":"","more":"<p>该文章没有什么创造性营养，也没有什么技术沉淀，各位看官轻轻带过，仅仅经验之谈，看过用过的人都会，简单的事情就平滑地带过。怎么让索然无味的文章更好地被他人深入阅读,要么就是实用，要么就是深刻，不扯淡, 直奔主题。</p>\n<h3 id=\"查看表结构\"><a href=\"#查看表结构\" class=\"headerlink\" title=\"查看表结构\"></a>查看表结构</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">desc Tbl;</span><br><span class=\"line\">show create table Tbl;</span><br><span class=\"line\">show full fields table Tbl;</span><br></pre></td></tr></table></figure>\n<p>如果表有很多分区，导致很多打点刷屏，那么可以用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">desc Tbl/G;</span><br></pre></td></tr></table></figure>\n<p>表太多的话，我的场景是2000张表,:(</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SHOW TABLES LIKE &apos;%tb%&apos;;</span><br></pre></td></tr></table></figure>\n<p>####查询数据库的字符集</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show variables like &apos;%character%&apos;;</span><br></pre></td></tr></table></figure>\n<p>####指定字符集直连</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -h10.145.135.234 -uoss -pxxx dbName --default-character-set=gbk;</span><br></pre></td></tr></table></figure>\n<p>####赋予权限</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show grants for &apos;xxx&apos;@&apos;xxx.xxx.xxx.xxx&apos;</span><br></pre></td></tr></table></figure>\n<p>####如果想备份，或者复制表</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">create table newtb select * from oldtable</span><br></pre></td></tr></table></figure>\n<p>####修改表字段</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alter tbA modify fieldA int(11) unsigned default &apos;0&apos;</span><br></pre></td></tr></table></figure>\n<p>####移除字段</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alter table t2 drop column c;</span><br></pre></td></tr></table></figure>\n<p>####修改主键</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alter table tbA drop primary key;</span><br><span class=\"line\">Alter table tbA add primary key(dtStatDate,File2)</span><br></pre></td></tr></table></figure>\n<p>####查询当前数据库的查询进程,干掉挂起的query</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show processlist;</span><br><span class=\"line\">kill pid</span><br></pre></td></tr></table></figure>\n<p>####直接在shell外部命令行执行:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -h10.112.111.111 -uxxx -pxxxx dbname -Ns -e&quot;</span><br><span class=\"line\">select distinct(iUin) from TableA where dtEventTime &gt;= &apos;2013-05-05&apos; </span><br><span class=\"line\">&quot; &gt; records.txt;</span><br></pre></td></tr></table></figure>\n<h4 id=\"排除重复记录\"><a href=\"#排除重复记录\" class=\"headerlink\" title=\"排除重复记录\"></a>排除重复记录</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INSERT IGNORE into</span><br><span class=\"line\">Replace Into 是为了让主键替换原有的记录</span><br></pre></td></tr></table></figure>\n<p>####load data infile语句<br>从一个文本文件中以很高的速度读入一个表中。使用这个命令之前，mysqld进程（服务）必须已经在运行。为了安全原因，当读取位于服务器上的文本文件时，文件必须处于数据库目录或可被所有人读取。另外，为了对服务器上文件使用load data infile，在服务器主机上你必须有file的权限。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">load data infile &quot;/home/Order txt&quot; into table Orders(Order_Number, Order_Date, Customer_ID) terminated by&apos;,&apos;;</span><br></pre></td></tr></table></figure>\n<h4 id=\"mysqldump-中解决-报”Access-denied-for-user-when-using-LOCK-TABLES”\"><a href=\"#mysqldump-中解决-报”Access-denied-for-user-when-using-LOCK-TABLES”\" class=\"headerlink\" title=\"mysqldump 中解决 报”Access denied for user when using LOCK TABLES”\"></a>mysqldump 中解决 报”Access denied for user when using LOCK TABLES”</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysqldump -udbuser -p dbname --skip-lock-tables &gt; dbname.sql</span><br></pre></td></tr></table></figure>\n<p>####监控数据库磁盘增长量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">use information_schema;</span><br><span class=\"line\">#库的大小</span><br><span class=\"line\">select concat(round(sum(DATA_LENGTH/1024/1024),2),&apos;MB&apos;) as data  from TABLES where table_schema=&apos;db1&apos;;</span><br></pre></td></tr></table></figure>\n<p>####时间函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM_UNIXTIME(iLoginTime,&apos;%Y-%m-%d&apos;)</span><br><span class=\"line\">unix_timestamp(&apos;2013-12-03&apos;);</span><br><span class=\"line\">Date_SUB(OrderDate,INTERVAL 2 DAY)</span><br><span class=\"line\">Date_ADD(OrderDate,INTERVAL 2 DAY)</span><br><span class=\"line\">timestampdiff(week,’2009-01-24′,’2009-06-20′);</span><br></pre></td></tr></table></figure>\n<p>####no exist,having<br>适合做留存用户分析</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT distinct field1</span><br><span class=\"line\">FROM table a</span><br><span class=\"line\">where date &lt;= 20130430 and</span><br><span class=\"line\">not exists (</span><br><span class=\"line\">        SELECT field1 FROM table b where date&gt;=20130501 and a.field1=b.field1</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">#举例子,可以计算第一次创建用户的人</span><br><span class=\"line\">select * from TbRole having min(CreateTime) between &apos;xxx&apos; and &apos;xxx&apos;</span><br></pre></td></tr></table></figure>\n<p>####mysql 逻辑运算,好像在编程的样子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case condition1</span><br><span class=\"line\">when result1 then &apos;xx&apos;</span><br><span class=\"line\">when result2 then &apos;xx&apos;</span><br><span class=\"line\">else result1 then &apos;xx&apos;</span><br><span class=\"line\">end as &apos;xx&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">ifnull(a,b) #如果a不为空的情况下执行a,否则执行b</span><br><span class=\"line\">if(condition,a,b)#如果符合condition 执行a,否则执行b</span><br></pre></td></tr></table></figure>\n<p>####妙用group by<br>可以在group by 里面做逻辑运算, 缩小逻辑范围</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * From tableA group by (round(field1/100,0));</span><br></pre></td></tr></table></figure>\n<p>####格式化字符串类型</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">concat(&apos;a&apos;,&apos;b&apos;)</span><br></pre></td></tr></table></figure>\n<p>####mysql的临时变量‘@’<br>以下sql是取各道具排前10的等级</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * from (</span><br><span class=\"line\">    select dtStatDate,iRoleLevel,iUserNum,</span><br><span class=\"line\">    if(@templevel=a.iRoleLevel,@tno:=@tno+1,@tno:=1) as tno,@templevel:=a.iRoleLevel </span><br><span class=\"line\">    from tbl_a , (SELECT @tno:= 0,@templevel:=null) tbl_b</span><br><span class=\"line\">    order by a.iRoleLevel asc,a.iUserNum desc</span><br><span class=\"line\">) c</span><br><span class=\"line\">where tno&lt;=10 order by iRoleLevel asc</span><br></pre></td></tr></table></figure>\n<p>####其他<br>union all 效率会比union高,因为union有去重功能,会耗时 </p>\n"},{"layout":"post","title":"热更新","date":"2014-01-06T12:58:00.000Z","comments":1,"_content":"  Server 端程序很多时候需要修改配置，这个时候如果重启服务就显得很不友好，代价也高。Nginx和Django，采用的是平滑启动.自动热更新,折腾的东西中遇到这样一个诉求，用python实现的话:\n \n1. 当修改配置后,通过对比py的修改时间，来推断该模块是否被修改过,从而reload指定模块就可以在不重启服务的情况下读取修改的配置,\n2. sys.module['modname']返回的是该模块的pyc文件，而该文件是没有修改时间的，所以计算修改时间需要取py文件的属性\n\n```python\nimport time\nimport sys, os\ndef auto_reload():\n    mods = [\"test_config\"]\n    for mod in mods:\n        try:\n            module = sys.modules[mod]\n        except:\n            continue\n        filename = module.__file__\n        print filename\n        if filename.endswith(\".pyc\"):\n            filename = filename.replace(\".pyc\", \".py\")\n            mod_time = os.path.getmtime(filename)\n        if not \"loadtime\" in module.__dict__:\n            module.loadtime = 0 # first load's time  1*\n            try:\n                if mod_time > module.loadtime:\n                    reload(module)\n                except:\n                    pass\n        module.loadtime = mod_time # 2*\n\nif __name__ == \"__main__\":\n    import time\n    import my_config\n    tmp = None\n    while True:\n        auto_reload()\n        if test_config.address != tmp:\n        print test_config.address\n        tmp = test_config.address\n        time.sleep(2)\n```\n\ntest_config.py\n\n```\naddress = \"127.0.0.1\"\n```\n","source":"_posts/2014-01-06-re-geng-xin.markdown","raw":"---\nlayout: post\ntitle: \"热更新\"\ndate: 2014-01-06 20:58\ncomments: true\ncategories: Programe\n---\n  Server 端程序很多时候需要修改配置，这个时候如果重启服务就显得很不友好，代价也高。Nginx和Django，采用的是平滑启动.自动热更新,折腾的东西中遇到这样一个诉求，用python实现的话:\n \n1. 当修改配置后,通过对比py的修改时间，来推断该模块是否被修改过,从而reload指定模块就可以在不重启服务的情况下读取修改的配置,\n2. sys.module['modname']返回的是该模块的pyc文件，而该文件是没有修改时间的，所以计算修改时间需要取py文件的属性\n\n```python\nimport time\nimport sys, os\ndef auto_reload():\n    mods = [\"test_config\"]\n    for mod in mods:\n        try:\n            module = sys.modules[mod]\n        except:\n            continue\n        filename = module.__file__\n        print filename\n        if filename.endswith(\".pyc\"):\n            filename = filename.replace(\".pyc\", \".py\")\n            mod_time = os.path.getmtime(filename)\n        if not \"loadtime\" in module.__dict__:\n            module.loadtime = 0 # first load's time  1*\n            try:\n                if mod_time > module.loadtime:\n                    reload(module)\n                except:\n                    pass\n        module.loadtime = mod_time # 2*\n\nif __name__ == \"__main__\":\n    import time\n    import my_config\n    tmp = None\n    while True:\n        auto_reload()\n        if test_config.address != tmp:\n        print test_config.address\n        tmp = test_config.address\n        time.sleep(2)\n```\n\ntest_config.py\n\n```\naddress = \"127.0.0.1\"\n```\n","slug":"2014-01-06-re-geng-xin","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8x001pnctjb9e12thh","content":"<p>  Server 端程序很多时候需要修改配置，这个时候如果重启服务就显得很不友好，代价也高。Nginx和Django，采用的是平滑启动.自动热更新,折腾的东西中遇到这样一个诉求，用python实现的话:</p>\n<ol>\n<li>当修改配置后,通过对比py的修改时间，来推断该模块是否被修改过,从而reload指定模块就可以在不重启服务的情况下读取修改的配置,</li>\n<li>sys.module[‘modname’]返回的是该模块的pyc文件，而该文件是没有修改时间的，所以计算修改时间需要取py文件的属性</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys, os</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">auto_reload</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    mods = [<span class=\"string\">\"test_config\"</span>]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> mod <span class=\"keyword\">in</span> mods:</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            module = sys.modules[mod]</span><br><span class=\"line\">        <span class=\"keyword\">except</span>:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        filename = module.__file__</span><br><span class=\"line\">        <span class=\"keyword\">print</span> filename</span><br><span class=\"line\">        <span class=\"keyword\">if</span> filename.endswith(<span class=\"string\">\".pyc\"</span>):</span><br><span class=\"line\">            filename = filename.replace(<span class=\"string\">\".pyc\"</span>, <span class=\"string\">\".py\"</span>)</span><br><span class=\"line\">            mod_time = os.path.getmtime(filename)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"string\">\"loadtime\"</span> <span class=\"keyword\">in</span> module.__dict__:</span><br><span class=\"line\">            module.loadtime = <span class=\"number\">0</span> <span class=\"comment\"># first load's time  1*</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> mod_time &gt; module.loadtime:</span><br><span class=\"line\">                    reload(module)</span><br><span class=\"line\">                <span class=\"keyword\">except</span>:</span><br><span class=\"line\">                    <span class=\"keyword\">pass</span></span><br><span class=\"line\">        module.loadtime = mod_time <span class=\"comment\"># 2*</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    <span class=\"keyword\">import</span> time</span><br><span class=\"line\">    <span class=\"keyword\">import</span> my_config</span><br><span class=\"line\">    tmp = <span class=\"keyword\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        auto_reload()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> test_config.address != tmp:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> test_config.address</span><br><span class=\"line\">        tmp = test_config.address</span><br><span class=\"line\">        time.sleep(<span class=\"number\">2</span>)</span><br></pre></td></tr></table></figure>\n<p>test_config.py</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">address = &quot;127.0.0.1&quot;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>  Server 端程序很多时候需要修改配置，这个时候如果重启服务就显得很不友好，代价也高。Nginx和Django，采用的是平滑启动.自动热更新,折腾的东西中遇到这样一个诉求，用python实现的话:</p>\n<ol>\n<li>当修改配置后,通过对比py的修改时间，来推断该模块是否被修改过,从而reload指定模块就可以在不重启服务的情况下读取修改的配置,</li>\n<li>sys.module[‘modname’]返回的是该模块的pyc文件，而该文件是没有修改时间的，所以计算修改时间需要取py文件的属性</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys, os</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">auto_reload</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    mods = [<span class=\"string\">\"test_config\"</span>]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> mod <span class=\"keyword\">in</span> mods:</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            module = sys.modules[mod]</span><br><span class=\"line\">        <span class=\"keyword\">except</span>:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        filename = module.__file__</span><br><span class=\"line\">        <span class=\"keyword\">print</span> filename</span><br><span class=\"line\">        <span class=\"keyword\">if</span> filename.endswith(<span class=\"string\">\".pyc\"</span>):</span><br><span class=\"line\">            filename = filename.replace(<span class=\"string\">\".pyc\"</span>, <span class=\"string\">\".py\"</span>)</span><br><span class=\"line\">            mod_time = os.path.getmtime(filename)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"string\">\"loadtime\"</span> <span class=\"keyword\">in</span> module.__dict__:</span><br><span class=\"line\">            module.loadtime = <span class=\"number\">0</span> <span class=\"comment\"># first load's time  1*</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span>:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> mod_time &gt; module.loadtime:</span><br><span class=\"line\">                    reload(module)</span><br><span class=\"line\">                <span class=\"keyword\">except</span>:</span><br><span class=\"line\">                    <span class=\"keyword\">pass</span></span><br><span class=\"line\">        module.loadtime = mod_time <span class=\"comment\"># 2*</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    <span class=\"keyword\">import</span> time</span><br><span class=\"line\">    <span class=\"keyword\">import</span> my_config</span><br><span class=\"line\">    tmp = <span class=\"keyword\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">        auto_reload()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> test_config.address != tmp:</span><br><span class=\"line\">        <span class=\"keyword\">print</span> test_config.address</span><br><span class=\"line\">        tmp = test_config.address</span><br><span class=\"line\">        time.sleep(<span class=\"number\">2</span>)</span><br></pre></td></tr></table></figure>\n<p>test_config.py</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">address = &quot;127.0.0.1&quot;</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"遇见","date":"2013-12-21T08:16:00.000Z","comments":1,"_content":"\n昨晚参加腾讯周年晚会,同事在YY今晚的明星是孙燕姿,可惜最后没有如他所愿\"遇见\"女神.当晚应邀表演的是同为15周年生日的羽泉.对于从来没有参加过大型演唱会的小白来说,人生又圆满了一点。\n\n在见到 ponyMa 等人时我并没有兴奋。反而是深居简入的 AllenZhang 张小龙,让我小激动了一把,大学时起对这样的孤胆极客有神秘的敬仰.张小龙很少在公众媒体前曝光,留给外界的事迹大概是单挑 foxmail,QQmail 之父,缔造微信神话,产品哲学大师。 这样一位爱在深夜听摇滚,烟瘾十足的中年老男人,看上去依然有很浓的技术宅风格,开玩笑时略显不自然的腼腆.微微的驼背。 越是神秘,外界越会过度解读。小龙哥说希望未来可以让大家去\"月球上打飞机\"... 我虽然坐在内场,但是终究是靠后,只好通过屏幕看清楚的.曾经在南方通讯大厦的期待见到却没能见到的人此时出现了, 低调的风格有深深的内涵。\n\n{% img /images/2013/12/Allen.jpg %}\n\n话说回来,同事虽然没有如愿听到孙燕姿,我却貌似被条件反射地提醒,浮现在脑海的是《遇见》,回来之后凭着某种鸡血,开始搜索曲子练习,在写这篇文章的时候, 可以弹出来。连续五个周末加班，突然可以自己安排时间,甚是知足。弹起琴的时候会忘掉很多东西。工作的事情依旧例行化,比较杂比较琐碎,出于责任心和对心境的自我锻炼(至少我是如此认为),内心有两种声音:\n\n+ 年轻人要有一种吃苦的态度,对于工作的事情不要挑三拣四\n+ 年轻人应该勇敢去追求自己想要的东西,很明显我们愿意追求真善美与理想\n\n对于前者,践行后发觉职场的厚黑学,日子过得很忙很累,收获是有的。迷茫的是,收获的东西可能不是你的初心,会怀疑是否有意义,往往抗拒的时候,是凭着意志去承受。\n\n对于后者,除了幸运到一定的程度才可能在中国实现吧,于是成为很多人的向往。 可以看到不少倔强的人没有放弃，因为有着的这样的情怀,所以不少人会对 Allen 这样的人物很敬仰,同样的还有云风.韩寒\n\n{% img /images/2013/12/gitar.jpg %}\n\n我们以某种莫名的执着与生活妥协着,却期待现实与理想可以在某个点遇见彼此。我试着用这种方式写下这篇碎语,不知道你们看懂了么？\n","source":"_posts/2013-12-21-yu-jian.markdown","raw":"---\nlayout: post\ntitle: \"遇见\"\ndate: 2013-12-21 16:16\ncomments: true\ncategories: Life\n---\n\n昨晚参加腾讯周年晚会,同事在YY今晚的明星是孙燕姿,可惜最后没有如他所愿\"遇见\"女神.当晚应邀表演的是同为15周年生日的羽泉.对于从来没有参加过大型演唱会的小白来说,人生又圆满了一点。\n\n在见到 ponyMa 等人时我并没有兴奋。反而是深居简入的 AllenZhang 张小龙,让我小激动了一把,大学时起对这样的孤胆极客有神秘的敬仰.张小龙很少在公众媒体前曝光,留给外界的事迹大概是单挑 foxmail,QQmail 之父,缔造微信神话,产品哲学大师。 这样一位爱在深夜听摇滚,烟瘾十足的中年老男人,看上去依然有很浓的技术宅风格,开玩笑时略显不自然的腼腆.微微的驼背。 越是神秘,外界越会过度解读。小龙哥说希望未来可以让大家去\"月球上打飞机\"... 我虽然坐在内场,但是终究是靠后,只好通过屏幕看清楚的.曾经在南方通讯大厦的期待见到却没能见到的人此时出现了, 低调的风格有深深的内涵。\n\n{% img /images/2013/12/Allen.jpg %}\n\n话说回来,同事虽然没有如愿听到孙燕姿,我却貌似被条件反射地提醒,浮现在脑海的是《遇见》,回来之后凭着某种鸡血,开始搜索曲子练习,在写这篇文章的时候, 可以弹出来。连续五个周末加班，突然可以自己安排时间,甚是知足。弹起琴的时候会忘掉很多东西。工作的事情依旧例行化,比较杂比较琐碎,出于责任心和对心境的自我锻炼(至少我是如此认为),内心有两种声音:\n\n+ 年轻人要有一种吃苦的态度,对于工作的事情不要挑三拣四\n+ 年轻人应该勇敢去追求自己想要的东西,很明显我们愿意追求真善美与理想\n\n对于前者,践行后发觉职场的厚黑学,日子过得很忙很累,收获是有的。迷茫的是,收获的东西可能不是你的初心,会怀疑是否有意义,往往抗拒的时候,是凭着意志去承受。\n\n对于后者,除了幸运到一定的程度才可能在中国实现吧,于是成为很多人的向往。 可以看到不少倔强的人没有放弃，因为有着的这样的情怀,所以不少人会对 Allen 这样的人物很敬仰,同样的还有云风.韩寒\n\n{% img /images/2013/12/gitar.jpg %}\n\n我们以某种莫名的执着与生活妥协着,却期待现实与理想可以在某个点遇见彼此。我试着用这种方式写下这篇碎语,不知道你们看懂了么？\n","slug":"2013-12-21-yu-jian","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8y001rnctjn2amejrr","content":"<p>昨晚参加腾讯周年晚会,同事在YY今晚的明星是孙燕姿,可惜最后没有如他所愿”遇见”女神.当晚应邀表演的是同为15周年生日的羽泉.对于从来没有参加过大型演唱会的小白来说,人生又圆满了一点。</p>\n<p>在见到 ponyMa 等人时我并没有兴奋。反而是深居简入的 AllenZhang 张小龙,让我小激动了一把,大学时起对这样的孤胆极客有神秘的敬仰.张小龙很少在公众媒体前曝光,留给外界的事迹大概是单挑 foxmail,QQmail 之父,缔造微信神话,产品哲学大师。 这样一位爱在深夜听摇滚,烟瘾十足的中年老男人,看上去依然有很浓的技术宅风格,开玩笑时略显不自然的腼腆.微微的驼背。 越是神秘,外界越会过度解读。小龙哥说希望未来可以让大家去”月球上打飞机”… 我虽然坐在内场,但是终究是靠后,只好通过屏幕看清楚的.曾经在南方通讯大厦的期待见到却没能见到的人此时出现了, 低调的风格有深深的内涵。</p>\n<img src=\"/images/2013/12/Allen.jpg\">\n<p>话说回来,同事虽然没有如愿听到孙燕姿,我却貌似被条件反射地提醒,浮现在脑海的是《遇见》,回来之后凭着某种鸡血,开始搜索曲子练习,在写这篇文章的时候, 可以弹出来。连续五个周末加班，突然可以自己安排时间,甚是知足。弹起琴的时候会忘掉很多东西。工作的事情依旧例行化,比较杂比较琐碎,出于责任心和对心境的自我锻炼(至少我是如此认为),内心有两种声音:</p>\n<ul>\n<li>年轻人要有一种吃苦的态度,对于工作的事情不要挑三拣四</li>\n<li>年轻人应该勇敢去追求自己想要的东西,很明显我们愿意追求真善美与理想</li>\n</ul>\n<p>对于前者,践行后发觉职场的厚黑学,日子过得很忙很累,收获是有的。迷茫的是,收获的东西可能不是你的初心,会怀疑是否有意义,往往抗拒的时候,是凭着意志去承受。</p>\n<p>对于后者,除了幸运到一定的程度才可能在中国实现吧,于是成为很多人的向往。 可以看到不少倔强的人没有放弃，因为有着的这样的情怀,所以不少人会对 Allen 这样的人物很敬仰,同样的还有云风.韩寒</p>\n<img src=\"/images/2013/12/gitar.jpg\">\n<p>我们以某种莫名的执着与生活妥协着,却期待现实与理想可以在某个点遇见彼此。我试着用这种方式写下这篇碎语,不知道你们看懂了么？</p>\n","site":{"data":{}},"excerpt":"","more":"<p>昨晚参加腾讯周年晚会,同事在YY今晚的明星是孙燕姿,可惜最后没有如他所愿”遇见”女神.当晚应邀表演的是同为15周年生日的羽泉.对于从来没有参加过大型演唱会的小白来说,人生又圆满了一点。</p>\n<p>在见到 ponyMa 等人时我并没有兴奋。反而是深居简入的 AllenZhang 张小龙,让我小激动了一把,大学时起对这样的孤胆极客有神秘的敬仰.张小龙很少在公众媒体前曝光,留给外界的事迹大概是单挑 foxmail,QQmail 之父,缔造微信神话,产品哲学大师。 这样一位爱在深夜听摇滚,烟瘾十足的中年老男人,看上去依然有很浓的技术宅风格,开玩笑时略显不自然的腼腆.微微的驼背。 越是神秘,外界越会过度解读。小龙哥说希望未来可以让大家去”月球上打飞机”… 我虽然坐在内场,但是终究是靠后,只好通过屏幕看清楚的.曾经在南方通讯大厦的期待见到却没能见到的人此时出现了, 低调的风格有深深的内涵。</p>\n<img src=\"/images/2013/12/Allen.jpg\">\n<p>话说回来,同事虽然没有如愿听到孙燕姿,我却貌似被条件反射地提醒,浮现在脑海的是《遇见》,回来之后凭着某种鸡血,开始搜索曲子练习,在写这篇文章的时候, 可以弹出来。连续五个周末加班，突然可以自己安排时间,甚是知足。弹起琴的时候会忘掉很多东西。工作的事情依旧例行化,比较杂比较琐碎,出于责任心和对心境的自我锻炼(至少我是如此认为),内心有两种声音:</p>\n<ul>\n<li>年轻人要有一种吃苦的态度,对于工作的事情不要挑三拣四</li>\n<li>年轻人应该勇敢去追求自己想要的东西,很明显我们愿意追求真善美与理想</li>\n</ul>\n<p>对于前者,践行后发觉职场的厚黑学,日子过得很忙很累,收获是有的。迷茫的是,收获的东西可能不是你的初心,会怀疑是否有意义,往往抗拒的时候,是凭着意志去承受。</p>\n<p>对于后者,除了幸运到一定的程度才可能在中国实现吧,于是成为很多人的向往。 可以看到不少倔强的人没有放弃，因为有着的这样的情怀,所以不少人会对 Allen 这样的人物很敬仰,同样的还有云风.韩寒</p>\n<img src=\"/images/2013/12/gitar.jpg\">\n<p>我们以某种莫名的执着与生活妥协着,却期待现实与理想可以在某个点遇见彼此。我试着用这种方式写下这篇碎语,不知道你们看懂了么？</p>\n"},{"layout":"post","title":"微信公众号开发","date":"2014-01-07T10:47:00.000Z","comments":1,"keywords":"微信公众号开发","description":"微信公众号开发","_content":"### 微信公众账号开发\n\n话说2013年的最后几分钟和2014的最开始几分钟我都是献给这货的.BTW,纯属个人折腾\n> 人生苦短,我爱python\n\n至于做的具体东西就在此略过了,以下是截图.主要是分享开发过程中的经验,我的代码是部署在自己的VPS上面\n\n{% img /images/2013/12/nba.jpg %}\n\n现在注册一个微信的服务号的成本很高了,一次人工审批不过的话就需要300元, 我用的是微信公众平台测试号.只要填写手机号和验证码。其限制条件是,只能有20个订阅粉丝.没关系,我要的是调通整个通讯以及业务化定制.\n\n#####注册\n会给你一个 `APPID`, `APPSeceret`,这个步骤需要你填写自己 Server 的 URL,以及填写 `TOKEN`,这些是未来完成通讯的许可证明\n\n#####微信认证\nServer 端应该对每个请求进行验证，确认是来自微信服务器的请求才做出相应\n\n加密/校验流程如下：\n\n* 将 `token`、`timestamp`、`nonce` 三个参数进行字典序排序\n* 将三个参数字符串拼接成一个字符串进行sha1加密\n* 开发者获得加密后的字符串可与 `signature` 对比，标识该请求来源于微信\n\n```python\nclass BaseHandler(tornado.web.RequestHandler):\n    #基类,实现基本认证，子类只需要继承就可以完成微信认证\n    def prepare(self):\n        timestamp = self.get_argument(\"timestamp\", None)\n        nonce = self.get_argument(\"nonce\", None)\n        signature = self.get_argument(\"signature\", None)\n        print 'request:', timestamp, nonce, signature\n        print self.request.method, timestamp, nonce, signature\n        if validate(timestamp, nonce, signature) is False:\n            print \"=========validate failed =====\"\n            self.finish()\n\ndef validate(timestamp, nonce, signature):\n    print 'validate:', timestamp, nonce, signature\n    if timestamp is None or nonce is None or signature is None:\n        return False\n    tmp = [TOKEN, timestamp, nonce]\n    tmp = sorted(tmparr)\n    tmpStr = ''.join(tmp)\n    hashStr = sha1(tmpStr).hexdigest()\n    return (hashStr == signature)\n```\n\n验证成功之后，才能进入业务逻辑,当我们在微信公众号填写自己服务的URL的时候，weixin会向该URL发起Get请求.做为首次验证,根据文档，需要将接收到的字符串原文返回\n\n```\nclass serverHandler(BaseHandler):\n    def get(self):\n        echostr = self.get_argument('echostr', None)\n        self.write(echostr)\n``` \n\n\n#####. 菜单订制\n 为了支持微信通信过程中不允许使用\"/u\" 字符编码，这里用到了tornado的render_string,一开始我是直接生成一个json.dump(menu)然后post过去,但一直存在编码问题， 使用render_string就解决了。感谢@ihao提醒\n\n```\nclass UIHandler(tornado.web.RequestHandler):\n    def get(self):\n        msg = self.render_string('menu.json')\n        createMenu(menu)\n```\n\n\n#####. 响应用户按键输入\n\n```\nxml = uni(self.request.body)        #获取微信服务器发送过来的xml,转化为unicode\ndic = xml2dict(xml)                 #将xml解析成dict\nif dic['MsgType'].lower() == 'event':\n    event = dic['Event'].lower()\n    if event == 'subscribe':\n        ctx = do_subscribe(dic)     #订阅逻辑\n        msg = self.render_string('text_resp.xml', dic=ctx)\n        self.write(msg)\n    elif event == 'click':\n        ctx = do_click(dic)         #点击逻辑\n        msg = self.render_string('text_resp.xml', dic=ctx)\n        self.write(msg)\n```\n\nself.write(msg)是将要发给用户的信息返回给微信服务器，之后微信服务器会将信息发送给用户\n\n\n#### 相关链接\n- [开发者文档](http://mp.weixin.qq.com/wiki/index.php)\n- [接口调试](http://mp.weixin.qq.com/debug/)\n\n\n#### 开发中用到的库\n- `tornado`\n- `virtualenv`\n- `pyquery(做爬虫)`\n- `pymongo`\n- `lxml`\n- `urllib2`\n\n\n","source":"_posts/2014-01-07-wei-xin-gong-zhong-hao-kai-fa.markdown","raw":"---\nlayout: post\ntitle: \"微信公众号开发\"\ndate: 2014-01-07 18:47\ncomments: true\ncategories: Server Product\nkeywords: 微信公众号开发\ndescription: 微信公众号开发 \n---\n### 微信公众账号开发\n\n话说2013年的最后几分钟和2014的最开始几分钟我都是献给这货的.BTW,纯属个人折腾\n> 人生苦短,我爱python\n\n至于做的具体东西就在此略过了,以下是截图.主要是分享开发过程中的经验,我的代码是部署在自己的VPS上面\n\n{% img /images/2013/12/nba.jpg %}\n\n现在注册一个微信的服务号的成本很高了,一次人工审批不过的话就需要300元, 我用的是微信公众平台测试号.只要填写手机号和验证码。其限制条件是,只能有20个订阅粉丝.没关系,我要的是调通整个通讯以及业务化定制.\n\n#####注册\n会给你一个 `APPID`, `APPSeceret`,这个步骤需要你填写自己 Server 的 URL,以及填写 `TOKEN`,这些是未来完成通讯的许可证明\n\n#####微信认证\nServer 端应该对每个请求进行验证，确认是来自微信服务器的请求才做出相应\n\n加密/校验流程如下：\n\n* 将 `token`、`timestamp`、`nonce` 三个参数进行字典序排序\n* 将三个参数字符串拼接成一个字符串进行sha1加密\n* 开发者获得加密后的字符串可与 `signature` 对比，标识该请求来源于微信\n\n```python\nclass BaseHandler(tornado.web.RequestHandler):\n    #基类,实现基本认证，子类只需要继承就可以完成微信认证\n    def prepare(self):\n        timestamp = self.get_argument(\"timestamp\", None)\n        nonce = self.get_argument(\"nonce\", None)\n        signature = self.get_argument(\"signature\", None)\n        print 'request:', timestamp, nonce, signature\n        print self.request.method, timestamp, nonce, signature\n        if validate(timestamp, nonce, signature) is False:\n            print \"=========validate failed =====\"\n            self.finish()\n\ndef validate(timestamp, nonce, signature):\n    print 'validate:', timestamp, nonce, signature\n    if timestamp is None or nonce is None or signature is None:\n        return False\n    tmp = [TOKEN, timestamp, nonce]\n    tmp = sorted(tmparr)\n    tmpStr = ''.join(tmp)\n    hashStr = sha1(tmpStr).hexdigest()\n    return (hashStr == signature)\n```\n\n验证成功之后，才能进入业务逻辑,当我们在微信公众号填写自己服务的URL的时候，weixin会向该URL发起Get请求.做为首次验证,根据文档，需要将接收到的字符串原文返回\n\n```\nclass serverHandler(BaseHandler):\n    def get(self):\n        echostr = self.get_argument('echostr', None)\n        self.write(echostr)\n``` \n\n\n#####. 菜单订制\n 为了支持微信通信过程中不允许使用\"/u\" 字符编码，这里用到了tornado的render_string,一开始我是直接生成一个json.dump(menu)然后post过去,但一直存在编码问题， 使用render_string就解决了。感谢@ihao提醒\n\n```\nclass UIHandler(tornado.web.RequestHandler):\n    def get(self):\n        msg = self.render_string('menu.json')\n        createMenu(menu)\n```\n\n\n#####. 响应用户按键输入\n\n```\nxml = uni(self.request.body)        #获取微信服务器发送过来的xml,转化为unicode\ndic = xml2dict(xml)                 #将xml解析成dict\nif dic['MsgType'].lower() == 'event':\n    event = dic['Event'].lower()\n    if event == 'subscribe':\n        ctx = do_subscribe(dic)     #订阅逻辑\n        msg = self.render_string('text_resp.xml', dic=ctx)\n        self.write(msg)\n    elif event == 'click':\n        ctx = do_click(dic)         #点击逻辑\n        msg = self.render_string('text_resp.xml', dic=ctx)\n        self.write(msg)\n```\n\nself.write(msg)是将要发给用户的信息返回给微信服务器，之后微信服务器会将信息发送给用户\n\n\n#### 相关链接\n- [开发者文档](http://mp.weixin.qq.com/wiki/index.php)\n- [接口调试](http://mp.weixin.qq.com/debug/)\n\n\n#### 开发中用到的库\n- `tornado`\n- `virtualenv`\n- `pyquery(做爬虫)`\n- `pymongo`\n- `lxml`\n- `urllib2`\n\n\n","slug":"2014-01-07-wei-xin-gong-zhong-hao-kai-fa","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd8z001tnctj2wqpazlh","content":"<h3 id=\"微信公众账号开发\"><a href=\"#微信公众账号开发\" class=\"headerlink\" title=\"微信公众账号开发\"></a>微信公众账号开发</h3><p>话说2013年的最后几分钟和2014的最开始几分钟我都是献给这货的.BTW,纯属个人折腾</p>\n<blockquote>\n<p>人生苦短,我爱python</p>\n</blockquote>\n<p>至于做的具体东西就在此略过了,以下是截图.主要是分享开发过程中的经验,我的代码是部署在自己的VPS上面</p>\n<img src=\"/images/2013/12/nba.jpg\">\n<p>现在注册一个微信的服务号的成本很高了,一次人工审批不过的话就需要300元, 我用的是微信公众平台测试号.只要填写手机号和验证码。其限制条件是,只能有20个订阅粉丝.没关系,我要的是调通整个通讯以及业务化定制.</p>\n<p>#####注册<br>会给你一个 <code>APPID</code>, <code>APPSeceret</code>,这个步骤需要你填写自己 Server 的 URL,以及填写 <code>TOKEN</code>,这些是未来完成通讯的许可证明</p>\n<p>#####微信认证<br>Server 端应该对每个请求进行验证，确认是来自微信服务器的请求才做出相应</p>\n<p>加密/校验流程如下：</p>\n<ul>\n<li>将 <code>token</code>、<code>timestamp</code>、<code>nonce</code> 三个参数进行字典序排序</li>\n<li>将三个参数字符串拼接成一个字符串进行sha1加密</li>\n<li>开发者获得加密后的字符串可与 <code>signature</code> 对比，标识该请求来源于微信</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BaseHandler</span><span class=\"params\">(tornado.web.RequestHandler)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\">#基类,实现基本认证，子类只需要继承就可以完成微信认证</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">prepare</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        timestamp = self.get_argument(<span class=\"string\">\"timestamp\"</span>, <span class=\"keyword\">None</span>)</span><br><span class=\"line\">        nonce = self.get_argument(<span class=\"string\">\"nonce\"</span>, <span class=\"keyword\">None</span>)</span><br><span class=\"line\">        signature = self.get_argument(<span class=\"string\">\"signature\"</span>, <span class=\"keyword\">None</span>)</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'request:'</span>, timestamp, nonce, signature</span><br><span class=\"line\">        <span class=\"keyword\">print</span> self.request.method, timestamp, nonce, signature</span><br><span class=\"line\">        <span class=\"keyword\">if</span> validate(timestamp, nonce, signature) <span class=\"keyword\">is</span> <span class=\"keyword\">False</span>:</span><br><span class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">\"=========validate failed =====\"</span></span><br><span class=\"line\">            self.finish()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">validate</span><span class=\"params\">(timestamp, nonce, signature)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'validate:'</span>, timestamp, nonce, signature</span><br><span class=\"line\">    <span class=\"keyword\">if</span> timestamp <span class=\"keyword\">is</span> <span class=\"keyword\">None</span> <span class=\"keyword\">or</span> nonce <span class=\"keyword\">is</span> <span class=\"keyword\">None</span> <span class=\"keyword\">or</span> signature <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\">    tmp = [TOKEN, timestamp, nonce]</span><br><span class=\"line\">    tmp = sorted(tmparr)</span><br><span class=\"line\">    tmpStr = <span class=\"string\">''</span>.join(tmp)</span><br><span class=\"line\">    hashStr = sha1(tmpStr).hexdigest()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (hashStr == signature)</span><br></pre></td></tr></table></figure>\n<p>验证成功之后，才能进入业务逻辑,当我们在微信公众号填写自己服务的URL的时候，weixin会向该URL发起Get请求.做为首次验证,根据文档，需要将接收到的字符串原文返回</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class serverHandler(BaseHandler):</span><br><span class=\"line\">    def get(self):</span><br><span class=\"line\">        echostr = self.get_argument(&apos;echostr&apos;, None)</span><br><span class=\"line\">        self.write(echostr)</span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#####. 菜单订制</span><br><span class=\"line\"> 为了支持微信通信过程中不允许使用&quot;/u&quot; 字符编码，这里用到了tornado的render_string,一开始我是直接生成一个json.dump(menu)然后post过去,但一直存在编码问题， 使用render_string就解决了。感谢@ihao提醒</span><br></pre></td></tr></table></figure>\n<p>class UIHandler(tornado.web.RequestHandler):<br>    def get(self):<br>        msg = self.render_string(‘menu.json’)<br>        createMenu(menu)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#####. 响应用户按键输入</span><br></pre></td></tr></table></figure></p>\n<p>xml = uni(self.request.body)        #获取微信服务器发送过来的xml,转化为unicode<br>dic = xml2dict(xml)                 #将xml解析成dict<br>if dic[‘MsgType’].lower() == ‘event’:<br>    event = dic[‘Event’].lower()<br>    if event == ‘subscribe’:<br>        ctx = do_subscribe(dic)     #订阅逻辑<br>        msg = self.render_string(‘text_resp.xml’, dic=ctx)<br>        self.write(msg)<br>    elif event == ‘click’:<br>        ctx = do_click(dic)         #点击逻辑<br>        msg = self.render_string(‘text_resp.xml’, dic=ctx)<br>        self.write(msg)<br><code>`</code></p>\n<p>self.write(msg)是将要发给用户的信息返回给微信服务器，之后微信服务器会将信息发送给用户</p>\n<h4 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h4><ul>\n<li><a href=\"http://mp.weixin.qq.com/wiki/index.php\" target=\"_blank\" rel=\"noopener\">开发者文档</a></li>\n<li><a href=\"http://mp.weixin.qq.com/debug/\" target=\"_blank\" rel=\"noopener\">接口调试</a></li>\n</ul>\n<h4 id=\"开发中用到的库\"><a href=\"#开发中用到的库\" class=\"headerlink\" title=\"开发中用到的库\"></a>开发中用到的库</h4><ul>\n<li><code>tornado</code></li>\n<li><code>virtualenv</code></li>\n<li><code>pyquery(做爬虫)</code></li>\n<li><code>pymongo</code></li>\n<li><code>lxml</code></li>\n<li><code>urllib2</code></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"微信公众账号开发\"><a href=\"#微信公众账号开发\" class=\"headerlink\" title=\"微信公众账号开发\"></a>微信公众账号开发</h3><p>话说2013年的最后几分钟和2014的最开始几分钟我都是献给这货的.BTW,纯属个人折腾</p>\n<blockquote>\n<p>人生苦短,我爱python</p>\n</blockquote>\n<p>至于做的具体东西就在此略过了,以下是截图.主要是分享开发过程中的经验,我的代码是部署在自己的VPS上面</p>\n<img src=\"/images/2013/12/nba.jpg\">\n<p>现在注册一个微信的服务号的成本很高了,一次人工审批不过的话就需要300元, 我用的是微信公众平台测试号.只要填写手机号和验证码。其限制条件是,只能有20个订阅粉丝.没关系,我要的是调通整个通讯以及业务化定制.</p>\n<p>#####注册<br>会给你一个 <code>APPID</code>, <code>APPSeceret</code>,这个步骤需要你填写自己 Server 的 URL,以及填写 <code>TOKEN</code>,这些是未来完成通讯的许可证明</p>\n<p>#####微信认证<br>Server 端应该对每个请求进行验证，确认是来自微信服务器的请求才做出相应</p>\n<p>加密/校验流程如下：</p>\n<ul>\n<li>将 <code>token</code>、<code>timestamp</code>、<code>nonce</code> 三个参数进行字典序排序</li>\n<li>将三个参数字符串拼接成一个字符串进行sha1加密</li>\n<li>开发者获得加密后的字符串可与 <code>signature</code> 对比，标识该请求来源于微信</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BaseHandler</span><span class=\"params\">(tornado.web.RequestHandler)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\">#基类,实现基本认证，子类只需要继承就可以完成微信认证</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">prepare</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        timestamp = self.get_argument(<span class=\"string\">\"timestamp\"</span>, <span class=\"keyword\">None</span>)</span><br><span class=\"line\">        nonce = self.get_argument(<span class=\"string\">\"nonce\"</span>, <span class=\"keyword\">None</span>)</span><br><span class=\"line\">        signature = self.get_argument(<span class=\"string\">\"signature\"</span>, <span class=\"keyword\">None</span>)</span><br><span class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'request:'</span>, timestamp, nonce, signature</span><br><span class=\"line\">        <span class=\"keyword\">print</span> self.request.method, timestamp, nonce, signature</span><br><span class=\"line\">        <span class=\"keyword\">if</span> validate(timestamp, nonce, signature) <span class=\"keyword\">is</span> <span class=\"keyword\">False</span>:</span><br><span class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">\"=========validate failed =====\"</span></span><br><span class=\"line\">            self.finish()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">validate</span><span class=\"params\">(timestamp, nonce, signature)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'validate:'</span>, timestamp, nonce, signature</span><br><span class=\"line\">    <span class=\"keyword\">if</span> timestamp <span class=\"keyword\">is</span> <span class=\"keyword\">None</span> <span class=\"keyword\">or</span> nonce <span class=\"keyword\">is</span> <span class=\"keyword\">None</span> <span class=\"keyword\">or</span> signature <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">False</span></span><br><span class=\"line\">    tmp = [TOKEN, timestamp, nonce]</span><br><span class=\"line\">    tmp = sorted(tmparr)</span><br><span class=\"line\">    tmpStr = <span class=\"string\">''</span>.join(tmp)</span><br><span class=\"line\">    hashStr = sha1(tmpStr).hexdigest()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (hashStr == signature)</span><br></pre></td></tr></table></figure>\n<p>验证成功之后，才能进入业务逻辑,当我们在微信公众号填写自己服务的URL的时候，weixin会向该URL发起Get请求.做为首次验证,根据文档，需要将接收到的字符串原文返回</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class serverHandler(BaseHandler):</span><br><span class=\"line\">    def get(self):</span><br><span class=\"line\">        echostr = self.get_argument(&apos;echostr&apos;, None)</span><br><span class=\"line\">        self.write(echostr)</span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#####. 菜单订制</span><br><span class=\"line\"> 为了支持微信通信过程中不允许使用&quot;/u&quot; 字符编码，这里用到了tornado的render_string,一开始我是直接生成一个json.dump(menu)然后post过去,但一直存在编码问题， 使用render_string就解决了。感谢@ihao提醒</span><br></pre></td></tr></table></figure>\n<p>class UIHandler(tornado.web.RequestHandler):<br>    def get(self):<br>        msg = self.render_string(‘menu.json’)<br>        createMenu(menu)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">#####. 响应用户按键输入</span><br></pre></td></tr></table></figure></p>\n<p>xml = uni(self.request.body)        #获取微信服务器发送过来的xml,转化为unicode<br>dic = xml2dict(xml)                 #将xml解析成dict<br>if dic[‘MsgType’].lower() == ‘event’:<br>    event = dic[‘Event’].lower()<br>    if event == ‘subscribe’:<br>        ctx = do_subscribe(dic)     #订阅逻辑<br>        msg = self.render_string(‘text_resp.xml’, dic=ctx)<br>        self.write(msg)<br>    elif event == ‘click’:<br>        ctx = do_click(dic)         #点击逻辑<br>        msg = self.render_string(‘text_resp.xml’, dic=ctx)<br>        self.write(msg)<br><code>`</code></p>\n<p>self.write(msg)是将要发给用户的信息返回给微信服务器，之后微信服务器会将信息发送给用户</p>\n<h4 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h4><ul>\n<li><a href=\"http://mp.weixin.qq.com/wiki/index.php\" target=\"_blank\" rel=\"noopener\">开发者文档</a></li>\n<li><a href=\"http://mp.weixin.qq.com/debug/\" target=\"_blank\" rel=\"noopener\">接口调试</a></li>\n</ul>\n<h4 id=\"开发中用到的库\"><a href=\"#开发中用到的库\" class=\"headerlink\" title=\"开发中用到的库\"></a>开发中用到的库</h4><ul>\n<li><code>tornado</code></li>\n<li><code>virtualenv</code></li>\n<li><code>pyquery(做爬虫)</code></li>\n<li><code>pymongo</code></li>\n<li><code>lxml</code></li>\n<li><code>urllib2</code></li>\n</ul>\n"},{"layout":"post","title":"Rework书摘","date":"2014-01-24T14:31:00.000Z","comments":1,"keywords":"Rework","description":"Rework 书评","_content":"\n读到ReWork这本久负盛名的书了。摘录了鄙人认为深刻的话语。\n\n{% img /images/2014/01/rework.jpg %}\n\n很多话有道理，但是我们见到的只有很少人真的会去做，至少是去刻意克服惰性和思维方式.\n\n该书是由37signal 这个创造了很多精品的公司著作的。有很强的现实指导意义，以下摘自《rework》\n\n* 谈到现实\n\n> 撕开这个“现实世界”的遮羞布后，你会发现栖居其中的人们都充满着悲观和绝望的情绪。他们期待看到新概念被斩落马下，他们认为这个社会还没有准备好迎接变革，也无力引发变革.不要相信他们。这个世界对于他们来说可能是“现实”的，但并不意味着你也要生活在这样的“现实”世界中。\n\n* 谈到抱怨\n\n>条件受限是好事 ，因此，在你高唱“始终不够”的悲观论调之前，请试试看自己利用现有的资源能走多远。没有一点浪费的空间，一切都需要你发挥最大的创造力\n\n* 谈到害怕失败 \n\n> 有种说法也十分常见：“你的退出策略是什么？（万一不成功，你怎么办？）”甚至在你刚刚准备起步时就会有人这样问你。一个连事业都没创立起来的人，就在考虑如何拔腿逃跑，到底在搞什么？至于那么着急吗？还没有进去就想着怎么出来，这种逻辑不是一般的混乱！\n\n* 专注做好一件事\n\n> 同时做N件事情的结果就是：一大把绝妙的点子最后被转化成一个蹩脚的产品。人不可能同时做所有的事情，并把事情做好。你的时间、资源、精力、注意力都是有限的。 一次做好一件事就已经不容易了。想一次做十件事？拉倒吧！从核心出发当你开始着手做一件事情时，总有一些力量将你拉向不同的方向。这当中包括你能做的、你想做的以及你必须做的事情。你应该从必须做的事情开始下手，即从核心出发\n\n\n* 过早关注细节\n\n> 不要过早关注细节.建筑师们从来不会过早去操心浴室要铺什么样的瓷砖、厨房要安什么牌子的洗碗机，这都是在平面图确定了以后才需要考虑的事。他们深知这些细节应该放到以后去考虑。\n\n* 项目周期的把控\n\n> 项目周期过长会打击士气。项目开发时间越长，成功的可能性越小。只要有足够的动力和士气，就要趁热打铁，积极决策，果断推进，现在就把事情做出来 \n\n* 把握本质的功能\n\n> 要记住，时尚会凋零。只有当你聚焦于长久的功能时，你才会发现自己把握住了永不落伍的东西\n\n* 尽快上线\n\n> 立马就上线你的产品或服务什么时候能做出来？你打算什么时候把它推向市场？什么时候能让人们拥有它？可能比你想象的要早得多。一旦你的产品实现了基本的功能，就要迅速把它亮出来\n\n* 打磨你的想法\n \n> 一个新创意的撩人程度并不代表其真实价值。有些东西现在看上去是“非要不可”，但是到了第二天早上，可能就会降级为“可有可无”。而“可有可无”的东西是不值得你不顾一切去做的。\n\n* 珍惜努力的你\n\n> 现在的你籍籍无名，这是件好事。籍籍无名就是一个绝佳的状态，你要庆幸自己目前还身在暗处。 \n\n\n* 关于招聘\n\n> 在37signals，我们一直没有雇用系统管理员，直到我们当中的一个人花了整整一个夏天的时间去设置一大堆服务器为止。在开始的3年时间里，我们中的另一个人做了所有的客服工作。之后我们才雇用了一名专职的客服人员。在把球传出去之前，我们都尽可能亲自带球。这样一来，我们在决定招聘时，就十分清楚自己到底需要什么样的员工了。\n\n> 但是在那之后，成长曲线就开始趋于平缓了。一个具有6个月工作经验的应聘者和一个具有6年工作经验的应聘者相比.其差别小得令人吃惊。真正的差别来自于个人的努力程度、性格差异以及智力水平\n\n> 常规教育不值一提我从来不把我自己受过的正规学校教育等同于我的受教育程度。——马克·吐温\n\n> 一个优秀的写手，其优点并不仅仅在于写作。文法清晰代表思路明晰。优秀的写手都懂得如何与人沟通。他们使事情变得易于理解，他们善于换位思考，懂得抓重点、砍枝节，这些都是合格的应聘者身上应具备的特点\n\n* 高效率工作\n\n> 就像谚语说的：“想要做成一件事，就去找你能找到的最忙碌的人。”你需要忙忙碌碌的人、需要有业余生活的人、需要关注好几件事情的人。你不能期望工作成为一个人生命的全部——至少你不愿意长期和这样的人共处。 \n\n* 小公司不应该被制度毒害\n\n> 规章制度是组织机体上的伤疤。它们是针对一种不太可能再次发生的情况而作出的过激反应，是对个人过失的一种集体惩罚。官僚主义便是因此而产生的。没有人一开始就想要官僚，这些东西都是慢慢侵蚀进来的。每次制定一项规章制度——也就是伤疤——官僚主义就滋生一点。  \n\n*  团队合作的氛围\n\n> “我们现在就得把这个功能加进去，没有这个功能我们就不能做了，每个人都想要它，这只是小事一桩，所以应该很简单，你应该能够很快把它做出来。”就这么区区60个字，却可引出100种假设，这就是祸端。\n\n* 抓住灵感\n\n> 灵感是个奇妙的东西，是效率放大器，是推进器。但是它不会停下来等你。灵感转瞬即逝，当它来找你时，要立即把它捕捉住，将其投入工作中去。 \n\n---------------------------------------------------------- 我是分割线 --------------------------------------------------------------\n\n推荐：\n 最近看到的[《站在两个世界的边缘》](http://book.douban.com/subject/25735727/) 深深被程浩打动了。末尾引用一句他的话，向其致敬。\n\n> “真正牛逼的，不是那些可以随口拿来夸耀的事迹，而是那些在困境中依然保持微笑的凡人。” - by 程浩\n","source":"_posts/2014-01-24-<<rework>>-shu-zhai.markdown","raw":"---\nlayout: post\ntitle: \"Rework书摘\"\ndate: 2014-01-24 22:31\ncomments: true\ncategories: Life\nkeywords: Rework\ndescription: Rework 书评\n---\n\n读到ReWork这本久负盛名的书了。摘录了鄙人认为深刻的话语。\n\n{% img /images/2014/01/rework.jpg %}\n\n很多话有道理，但是我们见到的只有很少人真的会去做，至少是去刻意克服惰性和思维方式.\n\n该书是由37signal 这个创造了很多精品的公司著作的。有很强的现实指导意义，以下摘自《rework》\n\n* 谈到现实\n\n> 撕开这个“现实世界”的遮羞布后，你会发现栖居其中的人们都充满着悲观和绝望的情绪。他们期待看到新概念被斩落马下，他们认为这个社会还没有准备好迎接变革，也无力引发变革.不要相信他们。这个世界对于他们来说可能是“现实”的，但并不意味着你也要生活在这样的“现实”世界中。\n\n* 谈到抱怨\n\n>条件受限是好事 ，因此，在你高唱“始终不够”的悲观论调之前，请试试看自己利用现有的资源能走多远。没有一点浪费的空间，一切都需要你发挥最大的创造力\n\n* 谈到害怕失败 \n\n> 有种说法也十分常见：“你的退出策略是什么？（万一不成功，你怎么办？）”甚至在你刚刚准备起步时就会有人这样问你。一个连事业都没创立起来的人，就在考虑如何拔腿逃跑，到底在搞什么？至于那么着急吗？还没有进去就想着怎么出来，这种逻辑不是一般的混乱！\n\n* 专注做好一件事\n\n> 同时做N件事情的结果就是：一大把绝妙的点子最后被转化成一个蹩脚的产品。人不可能同时做所有的事情，并把事情做好。你的时间、资源、精力、注意力都是有限的。 一次做好一件事就已经不容易了。想一次做十件事？拉倒吧！从核心出发当你开始着手做一件事情时，总有一些力量将你拉向不同的方向。这当中包括你能做的、你想做的以及你必须做的事情。你应该从必须做的事情开始下手，即从核心出发\n\n\n* 过早关注细节\n\n> 不要过早关注细节.建筑师们从来不会过早去操心浴室要铺什么样的瓷砖、厨房要安什么牌子的洗碗机，这都是在平面图确定了以后才需要考虑的事。他们深知这些细节应该放到以后去考虑。\n\n* 项目周期的把控\n\n> 项目周期过长会打击士气。项目开发时间越长，成功的可能性越小。只要有足够的动力和士气，就要趁热打铁，积极决策，果断推进，现在就把事情做出来 \n\n* 把握本质的功能\n\n> 要记住，时尚会凋零。只有当你聚焦于长久的功能时，你才会发现自己把握住了永不落伍的东西\n\n* 尽快上线\n\n> 立马就上线你的产品或服务什么时候能做出来？你打算什么时候把它推向市场？什么时候能让人们拥有它？可能比你想象的要早得多。一旦你的产品实现了基本的功能，就要迅速把它亮出来\n\n* 打磨你的想法\n \n> 一个新创意的撩人程度并不代表其真实价值。有些东西现在看上去是“非要不可”，但是到了第二天早上，可能就会降级为“可有可无”。而“可有可无”的东西是不值得你不顾一切去做的。\n\n* 珍惜努力的你\n\n> 现在的你籍籍无名，这是件好事。籍籍无名就是一个绝佳的状态，你要庆幸自己目前还身在暗处。 \n\n\n* 关于招聘\n\n> 在37signals，我们一直没有雇用系统管理员，直到我们当中的一个人花了整整一个夏天的时间去设置一大堆服务器为止。在开始的3年时间里，我们中的另一个人做了所有的客服工作。之后我们才雇用了一名专职的客服人员。在把球传出去之前，我们都尽可能亲自带球。这样一来，我们在决定招聘时，就十分清楚自己到底需要什么样的员工了。\n\n> 但是在那之后，成长曲线就开始趋于平缓了。一个具有6个月工作经验的应聘者和一个具有6年工作经验的应聘者相比.其差别小得令人吃惊。真正的差别来自于个人的努力程度、性格差异以及智力水平\n\n> 常规教育不值一提我从来不把我自己受过的正规学校教育等同于我的受教育程度。——马克·吐温\n\n> 一个优秀的写手，其优点并不仅仅在于写作。文法清晰代表思路明晰。优秀的写手都懂得如何与人沟通。他们使事情变得易于理解，他们善于换位思考，懂得抓重点、砍枝节，这些都是合格的应聘者身上应具备的特点\n\n* 高效率工作\n\n> 就像谚语说的：“想要做成一件事，就去找你能找到的最忙碌的人。”你需要忙忙碌碌的人、需要有业余生活的人、需要关注好几件事情的人。你不能期望工作成为一个人生命的全部——至少你不愿意长期和这样的人共处。 \n\n* 小公司不应该被制度毒害\n\n> 规章制度是组织机体上的伤疤。它们是针对一种不太可能再次发生的情况而作出的过激反应，是对个人过失的一种集体惩罚。官僚主义便是因此而产生的。没有人一开始就想要官僚，这些东西都是慢慢侵蚀进来的。每次制定一项规章制度——也就是伤疤——官僚主义就滋生一点。  \n\n*  团队合作的氛围\n\n> “我们现在就得把这个功能加进去，没有这个功能我们就不能做了，每个人都想要它，这只是小事一桩，所以应该很简单，你应该能够很快把它做出来。”就这么区区60个字，却可引出100种假设，这就是祸端。\n\n* 抓住灵感\n\n> 灵感是个奇妙的东西，是效率放大器，是推进器。但是它不会停下来等你。灵感转瞬即逝，当它来找你时，要立即把它捕捉住，将其投入工作中去。 \n\n---------------------------------------------------------- 我是分割线 --------------------------------------------------------------\n\n推荐：\n 最近看到的[《站在两个世界的边缘》](http://book.douban.com/subject/25735727/) 深深被程浩打动了。末尾引用一句他的话，向其致敬。\n\n> “真正牛逼的，不是那些可以随口拿来夸耀的事迹，而是那些在困境中依然保持微笑的凡人。” - by 程浩\n","slug":"2014-01-24-<<rework>>-shu-zhai","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd90001vnctjvgum5clr","content":"<p>读到ReWork这本久负盛名的书了。摘录了鄙人认为深刻的话语。</p>\n<img src=\"/images/2014/01/rework.jpg\">\n<p>很多话有道理，但是我们见到的只有很少人真的会去做，至少是去刻意克服惰性和思维方式.</p>\n<p>该书是由37signal 这个创造了很多精品的公司著作的。有很强的现实指导意义，以下摘自《rework》</p>\n<ul>\n<li>谈到现实</li>\n</ul>\n<blockquote>\n<p>撕开这个“现实世界”的遮羞布后，你会发现栖居其中的人们都充满着悲观和绝望的情绪。他们期待看到新概念被斩落马下，他们认为这个社会还没有准备好迎接变革，也无力引发变革.不要相信他们。这个世界对于他们来说可能是“现实”的，但并不意味着你也要生活在这样的“现实”世界中。</p>\n</blockquote>\n<ul>\n<li>谈到抱怨</li>\n</ul>\n<blockquote>\n<p>条件受限是好事 ，因此，在你高唱“始终不够”的悲观论调之前，请试试看自己利用现有的资源能走多远。没有一点浪费的空间，一切都需要你发挥最大的创造力</p>\n</blockquote>\n<ul>\n<li>谈到害怕失败 </li>\n</ul>\n<blockquote>\n<p>有种说法也十分常见：“你的退出策略是什么？（万一不成功，你怎么办？）”甚至在你刚刚准备起步时就会有人这样问你。一个连事业都没创立起来的人，就在考虑如何拔腿逃跑，到底在搞什么？至于那么着急吗？还没有进去就想着怎么出来，这种逻辑不是一般的混乱！</p>\n</blockquote>\n<ul>\n<li>专注做好一件事</li>\n</ul>\n<blockquote>\n<p>同时做N件事情的结果就是：一大把绝妙的点子最后被转化成一个蹩脚的产品。人不可能同时做所有的事情，并把事情做好。你的时间、资源、精力、注意力都是有限的。 一次做好一件事就已经不容易了。想一次做十件事？拉倒吧！从核心出发当你开始着手做一件事情时，总有一些力量将你拉向不同的方向。这当中包括你能做的、你想做的以及你必须做的事情。你应该从必须做的事情开始下手，即从核心出发</p>\n</blockquote>\n<ul>\n<li>过早关注细节</li>\n</ul>\n<blockquote>\n<p>不要过早关注细节.建筑师们从来不会过早去操心浴室要铺什么样的瓷砖、厨房要安什么牌子的洗碗机，这都是在平面图确定了以后才需要考虑的事。他们深知这些细节应该放到以后去考虑。</p>\n</blockquote>\n<ul>\n<li>项目周期的把控</li>\n</ul>\n<blockquote>\n<p>项目周期过长会打击士气。项目开发时间越长，成功的可能性越小。只要有足够的动力和士气，就要趁热打铁，积极决策，果断推进，现在就把事情做出来 </p>\n</blockquote>\n<ul>\n<li>把握本质的功能</li>\n</ul>\n<blockquote>\n<p>要记住，时尚会凋零。只有当你聚焦于长久的功能时，你才会发现自己把握住了永不落伍的东西</p>\n</blockquote>\n<ul>\n<li>尽快上线</li>\n</ul>\n<blockquote>\n<p>立马就上线你的产品或服务什么时候能做出来？你打算什么时候把它推向市场？什么时候能让人们拥有它？可能比你想象的要早得多。一旦你的产品实现了基本的功能，就要迅速把它亮出来</p>\n</blockquote>\n<ul>\n<li>打磨你的想法</li>\n</ul>\n<blockquote>\n<p>一个新创意的撩人程度并不代表其真实价值。有些东西现在看上去是“非要不可”，但是到了第二天早上，可能就会降级为“可有可无”。而“可有可无”的东西是不值得你不顾一切去做的。</p>\n</blockquote>\n<ul>\n<li>珍惜努力的你</li>\n</ul>\n<blockquote>\n<p>现在的你籍籍无名，这是件好事。籍籍无名就是一个绝佳的状态，你要庆幸自己目前还身在暗处。 </p>\n</blockquote>\n<ul>\n<li>关于招聘</li>\n</ul>\n<blockquote>\n<p>在37signals，我们一直没有雇用系统管理员，直到我们当中的一个人花了整整一个夏天的时间去设置一大堆服务器为止。在开始的3年时间里，我们中的另一个人做了所有的客服工作。之后我们才雇用了一名专职的客服人员。在把球传出去之前，我们都尽可能亲自带球。这样一来，我们在决定招聘时，就十分清楚自己到底需要什么样的员工了。</p>\n</blockquote>\n<blockquote>\n<p>但是在那之后，成长曲线就开始趋于平缓了。一个具有6个月工作经验的应聘者和一个具有6年工作经验的应聘者相比.其差别小得令人吃惊。真正的差别来自于个人的努力程度、性格差异以及智力水平</p>\n</blockquote>\n<blockquote>\n<p>常规教育不值一提我从来不把我自己受过的正规学校教育等同于我的受教育程度。——马克·吐温</p>\n</blockquote>\n<blockquote>\n<p>一个优秀的写手，其优点并不仅仅在于写作。文法清晰代表思路明晰。优秀的写手都懂得如何与人沟通。他们使事情变得易于理解，他们善于换位思考，懂得抓重点、砍枝节，这些都是合格的应聘者身上应具备的特点</p>\n</blockquote>\n<ul>\n<li>高效率工作</li>\n</ul>\n<blockquote>\n<p>就像谚语说的：“想要做成一件事，就去找你能找到的最忙碌的人。”你需要忙忙碌碌的人、需要有业余生活的人、需要关注好几件事情的人。你不能期望工作成为一个人生命的全部——至少你不愿意长期和这样的人共处。 </p>\n</blockquote>\n<ul>\n<li>小公司不应该被制度毒害</li>\n</ul>\n<blockquote>\n<p>规章制度是组织机体上的伤疤。它们是针对一种不太可能再次发生的情况而作出的过激反应，是对个人过失的一种集体惩罚。官僚主义便是因此而产生的。没有人一开始就想要官僚，这些东西都是慢慢侵蚀进来的。每次制定一项规章制度——也就是伤疤——官僚主义就滋生一点。  </p>\n</blockquote>\n<ul>\n<li>团队合作的氛围</li>\n</ul>\n<blockquote>\n<p>“我们现在就得把这个功能加进去，没有这个功能我们就不能做了，每个人都想要它，这只是小事一桩，所以应该很简单，你应该能够很快把它做出来。”就这么区区60个字，却可引出100种假设，这就是祸端。</p>\n</blockquote>\n<ul>\n<li>抓住灵感</li>\n</ul>\n<blockquote>\n<p>灵感是个奇妙的东西，是效率放大器，是推进器。但是它不会停下来等你。灵感转瞬即逝，当它来找你时，要立即把它捕捉住，将其投入工作中去。 </p>\n</blockquote>\n<p>———————————————————- 我是分割线 ————————————————————–</p>\n<p>推荐：<br> 最近看到的<a href=\"http://book.douban.com/subject/25735727/\" target=\"_blank\" rel=\"noopener\">《站在两个世界的边缘》</a> 深深被程浩打动了。末尾引用一句他的话，向其致敬。</p>\n<blockquote>\n<p>“真正牛逼的，不是那些可以随口拿来夸耀的事迹，而是那些在困境中依然保持微笑的凡人。” - by 程浩</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p>读到ReWork这本久负盛名的书了。摘录了鄙人认为深刻的话语。</p>\n<img src=\"/images/2014/01/rework.jpg\">\n<p>很多话有道理，但是我们见到的只有很少人真的会去做，至少是去刻意克服惰性和思维方式.</p>\n<p>该书是由37signal 这个创造了很多精品的公司著作的。有很强的现实指导意义，以下摘自《rework》</p>\n<ul>\n<li>谈到现实</li>\n</ul>\n<blockquote>\n<p>撕开这个“现实世界”的遮羞布后，你会发现栖居其中的人们都充满着悲观和绝望的情绪。他们期待看到新概念被斩落马下，他们认为这个社会还没有准备好迎接变革，也无力引发变革.不要相信他们。这个世界对于他们来说可能是“现实”的，但并不意味着你也要生活在这样的“现实”世界中。</p>\n</blockquote>\n<ul>\n<li>谈到抱怨</li>\n</ul>\n<blockquote>\n<p>条件受限是好事 ，因此，在你高唱“始终不够”的悲观论调之前，请试试看自己利用现有的资源能走多远。没有一点浪费的空间，一切都需要你发挥最大的创造力</p>\n</blockquote>\n<ul>\n<li>谈到害怕失败 </li>\n</ul>\n<blockquote>\n<p>有种说法也十分常见：“你的退出策略是什么？（万一不成功，你怎么办？）”甚至在你刚刚准备起步时就会有人这样问你。一个连事业都没创立起来的人，就在考虑如何拔腿逃跑，到底在搞什么？至于那么着急吗？还没有进去就想着怎么出来，这种逻辑不是一般的混乱！</p>\n</blockquote>\n<ul>\n<li>专注做好一件事</li>\n</ul>\n<blockquote>\n<p>同时做N件事情的结果就是：一大把绝妙的点子最后被转化成一个蹩脚的产品。人不可能同时做所有的事情，并把事情做好。你的时间、资源、精力、注意力都是有限的。 一次做好一件事就已经不容易了。想一次做十件事？拉倒吧！从核心出发当你开始着手做一件事情时，总有一些力量将你拉向不同的方向。这当中包括你能做的、你想做的以及你必须做的事情。你应该从必须做的事情开始下手，即从核心出发</p>\n</blockquote>\n<ul>\n<li>过早关注细节</li>\n</ul>\n<blockquote>\n<p>不要过早关注细节.建筑师们从来不会过早去操心浴室要铺什么样的瓷砖、厨房要安什么牌子的洗碗机，这都是在平面图确定了以后才需要考虑的事。他们深知这些细节应该放到以后去考虑。</p>\n</blockquote>\n<ul>\n<li>项目周期的把控</li>\n</ul>\n<blockquote>\n<p>项目周期过长会打击士气。项目开发时间越长，成功的可能性越小。只要有足够的动力和士气，就要趁热打铁，积极决策，果断推进，现在就把事情做出来 </p>\n</blockquote>\n<ul>\n<li>把握本质的功能</li>\n</ul>\n<blockquote>\n<p>要记住，时尚会凋零。只有当你聚焦于长久的功能时，你才会发现自己把握住了永不落伍的东西</p>\n</blockquote>\n<ul>\n<li>尽快上线</li>\n</ul>\n<blockquote>\n<p>立马就上线你的产品或服务什么时候能做出来？你打算什么时候把它推向市场？什么时候能让人们拥有它？可能比你想象的要早得多。一旦你的产品实现了基本的功能，就要迅速把它亮出来</p>\n</blockquote>\n<ul>\n<li>打磨你的想法</li>\n</ul>\n<blockquote>\n<p>一个新创意的撩人程度并不代表其真实价值。有些东西现在看上去是“非要不可”，但是到了第二天早上，可能就会降级为“可有可无”。而“可有可无”的东西是不值得你不顾一切去做的。</p>\n</blockquote>\n<ul>\n<li>珍惜努力的你</li>\n</ul>\n<blockquote>\n<p>现在的你籍籍无名，这是件好事。籍籍无名就是一个绝佳的状态，你要庆幸自己目前还身在暗处。 </p>\n</blockquote>\n<ul>\n<li>关于招聘</li>\n</ul>\n<blockquote>\n<p>在37signals，我们一直没有雇用系统管理员，直到我们当中的一个人花了整整一个夏天的时间去设置一大堆服务器为止。在开始的3年时间里，我们中的另一个人做了所有的客服工作。之后我们才雇用了一名专职的客服人员。在把球传出去之前，我们都尽可能亲自带球。这样一来，我们在决定招聘时，就十分清楚自己到底需要什么样的员工了。</p>\n</blockquote>\n<blockquote>\n<p>但是在那之后，成长曲线就开始趋于平缓了。一个具有6个月工作经验的应聘者和一个具有6年工作经验的应聘者相比.其差别小得令人吃惊。真正的差别来自于个人的努力程度、性格差异以及智力水平</p>\n</blockquote>\n<blockquote>\n<p>常规教育不值一提我从来不把我自己受过的正规学校教育等同于我的受教育程度。——马克·吐温</p>\n</blockquote>\n<blockquote>\n<p>一个优秀的写手，其优点并不仅仅在于写作。文法清晰代表思路明晰。优秀的写手都懂得如何与人沟通。他们使事情变得易于理解，他们善于换位思考，懂得抓重点、砍枝节，这些都是合格的应聘者身上应具备的特点</p>\n</blockquote>\n<ul>\n<li>高效率工作</li>\n</ul>\n<blockquote>\n<p>就像谚语说的：“想要做成一件事，就去找你能找到的最忙碌的人。”你需要忙忙碌碌的人、需要有业余生活的人、需要关注好几件事情的人。你不能期望工作成为一个人生命的全部——至少你不愿意长期和这样的人共处。 </p>\n</blockquote>\n<ul>\n<li>小公司不应该被制度毒害</li>\n</ul>\n<blockquote>\n<p>规章制度是组织机体上的伤疤。它们是针对一种不太可能再次发生的情况而作出的过激反应，是对个人过失的一种集体惩罚。官僚主义便是因此而产生的。没有人一开始就想要官僚，这些东西都是慢慢侵蚀进来的。每次制定一项规章制度——也就是伤疤——官僚主义就滋生一点。  </p>\n</blockquote>\n<ul>\n<li>团队合作的氛围</li>\n</ul>\n<blockquote>\n<p>“我们现在就得把这个功能加进去，没有这个功能我们就不能做了，每个人都想要它，这只是小事一桩，所以应该很简单，你应该能够很快把它做出来。”就这么区区60个字，却可引出100种假设，这就是祸端。</p>\n</blockquote>\n<ul>\n<li>抓住灵感</li>\n</ul>\n<blockquote>\n<p>灵感是个奇妙的东西，是效率放大器，是推进器。但是它不会停下来等你。灵感转瞬即逝，当它来找你时，要立即把它捕捉住，将其投入工作中去。 </p>\n</blockquote>\n<p>———————————————————- 我是分割线 ————————————————————–</p>\n<p>推荐：<br> 最近看到的<a href=\"http://book.douban.com/subject/25735727/\" target=\"_blank\" rel=\"noopener\">《站在两个世界的边缘》</a> 深深被程浩打动了。末尾引用一句他的话，向其致敬。</p>\n<blockquote>\n<p>“真正牛逼的，不是那些可以随口拿来夸耀的事迹，而是那些在困境中依然保持微笑的凡人。” - by 程浩</p>\n</blockquote>\n"},{"layout":"post","title":"SkipList","date":"2014-02-01T02:21:00.000Z","comments":1,"keywords":"skiplist","description":"skiplist, leveldb","_content":"\n几个星期之前还和@huangSir 说起了Golang支持了这\"B格高\"的玩意。跳表可以在列表中的查找可以快速的跳过部分列表，效率高.故名思义,过年这几天阅读Leveldb源码的时候,memtable也用了这玩意\n\n* [跳表简介](#第一节)\n* [数据结构](#第二节)\n* [应用场景](#第三节)\n\n<h3 id=\"第一节\">跳表简介</h3>\n\n{% img /images/2014/01/skiplist.png %}\n\n[Skip List](http://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8)是\n\n* 一种随机化的数据结构，基于并联的链表，\n* 其效率可比拟于二叉查找树（对于大多数操作需要O(log n)平均时间）。\n* 以空间换时间，对有序的链表随机化增加上附加的前进链接\n* 由多层链表组成，每一层有序的链表，第一层包含所有的元素；\n\n<h3 id=\"第二节\">数据结构</h3>\n\n* skiplist节点\n\n```c\nstruct node {\n    int key;\n    int value;   \n    node *next[1];  \n}\n```\n\n其中nodec * next[1] 是该节点的前向指针\n\n* skiplist数据结构\n\n```c\nstruct skiplist\n{\n    int level; //最大的层\n    node *header;链表头\n};\n```\n\n通常一个数据结构我们定义为表头信息和最大的层数\n\n\n* 初始化\n\n列表的初始化需要初始化头部，并使头部每层都指向末尾（NULL）。MAX_LEVEL是我们定义的常量\n\n```c\nnode *createNode(int level, int key, int value) {\n    node *ns = (node *) malloc(sizeof(node) + level * sizeof(node*));\n    ns->key = key;\n    ns->value = value;\n    return ns;\n}\n\nskiplist* createSkiplist() {\n    skiplist *sl = (skiplist *)malloc(sizeof(skiplist));\n    sl->level = 0;\n    sl->header = createNode(MAX_LEVEL-1,0,0);\n    for(int i=0; i<MAX_LEVEL; i++) {\n        sl->header->next[i] = NULL;\n    }\n    return sl;\n}\n```\n\n* 插入\n\n插入元素的时候元素所占有的层数完全是随机的，通过随机算法产生 需要三个步骤:\n\n- 第一步需要查找到在每层待插入位置，\n- 然后需要随机产生一个层数，\n- 最后就是从高层至下插入.\n\n```\nbool insert(skiplist *sl,int key,int value) {\n    node *update[MAX_LEVEL];\n    node *p, *q = NULL;\n    p = sl->header;\n    int k = sl->level;\n    for(int i = k-1; i >= 0; i--) {\n        while((q = p->next[i]) && (q->key<key)) {\n            p = q;\n        }\n        update[i]=p;\n    }\n    if(q && q->key == key) return false;\n    //产生一个随机层数K,新建一个待插入节点q, 层层插入\n    k = randomLevel();\n    //更新跳表的level\n    if(k > (sl->level)) {\n        for(int i = sl->level; i < k; i++){\n            update[i] = sl->header;\n        }\n        sl->level = k;\n    }\n    q = createNode(k, key, value);\n    //逐层更新节点的指针，和普通列表插入一样\n    for(int i = 0;i<k;i++)\n    {\n        q->next[i] = update[i]->next[i];\n        update[i]->next[i] = q;\n    }\n    return true;\n}\n```\n\n* 删除节点\n\n与插入类似的是，为了实现层层操作，用一个update数组维护每层需要的节点，如果删掉最大层则需要更新跳表的level。\n\n```c\nbool deleteSL(skiplist *sl,int key) {\n    node *update[MAX_LEVEL];\n    node *p,*q = NULL;\n    p = sl->header;\n    //从最高层开始搜\n    int k=sl->level;\n    for(int i = k-1; i >= 0; i--){\n        while((q = p->next[i]) && (q->key<key)) {\n            p = q;\n        }\n        update[i] = p;\n    }\n    if(q && q->key == key) {\n        //逐层删除，和普通列表删除一样\n        for(int i = 0; i<sl->level; i++){\n            if(update[i]->next[i] == q){\n                update[i]->next[i] = q->next[i];\n            }\n        }\n        free(q);\n        //如果删除的是最大层的节点，那么需要重新维护跳表的\n        for(int i=sl->level-1; i >= 0; i--){\n            if(sl->header->forward[i]==NULL){\n                sl->level--;\n            }\n        }\n        return true;\n    }\n    else\n        return false;\n}\n```\n\n* 查找\n\n从最高层查找起， 跳跃查找\n\n```c\nint search(skiplist * sl, int key) {\n    node * p, *q = NULL;\n    p = sl->header;\n    int k = sl->level;\n    for (int i = k-1; i >= 0; i--) {\n        while ((q = p->forward[i]) && q->key <= key) {\n            if (q->key == key) {\n                return q->value;\n            }\n            p = q;\n        }\n    }\n    return NULL;\n}\n```\n\n<h3 id=\"第三节\">应用场景</h3>\n如前面说道的，老夫在leveldb的memtable.c看到这一实现的， Redis也是用到了这样的设计，看来KV的设计对skiplist有偏好，leveldb需要内存中存储的是有序的key-val键值对, 作为一个内存数据库，快速是很重要的，特别是数据量大的时候。牺牲了部分空间(冗余的指针)换取时间,达到O(logn)的效果\n\n<h3>引用资料</h3>\n- [wikipedia](http://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8) \n- [skiplist讲解](http://blog.csdn.net/ict2014/article/details/17394259)\n- [source code](https://github.com/zheng-ji/ToyCollection/skiplist)\n\n\n","source":"_posts/2014-02-01-tiao-biao-skiplist.markdown","raw":"---\nlayout: post\ntitle: \"SkipList\"\ndate: 2014-02-01 10:21\ncomments: true\ncategories: Programe\nkeywords: skiplist\ndescription: skiplist, leveldb\n---\n\n几个星期之前还和@huangSir 说起了Golang支持了这\"B格高\"的玩意。跳表可以在列表中的查找可以快速的跳过部分列表，效率高.故名思义,过年这几天阅读Leveldb源码的时候,memtable也用了这玩意\n\n* [跳表简介](#第一节)\n* [数据结构](#第二节)\n* [应用场景](#第三节)\n\n<h3 id=\"第一节\">跳表简介</h3>\n\n{% img /images/2014/01/skiplist.png %}\n\n[Skip List](http://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8)是\n\n* 一种随机化的数据结构，基于并联的链表，\n* 其效率可比拟于二叉查找树（对于大多数操作需要O(log n)平均时间）。\n* 以空间换时间，对有序的链表随机化增加上附加的前进链接\n* 由多层链表组成，每一层有序的链表，第一层包含所有的元素；\n\n<h3 id=\"第二节\">数据结构</h3>\n\n* skiplist节点\n\n```c\nstruct node {\n    int key;\n    int value;   \n    node *next[1];  \n}\n```\n\n其中nodec * next[1] 是该节点的前向指针\n\n* skiplist数据结构\n\n```c\nstruct skiplist\n{\n    int level; //最大的层\n    node *header;链表头\n};\n```\n\n通常一个数据结构我们定义为表头信息和最大的层数\n\n\n* 初始化\n\n列表的初始化需要初始化头部，并使头部每层都指向末尾（NULL）。MAX_LEVEL是我们定义的常量\n\n```c\nnode *createNode(int level, int key, int value) {\n    node *ns = (node *) malloc(sizeof(node) + level * sizeof(node*));\n    ns->key = key;\n    ns->value = value;\n    return ns;\n}\n\nskiplist* createSkiplist() {\n    skiplist *sl = (skiplist *)malloc(sizeof(skiplist));\n    sl->level = 0;\n    sl->header = createNode(MAX_LEVEL-1,0,0);\n    for(int i=0; i<MAX_LEVEL; i++) {\n        sl->header->next[i] = NULL;\n    }\n    return sl;\n}\n```\n\n* 插入\n\n插入元素的时候元素所占有的层数完全是随机的，通过随机算法产生 需要三个步骤:\n\n- 第一步需要查找到在每层待插入位置，\n- 然后需要随机产生一个层数，\n- 最后就是从高层至下插入.\n\n```\nbool insert(skiplist *sl,int key,int value) {\n    node *update[MAX_LEVEL];\n    node *p, *q = NULL;\n    p = sl->header;\n    int k = sl->level;\n    for(int i = k-1; i >= 0; i--) {\n        while((q = p->next[i]) && (q->key<key)) {\n            p = q;\n        }\n        update[i]=p;\n    }\n    if(q && q->key == key) return false;\n    //产生一个随机层数K,新建一个待插入节点q, 层层插入\n    k = randomLevel();\n    //更新跳表的level\n    if(k > (sl->level)) {\n        for(int i = sl->level; i < k; i++){\n            update[i] = sl->header;\n        }\n        sl->level = k;\n    }\n    q = createNode(k, key, value);\n    //逐层更新节点的指针，和普通列表插入一样\n    for(int i = 0;i<k;i++)\n    {\n        q->next[i] = update[i]->next[i];\n        update[i]->next[i] = q;\n    }\n    return true;\n}\n```\n\n* 删除节点\n\n与插入类似的是，为了实现层层操作，用一个update数组维护每层需要的节点，如果删掉最大层则需要更新跳表的level。\n\n```c\nbool deleteSL(skiplist *sl,int key) {\n    node *update[MAX_LEVEL];\n    node *p,*q = NULL;\n    p = sl->header;\n    //从最高层开始搜\n    int k=sl->level;\n    for(int i = k-1; i >= 0; i--){\n        while((q = p->next[i]) && (q->key<key)) {\n            p = q;\n        }\n        update[i] = p;\n    }\n    if(q && q->key == key) {\n        //逐层删除，和普通列表删除一样\n        for(int i = 0; i<sl->level; i++){\n            if(update[i]->next[i] == q){\n                update[i]->next[i] = q->next[i];\n            }\n        }\n        free(q);\n        //如果删除的是最大层的节点，那么需要重新维护跳表的\n        for(int i=sl->level-1; i >= 0; i--){\n            if(sl->header->forward[i]==NULL){\n                sl->level--;\n            }\n        }\n        return true;\n    }\n    else\n        return false;\n}\n```\n\n* 查找\n\n从最高层查找起， 跳跃查找\n\n```c\nint search(skiplist * sl, int key) {\n    node * p, *q = NULL;\n    p = sl->header;\n    int k = sl->level;\n    for (int i = k-1; i >= 0; i--) {\n        while ((q = p->forward[i]) && q->key <= key) {\n            if (q->key == key) {\n                return q->value;\n            }\n            p = q;\n        }\n    }\n    return NULL;\n}\n```\n\n<h3 id=\"第三节\">应用场景</h3>\n如前面说道的，老夫在leveldb的memtable.c看到这一实现的， Redis也是用到了这样的设计，看来KV的设计对skiplist有偏好，leveldb需要内存中存储的是有序的key-val键值对, 作为一个内存数据库，快速是很重要的，特别是数据量大的时候。牺牲了部分空间(冗余的指针)换取时间,达到O(logn)的效果\n\n<h3>引用资料</h3>\n- [wikipedia](http://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8) \n- [skiplist讲解](http://blog.csdn.net/ict2014/article/details/17394259)\n- [source code](https://github.com/zheng-ji/ToyCollection/skiplist)\n\n\n","slug":"2014-02-01-tiao-biao-skiplist","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd91001ynctjg5qdtjot","content":"<p>几个星期之前还和@huangSir 说起了Golang支持了这”B格高”的玩意。跳表可以在列表中的查找可以快速的跳过部分列表，效率高.故名思义,过年这几天阅读Leveldb源码的时候,memtable也用了这玩意</p>\n<ul>\n<li><a href=\"#第一节\">跳表简介</a></li>\n<li><a href=\"#第二节\">数据结构</a></li>\n<li><a href=\"#第三节\">应用场景</a></li>\n</ul>\n<h3 id=\"第一节\">跳表简介</h3>\n\n<img src=\"/images/2014/01/skiplist.png\">\n<p><a href=\"http://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8\" target=\"_blank\" rel=\"noopener\">Skip List</a>是</p>\n<ul>\n<li>一种随机化的数据结构，基于并联的链表，</li>\n<li>其效率可比拟于二叉查找树（对于大多数操作需要O(log n)平均时间）。</li>\n<li>以空间换时间，对有序的链表随机化增加上附加的前进链接</li>\n<li>由多层链表组成，每一层有序的链表，第一层包含所有的元素；</li>\n</ul>\n<h3 id=\"第二节\">数据结构</h3>\n\n<ul>\n<li>skiplist节点</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">node</span> &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> key;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> value;   </span><br><span class=\"line\">    node *next[<span class=\"number\">1</span>];  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中nodec * next[1] 是该节点的前向指针</p>\n<ul>\n<li>skiplist数据结构</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">skiplist</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> level; <span class=\"comment\">//最大的层</span></span><br><span class=\"line\">    node *header;链表头</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>通常一个数据结构我们定义为表头信息和最大的层数</p>\n<ul>\n<li>初始化</li>\n</ul>\n<p>列表的初始化需要初始化头部，并使头部每层都指向末尾（NULL）。MAX_LEVEL是我们定义的常量</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">node *<span class=\"title\">createNode</span><span class=\"params\">(<span class=\"keyword\">int</span> level, <span class=\"keyword\">int</span> key, <span class=\"keyword\">int</span> value)</span> </span>&#123;</span><br><span class=\"line\">    node *ns = (node *) <span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(node) + level * <span class=\"keyword\">sizeof</span>(node*));</span><br><span class=\"line\">    ns-&gt;key = key;</span><br><span class=\"line\">    ns-&gt;value = value;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ns;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">skiplist* <span class=\"title\">createSkiplist</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    skiplist *sl = (skiplist *)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(skiplist));</span><br><span class=\"line\">    sl-&gt;level = <span class=\"number\">0</span>;</span><br><span class=\"line\">    sl-&gt;header = createNode(MAX_LEVEL<span class=\"number\">-1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;MAX_LEVEL; i++) &#123;</span><br><span class=\"line\">        sl-&gt;header-&gt;next[i] = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> sl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>插入</li>\n</ul>\n<p>插入元素的时候元素所占有的层数完全是随机的，通过随机算法产生 需要三个步骤:</p>\n<ul>\n<li>第一步需要查找到在每层待插入位置，</li>\n<li>然后需要随机产生一个层数，</li>\n<li>最后就是从高层至下插入.</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool insert(skiplist *sl,int key,int value) &#123;</span><br><span class=\"line\">    node *update[MAX_LEVEL];</span><br><span class=\"line\">    node *p, *q = NULL;</span><br><span class=\"line\">    p = sl-&gt;header;</span><br><span class=\"line\">    int k = sl-&gt;level;</span><br><span class=\"line\">    for(int i = k-1; i &gt;= 0; i--) &#123;</span><br><span class=\"line\">        while((q = p-&gt;next[i]) &amp;&amp; (q-&gt;key&lt;key)) &#123;</span><br><span class=\"line\">            p = q;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        update[i]=p;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(q &amp;&amp; q-&gt;key == key) return false;</span><br><span class=\"line\">    //产生一个随机层数K,新建一个待插入节点q, 层层插入</span><br><span class=\"line\">    k = randomLevel();</span><br><span class=\"line\">    //更新跳表的level</span><br><span class=\"line\">    if(k &gt; (sl-&gt;level)) &#123;</span><br><span class=\"line\">        for(int i = sl-&gt;level; i &lt; k; i++)&#123;</span><br><span class=\"line\">            update[i] = sl-&gt;header;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        sl-&gt;level = k;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    q = createNode(k, key, value);</span><br><span class=\"line\">    //逐层更新节点的指针，和普通列表插入一样</span><br><span class=\"line\">    for(int i = 0;i&lt;k;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        q-&gt;next[i] = update[i]-&gt;next[i];</span><br><span class=\"line\">        update[i]-&gt;next[i] = q;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>删除节点</li>\n</ul>\n<p>与插入类似的是，为了实现层层操作，用一个update数组维护每层需要的节点，如果删掉最大层则需要更新跳表的level。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">deleteSL</span><span class=\"params\">(skiplist *sl,<span class=\"keyword\">int</span> key)</span> </span>&#123;</span><br><span class=\"line\">    node *update[MAX_LEVEL];</span><br><span class=\"line\">    node *p,*q = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    p = sl-&gt;header;</span><br><span class=\"line\">    <span class=\"comment\">//从最高层开始搜</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> k=sl-&gt;level;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = k<span class=\"number\">-1</span>; i &gt;= <span class=\"number\">0</span>; i--)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>((q = p-&gt;next[i]) &amp;&amp; (q-&gt;key&lt;key)) &#123;</span><br><span class=\"line\">            p = q;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        update[i] = p;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(q &amp;&amp; q-&gt;key == key) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//逐层删除，和普通列表删除一样</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;sl-&gt;level; i++)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(update[i]-&gt;next[i] == q)&#123;</span><br><span class=\"line\">                update[i]-&gt;next[i] = q-&gt;next[i];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">free</span>(q);</span><br><span class=\"line\">        <span class=\"comment\">//如果删除的是最大层的节点，那么需要重新维护跳表的</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=sl-&gt;level<span class=\"number\">-1</span>; i &gt;= <span class=\"number\">0</span>; i--)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(sl-&gt;header-&gt;forward[i]==<span class=\"literal\">NULL</span>)&#123;</span><br><span class=\"line\">                sl-&gt;level--;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查找</li>\n</ul>\n<p>从最高层查找起， 跳跃查找</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">search</span><span class=\"params\">(skiplist * sl, <span class=\"keyword\">int</span> key)</span> </span>&#123;</span><br><span class=\"line\">    node * p, *q = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    p = sl-&gt;header;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> k = sl-&gt;level;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = k<span class=\"number\">-1</span>; i &gt;= <span class=\"number\">0</span>; i--) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> ((q = p-&gt;forward[i]) &amp;&amp; q-&gt;key &lt;= key) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (q-&gt;key == key) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">return</span> q-&gt;value;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            p = q;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p></p><h3 id=\"第三节\">应用场景</h3><br>如前面说道的，老夫在leveldb的memtable.c看到这一实现的， Redis也是用到了这样的设计，看来KV的设计对skiplist有偏好，leveldb需要内存中存储的是有序的key-val键值对, 作为一个内存数据库，快速是很重要的，特别是数据量大的时候。牺牲了部分空间(冗余的指针)换取时间,达到O(logn)的效果<p></p>\n<p></p><h3>引用资料</h3><p></p>\n<ul>\n<li><a href=\"http://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8\" target=\"_blank\" rel=\"noopener\">wikipedia</a> </li>\n<li><a href=\"http://blog.csdn.net/ict2014/article/details/17394259\" target=\"_blank\" rel=\"noopener\">skiplist讲解</a></li>\n<li><a href=\"https://github.com/zheng-ji/ToyCollection/skiplist\" target=\"_blank\" rel=\"noopener\">source code</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>几个星期之前还和@huangSir 说起了Golang支持了这”B格高”的玩意。跳表可以在列表中的查找可以快速的跳过部分列表，效率高.故名思义,过年这几天阅读Leveldb源码的时候,memtable也用了这玩意</p>\n<ul>\n<li><a href=\"#第一节\">跳表简介</a></li>\n<li><a href=\"#第二节\">数据结构</a></li>\n<li><a href=\"#第三节\">应用场景</a></li>\n</ul>\n<h3 id=\"第一节\">跳表简介</h3>\n\n<img src=\"/images/2014/01/skiplist.png\">\n<p><a href=\"http://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8\" target=\"_blank\" rel=\"noopener\">Skip List</a>是</p>\n<ul>\n<li>一种随机化的数据结构，基于并联的链表，</li>\n<li>其效率可比拟于二叉查找树（对于大多数操作需要O(log n)平均时间）。</li>\n<li>以空间换时间，对有序的链表随机化增加上附加的前进链接</li>\n<li>由多层链表组成，每一层有序的链表，第一层包含所有的元素；</li>\n</ul>\n<h3 id=\"第二节\">数据结构</h3>\n\n<ul>\n<li>skiplist节点</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">node</span> &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> key;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> value;   </span><br><span class=\"line\">    node *next[<span class=\"number\">1</span>];  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中nodec * next[1] 是该节点的前向指针</p>\n<ul>\n<li>skiplist数据结构</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">skiplist</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> level; <span class=\"comment\">//最大的层</span></span><br><span class=\"line\">    node *header;链表头</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>通常一个数据结构我们定义为表头信息和最大的层数</p>\n<ul>\n<li>初始化</li>\n</ul>\n<p>列表的初始化需要初始化头部，并使头部每层都指向末尾（NULL）。MAX_LEVEL是我们定义的常量</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">node *<span class=\"title\">createNode</span><span class=\"params\">(<span class=\"keyword\">int</span> level, <span class=\"keyword\">int</span> key, <span class=\"keyword\">int</span> value)</span> </span>&#123;</span><br><span class=\"line\">    node *ns = (node *) <span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(node) + level * <span class=\"keyword\">sizeof</span>(node*));</span><br><span class=\"line\">    ns-&gt;key = key;</span><br><span class=\"line\">    ns-&gt;value = value;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ns;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">skiplist* <span class=\"title\">createSkiplist</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    skiplist *sl = (skiplist *)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(skiplist));</span><br><span class=\"line\">    sl-&gt;level = <span class=\"number\">0</span>;</span><br><span class=\"line\">    sl-&gt;header = createNode(MAX_LEVEL<span class=\"number\">-1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;MAX_LEVEL; i++) &#123;</span><br><span class=\"line\">        sl-&gt;header-&gt;next[i] = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> sl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>插入</li>\n</ul>\n<p>插入元素的时候元素所占有的层数完全是随机的，通过随机算法产生 需要三个步骤:</p>\n<ul>\n<li>第一步需要查找到在每层待插入位置，</li>\n<li>然后需要随机产生一个层数，</li>\n<li>最后就是从高层至下插入.</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool insert(skiplist *sl,int key,int value) &#123;</span><br><span class=\"line\">    node *update[MAX_LEVEL];</span><br><span class=\"line\">    node *p, *q = NULL;</span><br><span class=\"line\">    p = sl-&gt;header;</span><br><span class=\"line\">    int k = sl-&gt;level;</span><br><span class=\"line\">    for(int i = k-1; i &gt;= 0; i--) &#123;</span><br><span class=\"line\">        while((q = p-&gt;next[i]) &amp;&amp; (q-&gt;key&lt;key)) &#123;</span><br><span class=\"line\">            p = q;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        update[i]=p;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(q &amp;&amp; q-&gt;key == key) return false;</span><br><span class=\"line\">    //产生一个随机层数K,新建一个待插入节点q, 层层插入</span><br><span class=\"line\">    k = randomLevel();</span><br><span class=\"line\">    //更新跳表的level</span><br><span class=\"line\">    if(k &gt; (sl-&gt;level)) &#123;</span><br><span class=\"line\">        for(int i = sl-&gt;level; i &lt; k; i++)&#123;</span><br><span class=\"line\">            update[i] = sl-&gt;header;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        sl-&gt;level = k;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    q = createNode(k, key, value);</span><br><span class=\"line\">    //逐层更新节点的指针，和普通列表插入一样</span><br><span class=\"line\">    for(int i = 0;i&lt;k;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        q-&gt;next[i] = update[i]-&gt;next[i];</span><br><span class=\"line\">        update[i]-&gt;next[i] = q;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>删除节点</li>\n</ul>\n<p>与插入类似的是，为了实现层层操作，用一个update数组维护每层需要的节点，如果删掉最大层则需要更新跳表的level。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">deleteSL</span><span class=\"params\">(skiplist *sl,<span class=\"keyword\">int</span> key)</span> </span>&#123;</span><br><span class=\"line\">    node *update[MAX_LEVEL];</span><br><span class=\"line\">    node *p,*q = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    p = sl-&gt;header;</span><br><span class=\"line\">    <span class=\"comment\">//从最高层开始搜</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> k=sl-&gt;level;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = k<span class=\"number\">-1</span>; i &gt;= <span class=\"number\">0</span>; i--)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>((q = p-&gt;next[i]) &amp;&amp; (q-&gt;key&lt;key)) &#123;</span><br><span class=\"line\">            p = q;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        update[i] = p;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(q &amp;&amp; q-&gt;key == key) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//逐层删除，和普通列表删除一样</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;sl-&gt;level; i++)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(update[i]-&gt;next[i] == q)&#123;</span><br><span class=\"line\">                update[i]-&gt;next[i] = q-&gt;next[i];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">free</span>(q);</span><br><span class=\"line\">        <span class=\"comment\">//如果删除的是最大层的节点，那么需要重新维护跳表的</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=sl-&gt;level<span class=\"number\">-1</span>; i &gt;= <span class=\"number\">0</span>; i--)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(sl-&gt;header-&gt;forward[i]==<span class=\"literal\">NULL</span>)&#123;</span><br><span class=\"line\">                sl-&gt;level--;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查找</li>\n</ul>\n<p>从最高层查找起， 跳跃查找</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">search</span><span class=\"params\">(skiplist * sl, <span class=\"keyword\">int</span> key)</span> </span>&#123;</span><br><span class=\"line\">    node * p, *q = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    p = sl-&gt;header;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> k = sl-&gt;level;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = k<span class=\"number\">-1</span>; i &gt;= <span class=\"number\">0</span>; i--) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> ((q = p-&gt;forward[i]) &amp;&amp; q-&gt;key &lt;= key) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (q-&gt;key == key) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">return</span> q-&gt;value;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            p = q;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p></p><h3 id=\"第三节\">应用场景</h3><br>如前面说道的，老夫在leveldb的memtable.c看到这一实现的， Redis也是用到了这样的设计，看来KV的设计对skiplist有偏好，leveldb需要内存中存储的是有序的key-val键值对, 作为一个内存数据库，快速是很重要的，特别是数据量大的时候。牺牲了部分空间(冗余的指针)换取时间,达到O(logn)的效果<p></p>\n<p></p><h3>引用资料</h3><p></p>\n<ul>\n<li><a href=\"http://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8\" target=\"_blank\" rel=\"noopener\">wikipedia</a> </li>\n<li><a href=\"http://blog.csdn.net/ict2014/article/details/17394259\" target=\"_blank\" rel=\"noopener\">skiplist讲解</a></li>\n<li><a href=\"https://github.com/zheng-ji/ToyCollection/skiplist\" target=\"_blank\" rel=\"noopener\">source code</a></li>\n</ul>\n"},{"layout":"post","title":"深入 strtok 函数","date":"2014-02-05T08:35:00.000Z","comments":1,"keywords":"strtok","description":"strtok源码","_content":"\n下午在写代码的时候用到了 strtok , 曾经是用过该函数的, 但每次书写都需要翻阅 C++ manual,而且需要多次调试, 每次需要用的时候速查, 看似解决问题，下次需要的时候又忘掉了。反而浪费时间遂决心去阅读源码。\n\n### Man strtok\n```c\nstrtok的函数原型为:\nchar *strtok(char *s, char *delim)\n```\n功能以包含在 delim 中的字符为分界符，将s切分成一个个子串；\n如果s为空值NULL，则函数保存的指针 SAVE_PTR 在下一次调用中将作为起始位置，\n这里说到的 save_ptr 是啥？还未知，\n但可以知道s在初次调用时为原始字符串，获取第一个分割得到的字符串，\n之后传进的参数为NULL，逐次获取字符串，当返回值为NULL的时候，解析该字符串结束\n\n### How to use?\n```c\nchar s[100] = \" zheng-ji is so stupid\";\nchar *del = \" \";\nchar *token ;\ntoken = strtok(s, del);\nwhile(token != NULL) {\n    printf(\"%s\\n\", token);\n    token = strtok(NULL, del);\n}\n```\n\n输出：\n\n```\nzheng-ji\nis\nso\nstupid\n```\n\n### 探究save_ptr\n\n```c\nstatic char *olds;\nchar * strtok (char *s，const char *delim）{\n    char *token;\n    if (s == NULL) s = olds;\n    /*将指针移到第一个非delim中的字符的位置*/\n    s += strspn (s, delim); \n    if (*s == '\\0') {\n        olds = s;\n        return NULL;\n    }\n    /*获取到delim中字符在字符串s中第一次出现的位置*/\n    token = s;\n    s = strpbrk (token, delim);\n    if (s == NULL)\n        olds = __rawmemchr (token, '\\0');\n    else {\n        /*重新给old赋值 */\n        *s = '\\0';\n        olds = s + 1;\n    }\n    return token;\n}\n```\n\n源码告知我们:\n\n+ 之前我们觉得神奇的SAVE_PTR(源码中为 static char * olds)原来是个静态字符指针，每次调用都被赋值。\n+ 如果第一位出现了需要被删除的字符，是会被跳过的。\n+ 如果传入的s为NULL，则将olds 作为继续解析的字符串。\n+ 该函数会修改原有的字符串。\n+ 非线程安全的函数，由于用到了静态全局变量，因此当有多个线程同时调用这个函数的时候就会出现问题.这个静态的指针变量就会变的混乱。同时在同一个程序中同时有两个字符串要解析，并且同时进行解析也是会出错的。\n","source":"_posts/2014-02-05-shen-ru-strtokhan-shu.markdown","raw":"---\nlayout: post\ntitle: \"深入 strtok 函数\"\ndate: 2014-02-05 16:35\ncomments: true\ncategories: Programe \nkeywords: strtok\ndescription: strtok源码\n---\n\n下午在写代码的时候用到了 strtok , 曾经是用过该函数的, 但每次书写都需要翻阅 C++ manual,而且需要多次调试, 每次需要用的时候速查, 看似解决问题，下次需要的时候又忘掉了。反而浪费时间遂决心去阅读源码。\n\n### Man strtok\n```c\nstrtok的函数原型为:\nchar *strtok(char *s, char *delim)\n```\n功能以包含在 delim 中的字符为分界符，将s切分成一个个子串；\n如果s为空值NULL，则函数保存的指针 SAVE_PTR 在下一次调用中将作为起始位置，\n这里说到的 save_ptr 是啥？还未知，\n但可以知道s在初次调用时为原始字符串，获取第一个分割得到的字符串，\n之后传进的参数为NULL，逐次获取字符串，当返回值为NULL的时候，解析该字符串结束\n\n### How to use?\n```c\nchar s[100] = \" zheng-ji is so stupid\";\nchar *del = \" \";\nchar *token ;\ntoken = strtok(s, del);\nwhile(token != NULL) {\n    printf(\"%s\\n\", token);\n    token = strtok(NULL, del);\n}\n```\n\n输出：\n\n```\nzheng-ji\nis\nso\nstupid\n```\n\n### 探究save_ptr\n\n```c\nstatic char *olds;\nchar * strtok (char *s，const char *delim）{\n    char *token;\n    if (s == NULL) s = olds;\n    /*将指针移到第一个非delim中的字符的位置*/\n    s += strspn (s, delim); \n    if (*s == '\\0') {\n        olds = s;\n        return NULL;\n    }\n    /*获取到delim中字符在字符串s中第一次出现的位置*/\n    token = s;\n    s = strpbrk (token, delim);\n    if (s == NULL)\n        olds = __rawmemchr (token, '\\0');\n    else {\n        /*重新给old赋值 */\n        *s = '\\0';\n        olds = s + 1;\n    }\n    return token;\n}\n```\n\n源码告知我们:\n\n+ 之前我们觉得神奇的SAVE_PTR(源码中为 static char * olds)原来是个静态字符指针，每次调用都被赋值。\n+ 如果第一位出现了需要被删除的字符，是会被跳过的。\n+ 如果传入的s为NULL，则将olds 作为继续解析的字符串。\n+ 该函数会修改原有的字符串。\n+ 非线程安全的函数，由于用到了静态全局变量，因此当有多个线程同时调用这个函数的时候就会出现问题.这个静态的指针变量就会变的混乱。同时在同一个程序中同时有两个字符串要解析，并且同时进行解析也是会出错的。\n","slug":"2014-02-05-shen-ru-strtokhan-shu","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd920020nctjqw3i6p3q","content":"<p>下午在写代码的时候用到了 strtok , 曾经是用过该函数的, 但每次书写都需要翻阅 C++ manual,而且需要多次调试, 每次需要用的时候速查, 看似解决问题，下次需要的时候又忘掉了。反而浪费时间遂决心去阅读源码。</p>\n<h3 id=\"Man-strtok\"><a href=\"#Man-strtok\" class=\"headerlink\" title=\"Man strtok\"></a>Man strtok</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">strtok的函数原型为:</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> *<span class=\"title\">strtok</span><span class=\"params\">(<span class=\"keyword\">char</span> *s, <span class=\"keyword\">char</span> *delim)</span></span></span><br></pre></td></tr></table></figure>\n<p>功能以包含在 delim 中的字符为分界符，将s切分成一个个子串；<br>如果s为空值NULL，则函数保存的指针 SAVE_PTR 在下一次调用中将作为起始位置，<br>这里说到的 save_ptr 是啥？还未知，<br>但可以知道s在初次调用时为原始字符串，获取第一个分割得到的字符串，<br>之后传进的参数为NULL，逐次获取字符串，当返回值为NULL的时候，解析该字符串结束</p>\n<h3 id=\"How-to-use\"><a href=\"#How-to-use\" class=\"headerlink\" title=\"How to use?\"></a>How to use?</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> s[<span class=\"number\">100</span>] = <span class=\"string\">\" zheng-ji is so stupid\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">char</span> *del = <span class=\"string\">\" \"</span>;</span><br><span class=\"line\"><span class=\"keyword\">char</span> *token ;</span><br><span class=\"line\">token = strtok(s, del);</span><br><span class=\"line\"><span class=\"keyword\">while</span>(token != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%s\\n\"</span>, token);</span><br><span class=\"line\">    token = strtok(<span class=\"literal\">NULL</span>, del);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>输出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zheng-ji</span><br><span class=\"line\">is</span><br><span class=\"line\">so</span><br><span class=\"line\">stupid</span><br></pre></td></tr></table></figure>\n<h3 id=\"探究save-ptr\"><a href=\"#探究save-ptr\" class=\"headerlink\" title=\"探究save_ptr\"></a>探究save_ptr</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"keyword\">char</span> *olds;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> * <span class=\"title\">strtok</span> <span class=\"params\">(<span class=\"keyword\">char</span> *s，<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *delim）&#123;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">    <span class=\"keyword\">char</span> *token;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">    <span class=\"keyword\">if</span> (s == <span class=\"literal\">NULL</span>)</span> s </span>= olds;</span><br><span class=\"line\">    <span class=\"comment\">/*将指针移到第一个非delim中的字符的位置*/</span></span><br><span class=\"line\">    s += <span class=\"built_in\">strspn</span> (s, delim); </span><br><span class=\"line\">    <span class=\"keyword\">if</span> (*s == <span class=\"string\">'\\0'</span>) &#123;</span><br><span class=\"line\">        olds = s;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/*获取到delim中字符在字符串s中第一次出现的位置*/</span></span><br><span class=\"line\">    token = s;</span><br><span class=\"line\">    s = <span class=\"built_in\">strpbrk</span> (token, delim);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        olds = __rawmemchr (token, <span class=\"string\">'\\0'</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">/*重新给old赋值 */</span></span><br><span class=\"line\">        *s = <span class=\"string\">'\\0'</span>;</span><br><span class=\"line\">        olds = s + <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> token;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>源码告知我们:</p>\n<ul>\n<li>之前我们觉得神奇的SAVE_PTR(源码中为 static char * olds)原来是个静态字符指针，每次调用都被赋值。</li>\n<li>如果第一位出现了需要被删除的字符，是会被跳过的。</li>\n<li>如果传入的s为NULL，则将olds 作为继续解析的字符串。</li>\n<li>该函数会修改原有的字符串。</li>\n<li>非线程安全的函数，由于用到了静态全局变量，因此当有多个线程同时调用这个函数的时候就会出现问题.这个静态的指针变量就会变的混乱。同时在同一个程序中同时有两个字符串要解析，并且同时进行解析也是会出错的。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>下午在写代码的时候用到了 strtok , 曾经是用过该函数的, 但每次书写都需要翻阅 C++ manual,而且需要多次调试, 每次需要用的时候速查, 看似解决问题，下次需要的时候又忘掉了。反而浪费时间遂决心去阅读源码。</p>\n<h3 id=\"Man-strtok\"><a href=\"#Man-strtok\" class=\"headerlink\" title=\"Man strtok\"></a>Man strtok</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">strtok的函数原型为:</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> *<span class=\"title\">strtok</span><span class=\"params\">(<span class=\"keyword\">char</span> *s, <span class=\"keyword\">char</span> *delim)</span></span></span><br></pre></td></tr></table></figure>\n<p>功能以包含在 delim 中的字符为分界符，将s切分成一个个子串；<br>如果s为空值NULL，则函数保存的指针 SAVE_PTR 在下一次调用中将作为起始位置，<br>这里说到的 save_ptr 是啥？还未知，<br>但可以知道s在初次调用时为原始字符串，获取第一个分割得到的字符串，<br>之后传进的参数为NULL，逐次获取字符串，当返回值为NULL的时候，解析该字符串结束</p>\n<h3 id=\"How-to-use\"><a href=\"#How-to-use\" class=\"headerlink\" title=\"How to use?\"></a>How to use?</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> s[<span class=\"number\">100</span>] = <span class=\"string\">\" zheng-ji is so stupid\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">char</span> *del = <span class=\"string\">\" \"</span>;</span><br><span class=\"line\"><span class=\"keyword\">char</span> *token ;</span><br><span class=\"line\">token = strtok(s, del);</span><br><span class=\"line\"><span class=\"keyword\">while</span>(token != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%s\\n\"</span>, token);</span><br><span class=\"line\">    token = strtok(<span class=\"literal\">NULL</span>, del);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>输出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zheng-ji</span><br><span class=\"line\">is</span><br><span class=\"line\">so</span><br><span class=\"line\">stupid</span><br></pre></td></tr></table></figure>\n<h3 id=\"探究save-ptr\"><a href=\"#探究save-ptr\" class=\"headerlink\" title=\"探究save_ptr\"></a>探究save_ptr</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"keyword\">char</span> *olds;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> * <span class=\"title\">strtok</span> <span class=\"params\">(<span class=\"keyword\">char</span> *s，<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *delim）&#123;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">    <span class=\"keyword\">char</span> *token;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">    <span class=\"keyword\">if</span> (s == <span class=\"literal\">NULL</span>)</span> s </span>= olds;</span><br><span class=\"line\">    <span class=\"comment\">/*将指针移到第一个非delim中的字符的位置*/</span></span><br><span class=\"line\">    s += <span class=\"built_in\">strspn</span> (s, delim); </span><br><span class=\"line\">    <span class=\"keyword\">if</span> (*s == <span class=\"string\">'\\0'</span>) &#123;</span><br><span class=\"line\">        olds = s;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/*获取到delim中字符在字符串s中第一次出现的位置*/</span></span><br><span class=\"line\">    token = s;</span><br><span class=\"line\">    s = <span class=\"built_in\">strpbrk</span> (token, delim);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        olds = __rawmemchr (token, <span class=\"string\">'\\0'</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">/*重新给old赋值 */</span></span><br><span class=\"line\">        *s = <span class=\"string\">'\\0'</span>;</span><br><span class=\"line\">        olds = s + <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> token;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>源码告知我们:</p>\n<ul>\n<li>之前我们觉得神奇的SAVE_PTR(源码中为 static char * olds)原来是个静态字符指针，每次调用都被赋值。</li>\n<li>如果第一位出现了需要被删除的字符，是会被跳过的。</li>\n<li>如果传入的s为NULL，则将olds 作为继续解析的字符串。</li>\n<li>该函数会修改原有的字符串。</li>\n<li>非线程安全的函数，由于用到了静态全局变量，因此当有多个线程同时调用这个函数的时候就会出现问题.这个静态的指针变量就会变的混乱。同时在同一个程序中同时有两个字符串要解析，并且同时进行解析也是会出错的。</li>\n</ul>\n"},{"layout":"post","title":"socket黏包引发的YY","date":"2014-02-24T15:11:00.000Z","comments":1,"keywords":"socket 粘包","description":"socket 粘包","_content":"这段时间在帮朋友写一个网络程序, 这个过程中重温了原生的socket编程, 在调试中遇到了一些问题，为此好好回顾了计算机网络, 学生时代学的不好啊！ 并由此引出的思考, 遂做笔记如下。\n\n如果你也写过socket程序，作为一个没有太多经验的人，有时候你会发现明明要发送的数据只发送了一部分；或者接收到的数据里面包含发送端几次发送过来的数据。于是悲剧就发生在一行行 debug 之中，特别是夜深人静的时候，双眼泛着血丝, 带着一阵阵脊椎的刺痛。\n\n后来从 Google 那里知道前者是粘包，后者是半包状况。\n\n### 什么是粘包和半包\n为什么会出现粘包与半包状况，是因为 TCP 是基于数据流的传输协议，通常是建立连接之后，就持续的像水流一样发送数据，直到关闭连接，也就是我们传说中的长连接. (PS: HTTP 1.1以后keep alive也是保持长连接，无状态与否是业务层面来决定的，比如HTTP 本身是无状态的，但我们可以通过 Cookie Session 来使其有状态, HTTP 其下层 协议是 TCP，两者本身没有可比性。)\n\n**粘包**：发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾, 导致了接收的数据冗杂\n\n**半包**: 接收方没有接收完整的一个包。\n\n### 可能导致的原因\n\n+ 粘包可能是 TCP 协议造成的，TCP 为提高传输效率(优化算法)，发送方往往会收集足够多的数据才发送一包数据，导致了接收方粘包。或者是由于接收方进程来不及接收数据，导致数据在接收端缓冲区黏住了。\n\n+ 半包可能是因为TCP为提高传输效率, 分配一个足够大的包，导致发送端的数据太大，以至于接收方并不一定能一次接受完。\n\n### 怎么避免\n我们需要了解的网络知识是。Socket内部默认的收发缓冲区大小是8k左右， 根据业务重新配置这个值，让系统达到最佳状态, 可以用SetSockOpt 函数配置。\n\n在谈及TCP/UDP 发包的时候，势必需要了解 IP 层和链路成会将包分片发送, 如果分片的大小太大就可能导致丢包的几率大， 特别是对于 UDP 这样不可靠的传输协议, 包太小又导致效率低， 广域网的分片大小是几十字节，\n\n好了，该谈谈怎么避免粘包和半包。\n如果你阅读过网络通信的代码，你大概会看到一个包的设计通常会由 Header 部分和 Body 部分，Header 部分通常会有一个域叫做消息长度，通常是为了给接收端做预处理用的. 曾经天真的以为这样的设计是多余的。\n\n通常是 包头+包长+包体 的协议形式(好吧扯淡这么多这是个重点)，当服务器端获取到指定的包长时才说明获取完整。\n\n### 接收端的处理\n发包的时候一旦有包的长度那么接收方可以按长度组合。\n\n+ TCP 作为面向连接的数据流协议， 是像水流一样发包，不会整个包到达。\n+ UDP 是数据报的协议， 接收端是整包到达的。 \n\n你会问，如果接收端的缓冲区比较小，处理 TCP 的时候可以持续收数据，返回实际接受的长度， 这点在使用 epoll 边缘触发的时候需要特别注意，它只被内核唤醒一次状态的改变。而 UDP 由于是整个包接收的，大于接收端缓冲区的数据就会被丢弃返回 WSAEMSGSIZE 。 \n\n感觉这样的理解是可以对面向数据流的TCP连接与数据报的UDP连接有更深的认识。\n\n### 实时网游中多数使用什么网络协议呢\n这几天一直在抠网络的知识，然后也思考这个问题，虽然以前也想过。\n\nTCP 是可靠的传输协议，他具有超时重传， 拥塞控制， 流量控制等，这是靠协议来保证的，因此他的数据传输会有一定的代价 ，体现在传输的开销以及时延会比UDP大， UDP 仅仅是将数据包提供给对方，不做任何多余(可能这个词用的不好)的协议上保障。 \n\n#### 我们来假设这样的场景：\n\n一个实时网络游戏上，玩家A发包给玩家B，如果采用TCP 协议， 因为网络波动 TCP 会超时重传导致数据发送延迟，导致 玩家B在做下一个动作的时候收到的还是上次动作的消息，这对用户体验不利。 反之如果是 UDP 的话，由于其开销小，而且尽力而为将数据发送给玩家B， 碰到丢包的时候就忽略之，只要新的包能被接收到用户也是无痛感知的。如果真的需要保证安全性，我们可以兼用TCP 来做一些道具购买这样的安全性功能, 保证消息的可靠传输。\n\n遗憾的是， 我没做过网游，只能自己YY, 很多时候看不懂大神云风的博客，就一点点去抠去代入，终究还是觉得环境很重要, 如果有一天能将其所有文章都领会我想会是件令人高兴的事。 我又YY了。。。\n\n夜深了,晚安, 愿有梦的程序猿好梦。\n\n","source":"_posts/2014-02-24-socketnian-bao.markdown","raw":"---\nlayout: post\ntitle: \"socket黏包引发的YY\"\ndate: 2014-02-24 23:11\ncomments: true\ncategories: NetWork \nkeywords: socket 粘包\ndescription: socket 粘包 \n---\n这段时间在帮朋友写一个网络程序, 这个过程中重温了原生的socket编程, 在调试中遇到了一些问题，为此好好回顾了计算机网络, 学生时代学的不好啊！ 并由此引出的思考, 遂做笔记如下。\n\n如果你也写过socket程序，作为一个没有太多经验的人，有时候你会发现明明要发送的数据只发送了一部分；或者接收到的数据里面包含发送端几次发送过来的数据。于是悲剧就发生在一行行 debug 之中，特别是夜深人静的时候，双眼泛着血丝, 带着一阵阵脊椎的刺痛。\n\n后来从 Google 那里知道前者是粘包，后者是半包状况。\n\n### 什么是粘包和半包\n为什么会出现粘包与半包状况，是因为 TCP 是基于数据流的传输协议，通常是建立连接之后，就持续的像水流一样发送数据，直到关闭连接，也就是我们传说中的长连接. (PS: HTTP 1.1以后keep alive也是保持长连接，无状态与否是业务层面来决定的，比如HTTP 本身是无状态的，但我们可以通过 Cookie Session 来使其有状态, HTTP 其下层 协议是 TCP，两者本身没有可比性。)\n\n**粘包**：发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾, 导致了接收的数据冗杂\n\n**半包**: 接收方没有接收完整的一个包。\n\n### 可能导致的原因\n\n+ 粘包可能是 TCP 协议造成的，TCP 为提高传输效率(优化算法)，发送方往往会收集足够多的数据才发送一包数据，导致了接收方粘包。或者是由于接收方进程来不及接收数据，导致数据在接收端缓冲区黏住了。\n\n+ 半包可能是因为TCP为提高传输效率, 分配一个足够大的包，导致发送端的数据太大，以至于接收方并不一定能一次接受完。\n\n### 怎么避免\n我们需要了解的网络知识是。Socket内部默认的收发缓冲区大小是8k左右， 根据业务重新配置这个值，让系统达到最佳状态, 可以用SetSockOpt 函数配置。\n\n在谈及TCP/UDP 发包的时候，势必需要了解 IP 层和链路成会将包分片发送, 如果分片的大小太大就可能导致丢包的几率大， 特别是对于 UDP 这样不可靠的传输协议, 包太小又导致效率低， 广域网的分片大小是几十字节，\n\n好了，该谈谈怎么避免粘包和半包。\n如果你阅读过网络通信的代码，你大概会看到一个包的设计通常会由 Header 部分和 Body 部分，Header 部分通常会有一个域叫做消息长度，通常是为了给接收端做预处理用的. 曾经天真的以为这样的设计是多余的。\n\n通常是 包头+包长+包体 的协议形式(好吧扯淡这么多这是个重点)，当服务器端获取到指定的包长时才说明获取完整。\n\n### 接收端的处理\n发包的时候一旦有包的长度那么接收方可以按长度组合。\n\n+ TCP 作为面向连接的数据流协议， 是像水流一样发包，不会整个包到达。\n+ UDP 是数据报的协议， 接收端是整包到达的。 \n\n你会问，如果接收端的缓冲区比较小，处理 TCP 的时候可以持续收数据，返回实际接受的长度， 这点在使用 epoll 边缘触发的时候需要特别注意，它只被内核唤醒一次状态的改变。而 UDP 由于是整个包接收的，大于接收端缓冲区的数据就会被丢弃返回 WSAEMSGSIZE 。 \n\n感觉这样的理解是可以对面向数据流的TCP连接与数据报的UDP连接有更深的认识。\n\n### 实时网游中多数使用什么网络协议呢\n这几天一直在抠网络的知识，然后也思考这个问题，虽然以前也想过。\n\nTCP 是可靠的传输协议，他具有超时重传， 拥塞控制， 流量控制等，这是靠协议来保证的，因此他的数据传输会有一定的代价 ，体现在传输的开销以及时延会比UDP大， UDP 仅仅是将数据包提供给对方，不做任何多余(可能这个词用的不好)的协议上保障。 \n\n#### 我们来假设这样的场景：\n\n一个实时网络游戏上，玩家A发包给玩家B，如果采用TCP 协议， 因为网络波动 TCP 会超时重传导致数据发送延迟，导致 玩家B在做下一个动作的时候收到的还是上次动作的消息，这对用户体验不利。 反之如果是 UDP 的话，由于其开销小，而且尽力而为将数据发送给玩家B， 碰到丢包的时候就忽略之，只要新的包能被接收到用户也是无痛感知的。如果真的需要保证安全性，我们可以兼用TCP 来做一些道具购买这样的安全性功能, 保证消息的可靠传输。\n\n遗憾的是， 我没做过网游，只能自己YY, 很多时候看不懂大神云风的博客，就一点点去抠去代入，终究还是觉得环境很重要, 如果有一天能将其所有文章都领会我想会是件令人高兴的事。 我又YY了。。。\n\n夜深了,晚安, 愿有梦的程序猿好梦。\n\n","slug":"2014-02-24-socketnian-bao","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd930022nctjfskhyteo","content":"<p>这段时间在帮朋友写一个网络程序, 这个过程中重温了原生的socket编程, 在调试中遇到了一些问题，为此好好回顾了计算机网络, 学生时代学的不好啊！ 并由此引出的思考, 遂做笔记如下。</p>\n<p>如果你也写过socket程序，作为一个没有太多经验的人，有时候你会发现明明要发送的数据只发送了一部分；或者接收到的数据里面包含发送端几次发送过来的数据。于是悲剧就发生在一行行 debug 之中，特别是夜深人静的时候，双眼泛着血丝, 带着一阵阵脊椎的刺痛。</p>\n<p>后来从 Google 那里知道前者是粘包，后者是半包状况。</p>\n<h3 id=\"什么是粘包和半包\"><a href=\"#什么是粘包和半包\" class=\"headerlink\" title=\"什么是粘包和半包\"></a>什么是粘包和半包</h3><p>为什么会出现粘包与半包状况，是因为 TCP 是基于数据流的传输协议，通常是建立连接之后，就持续的像水流一样发送数据，直到关闭连接，也就是我们传说中的长连接. (PS: HTTP 1.1以后keep alive也是保持长连接，无状态与否是业务层面来决定的，比如HTTP 本身是无状态的，但我们可以通过 Cookie Session 来使其有状态, HTTP 其下层 协议是 TCP，两者本身没有可比性。)</p>\n<p><strong>粘包</strong>：发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾, 导致了接收的数据冗杂</p>\n<p><strong>半包</strong>: 接收方没有接收完整的一个包。</p>\n<h3 id=\"可能导致的原因\"><a href=\"#可能导致的原因\" class=\"headerlink\" title=\"可能导致的原因\"></a>可能导致的原因</h3><ul>\n<li><p>粘包可能是 TCP 协议造成的，TCP 为提高传输效率(优化算法)，发送方往往会收集足够多的数据才发送一包数据，导致了接收方粘包。或者是由于接收方进程来不及接收数据，导致数据在接收端缓冲区黏住了。</p>\n</li>\n<li><p>半包可能是因为TCP为提高传输效率, 分配一个足够大的包，导致发送端的数据太大，以至于接收方并不一定能一次接受完。</p>\n</li>\n</ul>\n<h3 id=\"怎么避免\"><a href=\"#怎么避免\" class=\"headerlink\" title=\"怎么避免\"></a>怎么避免</h3><p>我们需要了解的网络知识是。Socket内部默认的收发缓冲区大小是8k左右， 根据业务重新配置这个值，让系统达到最佳状态, 可以用SetSockOpt 函数配置。</p>\n<p>在谈及TCP/UDP 发包的时候，势必需要了解 IP 层和链路成会将包分片发送, 如果分片的大小太大就可能导致丢包的几率大， 特别是对于 UDP 这样不可靠的传输协议, 包太小又导致效率低， 广域网的分片大小是几十字节，</p>\n<p>好了，该谈谈怎么避免粘包和半包。<br>如果你阅读过网络通信的代码，你大概会看到一个包的设计通常会由 Header 部分和 Body 部分，Header 部分通常会有一个域叫做消息长度，通常是为了给接收端做预处理用的. 曾经天真的以为这样的设计是多余的。</p>\n<p>通常是 包头+包长+包体 的协议形式(好吧扯淡这么多这是个重点)，当服务器端获取到指定的包长时才说明获取完整。</p>\n<h3 id=\"接收端的处理\"><a href=\"#接收端的处理\" class=\"headerlink\" title=\"接收端的处理\"></a>接收端的处理</h3><p>发包的时候一旦有包的长度那么接收方可以按长度组合。</p>\n<ul>\n<li>TCP 作为面向连接的数据流协议， 是像水流一样发包，不会整个包到达。</li>\n<li>UDP 是数据报的协议， 接收端是整包到达的。 </li>\n</ul>\n<p>你会问，如果接收端的缓冲区比较小，处理 TCP 的时候可以持续收数据，返回实际接受的长度， 这点在使用 epoll 边缘触发的时候需要特别注意，它只被内核唤醒一次状态的改变。而 UDP 由于是整个包接收的，大于接收端缓冲区的数据就会被丢弃返回 WSAEMSGSIZE 。 </p>\n<p>感觉这样的理解是可以对面向数据流的TCP连接与数据报的UDP连接有更深的认识。</p>\n<h3 id=\"实时网游中多数使用什么网络协议呢\"><a href=\"#实时网游中多数使用什么网络协议呢\" class=\"headerlink\" title=\"实时网游中多数使用什么网络协议呢\"></a>实时网游中多数使用什么网络协议呢</h3><p>这几天一直在抠网络的知识，然后也思考这个问题，虽然以前也想过。</p>\n<p>TCP 是可靠的传输协议，他具有超时重传， 拥塞控制， 流量控制等，这是靠协议来保证的，因此他的数据传输会有一定的代价 ，体现在传输的开销以及时延会比UDP大， UDP 仅仅是将数据包提供给对方，不做任何多余(可能这个词用的不好)的协议上保障。 </p>\n<h4 id=\"我们来假设这样的场景：\"><a href=\"#我们来假设这样的场景：\" class=\"headerlink\" title=\"我们来假设这样的场景：\"></a>我们来假设这样的场景：</h4><p>一个实时网络游戏上，玩家A发包给玩家B，如果采用TCP 协议， 因为网络波动 TCP 会超时重传导致数据发送延迟，导致 玩家B在做下一个动作的时候收到的还是上次动作的消息，这对用户体验不利。 反之如果是 UDP 的话，由于其开销小，而且尽力而为将数据发送给玩家B， 碰到丢包的时候就忽略之，只要新的包能被接收到用户也是无痛感知的。如果真的需要保证安全性，我们可以兼用TCP 来做一些道具购买这样的安全性功能, 保证消息的可靠传输。</p>\n<p>遗憾的是， 我没做过网游，只能自己YY, 很多时候看不懂大神云风的博客，就一点点去抠去代入，终究还是觉得环境很重要, 如果有一天能将其所有文章都领会我想会是件令人高兴的事。 我又YY了。。。</p>\n<p>夜深了,晚安, 愿有梦的程序猿好梦。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>这段时间在帮朋友写一个网络程序, 这个过程中重温了原生的socket编程, 在调试中遇到了一些问题，为此好好回顾了计算机网络, 学生时代学的不好啊！ 并由此引出的思考, 遂做笔记如下。</p>\n<p>如果你也写过socket程序，作为一个没有太多经验的人，有时候你会发现明明要发送的数据只发送了一部分；或者接收到的数据里面包含发送端几次发送过来的数据。于是悲剧就发生在一行行 debug 之中，特别是夜深人静的时候，双眼泛着血丝, 带着一阵阵脊椎的刺痛。</p>\n<p>后来从 Google 那里知道前者是粘包，后者是半包状况。</p>\n<h3 id=\"什么是粘包和半包\"><a href=\"#什么是粘包和半包\" class=\"headerlink\" title=\"什么是粘包和半包\"></a>什么是粘包和半包</h3><p>为什么会出现粘包与半包状况，是因为 TCP 是基于数据流的传输协议，通常是建立连接之后，就持续的像水流一样发送数据，直到关闭连接，也就是我们传说中的长连接. (PS: HTTP 1.1以后keep alive也是保持长连接，无状态与否是业务层面来决定的，比如HTTP 本身是无状态的，但我们可以通过 Cookie Session 来使其有状态, HTTP 其下层 协议是 TCP，两者本身没有可比性。)</p>\n<p><strong>粘包</strong>：发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾, 导致了接收的数据冗杂</p>\n<p><strong>半包</strong>: 接收方没有接收完整的一个包。</p>\n<h3 id=\"可能导致的原因\"><a href=\"#可能导致的原因\" class=\"headerlink\" title=\"可能导致的原因\"></a>可能导致的原因</h3><ul>\n<li><p>粘包可能是 TCP 协议造成的，TCP 为提高传输效率(优化算法)，发送方往往会收集足够多的数据才发送一包数据，导致了接收方粘包。或者是由于接收方进程来不及接收数据，导致数据在接收端缓冲区黏住了。</p>\n</li>\n<li><p>半包可能是因为TCP为提高传输效率, 分配一个足够大的包，导致发送端的数据太大，以至于接收方并不一定能一次接受完。</p>\n</li>\n</ul>\n<h3 id=\"怎么避免\"><a href=\"#怎么避免\" class=\"headerlink\" title=\"怎么避免\"></a>怎么避免</h3><p>我们需要了解的网络知识是。Socket内部默认的收发缓冲区大小是8k左右， 根据业务重新配置这个值，让系统达到最佳状态, 可以用SetSockOpt 函数配置。</p>\n<p>在谈及TCP/UDP 发包的时候，势必需要了解 IP 层和链路成会将包分片发送, 如果分片的大小太大就可能导致丢包的几率大， 特别是对于 UDP 这样不可靠的传输协议, 包太小又导致效率低， 广域网的分片大小是几十字节，</p>\n<p>好了，该谈谈怎么避免粘包和半包。<br>如果你阅读过网络通信的代码，你大概会看到一个包的设计通常会由 Header 部分和 Body 部分，Header 部分通常会有一个域叫做消息长度，通常是为了给接收端做预处理用的. 曾经天真的以为这样的设计是多余的。</p>\n<p>通常是 包头+包长+包体 的协议形式(好吧扯淡这么多这是个重点)，当服务器端获取到指定的包长时才说明获取完整。</p>\n<h3 id=\"接收端的处理\"><a href=\"#接收端的处理\" class=\"headerlink\" title=\"接收端的处理\"></a>接收端的处理</h3><p>发包的时候一旦有包的长度那么接收方可以按长度组合。</p>\n<ul>\n<li>TCP 作为面向连接的数据流协议， 是像水流一样发包，不会整个包到达。</li>\n<li>UDP 是数据报的协议， 接收端是整包到达的。 </li>\n</ul>\n<p>你会问，如果接收端的缓冲区比较小，处理 TCP 的时候可以持续收数据，返回实际接受的长度， 这点在使用 epoll 边缘触发的时候需要特别注意，它只被内核唤醒一次状态的改变。而 UDP 由于是整个包接收的，大于接收端缓冲区的数据就会被丢弃返回 WSAEMSGSIZE 。 </p>\n<p>感觉这样的理解是可以对面向数据流的TCP连接与数据报的UDP连接有更深的认识。</p>\n<h3 id=\"实时网游中多数使用什么网络协议呢\"><a href=\"#实时网游中多数使用什么网络协议呢\" class=\"headerlink\" title=\"实时网游中多数使用什么网络协议呢\"></a>实时网游中多数使用什么网络协议呢</h3><p>这几天一直在抠网络的知识，然后也思考这个问题，虽然以前也想过。</p>\n<p>TCP 是可靠的传输协议，他具有超时重传， 拥塞控制， 流量控制等，这是靠协议来保证的，因此他的数据传输会有一定的代价 ，体现在传输的开销以及时延会比UDP大， UDP 仅仅是将数据包提供给对方，不做任何多余(可能这个词用的不好)的协议上保障。 </p>\n<h4 id=\"我们来假设这样的场景：\"><a href=\"#我们来假设这样的场景：\" class=\"headerlink\" title=\"我们来假设这样的场景：\"></a>我们来假设这样的场景：</h4><p>一个实时网络游戏上，玩家A发包给玩家B，如果采用TCP 协议， 因为网络波动 TCP 会超时重传导致数据发送延迟，导致 玩家B在做下一个动作的时候收到的还是上次动作的消息，这对用户体验不利。 反之如果是 UDP 的话，由于其开销小，而且尽力而为将数据发送给玩家B， 碰到丢包的时候就忽略之，只要新的包能被接收到用户也是无痛感知的。如果真的需要保证安全性，我们可以兼用TCP 来做一些道具购买这样的安全性功能, 保证消息的可靠传输。</p>\n<p>遗憾的是， 我没做过网游，只能自己YY, 很多时候看不懂大神云风的博客，就一点点去抠去代入，终究还是觉得环境很重要, 如果有一天能将其所有文章都领会我想会是件令人高兴的事。 我又YY了。。。</p>\n<p>夜深了,晚安, 愿有梦的程序猿好梦。</p>\n"},{"layout":"post","title":" Expect 与系统自动交互","date":"2014-03-13T15:05:00.000Z","comments":1,"keywords":"expect语言","description":"expect语言","_content":"\n在`linux`下 做一些操作的时候，比如使用 *scp*, *telnet* 等命令，通常系统会让你输入密码，你只好乖乖地停下来输入。倘若你希望批量执行一个脚本中得所有命令，系统执行到某句命令的时候停下来让你输入密码，就比较囧了。于是你感慨，如果是一气呵成多省事啊。\n\n这个时候，你可以使用 *expect* 语言帮我们解决问题。\n\n###官方定义\n> Expect是一个用来实现自动交互功能的软件套件 (Expect [is a] software suite for automating interactive tools)\n\nexpect 是 [Don Libes](http://en.wikipedia.org/wiki/Don_Libes) 编写的免费编程工具语言, 由expect-send对组成：\n\nexpect等待输出中输出特定的字符，通常是一个提示符，然后发送特定的响应。\n\n-------------------------------------------------\n\n先来个 helloworld, 注意需要在exp脚本前面加上 `#!/usr/bin/expect`\n\n```sh\n#!/usr/bin/expect\nsend_user \"hello world\"\n```\n\n这里的 send_user 类似 echo \n\n### 常见用法\n\n```\nset i 0    \nset user [lindex $argv 0]\nset timeout 300\nset i 0\nwhile { $i < 10 } {\n    puts $i;\n    incr i;\n}\n```\n\n以上分别是:\n\n+ 将0赋值给变量i;\n+ 获取脚本的第一个参数给变量user;\n+ 设置超时时间是300秒\n+ 循环使用，不多说\n\n-------------------------\n\n在 expect脚本中, 最亮点的是 spawn 会启动一个进程，由 expect 和 send 组合负责跟该进程交互, in short \n\n+ expect捕获进程需要什么信息\n+ send将这个信息发给进程\n+ expect eof与spawn对应，表示捕获终端输出信息的终止，即进程已结束\n+ expect都是使用 {}，且{, }使用时，前后需要留空格。 只要其中一项符合，就会执行该项，类似switch\n\n看完以下代码相信你就明白其魅力了 ：）\n\n```sh\n#!/usr/bin/expect\n  \nset timeout 10\nset host [lindex $argv 0]\nset username [lindex $argv 1]\nset password [lindex $argv 2]\n \nspawn ssh $username@$host\nexpect {\n    \"(yes/no)?\" {\n        send \"yes\\n\"\n        expect \"*assword:\" { send \"$password\\n\" }\n    }\n    \"*assword:\" {\n        send \"$password\\n\"\n    }\n}\n\nexpect \"$\"\nexpect eof\n```\n\n使用时, 执行如下脚本命令.  其中`expect` 捕获到 \"*assword:\", 发送 `$password` 变量,  捕获到`$`符号，表示登陆成功，结束 spawn 进程\n\n```\n./autosh.exp xxx(ip地址) xxx(用户名) xxx(密码)\n```\n\n-----------------------------\n\n感觉这样的脚本在自动化运维可以有很多运用之处, 至少让你可以在执行需要交互命令的时候跑去喝茶。\nHappy Hacking :-)\n\n\n","source":"_posts/2014-03-13-expect-yu-xi-tong-zi-dong-jiao-hu.markdown","raw":"---\nlayout: post\ntitle: \" Expect 与系统自动交互\"\ndate: 2014-03-13 23:05\ncomments: true\ncategories: Programe\nkeywords: expect语言\ndescription: expect语言\n---\n\n在`linux`下 做一些操作的时候，比如使用 *scp*, *telnet* 等命令，通常系统会让你输入密码，你只好乖乖地停下来输入。倘若你希望批量执行一个脚本中得所有命令，系统执行到某句命令的时候停下来让你输入密码，就比较囧了。于是你感慨，如果是一气呵成多省事啊。\n\n这个时候，你可以使用 *expect* 语言帮我们解决问题。\n\n###官方定义\n> Expect是一个用来实现自动交互功能的软件套件 (Expect [is a] software suite for automating interactive tools)\n\nexpect 是 [Don Libes](http://en.wikipedia.org/wiki/Don_Libes) 编写的免费编程工具语言, 由expect-send对组成：\n\nexpect等待输出中输出特定的字符，通常是一个提示符，然后发送特定的响应。\n\n-------------------------------------------------\n\n先来个 helloworld, 注意需要在exp脚本前面加上 `#!/usr/bin/expect`\n\n```sh\n#!/usr/bin/expect\nsend_user \"hello world\"\n```\n\n这里的 send_user 类似 echo \n\n### 常见用法\n\n```\nset i 0    \nset user [lindex $argv 0]\nset timeout 300\nset i 0\nwhile { $i < 10 } {\n    puts $i;\n    incr i;\n}\n```\n\n以上分别是:\n\n+ 将0赋值给变量i;\n+ 获取脚本的第一个参数给变量user;\n+ 设置超时时间是300秒\n+ 循环使用，不多说\n\n-------------------------\n\n在 expect脚本中, 最亮点的是 spawn 会启动一个进程，由 expect 和 send 组合负责跟该进程交互, in short \n\n+ expect捕获进程需要什么信息\n+ send将这个信息发给进程\n+ expect eof与spawn对应，表示捕获终端输出信息的终止，即进程已结束\n+ expect都是使用 {}，且{, }使用时，前后需要留空格。 只要其中一项符合，就会执行该项，类似switch\n\n看完以下代码相信你就明白其魅力了 ：）\n\n```sh\n#!/usr/bin/expect\n  \nset timeout 10\nset host [lindex $argv 0]\nset username [lindex $argv 1]\nset password [lindex $argv 2]\n \nspawn ssh $username@$host\nexpect {\n    \"(yes/no)?\" {\n        send \"yes\\n\"\n        expect \"*assword:\" { send \"$password\\n\" }\n    }\n    \"*assword:\" {\n        send \"$password\\n\"\n    }\n}\n\nexpect \"$\"\nexpect eof\n```\n\n使用时, 执行如下脚本命令.  其中`expect` 捕获到 \"*assword:\", 发送 `$password` 变量,  捕获到`$`符号，表示登陆成功，结束 spawn 进程\n\n```\n./autosh.exp xxx(ip地址) xxx(用户名) xxx(密码)\n```\n\n-----------------------------\n\n感觉这样的脚本在自动化运维可以有很多运用之处, 至少让你可以在执行需要交互命令的时候跑去喝茶。\nHappy Hacking :-)\n\n\n","slug":"2014-03-13-expect-yu-xi-tong-zi-dong-jiao-hu","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd940024nctjk4ml92vn","content":"<p>在<code>linux</code>下 做一些操作的时候，比如使用 <em>scp</em>, <em>telnet</em> 等命令，通常系统会让你输入密码，你只好乖乖地停下来输入。倘若你希望批量执行一个脚本中得所有命令，系统执行到某句命令的时候停下来让你输入密码，就比较囧了。于是你感慨，如果是一气呵成多省事啊。</p>\n<p>这个时候，你可以使用 <em>expect</em> 语言帮我们解决问题。</p>\n<p>###官方定义</p>\n<blockquote>\n<p>Expect是一个用来实现自动交互功能的软件套件 (Expect [is a] software suite for automating interactive tools)</p>\n</blockquote>\n<p>expect 是 <a href=\"http://en.wikipedia.org/wiki/Don_Libes\" target=\"_blank\" rel=\"noopener\">Don Libes</a> 编写的免费编程工具语言, 由expect-send对组成：</p>\n<p>expect等待输出中输出特定的字符，通常是一个提示符，然后发送特定的响应。</p>\n<hr>\n<p>先来个 helloworld, 注意需要在exp脚本前面加上 <code>#!/usr/bin/expect</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/expect</span></span><br><span class=\"line\">send_user <span class=\"string\">\"hello world\"</span></span><br></pre></td></tr></table></figure>\n<p>这里的 send_user 类似 echo </p>\n<h3 id=\"常见用法\"><a href=\"#常见用法\" class=\"headerlink\" title=\"常见用法\"></a>常见用法</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set i 0    </span><br><span class=\"line\">set user [lindex $argv 0]</span><br><span class=\"line\">set timeout 300</span><br><span class=\"line\">set i 0</span><br><span class=\"line\">while &#123; $i &lt; 10 &#125; &#123;</span><br><span class=\"line\">    puts $i;</span><br><span class=\"line\">    incr i;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上分别是:</p>\n<ul>\n<li>将0赋值给变量i;</li>\n<li>获取脚本的第一个参数给变量user;</li>\n<li>设置超时时间是300秒</li>\n<li>循环使用，不多说</li>\n</ul>\n<hr>\n<p>在 expect脚本中, 最亮点的是 spawn 会启动一个进程，由 expect 和 send 组合负责跟该进程交互, in short </p>\n<ul>\n<li>expect捕获进程需要什么信息</li>\n<li>send将这个信息发给进程</li>\n<li>expect eof与spawn对应，表示捕获终端输出信息的终止，即进程已结束</li>\n<li>expect都是使用 {}，且{, }使用时，前后需要留空格。 只要其中一项符合，就会执行该项，类似switch</li>\n</ul>\n<p>看完以下代码相信你就明白其魅力了 ：）</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/expect</span></span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"built_in\">set</span> timeout 10</span><br><span class=\"line\"><span class=\"built_in\">set</span> host [lindex <span class=\"variable\">$argv</span> 0]</span><br><span class=\"line\"><span class=\"built_in\">set</span> username [lindex <span class=\"variable\">$argv</span> 1]</span><br><span class=\"line\"><span class=\"built_in\">set</span> password [lindex <span class=\"variable\">$argv</span> 2]</span><br><span class=\"line\"> </span><br><span class=\"line\">spawn ssh <span class=\"variable\">$username</span>@<span class=\"variable\">$host</span></span><br><span class=\"line\">expect &#123;</span><br><span class=\"line\">    <span class=\"string\">\"(yes/no)?\"</span> &#123;</span><br><span class=\"line\">        send <span class=\"string\">\"yes\\n\"</span></span><br><span class=\"line\">        expect <span class=\"string\">\"*assword:\"</span> &#123; send <span class=\"string\">\"<span class=\"variable\">$password</span>\\n\"</span> &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"string\">\"*assword:\"</span> &#123;</span><br><span class=\"line\">        send <span class=\"string\">\"<span class=\"variable\">$password</span>\\n\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">expect <span class=\"string\">\"$\"</span></span><br><span class=\"line\">expect eof</span><br></pre></td></tr></table></figure>\n<p>使用时, 执行如下脚本命令.  其中<code>expect</code> 捕获到 “*assword:”, 发送 <code>$password</code> 变量,  捕获到<code>$</code>符号，表示登陆成功，结束 spawn 进程</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./autosh.exp xxx(ip地址) xxx(用户名) xxx(密码)</span><br></pre></td></tr></table></figure>\n<hr>\n<p>感觉这样的脚本在自动化运维可以有很多运用之处, 至少让你可以在执行需要交互命令的时候跑去喝茶。<br>Happy Hacking :-)</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在<code>linux</code>下 做一些操作的时候，比如使用 <em>scp</em>, <em>telnet</em> 等命令，通常系统会让你输入密码，你只好乖乖地停下来输入。倘若你希望批量执行一个脚本中得所有命令，系统执行到某句命令的时候停下来让你输入密码，就比较囧了。于是你感慨，如果是一气呵成多省事啊。</p>\n<p>这个时候，你可以使用 <em>expect</em> 语言帮我们解决问题。</p>\n<p>###官方定义</p>\n<blockquote>\n<p>Expect是一个用来实现自动交互功能的软件套件 (Expect [is a] software suite for automating interactive tools)</p>\n</blockquote>\n<p>expect 是 <a href=\"http://en.wikipedia.org/wiki/Don_Libes\" target=\"_blank\" rel=\"noopener\">Don Libes</a> 编写的免费编程工具语言, 由expect-send对组成：</p>\n<p>expect等待输出中输出特定的字符，通常是一个提示符，然后发送特定的响应。</p>\n<hr>\n<p>先来个 helloworld, 注意需要在exp脚本前面加上 <code>#!/usr/bin/expect</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/expect</span></span><br><span class=\"line\">send_user <span class=\"string\">\"hello world\"</span></span><br></pre></td></tr></table></figure>\n<p>这里的 send_user 类似 echo </p>\n<h3 id=\"常见用法\"><a href=\"#常见用法\" class=\"headerlink\" title=\"常见用法\"></a>常见用法</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set i 0    </span><br><span class=\"line\">set user [lindex $argv 0]</span><br><span class=\"line\">set timeout 300</span><br><span class=\"line\">set i 0</span><br><span class=\"line\">while &#123; $i &lt; 10 &#125; &#123;</span><br><span class=\"line\">    puts $i;</span><br><span class=\"line\">    incr i;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上分别是:</p>\n<ul>\n<li>将0赋值给变量i;</li>\n<li>获取脚本的第一个参数给变量user;</li>\n<li>设置超时时间是300秒</li>\n<li>循环使用，不多说</li>\n</ul>\n<hr>\n<p>在 expect脚本中, 最亮点的是 spawn 会启动一个进程，由 expect 和 send 组合负责跟该进程交互, in short </p>\n<ul>\n<li>expect捕获进程需要什么信息</li>\n<li>send将这个信息发给进程</li>\n<li>expect eof与spawn对应，表示捕获终端输出信息的终止，即进程已结束</li>\n<li>expect都是使用 {}，且{, }使用时，前后需要留空格。 只要其中一项符合，就会执行该项，类似switch</li>\n</ul>\n<p>看完以下代码相信你就明白其魅力了 ：）</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/expect</span></span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"built_in\">set</span> timeout 10</span><br><span class=\"line\"><span class=\"built_in\">set</span> host [lindex <span class=\"variable\">$argv</span> 0]</span><br><span class=\"line\"><span class=\"built_in\">set</span> username [lindex <span class=\"variable\">$argv</span> 1]</span><br><span class=\"line\"><span class=\"built_in\">set</span> password [lindex <span class=\"variable\">$argv</span> 2]</span><br><span class=\"line\"> </span><br><span class=\"line\">spawn ssh <span class=\"variable\">$username</span>@<span class=\"variable\">$host</span></span><br><span class=\"line\">expect &#123;</span><br><span class=\"line\">    <span class=\"string\">\"(yes/no)?\"</span> &#123;</span><br><span class=\"line\">        send <span class=\"string\">\"yes\\n\"</span></span><br><span class=\"line\">        expect <span class=\"string\">\"*assword:\"</span> &#123; send <span class=\"string\">\"<span class=\"variable\">$password</span>\\n\"</span> &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"string\">\"*assword:\"</span> &#123;</span><br><span class=\"line\">        send <span class=\"string\">\"<span class=\"variable\">$password</span>\\n\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">expect <span class=\"string\">\"$\"</span></span><br><span class=\"line\">expect eof</span><br></pre></td></tr></table></figure>\n<p>使用时, 执行如下脚本命令.  其中<code>expect</code> 捕获到 “*assword:”, 发送 <code>$password</code> 变量,  捕获到<code>$</code>符号，表示登陆成功，结束 spawn 进程</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./autosh.exp xxx(ip地址) xxx(用户名) xxx(密码)</span><br></pre></td></tr></table></figure>\n<hr>\n<p>感觉这样的脚本在自动化运维可以有很多运用之处, 至少让你可以在执行需要交互命令的时候跑去喝茶。<br>Happy Hacking :-)</p>\n"},{"layout":"post","title":"留下了些东西","date":"2014-04-22T11:32:00.000Z","comments":1,"description":"腾讯经历","_content":"  出于对这两个月的交代，记录下完成自动化平台开发的这段经历。\n\n  所在的 Team 业务性很浓，浓到大家已经不愿意改变，可以忍受无尽的重复劳动和时间摧残。业务繁多，导致需要花费很多时间去学习和适应人为的规则，在我看来是很不应该了。\n\n  当某一天 leader 突然说希望有一个自动化的平台来处理我们的业务，解放外包以及正职人员的劳动力，降低新人熟悉业务的门槛。我很诧异但也很高兴他会提出来这件事情，不具说原因了，至少我很开心，每日机械的做业务是件很忧伤的事情。\n\n\n### 做的事\n   项目中，我承担了大部分后台功能的开发（C++），感谢同事的信任（也许我相对比较吃苦爱折腾）。今天系统上线了并承接10个业务，挺欣慰的。\n   该系统是个做个自动化的运营开发系统，并不复杂。\n\n   * 支持批量查询现网游戏日志的数据库，多线程去执行多个大区的数据。可以切换不同的数据库。UI类似phpmyadmin的界面;\n   * 上传统计代码后，自动编译和发布可执行文件到各个统计机;\n   * 支持任务队列补算;\n   * 跟踪任务执行情况，trace 错误信息;\n   * 解析统计机器的crontab的内容，可在系统配置调度信息;\n   * 解析统计机器的调度脚本,增删改查程序，以及其执行顺序;\n\n   希望该系统可以取代原本粗暴重复的操作。提升效率的同时也降低出错的可能。\n\n\n### 说到写文档。\n\n   `资深同事`觉得要写的高 (厚) 大（黑）上 (学)，甚至吹嘘地出彩。大公司的生存之道，这些潜规则你不愿意去遵守，有时候会受伤，很多时候我选择忠于内心,包括这次。因为我终究认为这东西很平凡，它的优点在于有价值，不是纯粹为 KPI 为生的物品。我用 `markdown` 把整个后台设计和类图都清爽的表达出来。在给组内推行 markdown 的时候，本以为如此好用的工具会得到大家青睐，但显然大家还是不愿意接受，遗憾。\n\n\n###something\n   系统模拟了业务人员平时的工作流程，所以适应起来相对容易。不过依然有部分同事会排斥，新东西的诞生让他们有了不信任感。也许需要给他们更多的时间来适应。或许生活中我们也会这样，新事物总需要经受住考验质疑，只有足够好才会被历史选择。\n\n   这个开发过程中，也让我看到很多不好的过程，比如代码发布，持续构建，技术选择。做的不是很好，但平日的阅读和折腾理解让我坚信有更对的选择。比如访问量不大的系统用C++写CGI就是很蛋疼的选择，PM 的个人视野也限制了进展的效率。\n\n   这个工具开发烧了我不少脑筋，需要足够智能去适配业务，以及变态的需求，极力去推动这个系统也让软技能也有一番磨练。\n\n----\n\n末了，我在腾讯还是留下了一个让自己自豪的东西。\n","source":"_posts/2014-04-22-liu-xia-liao-xie-dong-xi.markdown","raw":"---\nlayout: post\ntitle: \"留下了些东西\"\ndate: 2014-04-22 19:32\ncomments: true\ncategories: Product \ndescription: 腾讯经历  \n---\n  出于对这两个月的交代，记录下完成自动化平台开发的这段经历。\n\n  所在的 Team 业务性很浓，浓到大家已经不愿意改变，可以忍受无尽的重复劳动和时间摧残。业务繁多，导致需要花费很多时间去学习和适应人为的规则，在我看来是很不应该了。\n\n  当某一天 leader 突然说希望有一个自动化的平台来处理我们的业务，解放外包以及正职人员的劳动力，降低新人熟悉业务的门槛。我很诧异但也很高兴他会提出来这件事情，不具说原因了，至少我很开心，每日机械的做业务是件很忧伤的事情。\n\n\n### 做的事\n   项目中，我承担了大部分后台功能的开发（C++），感谢同事的信任（也许我相对比较吃苦爱折腾）。今天系统上线了并承接10个业务，挺欣慰的。\n   该系统是个做个自动化的运营开发系统，并不复杂。\n\n   * 支持批量查询现网游戏日志的数据库，多线程去执行多个大区的数据。可以切换不同的数据库。UI类似phpmyadmin的界面;\n   * 上传统计代码后，自动编译和发布可执行文件到各个统计机;\n   * 支持任务队列补算;\n   * 跟踪任务执行情况，trace 错误信息;\n   * 解析统计机器的crontab的内容，可在系统配置调度信息;\n   * 解析统计机器的调度脚本,增删改查程序，以及其执行顺序;\n\n   希望该系统可以取代原本粗暴重复的操作。提升效率的同时也降低出错的可能。\n\n\n### 说到写文档。\n\n   `资深同事`觉得要写的高 (厚) 大（黑）上 (学)，甚至吹嘘地出彩。大公司的生存之道，这些潜规则你不愿意去遵守，有时候会受伤，很多时候我选择忠于内心,包括这次。因为我终究认为这东西很平凡，它的优点在于有价值，不是纯粹为 KPI 为生的物品。我用 `markdown` 把整个后台设计和类图都清爽的表达出来。在给组内推行 markdown 的时候，本以为如此好用的工具会得到大家青睐，但显然大家还是不愿意接受，遗憾。\n\n\n###something\n   系统模拟了业务人员平时的工作流程，所以适应起来相对容易。不过依然有部分同事会排斥，新东西的诞生让他们有了不信任感。也许需要给他们更多的时间来适应。或许生活中我们也会这样，新事物总需要经受住考验质疑，只有足够好才会被历史选择。\n\n   这个开发过程中，也让我看到很多不好的过程，比如代码发布，持续构建，技术选择。做的不是很好，但平日的阅读和折腾理解让我坚信有更对的选择。比如访问量不大的系统用C++写CGI就是很蛋疼的选择，PM 的个人视野也限制了进展的效率。\n\n   这个工具开发烧了我不少脑筋，需要足够智能去适配业务，以及变态的需求，极力去推动这个系统也让软技能也有一番磨练。\n\n----\n\n末了，我在腾讯还是留下了一个让自己自豪的东西。\n","slug":"2014-04-22-liu-xia-liao-xie-dong-xi","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd950026nctjizb924se","content":"<p>  出于对这两个月的交代，记录下完成自动化平台开发的这段经历。</p>\n<p>  所在的 Team 业务性很浓，浓到大家已经不愿意改变，可以忍受无尽的重复劳动和时间摧残。业务繁多，导致需要花费很多时间去学习和适应人为的规则，在我看来是很不应该了。</p>\n<p>  当某一天 leader 突然说希望有一个自动化的平台来处理我们的业务，解放外包以及正职人员的劳动力，降低新人熟悉业务的门槛。我很诧异但也很高兴他会提出来这件事情，不具说原因了，至少我很开心，每日机械的做业务是件很忧伤的事情。</p>\n<h3 id=\"做的事\"><a href=\"#做的事\" class=\"headerlink\" title=\"做的事\"></a>做的事</h3><p>   项目中，我承担了大部分后台功能的开发（C++），感谢同事的信任（也许我相对比较吃苦爱折腾）。今天系统上线了并承接10个业务，挺欣慰的。<br>   该系统是个做个自动化的运营开发系统，并不复杂。</p>\n<ul>\n<li>支持批量查询现网游戏日志的数据库，多线程去执行多个大区的数据。可以切换不同的数据库。UI类似phpmyadmin的界面;</li>\n<li>上传统计代码后，自动编译和发布可执行文件到各个统计机;</li>\n<li>支持任务队列补算;</li>\n<li>跟踪任务执行情况，trace 错误信息;</li>\n<li>解析统计机器的crontab的内容，可在系统配置调度信息;</li>\n<li><p>解析统计机器的调度脚本,增删改查程序，以及其执行顺序;</p>\n<p>希望该系统可以取代原本粗暴重复的操作。提升效率的同时也降低出错的可能。</p>\n</li>\n</ul>\n<h3 id=\"说到写文档。\"><a href=\"#说到写文档。\" class=\"headerlink\" title=\"说到写文档。\"></a>说到写文档。</h3><p>   <code>资深同事</code>觉得要写的高 (厚) 大（黑）上 (学)，甚至吹嘘地出彩。大公司的生存之道，这些潜规则你不愿意去遵守，有时候会受伤，很多时候我选择忠于内心,包括这次。因为我终究认为这东西很平凡，它的优点在于有价值，不是纯粹为 KPI 为生的物品。我用 <code>markdown</code> 把整个后台设计和类图都清爽的表达出来。在给组内推行 markdown 的时候，本以为如此好用的工具会得到大家青睐，但显然大家还是不愿意接受，遗憾。</p>\n<p>###something<br>   系统模拟了业务人员平时的工作流程，所以适应起来相对容易。不过依然有部分同事会排斥，新东西的诞生让他们有了不信任感。也许需要给他们更多的时间来适应。或许生活中我们也会这样，新事物总需要经受住考验质疑，只有足够好才会被历史选择。</p>\n<p>   这个开发过程中，也让我看到很多不好的过程，比如代码发布，持续构建，技术选择。做的不是很好，但平日的阅读和折腾理解让我坚信有更对的选择。比如访问量不大的系统用C++写CGI就是很蛋疼的选择，PM 的个人视野也限制了进展的效率。</p>\n<p>   这个工具开发烧了我不少脑筋，需要足够智能去适配业务，以及变态的需求，极力去推动这个系统也让软技能也有一番磨练。</p>\n<hr>\n<p>末了，我在腾讯还是留下了一个让自己自豪的东西。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>  出于对这两个月的交代，记录下完成自动化平台开发的这段经历。</p>\n<p>  所在的 Team 业务性很浓，浓到大家已经不愿意改变，可以忍受无尽的重复劳动和时间摧残。业务繁多，导致需要花费很多时间去学习和适应人为的规则，在我看来是很不应该了。</p>\n<p>  当某一天 leader 突然说希望有一个自动化的平台来处理我们的业务，解放外包以及正职人员的劳动力，降低新人熟悉业务的门槛。我很诧异但也很高兴他会提出来这件事情，不具说原因了，至少我很开心，每日机械的做业务是件很忧伤的事情。</p>\n<h3 id=\"做的事\"><a href=\"#做的事\" class=\"headerlink\" title=\"做的事\"></a>做的事</h3><p>   项目中，我承担了大部分后台功能的开发（C++），感谢同事的信任（也许我相对比较吃苦爱折腾）。今天系统上线了并承接10个业务，挺欣慰的。<br>   该系统是个做个自动化的运营开发系统，并不复杂。</p>\n<ul>\n<li>支持批量查询现网游戏日志的数据库，多线程去执行多个大区的数据。可以切换不同的数据库。UI类似phpmyadmin的界面;</li>\n<li>上传统计代码后，自动编译和发布可执行文件到各个统计机;</li>\n<li>支持任务队列补算;</li>\n<li>跟踪任务执行情况，trace 错误信息;</li>\n<li>解析统计机器的crontab的内容，可在系统配置调度信息;</li>\n<li><p>解析统计机器的调度脚本,增删改查程序，以及其执行顺序;</p>\n<p>希望该系统可以取代原本粗暴重复的操作。提升效率的同时也降低出错的可能。</p>\n</li>\n</ul>\n<h3 id=\"说到写文档。\"><a href=\"#说到写文档。\" class=\"headerlink\" title=\"说到写文档。\"></a>说到写文档。</h3><p>   <code>资深同事</code>觉得要写的高 (厚) 大（黑）上 (学)，甚至吹嘘地出彩。大公司的生存之道，这些潜规则你不愿意去遵守，有时候会受伤，很多时候我选择忠于内心,包括这次。因为我终究认为这东西很平凡，它的优点在于有价值，不是纯粹为 KPI 为生的物品。我用 <code>markdown</code> 把整个后台设计和类图都清爽的表达出来。在给组内推行 markdown 的时候，本以为如此好用的工具会得到大家青睐，但显然大家还是不愿意接受，遗憾。</p>\n<p>###something<br>   系统模拟了业务人员平时的工作流程，所以适应起来相对容易。不过依然有部分同事会排斥，新东西的诞生让他们有了不信任感。也许需要给他们更多的时间来适应。或许生活中我们也会这样，新事物总需要经受住考验质疑，只有足够好才会被历史选择。</p>\n<p>   这个开发过程中，也让我看到很多不好的过程，比如代码发布，持续构建，技术选择。做的不是很好，但平日的阅读和折腾理解让我坚信有更对的选择。比如访问量不大的系统用C++写CGI就是很蛋疼的选择，PM 的个人视野也限制了进展的效率。</p>\n<p>   这个工具开发烧了我不少脑筋，需要足够智能去适配业务，以及变态的需求，极力去推动这个系统也让软技能也有一番磨练。</p>\n<hr>\n<p>末了，我在腾讯还是留下了一个让自己自豪的东西。</p>\n"},{"layout":"post","title":"伪文青","date":"2014-04-28T04:18:00.000Z","comments":1,"_content":"在深圳有感情的地方不多，深圳大学算是一个了，周六的晚上有吉他社的学生们在这里学习音乐，遗憾的是我最近才发现，如果一年前知道的话就不用自己“闭门造车\"了。\n\n在华工的时候身边有几位哥们（uc,jh）玩吉他的时候，心生喜爱。2013年的5月份。某个炎热的傍晚，拨起琴弦，就再也停不下来了。\n\n*2013-06-20* 老家的小孩子们在中考，我初次看[左轮吉他](http://www.youku.com/playlist_show/id_6096855.html)，一连看了好多集。打下一些基本知识，我是个实践至上的人，所以迫不及待的玩了。\n\n####《同桌的你》 懵懵懂懂####\n\n我的启蒙曲子是《同桌的你》，现在回头看来，新手弹这首歌的确是难。里面有个横按,我当时竟然天真的相信，一定可以练习会的。这个时候遇到的门槛，也是很多初学者会遇到的。\n\n* 看不懂谱\n* 手指按弦会痛，按的吃力\n* 和弦不熟悉，指法错位\n* 转换迟钝，节拍乱\n\n左轮大师的建议是，`53231323`（数字表示弦的位置），对每个和弦不厌其烦地练习，直至左右手协调，这里不是轻妙淡写，需要花苦功夫，时间比较漫长，记得手指脱了3次皮，痛到麻木，麻木到成茧，然后可以53231323 任何一个和弦，可以试着（C-Am-G-E-Dm）。觉得流利了之后，就要玩点难的和弦，比如有横按，大横按，这个时候就要去玩，Bm7-F 等和弦。\n\n\n同桌的你，是4/4拍，相对缓慢，慢音乐，给新手和弦转换留下缓冲时间。这个时候如果下了苦功夫就可以弹会了。话说回来，喜欢也不叫苦，比如写代码，弹出来的那几分钟你会发自内心的高兴,即便听众只有你自己。\n\n####《董小姐》 躁起来 #####\n左立的吉他还有宋冬野的《董小姐》, 给了我沁人心脾的感受，那会每天下班回来就反复的操练,门窗关的严实，赶上剑灵正在火热上线，回来都11点了，折腾到2点是常有的事儿。高速成长的时期，人是不会疲倦的。董小姐是个很不错的歌曲。可以安抚你焦虑的内心，这首歌曲的弹奏可以熟悉普通的慢和弦。 \n我还跟宿舍的兄弟说，哪天我们码不了，去街头卖唱好么。 = =\n\n\n####《那些花儿》 感受节拍####\n大学毕业晚会，我们班有人表演《那些花儿》，范玮琪的歌曲青春，略带伤感。民谣式的蓝调歌曲很早就俘虏了我这种伪理性派，征服它需要很快的指法。好了，我需要去学习快节拍的拨弦转换。\n\n我发现，有规律的和旋，你弹的越快，肌肉记忆也会更好。肌肉像上了机械链条，一直在动。那时候早上起来先玩下快速弹奏，然后再刷牙，再看RSS。\n\n####《情非得已》 切音了####\nuc说过，如果需要学习jazz 风格的话，需要有切音技巧，我找来了庾澄庆的《情非得已》，看了下[大伟吉他](http://www.daweijita.com/?p=1958) 这种相对高端点，其实也可以用手掌心切音。\n\n这首完整的曲子是我和jh哥哥一起玩的，很开心。一起成长的感觉很爽。\n\n####《爱的罗曼史》 solo了###\n当年因为《蓝色生死恋》而风靡全球的曲子，第一段弹起来，记下和弦，弹奏不难，第二部份就蛋疼了，要死记硬背。。。这是我的弱项，求破。\n\n后来\n\n> * 《晴天》\n> * 《遇见》\n> * 《朋友》\n> * 《海阔天空》\n> * 《天空之城》\n> * 《送别》\n> * 《再见》\n> * 《夜空中最亮的星》\n> * 《一万次悲伤》\n> * 《张三的歌》\n> * 《彩虹》\n> * ..........\n\n已经成为一种寄托了。\n\n**Practice make Perfect, 没有捷径**\n\n互联网就是老师，然后让你的手指历经一次又一次磨练。慢慢可以自如转换，不需要看指板。随之而来的有乐感，包括节拍。我听觉不敏锐，需要一个APP来调弦。\n\n上个刺激的图吧,3.4w RMB 一把，想想就好。有钱到那种地步可以考虑下.努力赚钱~~\n{% img /images/2014/04/guitar.jpg %}\n\n---\n一辈子找到你喜欢的东西，而且持续做下去是挺幸福的,\n\n过程中，坚持与耐心是一种美德。这点跟我们程序员对技术的追求，我想是一样的,\n\n想象有一天，我可以在某个安静的大树下弹奏，慢慢老去,\n\n夕阳下的深大文山湖，有一位小朋友看着叔叔在弹，也许你猜到那位 SB 是谁了吧。\n\n2014-04-28 \n\n","source":"_posts/2014-04-28-wei-wen-yi-lu.markdown","raw":"---\nlayout: post\ntitle: \"伪文青\"\ndate: 2014-04-28 12:18\ncomments: true\ncategories: Life\n---\n在深圳有感情的地方不多，深圳大学算是一个了，周六的晚上有吉他社的学生们在这里学习音乐，遗憾的是我最近才发现，如果一年前知道的话就不用自己“闭门造车\"了。\n\n在华工的时候身边有几位哥们（uc,jh）玩吉他的时候，心生喜爱。2013年的5月份。某个炎热的傍晚，拨起琴弦，就再也停不下来了。\n\n*2013-06-20* 老家的小孩子们在中考，我初次看[左轮吉他](http://www.youku.com/playlist_show/id_6096855.html)，一连看了好多集。打下一些基本知识，我是个实践至上的人，所以迫不及待的玩了。\n\n####《同桌的你》 懵懵懂懂####\n\n我的启蒙曲子是《同桌的你》，现在回头看来，新手弹这首歌的确是难。里面有个横按,我当时竟然天真的相信，一定可以练习会的。这个时候遇到的门槛，也是很多初学者会遇到的。\n\n* 看不懂谱\n* 手指按弦会痛，按的吃力\n* 和弦不熟悉，指法错位\n* 转换迟钝，节拍乱\n\n左轮大师的建议是，`53231323`（数字表示弦的位置），对每个和弦不厌其烦地练习，直至左右手协调，这里不是轻妙淡写，需要花苦功夫，时间比较漫长，记得手指脱了3次皮，痛到麻木，麻木到成茧，然后可以53231323 任何一个和弦，可以试着（C-Am-G-E-Dm）。觉得流利了之后，就要玩点难的和弦，比如有横按，大横按，这个时候就要去玩，Bm7-F 等和弦。\n\n\n同桌的你，是4/4拍，相对缓慢，慢音乐，给新手和弦转换留下缓冲时间。这个时候如果下了苦功夫就可以弹会了。话说回来，喜欢也不叫苦，比如写代码，弹出来的那几分钟你会发自内心的高兴,即便听众只有你自己。\n\n####《董小姐》 躁起来 #####\n左立的吉他还有宋冬野的《董小姐》, 给了我沁人心脾的感受，那会每天下班回来就反复的操练,门窗关的严实，赶上剑灵正在火热上线，回来都11点了，折腾到2点是常有的事儿。高速成长的时期，人是不会疲倦的。董小姐是个很不错的歌曲。可以安抚你焦虑的内心，这首歌曲的弹奏可以熟悉普通的慢和弦。 \n我还跟宿舍的兄弟说，哪天我们码不了，去街头卖唱好么。 = =\n\n\n####《那些花儿》 感受节拍####\n大学毕业晚会，我们班有人表演《那些花儿》，范玮琪的歌曲青春，略带伤感。民谣式的蓝调歌曲很早就俘虏了我这种伪理性派，征服它需要很快的指法。好了，我需要去学习快节拍的拨弦转换。\n\n我发现，有规律的和旋，你弹的越快，肌肉记忆也会更好。肌肉像上了机械链条，一直在动。那时候早上起来先玩下快速弹奏，然后再刷牙，再看RSS。\n\n####《情非得已》 切音了####\nuc说过，如果需要学习jazz 风格的话，需要有切音技巧，我找来了庾澄庆的《情非得已》，看了下[大伟吉他](http://www.daweijita.com/?p=1958) 这种相对高端点，其实也可以用手掌心切音。\n\n这首完整的曲子是我和jh哥哥一起玩的，很开心。一起成长的感觉很爽。\n\n####《爱的罗曼史》 solo了###\n当年因为《蓝色生死恋》而风靡全球的曲子，第一段弹起来，记下和弦，弹奏不难，第二部份就蛋疼了，要死记硬背。。。这是我的弱项，求破。\n\n后来\n\n> * 《晴天》\n> * 《遇见》\n> * 《朋友》\n> * 《海阔天空》\n> * 《天空之城》\n> * 《送别》\n> * 《再见》\n> * 《夜空中最亮的星》\n> * 《一万次悲伤》\n> * 《张三的歌》\n> * 《彩虹》\n> * ..........\n\n已经成为一种寄托了。\n\n**Practice make Perfect, 没有捷径**\n\n互联网就是老师，然后让你的手指历经一次又一次磨练。慢慢可以自如转换，不需要看指板。随之而来的有乐感，包括节拍。我听觉不敏锐，需要一个APP来调弦。\n\n上个刺激的图吧,3.4w RMB 一把，想想就好。有钱到那种地步可以考虑下.努力赚钱~~\n{% img /images/2014/04/guitar.jpg %}\n\n---\n一辈子找到你喜欢的东西，而且持续做下去是挺幸福的,\n\n过程中，坚持与耐心是一种美德。这点跟我们程序员对技术的追求，我想是一样的,\n\n想象有一天，我可以在某个安静的大树下弹奏，慢慢老去,\n\n夕阳下的深大文山湖，有一位小朋友看着叔叔在弹，也许你猜到那位 SB 是谁了吧。\n\n2014-04-28 \n\n","slug":"2014-04-28-wei-wen-yi-lu","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd960028nctjj52drdno","content":"<p>在深圳有感情的地方不多，深圳大学算是一个了，周六的晚上有吉他社的学生们在这里学习音乐，遗憾的是我最近才发现，如果一年前知道的话就不用自己“闭门造车”了。</p>\n<p>在华工的时候身边有几位哥们（uc,jh）玩吉他的时候，心生喜爱。2013年的5月份。某个炎热的傍晚，拨起琴弦，就再也停不下来了。</p>\n<p><em>2013-06-20</em> 老家的小孩子们在中考，我初次看<a href=\"http://www.youku.com/playlist_show/id_6096855.html\" target=\"_blank\" rel=\"noopener\">左轮吉他</a>，一连看了好多集。打下一些基本知识，我是个实践至上的人，所以迫不及待的玩了。</p>\n<p>####《同桌的你》 懵懵懂懂####</p>\n<p>我的启蒙曲子是《同桌的你》，现在回头看来，新手弹这首歌的确是难。里面有个横按,我当时竟然天真的相信，一定可以练习会的。这个时候遇到的门槛，也是很多初学者会遇到的。</p>\n<ul>\n<li>看不懂谱</li>\n<li>手指按弦会痛，按的吃力</li>\n<li>和弦不熟悉，指法错位</li>\n<li>转换迟钝，节拍乱</li>\n</ul>\n<p>左轮大师的建议是，<code>53231323</code>（数字表示弦的位置），对每个和弦不厌其烦地练习，直至左右手协调，这里不是轻妙淡写，需要花苦功夫，时间比较漫长，记得手指脱了3次皮，痛到麻木，麻木到成茧，然后可以53231323 任何一个和弦，可以试着（C-Am-G-E-Dm）。觉得流利了之后，就要玩点难的和弦，比如有横按，大横按，这个时候就要去玩，Bm7-F 等和弦。</p>\n<p>同桌的你，是4/4拍，相对缓慢，慢音乐，给新手和弦转换留下缓冲时间。这个时候如果下了苦功夫就可以弹会了。话说回来，喜欢也不叫苦，比如写代码，弹出来的那几分钟你会发自内心的高兴,即便听众只有你自己。</p>\n<p>####《董小姐》 躁起来 #####<br>左立的吉他还有宋冬野的《董小姐》, 给了我沁人心脾的感受，那会每天下班回来就反复的操练,门窗关的严实，赶上剑灵正在火热上线，回来都11点了，折腾到2点是常有的事儿。高速成长的时期，人是不会疲倦的。董小姐是个很不错的歌曲。可以安抚你焦虑的内心，这首歌曲的弹奏可以熟悉普通的慢和弦。<br>我还跟宿舍的兄弟说，哪天我们码不了，去街头卖唱好么。 = =</p>\n<p>####《那些花儿》 感受节拍####<br>大学毕业晚会，我们班有人表演《那些花儿》，范玮琪的歌曲青春，略带伤感。民谣式的蓝调歌曲很早就俘虏了我这种伪理性派，征服它需要很快的指法。好了，我需要去学习快节拍的拨弦转换。</p>\n<p>我发现，有规律的和旋，你弹的越快，肌肉记忆也会更好。肌肉像上了机械链条，一直在动。那时候早上起来先玩下快速弹奏，然后再刷牙，再看RSS。</p>\n<p>####《情非得已》 切音了####<br>uc说过，如果需要学习jazz 风格的话，需要有切音技巧，我找来了庾澄庆的《情非得已》，看了下<a href=\"http://www.daweijita.com/?p=1958\" target=\"_blank\" rel=\"noopener\">大伟吉他</a> 这种相对高端点，其实也可以用手掌心切音。</p>\n<p>这首完整的曲子是我和jh哥哥一起玩的，很开心。一起成长的感觉很爽。</p>\n<p>####《爱的罗曼史》 solo了###<br>当年因为《蓝色生死恋》而风靡全球的曲子，第一段弹起来，记下和弦，弹奏不难，第二部份就蛋疼了，要死记硬背。。。这是我的弱项，求破。</p>\n<p>后来</p>\n<blockquote>\n<ul>\n<li>《晴天》</li>\n<li>《遇见》</li>\n<li>《朋友》</li>\n<li>《海阔天空》</li>\n<li>《天空之城》</li>\n<li>《送别》</li>\n<li>《再见》</li>\n<li>《夜空中最亮的星》</li>\n<li>《一万次悲伤》</li>\n<li>《张三的歌》</li>\n<li>《彩虹》</li>\n<li>……….</li>\n</ul>\n</blockquote>\n<p>已经成为一种寄托了。</p>\n<p><strong>Practice make Perfect, 没有捷径</strong></p>\n<p>互联网就是老师，然后让你的手指历经一次又一次磨练。慢慢可以自如转换，不需要看指板。随之而来的有乐感，包括节拍。我听觉不敏锐，需要一个APP来调弦。</p>\n<p>上个刺激的图吧,3.4w RMB 一把，想想就好。有钱到那种地步可以考虑下.努力赚钱~~<br><img src=\"/images/2014/04/guitar.jpg\"></p>\n<hr>\n<p>一辈子找到你喜欢的东西，而且持续做下去是挺幸福的,</p>\n<p>过程中，坚持与耐心是一种美德。这点跟我们程序员对技术的追求，我想是一样的,</p>\n<p>想象有一天，我可以在某个安静的大树下弹奏，慢慢老去,</p>\n<p>夕阳下的深大文山湖，有一位小朋友看着叔叔在弹，也许你猜到那位 SB 是谁了吧。</p>\n<p>2014-04-28 </p>\n","site":{"data":{}},"excerpt":"","more":"<p>在深圳有感情的地方不多，深圳大学算是一个了，周六的晚上有吉他社的学生们在这里学习音乐，遗憾的是我最近才发现，如果一年前知道的话就不用自己“闭门造车”了。</p>\n<p>在华工的时候身边有几位哥们（uc,jh）玩吉他的时候，心生喜爱。2013年的5月份。某个炎热的傍晚，拨起琴弦，就再也停不下来了。</p>\n<p><em>2013-06-20</em> 老家的小孩子们在中考，我初次看<a href=\"http://www.youku.com/playlist_show/id_6096855.html\" target=\"_blank\" rel=\"noopener\">左轮吉他</a>，一连看了好多集。打下一些基本知识，我是个实践至上的人，所以迫不及待的玩了。</p>\n<p>####《同桌的你》 懵懵懂懂####</p>\n<p>我的启蒙曲子是《同桌的你》，现在回头看来，新手弹这首歌的确是难。里面有个横按,我当时竟然天真的相信，一定可以练习会的。这个时候遇到的门槛，也是很多初学者会遇到的。</p>\n<ul>\n<li>看不懂谱</li>\n<li>手指按弦会痛，按的吃力</li>\n<li>和弦不熟悉，指法错位</li>\n<li>转换迟钝，节拍乱</li>\n</ul>\n<p>左轮大师的建议是，<code>53231323</code>（数字表示弦的位置），对每个和弦不厌其烦地练习，直至左右手协调，这里不是轻妙淡写，需要花苦功夫，时间比较漫长，记得手指脱了3次皮，痛到麻木，麻木到成茧，然后可以53231323 任何一个和弦，可以试着（C-Am-G-E-Dm）。觉得流利了之后，就要玩点难的和弦，比如有横按，大横按，这个时候就要去玩，Bm7-F 等和弦。</p>\n<p>同桌的你，是4/4拍，相对缓慢，慢音乐，给新手和弦转换留下缓冲时间。这个时候如果下了苦功夫就可以弹会了。话说回来，喜欢也不叫苦，比如写代码，弹出来的那几分钟你会发自内心的高兴,即便听众只有你自己。</p>\n<p>####《董小姐》 躁起来 #####<br>左立的吉他还有宋冬野的《董小姐》, 给了我沁人心脾的感受，那会每天下班回来就反复的操练,门窗关的严实，赶上剑灵正在火热上线，回来都11点了，折腾到2点是常有的事儿。高速成长的时期，人是不会疲倦的。董小姐是个很不错的歌曲。可以安抚你焦虑的内心，这首歌曲的弹奏可以熟悉普通的慢和弦。<br>我还跟宿舍的兄弟说，哪天我们码不了，去街头卖唱好么。 = =</p>\n<p>####《那些花儿》 感受节拍####<br>大学毕业晚会，我们班有人表演《那些花儿》，范玮琪的歌曲青春，略带伤感。民谣式的蓝调歌曲很早就俘虏了我这种伪理性派，征服它需要很快的指法。好了，我需要去学习快节拍的拨弦转换。</p>\n<p>我发现，有规律的和旋，你弹的越快，肌肉记忆也会更好。肌肉像上了机械链条，一直在动。那时候早上起来先玩下快速弹奏，然后再刷牙，再看RSS。</p>\n<p>####《情非得已》 切音了####<br>uc说过，如果需要学习jazz 风格的话，需要有切音技巧，我找来了庾澄庆的《情非得已》，看了下<a href=\"http://www.daweijita.com/?p=1958\" target=\"_blank\" rel=\"noopener\">大伟吉他</a> 这种相对高端点，其实也可以用手掌心切音。</p>\n<p>这首完整的曲子是我和jh哥哥一起玩的，很开心。一起成长的感觉很爽。</p>\n<p>####《爱的罗曼史》 solo了###<br>当年因为《蓝色生死恋》而风靡全球的曲子，第一段弹起来，记下和弦，弹奏不难，第二部份就蛋疼了，要死记硬背。。。这是我的弱项，求破。</p>\n<p>后来</p>\n<blockquote>\n<ul>\n<li>《晴天》</li>\n<li>《遇见》</li>\n<li>《朋友》</li>\n<li>《海阔天空》</li>\n<li>《天空之城》</li>\n<li>《送别》</li>\n<li>《再见》</li>\n<li>《夜空中最亮的星》</li>\n<li>《一万次悲伤》</li>\n<li>《张三的歌》</li>\n<li>《彩虹》</li>\n<li>……….</li>\n</ul>\n</blockquote>\n<p>已经成为一种寄托了。</p>\n<p><strong>Practice make Perfect, 没有捷径</strong></p>\n<p>互联网就是老师，然后让你的手指历经一次又一次磨练。慢慢可以自如转换，不需要看指板。随之而来的有乐感，包括节拍。我听觉不敏锐，需要一个APP来调弦。</p>\n<p>上个刺激的图吧,3.4w RMB 一把，想想就好。有钱到那种地步可以考虑下.努力赚钱~~<br><img src=\"/images/2014/04/guitar.jpg\"></p>\n<hr>\n<p>一辈子找到你喜欢的东西，而且持续做下去是挺幸福的,</p>\n<p>过程中，坚持与耐心是一种美德。这点跟我们程序员对技术的追求，我想是一样的,</p>\n<p>想象有一天，我可以在某个安静的大树下弹奏，慢慢老去,</p>\n<p>夕阳下的深大文山湖，有一位小朋友看着叔叔在弹，也许你猜到那位 SB 是谁了吧。</p>\n<p>2014-04-28 </p>\n"},{"layout":"post","title":"Mac 安装 Go","date":"2014-05-03T01:32:00.000Z","comments":1,"keywords":"mac golang","description":"mac golang","_content":"\n修改 `~.zshrc`, 添加以下环境变量\n\n```\nexport GOROOT=$HOME/go\nexport GOBIN=$GOROOT/bin\nexport PATH=$PATH:$GOBIN\nexport GOPATH=/Users/zj/workspace/gocode\n```\n\n\n开始安装,耗时有点久\n保证你的电脑安装有 hg, 如果没有, 请执行 \n\n```\nsudo easy_install mercurial\nhg clone -u release https://code.google.com/p/go\ncd go/src\n./all.bash\n```\n\n开始检验, 执行 go , 出现一系列 Usage信息就算通过了 ：）。\n\n","source":"_posts/2014-05-03-mac-an-zhuang-go.markdown","raw":"---\nlayout: post\ntitle: \"Mac 安装 Go\"\ndate: 2014-05-03 09:32\ncomments: true\ncategories: Programe\nkeywords: mac golang\ndescription: mac golang\n---\n\n修改 `~.zshrc`, 添加以下环境变量\n\n```\nexport GOROOT=$HOME/go\nexport GOBIN=$GOROOT/bin\nexport PATH=$PATH:$GOBIN\nexport GOPATH=/Users/zj/workspace/gocode\n```\n\n\n开始安装,耗时有点久\n保证你的电脑安装有 hg, 如果没有, 请执行 \n\n```\nsudo easy_install mercurial\nhg clone -u release https://code.google.com/p/go\ncd go/src\n./all.bash\n```\n\n开始检验, 执行 go , 出现一系列 Usage信息就算通过了 ：）。\n\n","slug":"2014-05-03-mac-an-zhuang-go","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd97002anctj2yv19ngv","content":"<p>修改 <code>~.zshrc</code>, 添加以下环境变量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export GOROOT=$HOME/go</span><br><span class=\"line\">export GOBIN=$GOROOT/bin</span><br><span class=\"line\">export PATH=$PATH:$GOBIN</span><br><span class=\"line\">export GOPATH=/Users/zj/workspace/gocode</span><br></pre></td></tr></table></figure>\n<p>开始安装,耗时有点久<br>保证你的电脑安装有 hg, 如果没有, 请执行 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo easy_install mercurial</span><br><span class=\"line\">hg clone -u release https://code.google.com/p/go</span><br><span class=\"line\">cd go/src</span><br><span class=\"line\">./all.bash</span><br></pre></td></tr></table></figure>\n<p>开始检验, 执行 go , 出现一系列 Usage信息就算通过了 ：）。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>修改 <code>~.zshrc</code>, 添加以下环境变量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export GOROOT=$HOME/go</span><br><span class=\"line\">export GOBIN=$GOROOT/bin</span><br><span class=\"line\">export PATH=$PATH:$GOBIN</span><br><span class=\"line\">export GOPATH=/Users/zj/workspace/gocode</span><br></pre></td></tr></table></figure>\n<p>开始安装,耗时有点久<br>保证你的电脑安装有 hg, 如果没有, 请执行 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo easy_install mercurial</span><br><span class=\"line\">hg clone -u release https://code.google.com/p/go</span><br><span class=\"line\">cd go/src</span><br><span class=\"line\">./all.bash</span><br></pre></td></tr></table></figure>\n<p>开始检验, 执行 go , 出现一系列 Usage信息就算通过了 ：）。</p>\n"},{"layout":"post","title":"制作 setup.py","date":"2014-05-03T03:52:00.000Z","comments":1,"keywords":"python setuptool","description":"python setuptool","_content":"\n做好一个 Python Module 之后，可以把源代码包含进项目中。但是如果有很多依赖项目的话就不好管理了，这个时候我们用 setuptools 工具来安装到系统的包。\n\n### 制作与安装\n\n以下给出一个 demo \n\n```\nmkdir hacker\nvim foo.py\n```\n\n编辑 foo.py \n\n```python\nclass Hacker():\n    def __init__(self):\n        self.motto = \"No evil, Be Hacker\"\n    def printMotto(self):\n        print self.motto\n```\n\n开始编写 setup.py, 也许是为了知识产权保护，里面按照规矩会让作者填上资料。\n\n```python\nfrom distutils.core import setup\nsetup(name='Hacker',\n        version='1.0',\n        description='be hake or be hacked',\n        author='zheng-ji',\n        author_email='zhengji91@gmail.com',\n        url='http://zheng-ji.info',\n        py_modules=['foo'],\n        install_requires=[\"requests\"]\n     )\n```\n\n好了，这个时候执行,\n\n```\nsudo python setup.py install\n```\n\n该命令，会把模块复制到 `/usr/lib/python2.7/` 下面. 之后可以直接 import foo, 使用该模块。\n\n### 删除\n\n```\npython setup.py install --record files.txt\ncat files.txt | xargs rm -rf\n```\n\n\n\n\n\n\n","source":"_posts/2014-05-03-make-setup-dot-py.markdown","raw":"---\nlayout: post\ntitle: \"制作 setup.py\"\ndate: 2014-05-03 11:52\ncomments: true\ncategories: Programe\nkeywords: python setuptool\ndescription: python setuptool\n---\n\n做好一个 Python Module 之后，可以把源代码包含进项目中。但是如果有很多依赖项目的话就不好管理了，这个时候我们用 setuptools 工具来安装到系统的包。\n\n### 制作与安装\n\n以下给出一个 demo \n\n```\nmkdir hacker\nvim foo.py\n```\n\n编辑 foo.py \n\n```python\nclass Hacker():\n    def __init__(self):\n        self.motto = \"No evil, Be Hacker\"\n    def printMotto(self):\n        print self.motto\n```\n\n开始编写 setup.py, 也许是为了知识产权保护，里面按照规矩会让作者填上资料。\n\n```python\nfrom distutils.core import setup\nsetup(name='Hacker',\n        version='1.0',\n        description='be hake or be hacked',\n        author='zheng-ji',\n        author_email='zhengji91@gmail.com',\n        url='http://zheng-ji.info',\n        py_modules=['foo'],\n        install_requires=[\"requests\"]\n     )\n```\n\n好了，这个时候执行,\n\n```\nsudo python setup.py install\n```\n\n该命令，会把模块复制到 `/usr/lib/python2.7/` 下面. 之后可以直接 import foo, 使用该模块。\n\n### 删除\n\n```\npython setup.py install --record files.txt\ncat files.txt | xargs rm -rf\n```\n\n\n\n\n\n\n","slug":"2014-05-03-make-setup-dot-py","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd98002cnctj3coce4dw","content":"<p>做好一个 Python Module 之后，可以把源代码包含进项目中。但是如果有很多依赖项目的话就不好管理了，这个时候我们用 setuptools 工具来安装到系统的包。</p>\n<h3 id=\"制作与安装\"><a href=\"#制作与安装\" class=\"headerlink\" title=\"制作与安装\"></a>制作与安装</h3><p>以下给出一个 demo </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir hacker</span><br><span class=\"line\">vim foo.py</span><br></pre></td></tr></table></figure>\n<p>编辑 foo.py </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Hacker</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self.motto = <span class=\"string\">\"No evil, Be Hacker\"</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">printMotto</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">print</span> self.motto</span><br></pre></td></tr></table></figure>\n<p>开始编写 setup.py, 也许是为了知识产权保护，里面按照规矩会让作者填上资料。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> distutils.core <span class=\"keyword\">import</span> setup</span><br><span class=\"line\">setup(name=<span class=\"string\">'Hacker'</span>,</span><br><span class=\"line\">        version=<span class=\"string\">'1.0'</span>,</span><br><span class=\"line\">        description=<span class=\"string\">'be hake or be hacked'</span>,</span><br><span class=\"line\">        author=<span class=\"string\">'zheng-ji'</span>,</span><br><span class=\"line\">        author_email=<span class=\"string\">'zhengji91@gmail.com'</span>,</span><br><span class=\"line\">        url=<span class=\"string\">'http://zheng-ji.info'</span>,</span><br><span class=\"line\">        py_modules=[<span class=\"string\">'foo'</span>],</span><br><span class=\"line\">        install_requires=[<span class=\"string\">\"requests\"</span>]</span><br><span class=\"line\">     )</span><br></pre></td></tr></table></figure>\n<p>好了，这个时候执行,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo python setup.py install</span><br></pre></td></tr></table></figure>\n<p>该命令，会把模块复制到 <code>/usr/lib/python2.7/</code> 下面. 之后可以直接 import foo, 使用该模块。</p>\n<h3 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py install --record files.txt</span><br><span class=\"line\">cat files.txt | xargs rm -rf</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>做好一个 Python Module 之后，可以把源代码包含进项目中。但是如果有很多依赖项目的话就不好管理了，这个时候我们用 setuptools 工具来安装到系统的包。</p>\n<h3 id=\"制作与安装\"><a href=\"#制作与安装\" class=\"headerlink\" title=\"制作与安装\"></a>制作与安装</h3><p>以下给出一个 demo </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir hacker</span><br><span class=\"line\">vim foo.py</span><br></pre></td></tr></table></figure>\n<p>编辑 foo.py </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Hacker</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self.motto = <span class=\"string\">\"No evil, Be Hacker\"</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">printMotto</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">print</span> self.motto</span><br></pre></td></tr></table></figure>\n<p>开始编写 setup.py, 也许是为了知识产权保护，里面按照规矩会让作者填上资料。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> distutils.core <span class=\"keyword\">import</span> setup</span><br><span class=\"line\">setup(name=<span class=\"string\">'Hacker'</span>,</span><br><span class=\"line\">        version=<span class=\"string\">'1.0'</span>,</span><br><span class=\"line\">        description=<span class=\"string\">'be hake or be hacked'</span>,</span><br><span class=\"line\">        author=<span class=\"string\">'zheng-ji'</span>,</span><br><span class=\"line\">        author_email=<span class=\"string\">'zhengji91@gmail.com'</span>,</span><br><span class=\"line\">        url=<span class=\"string\">'http://zheng-ji.info'</span>,</span><br><span class=\"line\">        py_modules=[<span class=\"string\">'foo'</span>],</span><br><span class=\"line\">        install_requires=[<span class=\"string\">\"requests\"</span>]</span><br><span class=\"line\">     )</span><br></pre></td></tr></table></figure>\n<p>好了，这个时候执行,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo python setup.py install</span><br></pre></td></tr></table></figure>\n<p>该命令，会把模块复制到 <code>/usr/lib/python2.7/</code> 下面. 之后可以直接 import foo, 使用该模块。</p>\n<h3 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py install --record files.txt</span><br><span class=\"line\">cat files.txt | xargs rm -rf</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"打磨的青春","date":"2014-06-21T08:05:00.000Z","comments":1,"_content":"\n  在知乎上阅读到不少精彩的文字，无不被作者的清晰思维与条理折服，用欲罢不能的形容词来描述这类文章都不为过, 同样的感受也发生在阅读韩寒的文章里。近一个月来，每晚回宿舍入眠前顺带阅读其犀利的文笔，如有酣畅淋漓之感。也希望自己写的文章可以让本人阅读完后，有通体舒畅之感，奈何文笔和思维欠佳，每每下笔不能成满意之章，遂很久没有更新博客。\n\n\n  Twitter上面有人说，技术博客写的久的人，越发不是很愿意提笔记载，浅显的技能，或者说通过互联网共享得到的知识不应以一种“原创”的姿态记录在博客上。在同样的驱动下，我更倾向地选择 [wiki](http://wiki.zheng-ji.info)，知识点的编织，还在坚持。如果有干货输出，自然还是会在博客书写。\n\n\n  近日所见所闻，所作所为，所思所想。让我又一次遇见自己的各种缺点。归结为心智远未成熟，还需要成长。成长为一个令自己自豪的程序员，\n我想我还不够专注，不够坚持（这种坚持不仅仅是身体力行，我现在更认为是心智的调整），解决问题的能力不够 Powerful。理解的深度也不够。失望自然会有，幸好知道可以改进的点。继续向前走的路漫漫。\n\n\n  可以不被社交工具这个无形的时间黑洞吸走太多的时间，更好地专注。抱歉的是，朋友群里好多事情似乎都错过了。\n\n\n  在新的地方开始新的生活，这次角色互换了，我教起朋友们玩起了吉他。这样的日子让我怀念起大学时的 uc,jh 的教导。10年前看翡翠台时听到的《明年今日》，喜欢的歌曲在今晚被被弹奏出来的感觉很美妙。我是这么鼓励和我一起学吉他的朋友的。\n\n\n  被打磨的青春，貌似又跑题了，承认我思维不够严谨。\n\n\n今天华亮来大学城，巧的是，每次友人来访都逢下雨，华亮还是一如既往地令人感受到正能量，按他的话，海贼王的精神 ：）\n\n\n看着这个青年离开的背影，分明是被打磨的青春。终于回到正题了，这篇随笔仅仅是稍纵即逝的灵感，借此勉励。\n\n","source":"_posts/2014-06-21-da-mo-de-qing-chun.markdown","raw":"---\nlayout: post\ntitle: \"打磨的青春\"\ndate: 2014-06-21 16:05\ncomments: true\ncategories: Life  \n---\n\n  在知乎上阅读到不少精彩的文字，无不被作者的清晰思维与条理折服，用欲罢不能的形容词来描述这类文章都不为过, 同样的感受也发生在阅读韩寒的文章里。近一个月来，每晚回宿舍入眠前顺带阅读其犀利的文笔，如有酣畅淋漓之感。也希望自己写的文章可以让本人阅读完后，有通体舒畅之感，奈何文笔和思维欠佳，每每下笔不能成满意之章，遂很久没有更新博客。\n\n\n  Twitter上面有人说，技术博客写的久的人，越发不是很愿意提笔记载，浅显的技能，或者说通过互联网共享得到的知识不应以一种“原创”的姿态记录在博客上。在同样的驱动下，我更倾向地选择 [wiki](http://wiki.zheng-ji.info)，知识点的编织，还在坚持。如果有干货输出，自然还是会在博客书写。\n\n\n  近日所见所闻，所作所为，所思所想。让我又一次遇见自己的各种缺点。归结为心智远未成熟，还需要成长。成长为一个令自己自豪的程序员，\n我想我还不够专注，不够坚持（这种坚持不仅仅是身体力行，我现在更认为是心智的调整），解决问题的能力不够 Powerful。理解的深度也不够。失望自然会有，幸好知道可以改进的点。继续向前走的路漫漫。\n\n\n  可以不被社交工具这个无形的时间黑洞吸走太多的时间，更好地专注。抱歉的是，朋友群里好多事情似乎都错过了。\n\n\n  在新的地方开始新的生活，这次角色互换了，我教起朋友们玩起了吉他。这样的日子让我怀念起大学时的 uc,jh 的教导。10年前看翡翠台时听到的《明年今日》，喜欢的歌曲在今晚被被弹奏出来的感觉很美妙。我是这么鼓励和我一起学吉他的朋友的。\n\n\n  被打磨的青春，貌似又跑题了，承认我思维不够严谨。\n\n\n今天华亮来大学城，巧的是，每次友人来访都逢下雨，华亮还是一如既往地令人感受到正能量，按他的话，海贼王的精神 ：）\n\n\n看着这个青年离开的背影，分明是被打磨的青春。终于回到正题了，这篇随笔仅仅是稍纵即逝的灵感，借此勉励。\n\n","slug":"2014-06-21-da-mo-de-qing-chun","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd99002enctjeyjb5rr0","content":"<p>  在知乎上阅读到不少精彩的文字，无不被作者的清晰思维与条理折服，用欲罢不能的形容词来描述这类文章都不为过, 同样的感受也发生在阅读韩寒的文章里。近一个月来，每晚回宿舍入眠前顺带阅读其犀利的文笔，如有酣畅淋漓之感。也希望自己写的文章可以让本人阅读完后，有通体舒畅之感，奈何文笔和思维欠佳，每每下笔不能成满意之章，遂很久没有更新博客。</p>\n<p>  Twitter上面有人说，技术博客写的久的人，越发不是很愿意提笔记载，浅显的技能，或者说通过互联网共享得到的知识不应以一种“原创”的姿态记录在博客上。在同样的驱动下，我更倾向地选择 <a href=\"http://wiki.zheng-ji.info\" target=\"_blank\" rel=\"noopener\">wiki</a>，知识点的编织，还在坚持。如果有干货输出，自然还是会在博客书写。</p>\n<p>  近日所见所闻，所作所为，所思所想。让我又一次遇见自己的各种缺点。归结为心智远未成熟，还需要成长。成长为一个令自己自豪的程序员，<br>我想我还不够专注，不够坚持（这种坚持不仅仅是身体力行，我现在更认为是心智的调整），解决问题的能力不够 Powerful。理解的深度也不够。失望自然会有，幸好知道可以改进的点。继续向前走的路漫漫。</p>\n<p>  可以不被社交工具这个无形的时间黑洞吸走太多的时间，更好地专注。抱歉的是，朋友群里好多事情似乎都错过了。</p>\n<p>  在新的地方开始新的生活，这次角色互换了，我教起朋友们玩起了吉他。这样的日子让我怀念起大学时的 uc,jh 的教导。10年前看翡翠台时听到的《明年今日》，喜欢的歌曲在今晚被被弹奏出来的感觉很美妙。我是这么鼓励和我一起学吉他的朋友的。</p>\n<p>  被打磨的青春，貌似又跑题了，承认我思维不够严谨。</p>\n<p>今天华亮来大学城，巧的是，每次友人来访都逢下雨，华亮还是一如既往地令人感受到正能量，按他的话，海贼王的精神 ：）</p>\n<p>看着这个青年离开的背影，分明是被打磨的青春。终于回到正题了，这篇随笔仅仅是稍纵即逝的灵感，借此勉励。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>  在知乎上阅读到不少精彩的文字，无不被作者的清晰思维与条理折服，用欲罢不能的形容词来描述这类文章都不为过, 同样的感受也发生在阅读韩寒的文章里。近一个月来，每晚回宿舍入眠前顺带阅读其犀利的文笔，如有酣畅淋漓之感。也希望自己写的文章可以让本人阅读完后，有通体舒畅之感，奈何文笔和思维欠佳，每每下笔不能成满意之章，遂很久没有更新博客。</p>\n<p>  Twitter上面有人说，技术博客写的久的人，越发不是很愿意提笔记载，浅显的技能，或者说通过互联网共享得到的知识不应以一种“原创”的姿态记录在博客上。在同样的驱动下，我更倾向地选择 <a href=\"http://wiki.zheng-ji.info\" target=\"_blank\" rel=\"noopener\">wiki</a>，知识点的编织，还在坚持。如果有干货输出，自然还是会在博客书写。</p>\n<p>  近日所见所闻，所作所为，所思所想。让我又一次遇见自己的各种缺点。归结为心智远未成熟，还需要成长。成长为一个令自己自豪的程序员，<br>我想我还不够专注，不够坚持（这种坚持不仅仅是身体力行，我现在更认为是心智的调整），解决问题的能力不够 Powerful。理解的深度也不够。失望自然会有，幸好知道可以改进的点。继续向前走的路漫漫。</p>\n<p>  可以不被社交工具这个无形的时间黑洞吸走太多的时间，更好地专注。抱歉的是，朋友群里好多事情似乎都错过了。</p>\n<p>  在新的地方开始新的生活，这次角色互换了，我教起朋友们玩起了吉他。这样的日子让我怀念起大学时的 uc,jh 的教导。10年前看翡翠台时听到的《明年今日》，喜欢的歌曲在今晚被被弹奏出来的感觉很美妙。我是这么鼓励和我一起学吉他的朋友的。</p>\n<p>  被打磨的青春，貌似又跑题了，承认我思维不够严谨。</p>\n<p>今天华亮来大学城，巧的是，每次友人来访都逢下雨，华亮还是一如既往地令人感受到正能量，按他的话，海贼王的精神 ：）</p>\n<p>看着这个青年离开的背影，分明是被打磨的青春。终于回到正题了，这篇随笔仅仅是稍纵即逝的灵感，借此勉励。</p>\n"},{"layout":"post","title":"Go Protobuf","date":"2014-07-12T09:39:00.000Z","comments":1,"_content":"\nprotobuf 是谷歌出品的，质量就无需质疑了，广泛运用于工业界\n优点简而言之是：\n\n* 二进制，速度快，便于拓展；\n* 自动生成代码接口，支持多语言\n\n对于第一点, 貌似优秀的开源代码没这么干都不好意思开放。\n\n### 安装\n\n比较蛋疼,折腾一小段时间。\n\n```\ngo get code.google.com/p/goprotobuf/{proto, protoc-gen-go}\n\ngo install code.google.com/p/goprotobuf/proto\n\nsudo apt-get install protobuf-compiler\n```\n\n### 使用\n\n是在项目内部新建一个proto.文件, 然后执行\n\n```\nprotoc --go_out=. xxx.proto\n```\n\n","source":"_posts/2014-07-12-goan-zhuang-protobuf.markdown","raw":"---\nlayout: post\ntitle: \"Go Protobuf\"\ndate: 2014-07-12 17:39\ncomments: true\ncategories: Programe \n---\n\nprotobuf 是谷歌出品的，质量就无需质疑了，广泛运用于工业界\n优点简而言之是：\n\n* 二进制，速度快，便于拓展；\n* 自动生成代码接口，支持多语言\n\n对于第一点, 貌似优秀的开源代码没这么干都不好意思开放。\n\n### 安装\n\n比较蛋疼,折腾一小段时间。\n\n```\ngo get code.google.com/p/goprotobuf/{proto, protoc-gen-go}\n\ngo install code.google.com/p/goprotobuf/proto\n\nsudo apt-get install protobuf-compiler\n```\n\n### 使用\n\n是在项目内部新建一个proto.文件, 然后执行\n\n```\nprotoc --go_out=. xxx.proto\n```\n\n","slug":"2014-07-12-goan-zhuang-protobuf","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9a002gnctjm2fdgzaz","content":"<p>protobuf 是谷歌出品的，质量就无需质疑了，广泛运用于工业界<br>优点简而言之是：</p>\n<ul>\n<li>二进制，速度快，便于拓展；</li>\n<li>自动生成代码接口，支持多语言</li>\n</ul>\n<p>对于第一点, 貌似优秀的开源代码没这么干都不好意思开放。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>比较蛋疼,折腾一小段时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go get code.google.com/p/goprotobuf/&#123;proto, protoc-gen-go&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">go install code.google.com/p/goprotobuf/proto</span><br><span class=\"line\"></span><br><span class=\"line\">sudo apt-get install protobuf-compiler</span><br></pre></td></tr></table></figure>\n<h3 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h3><p>是在项目内部新建一个proto.文件, 然后执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protoc --go_out=. xxx.proto</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>protobuf 是谷歌出品的，质量就无需质疑了，广泛运用于工业界<br>优点简而言之是：</p>\n<ul>\n<li>二进制，速度快，便于拓展；</li>\n<li>自动生成代码接口，支持多语言</li>\n</ul>\n<p>对于第一点, 貌似优秀的开源代码没这么干都不好意思开放。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>比较蛋疼,折腾一小段时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go get code.google.com/p/goprotobuf/&#123;proto, protoc-gen-go&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">go install code.google.com/p/goprotobuf/proto</span><br><span class=\"line\"></span><br><span class=\"line\">sudo apt-get install protobuf-compiler</span><br></pre></td></tr></table></figure>\n<h3 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h3><p>是在项目内部新建一个proto.文件, 然后执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protoc --go_out=. xxx.proto</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"折腾 Docker","date":"2014-07-16T12:20:00.000Z","comments":1,"keywords":"ubuntu docker","description":"ubuntu docker","_content":"\n  早在1年前就听过 [docker](http://docs.docker.com/)这个 Golang 社区的明星产品 。\n\n### 简单地介绍\n\n  Docker 提供了一个可以运行你的应用程序的容器。像一个可移植的容器引擎那样工作。它把应用程序及所有程序的依赖环境打包到一个虚拟容器中，这个虚拟容器可以运行在任何一种 Linux 服务器上。这大大地提高了程序运行的灵活性和可移植性，极大的降低运维成本。\n\n### 组成\n\n* Docker 服务器守护程序（server daemon），用于管理所有的容器。\n* Docker 命令行客户端，用于控制服务器守护程序。\n* Docker 镜像：查找和浏览 docker 容器镜像。它也访问这里得到：[链接](https://index.docker.io/)\n\n\n### 有了虚拟机为什么还要docker?\n  virtualbox 等虚拟机提供的是完整的操作系统环境, 迁移的时候太大了。它们包含了大量类似硬件驱动、虚拟处理器、网络接口等等并不需要的信息，也需要比较长时间的启动，同时也会消耗大量的内存、CPU 资源。\n\n  Docker 相比起来就非常轻量级了。运行起来就和一个常规程序差不多。这个容器不仅仅运行快，创建一个镜像和制作文件系统快照也很快,甚至比vagrant更节约资源\n\n### 初体验\n下载docker 并安装 ubuntu 12.04 这里如果没有指明 `ubuntu:12.04`, 会将所有ubuntu镜像都下载。由于被墙，速度惨不忍睹.\n\n```\nzj@zheng-ji:~$ sudo apt-get install docker.io\nzj@zheng-ji:~$ sudo docker pull ubuntu:12.04 \n```\n\n查看已有的镜像\n\n```\nzj@zheng-ji:~$ sudo docker images\n```\n\n使用 bash 命令进入docker的指定镜像\n\n```\nzj@zheng-ji:~$ sudo docker run -t -i -p 3000 ubuntu:12.04 /bin/bash\n```\n\n这时候我就可以像一个新系统一样把玩了, 比如创建一个目录。\n\n```\nzj@zheng-ji:~$ mkdir /home/zj/test\n```\n\n好了，我想把这个现场保存下来做移植到别的地方直接使用。需要到 [这里](https://registry.hub.docker.com/u/) 注册一个账户，然后再上传，类似在 github  上面一样的操作。\n\n```\nsudo docker ps \n\n//因为我已经commit 过一次，所以名字变成我的别名 zhengji/helloworld\nzj@zheng-ji:~$ docker ps\nCONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS                     NAMES\n8dad3aa4451f        zhengji/helloworld:latest   bin/bash            27 minutes ago      Up 27 minutes       0.0.0.0:49156->3000/tcp   high_galileo      \n```\n\n可以看到要保存的镜像的 CONTAINER ID\n\n这个时候提交\n\n```\nzj@zheng-ji:~$ sudo docker commit 8dad3aa4451f zhengji/helloworld -m \"test\"\n61f9527f368395ee228af07062b3f1a26fa7143ba2721c4f9755ae93d588358e\n\nzj@zheng-ji:~$ sudo docker push zhengji/helloworld\n```\n\n下次pull 下来就可以使用了\n\n```\nsudo docker pull zhengji/helloworld\n```\n\n----------\n\n### 可能遇到的坑\n\n* 需要编辑 /etc/default/docker.io 然后编辑里面的,使得其可以解决 DNS解析\n\n```\nDOCKER_OPTS = \"-dns 8.8.8.8\"\n```\n\n* 设置 ufw 端口可转发\n\n```\nvim /etc/default/ufw\nDEFAULT_FORWARD_POLICY = \"ACCEPT\"\n```\n\n\n### 参考链接\n\n* [docker 中文](http://www.docker.org.cn/book/docker.html)\n* [docker官网](http://www.docker.org.cn/book/docker.html)\n* [Docker入门教程](http://segmentfault.com/a/1190000000366923)\n\n\n","source":"_posts/2014-07-16-zhe-teng-docker.markdown","raw":"---\nlayout: post\ntitle: \"折腾 Docker\"\ndate: 2014-07-16 20:20\ncomments: true\ncategories: Server \nkeywords: ubuntu docker\ndescription: ubuntu docker\n---\n\n  早在1年前就听过 [docker](http://docs.docker.com/)这个 Golang 社区的明星产品 。\n\n### 简单地介绍\n\n  Docker 提供了一个可以运行你的应用程序的容器。像一个可移植的容器引擎那样工作。它把应用程序及所有程序的依赖环境打包到一个虚拟容器中，这个虚拟容器可以运行在任何一种 Linux 服务器上。这大大地提高了程序运行的灵活性和可移植性，极大的降低运维成本。\n\n### 组成\n\n* Docker 服务器守护程序（server daemon），用于管理所有的容器。\n* Docker 命令行客户端，用于控制服务器守护程序。\n* Docker 镜像：查找和浏览 docker 容器镜像。它也访问这里得到：[链接](https://index.docker.io/)\n\n\n### 有了虚拟机为什么还要docker?\n  virtualbox 等虚拟机提供的是完整的操作系统环境, 迁移的时候太大了。它们包含了大量类似硬件驱动、虚拟处理器、网络接口等等并不需要的信息，也需要比较长时间的启动，同时也会消耗大量的内存、CPU 资源。\n\n  Docker 相比起来就非常轻量级了。运行起来就和一个常规程序差不多。这个容器不仅仅运行快，创建一个镜像和制作文件系统快照也很快,甚至比vagrant更节约资源\n\n### 初体验\n下载docker 并安装 ubuntu 12.04 这里如果没有指明 `ubuntu:12.04`, 会将所有ubuntu镜像都下载。由于被墙，速度惨不忍睹.\n\n```\nzj@zheng-ji:~$ sudo apt-get install docker.io\nzj@zheng-ji:~$ sudo docker pull ubuntu:12.04 \n```\n\n查看已有的镜像\n\n```\nzj@zheng-ji:~$ sudo docker images\n```\n\n使用 bash 命令进入docker的指定镜像\n\n```\nzj@zheng-ji:~$ sudo docker run -t -i -p 3000 ubuntu:12.04 /bin/bash\n```\n\n这时候我就可以像一个新系统一样把玩了, 比如创建一个目录。\n\n```\nzj@zheng-ji:~$ mkdir /home/zj/test\n```\n\n好了，我想把这个现场保存下来做移植到别的地方直接使用。需要到 [这里](https://registry.hub.docker.com/u/) 注册一个账户，然后再上传，类似在 github  上面一样的操作。\n\n```\nsudo docker ps \n\n//因为我已经commit 过一次，所以名字变成我的别名 zhengji/helloworld\nzj@zheng-ji:~$ docker ps\nCONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS                     NAMES\n8dad3aa4451f        zhengji/helloworld:latest   bin/bash            27 minutes ago      Up 27 minutes       0.0.0.0:49156->3000/tcp   high_galileo      \n```\n\n可以看到要保存的镜像的 CONTAINER ID\n\n这个时候提交\n\n```\nzj@zheng-ji:~$ sudo docker commit 8dad3aa4451f zhengji/helloworld -m \"test\"\n61f9527f368395ee228af07062b3f1a26fa7143ba2721c4f9755ae93d588358e\n\nzj@zheng-ji:~$ sudo docker push zhengji/helloworld\n```\n\n下次pull 下来就可以使用了\n\n```\nsudo docker pull zhengji/helloworld\n```\n\n----------\n\n### 可能遇到的坑\n\n* 需要编辑 /etc/default/docker.io 然后编辑里面的,使得其可以解决 DNS解析\n\n```\nDOCKER_OPTS = \"-dns 8.8.8.8\"\n```\n\n* 设置 ufw 端口可转发\n\n```\nvim /etc/default/ufw\nDEFAULT_FORWARD_POLICY = \"ACCEPT\"\n```\n\n\n### 参考链接\n\n* [docker 中文](http://www.docker.org.cn/book/docker.html)\n* [docker官网](http://www.docker.org.cn/book/docker.html)\n* [Docker入门教程](http://segmentfault.com/a/1190000000366923)\n\n\n","slug":"2014-07-16-zhe-teng-docker","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9b002inctj0avu1hbn","content":"<p>  早在1年前就听过 <a href=\"http://docs.docker.com/\" target=\"_blank\" rel=\"noopener\">docker</a>这个 Golang 社区的明星产品 。</p>\n<h3 id=\"简单地介绍\"><a href=\"#简单地介绍\" class=\"headerlink\" title=\"简单地介绍\"></a>简单地介绍</h3><p>  Docker 提供了一个可以运行你的应用程序的容器。像一个可移植的容器引擎那样工作。它把应用程序及所有程序的依赖环境打包到一个虚拟容器中，这个虚拟容器可以运行在任何一种 Linux 服务器上。这大大地提高了程序运行的灵活性和可移植性，极大的降低运维成本。</p>\n<h3 id=\"组成\"><a href=\"#组成\" class=\"headerlink\" title=\"组成\"></a>组成</h3><ul>\n<li>Docker 服务器守护程序（server daemon），用于管理所有的容器。</li>\n<li>Docker 命令行客户端，用于控制服务器守护程序。</li>\n<li>Docker 镜像：查找和浏览 docker 容器镜像。它也访问这里得到：<a href=\"https://index.docker.io/\" target=\"_blank\" rel=\"noopener\">链接</a></li>\n</ul>\n<h3 id=\"有了虚拟机为什么还要docker\"><a href=\"#有了虚拟机为什么还要docker\" class=\"headerlink\" title=\"有了虚拟机为什么还要docker?\"></a>有了虚拟机为什么还要docker?</h3><p>  virtualbox 等虚拟机提供的是完整的操作系统环境, 迁移的时候太大了。它们包含了大量类似硬件驱动、虚拟处理器、网络接口等等并不需要的信息，也需要比较长时间的启动，同时也会消耗大量的内存、CPU 资源。</p>\n<p>  Docker 相比起来就非常轻量级了。运行起来就和一个常规程序差不多。这个容器不仅仅运行快，创建一个镜像和制作文件系统快照也很快,甚至比vagrant更节约资源</p>\n<h3 id=\"初体验\"><a href=\"#初体验\" class=\"headerlink\" title=\"初体验\"></a>初体验</h3><p>下载docker 并安装 ubuntu 12.04 这里如果没有指明 <code>ubuntu:12.04</code>, 会将所有ubuntu镜像都下载。由于被墙，速度惨不忍睹.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ sudo apt-get install docker.io</span><br><span class=\"line\">zj@zheng-ji:~$ sudo docker pull ubuntu:12.04</span><br></pre></td></tr></table></figure>\n<p>查看已有的镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ sudo docker images</span><br></pre></td></tr></table></figure>\n<p>使用 bash 命令进入docker的指定镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ sudo docker run -t -i -p 3000 ubuntu:12.04 /bin/bash</span><br></pre></td></tr></table></figure>\n<p>这时候我就可以像一个新系统一样把玩了, 比如创建一个目录。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ mkdir /home/zj/test</span><br></pre></td></tr></table></figure>\n<p>好了，我想把这个现场保存下来做移植到别的地方直接使用。需要到 <a href=\"https://registry.hub.docker.com/u/\" target=\"_blank\" rel=\"noopener\">这里</a> 注册一个账户，然后再上传，类似在 github  上面一样的操作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker ps </span><br><span class=\"line\"></span><br><span class=\"line\">//因为我已经commit 过一次，所以名字变成我的别名 zhengji/helloworld</span><br><span class=\"line\">zj@zheng-ji:~$ docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class=\"line\">8dad3aa4451f        zhengji/helloworld:latest   bin/bash            27 minutes ago      Up 27 minutes       0.0.0.0:49156-&gt;3000/tcp   high_galileo</span><br></pre></td></tr></table></figure>\n<p>可以看到要保存的镜像的 CONTAINER ID</p>\n<p>这个时候提交</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ sudo docker commit 8dad3aa4451f zhengji/helloworld -m &quot;test&quot;</span><br><span class=\"line\">61f9527f368395ee228af07062b3f1a26fa7143ba2721c4f9755ae93d588358e</span><br><span class=\"line\"></span><br><span class=\"line\">zj@zheng-ji:~$ sudo docker push zhengji/helloworld</span><br></pre></td></tr></table></figure>\n<p>下次pull 下来就可以使用了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker pull zhengji/helloworld</span><br></pre></td></tr></table></figure>\n<hr>\n<h3 id=\"可能遇到的坑\"><a href=\"#可能遇到的坑\" class=\"headerlink\" title=\"可能遇到的坑\"></a>可能遇到的坑</h3><ul>\n<li>需要编辑 /etc/default/docker.io 然后编辑里面的,使得其可以解决 DNS解析</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DOCKER_OPTS = &quot;-dns 8.8.8.8&quot;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>设置 ufw 端口可转发</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/default/ufw</span><br><span class=\"line\">DEFAULT_FORWARD_POLICY = &quot;ACCEPT&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h3><ul>\n<li><a href=\"http://www.docker.org.cn/book/docker.html\" target=\"_blank\" rel=\"noopener\">docker 中文</a></li>\n<li><a href=\"http://www.docker.org.cn/book/docker.html\" target=\"_blank\" rel=\"noopener\">docker官网</a></li>\n<li><a href=\"http://segmentfault.com/a/1190000000366923\" target=\"_blank\" rel=\"noopener\">Docker入门教程</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>  早在1年前就听过 <a href=\"http://docs.docker.com/\" target=\"_blank\" rel=\"noopener\">docker</a>这个 Golang 社区的明星产品 。</p>\n<h3 id=\"简单地介绍\"><a href=\"#简单地介绍\" class=\"headerlink\" title=\"简单地介绍\"></a>简单地介绍</h3><p>  Docker 提供了一个可以运行你的应用程序的容器。像一个可移植的容器引擎那样工作。它把应用程序及所有程序的依赖环境打包到一个虚拟容器中，这个虚拟容器可以运行在任何一种 Linux 服务器上。这大大地提高了程序运行的灵活性和可移植性，极大的降低运维成本。</p>\n<h3 id=\"组成\"><a href=\"#组成\" class=\"headerlink\" title=\"组成\"></a>组成</h3><ul>\n<li>Docker 服务器守护程序（server daemon），用于管理所有的容器。</li>\n<li>Docker 命令行客户端，用于控制服务器守护程序。</li>\n<li>Docker 镜像：查找和浏览 docker 容器镜像。它也访问这里得到：<a href=\"https://index.docker.io/\" target=\"_blank\" rel=\"noopener\">链接</a></li>\n</ul>\n<h3 id=\"有了虚拟机为什么还要docker\"><a href=\"#有了虚拟机为什么还要docker\" class=\"headerlink\" title=\"有了虚拟机为什么还要docker?\"></a>有了虚拟机为什么还要docker?</h3><p>  virtualbox 等虚拟机提供的是完整的操作系统环境, 迁移的时候太大了。它们包含了大量类似硬件驱动、虚拟处理器、网络接口等等并不需要的信息，也需要比较长时间的启动，同时也会消耗大量的内存、CPU 资源。</p>\n<p>  Docker 相比起来就非常轻量级了。运行起来就和一个常规程序差不多。这个容器不仅仅运行快，创建一个镜像和制作文件系统快照也很快,甚至比vagrant更节约资源</p>\n<h3 id=\"初体验\"><a href=\"#初体验\" class=\"headerlink\" title=\"初体验\"></a>初体验</h3><p>下载docker 并安装 ubuntu 12.04 这里如果没有指明 <code>ubuntu:12.04</code>, 会将所有ubuntu镜像都下载。由于被墙，速度惨不忍睹.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ sudo apt-get install docker.io</span><br><span class=\"line\">zj@zheng-ji:~$ sudo docker pull ubuntu:12.04</span><br></pre></td></tr></table></figure>\n<p>查看已有的镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ sudo docker images</span><br></pre></td></tr></table></figure>\n<p>使用 bash 命令进入docker的指定镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ sudo docker run -t -i -p 3000 ubuntu:12.04 /bin/bash</span><br></pre></td></tr></table></figure>\n<p>这时候我就可以像一个新系统一样把玩了, 比如创建一个目录。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ mkdir /home/zj/test</span><br></pre></td></tr></table></figure>\n<p>好了，我想把这个现场保存下来做移植到别的地方直接使用。需要到 <a href=\"https://registry.hub.docker.com/u/\" target=\"_blank\" rel=\"noopener\">这里</a> 注册一个账户，然后再上传，类似在 github  上面一样的操作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker ps </span><br><span class=\"line\"></span><br><span class=\"line\">//因为我已经commit 过一次，所以名字变成我的别名 zhengji/helloworld</span><br><span class=\"line\">zj@zheng-ji:~$ docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class=\"line\">8dad3aa4451f        zhengji/helloworld:latest   bin/bash            27 minutes ago      Up 27 minutes       0.0.0.0:49156-&gt;3000/tcp   high_galileo</span><br></pre></td></tr></table></figure>\n<p>可以看到要保存的镜像的 CONTAINER ID</p>\n<p>这个时候提交</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~$ sudo docker commit 8dad3aa4451f zhengji/helloworld -m &quot;test&quot;</span><br><span class=\"line\">61f9527f368395ee228af07062b3f1a26fa7143ba2721c4f9755ae93d588358e</span><br><span class=\"line\"></span><br><span class=\"line\">zj@zheng-ji:~$ sudo docker push zhengji/helloworld</span><br></pre></td></tr></table></figure>\n<p>下次pull 下来就可以使用了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker pull zhengji/helloworld</span><br></pre></td></tr></table></figure>\n<hr>\n<h3 id=\"可能遇到的坑\"><a href=\"#可能遇到的坑\" class=\"headerlink\" title=\"可能遇到的坑\"></a>可能遇到的坑</h3><ul>\n<li>需要编辑 /etc/default/docker.io 然后编辑里面的,使得其可以解决 DNS解析</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DOCKER_OPTS = &quot;-dns 8.8.8.8&quot;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>设置 ufw 端口可转发</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/default/ufw</span><br><span class=\"line\">DEFAULT_FORWARD_POLICY = &quot;ACCEPT&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h3><ul>\n<li><a href=\"http://www.docker.org.cn/book/docker.html\" target=\"_blank\" rel=\"noopener\">docker 中文</a></li>\n<li><a href=\"http://www.docker.org.cn/book/docker.html\" target=\"_blank\" rel=\"noopener\">docker官网</a></li>\n<li><a href=\"http://segmentfault.com/a/1190000000366923\" target=\"_blank\" rel=\"noopener\">Docker入门教程</a></li>\n</ul>\n"},{"layout":"post","title":"rsyslog 接收远程日志","date":"2014-07-27T06:26:00.000Z","comments":1,"keywords":"rsyslog 配置","description":"rsyslog 配置","_content":"\nRsyslog 接收远程日志\n\n需要开启运程模式, 以ubuntu为例子\n\n```\nvim /etc/default/rsyslog\nRSYSLOGD_OPTIONS=\"-c5 -r -x\"\n```\n\n编写模板,文档中说到要在`rsyslog.conf`里面编辑\n\n```\nvim /etc/rsyslog.conf\n$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat\n$template DynFile, \"/data/log/%$year%%$month%%$day%/%$year%%$month%%$day%%$hour%.log\"\n$template dotalogformat, \"%msg%\\n\"\n```\n\n编写过滤规则, 修改 `/etc/rsysconf.d/your_business.conf`\n\n```\n# 开通端口\n$ModLoad imtcp\n$InputTCPServerRun 1514\n\n# 过滤规则\nif $msg contains \"xx\" then ?DynFile;dotalogformat\n\n# 为了不让它写入syslog.log 而直接写入目标模板\n:msg, contains, \"xx\" ~\n```\n\n重启服务\n\n```\nsudo service rsyslog start\n```\n\n","source":"_posts/2014-07-27-rsyslog-jie-shou-yuan-cheng-ri-zhi.markdown","raw":"---\nlayout: post\ntitle: \"rsyslog 接收远程日志\"\ndate: 2014-07-27 14:26\ncomments: true\nkeywords: rsyslog 配置\ndescription: rsyslog 配置\ncategories: Server\n---\n\nRsyslog 接收远程日志\n\n需要开启运程模式, 以ubuntu为例子\n\n```\nvim /etc/default/rsyslog\nRSYSLOGD_OPTIONS=\"-c5 -r -x\"\n```\n\n编写模板,文档中说到要在`rsyslog.conf`里面编辑\n\n```\nvim /etc/rsyslog.conf\n$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat\n$template DynFile, \"/data/log/%$year%%$month%%$day%/%$year%%$month%%$day%%$hour%.log\"\n$template dotalogformat, \"%msg%\\n\"\n```\n\n编写过滤规则, 修改 `/etc/rsysconf.d/your_business.conf`\n\n```\n# 开通端口\n$ModLoad imtcp\n$InputTCPServerRun 1514\n\n# 过滤规则\nif $msg contains \"xx\" then ?DynFile;dotalogformat\n\n# 为了不让它写入syslog.log 而直接写入目标模板\n:msg, contains, \"xx\" ~\n```\n\n重启服务\n\n```\nsudo service rsyslog start\n```\n\n","slug":"2014-07-27-rsyslog-jie-shou-yuan-cheng-ri-zhi","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9c002knctj29xqtk7z","content":"<p>Rsyslog 接收远程日志</p>\n<p>需要开启运程模式, 以ubuntu为例子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/default/rsyslog</span><br><span class=\"line\">RSYSLOGD_OPTIONS=&quot;-c5 -r -x&quot;</span><br></pre></td></tr></table></figure>\n<p>编写模板,文档中说到要在<code>rsyslog.conf</code>里面编辑</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/rsyslog.conf</span><br><span class=\"line\">$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat</span><br><span class=\"line\">$template DynFile, &quot;/data/log/%$year%%$month%%$day%/%$year%%$month%%$day%%$hour%.log&quot;</span><br><span class=\"line\">$template dotalogformat, &quot;%msg%\\n&quot;</span><br></pre></td></tr></table></figure>\n<p>编写过滤规则, 修改 <code>/etc/rsysconf.d/your_business.conf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 开通端口</span><br><span class=\"line\">$ModLoad imtcp</span><br><span class=\"line\">$InputTCPServerRun 1514</span><br><span class=\"line\"></span><br><span class=\"line\"># 过滤规则</span><br><span class=\"line\">if $msg contains &quot;xx&quot; then ?DynFile;dotalogformat</span><br><span class=\"line\"></span><br><span class=\"line\"># 为了不让它写入syslog.log 而直接写入目标模板</span><br><span class=\"line\">:msg, contains, &quot;xx&quot; ~</span><br></pre></td></tr></table></figure>\n<p>重启服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo service rsyslog start</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>Rsyslog 接收远程日志</p>\n<p>需要开启运程模式, 以ubuntu为例子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/default/rsyslog</span><br><span class=\"line\">RSYSLOGD_OPTIONS=&quot;-c5 -r -x&quot;</span><br></pre></td></tr></table></figure>\n<p>编写模板,文档中说到要在<code>rsyslog.conf</code>里面编辑</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/rsyslog.conf</span><br><span class=\"line\">$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat</span><br><span class=\"line\">$template DynFile, &quot;/data/log/%$year%%$month%%$day%/%$year%%$month%%$day%%$hour%.log&quot;</span><br><span class=\"line\">$template dotalogformat, &quot;%msg%\\n&quot;</span><br></pre></td></tr></table></figure>\n<p>编写过滤规则, 修改 <code>/etc/rsysconf.d/your_business.conf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 开通端口</span><br><span class=\"line\">$ModLoad imtcp</span><br><span class=\"line\">$InputTCPServerRun 1514</span><br><span class=\"line\"></span><br><span class=\"line\"># 过滤规则</span><br><span class=\"line\">if $msg contains &quot;xx&quot; then ?DynFile;dotalogformat</span><br><span class=\"line\"></span><br><span class=\"line\"># 为了不让它写入syslog.log 而直接写入目标模板</span><br><span class=\"line\">:msg, contains, &quot;xx&quot; ~</span><br></pre></td></tr></table></figure>\n<p>重启服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo service rsyslog start</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Percona Server 做主从","date":"2014-09-07T07:31:00.000Z","comments":1,"description":"Mysql 主从","_content":"\n数据库做主从目的:\n\n+ 故障恢复， 柔性可用\n+ 也可以做读写分离\n\n实验过程中 mysql 用的版本是 Percona Server ，\n\n[安装过程](http://www.percona.com/doc/percona-server/5.5/installation/apt_repo.html)\n\n由于修改默认的数据目录，数据文件不再使用 `/var/lib/mysql`,数据文件夹被我安放位置是 `/data/mysql/data` 同时log 目录也放在这里 `/data/mysql/log` \n注意需要修改目录属主\n\n```\nsudo chown mysql:mysql  -R /data/mysql\n然后执行 sudo mysql_install_db \n```\n\n\n这时候会发生 `sudo service mysql stop` 失败，原因和方法见此 [神贴](http://serverfault.com/questions/32692/cant-start-stop-mysql-service/420222#420222)\n\n好了开始进入正题了，备份数据的原理\n\n+ 在主库上把数据更改记录到二进制日志 (Binary Log) \n+ 备库将主库的日志复制到自己的中继日志中\n+ 备库读取中继日志的事件，将其重放到备库的数据之上\n\n\n从其他服务器克隆备库的方法：\n\n+ 使用冷备份：关闭主库，将数据复制到备库，重启主库后，会使用一个新的二进制日志文件，在备库执行 CHANGE MASTER TO 指向这个文件的起始处，缺陷在于关闭主库\n+ 使用热备份，如果仅使用，mysqlhotcopy,或rsync来复制数据\n+ 使用快照或备份：需要知道二进制日志坐标，就可以使用主库的快照和备份来初始化备库，只需要把备份或快照恢复到备库，然后使用 CHANGE MASTER TO 指定二进制日志的坐标.\n+ 用`Percona Xtrabackup`  个人推荐  [链接](http://www.percona.com/doc/percona-xtrabackup/2.1/howtos/setting_up_replication.html)\n\n----\n\n### 实际的步骤如下\n\n+ 备份主库的数据\n\n```\ninnobackupex --user=root --password=xxx /home/zj/backup\n```\n在/home/zj/backup目录下就生成了2014-08-21_10-11-4` 目录\n\n+ 复制数据到从库，通过`scp`将上一步生成的目录放置在从库机器(~/tmp`)将原来的data目录备份, 在从库机器执行\n\n```\nmv /data/mysql/data /data/mysql/data_bak\nmv ~/tmp/2014-08-21_10-11-46  /data/mysql/data\nchown mysql:mysql -R /data/mysql/data\n```\n\n+ 配置主服务器\n\n```\nGRANT REPLICATION SLAVE ON *.*  TO 'repl'@'$slaveip' IDENTIFIED BY ''slavepass\n```\n\n+ 配置从数据库,并重启\n\n```\nserver-id=2\n```\n\n+ 开始复制\n\n需要定位位置\n\n```\ncat /data/mysql/data/xtrabackup_binlog_info\nlog-bin.000001     481\n```\n\n+ 在从库执行 \n\n```\nmysql> CHANGE MASTER TO MASTER_HOST='$masterip',\n       MASTER_USER='repl',\n       MASTER_PASSWORD='$slavepass',\n       MASTER_LOG_FILE='log-bin.000001',\n       MASTER_LOG_POS=481;\nmysql> START SLAVE;\nmysql> SHOW SLAVE STATUS \\G\n ```\n\n-----\n\n系统学习的书籍 \n\n[《高性能 mysql》](http://book.douban.com/subject/23008813/)\n \n","source":"_posts/2014-09-07-percona-server-zuo-zhu-cong.markdown","raw":"---\nlayout: post\ntitle: \"Percona Server 做主从\"\ndate: 2014-09-07 15:31\ncomments: true\ndescription: Mysql 主从\ncategories: DataBase\n---\n\n数据库做主从目的:\n\n+ 故障恢复， 柔性可用\n+ 也可以做读写分离\n\n实验过程中 mysql 用的版本是 Percona Server ，\n\n[安装过程](http://www.percona.com/doc/percona-server/5.5/installation/apt_repo.html)\n\n由于修改默认的数据目录，数据文件不再使用 `/var/lib/mysql`,数据文件夹被我安放位置是 `/data/mysql/data` 同时log 目录也放在这里 `/data/mysql/log` \n注意需要修改目录属主\n\n```\nsudo chown mysql:mysql  -R /data/mysql\n然后执行 sudo mysql_install_db \n```\n\n\n这时候会发生 `sudo service mysql stop` 失败，原因和方法见此 [神贴](http://serverfault.com/questions/32692/cant-start-stop-mysql-service/420222#420222)\n\n好了开始进入正题了，备份数据的原理\n\n+ 在主库上把数据更改记录到二进制日志 (Binary Log) \n+ 备库将主库的日志复制到自己的中继日志中\n+ 备库读取中继日志的事件，将其重放到备库的数据之上\n\n\n从其他服务器克隆备库的方法：\n\n+ 使用冷备份：关闭主库，将数据复制到备库，重启主库后，会使用一个新的二进制日志文件，在备库执行 CHANGE MASTER TO 指向这个文件的起始处，缺陷在于关闭主库\n+ 使用热备份，如果仅使用，mysqlhotcopy,或rsync来复制数据\n+ 使用快照或备份：需要知道二进制日志坐标，就可以使用主库的快照和备份来初始化备库，只需要把备份或快照恢复到备库，然后使用 CHANGE MASTER TO 指定二进制日志的坐标.\n+ 用`Percona Xtrabackup`  个人推荐  [链接](http://www.percona.com/doc/percona-xtrabackup/2.1/howtos/setting_up_replication.html)\n\n----\n\n### 实际的步骤如下\n\n+ 备份主库的数据\n\n```\ninnobackupex --user=root --password=xxx /home/zj/backup\n```\n在/home/zj/backup目录下就生成了2014-08-21_10-11-4` 目录\n\n+ 复制数据到从库，通过`scp`将上一步生成的目录放置在从库机器(~/tmp`)将原来的data目录备份, 在从库机器执行\n\n```\nmv /data/mysql/data /data/mysql/data_bak\nmv ~/tmp/2014-08-21_10-11-46  /data/mysql/data\nchown mysql:mysql -R /data/mysql/data\n```\n\n+ 配置主服务器\n\n```\nGRANT REPLICATION SLAVE ON *.*  TO 'repl'@'$slaveip' IDENTIFIED BY ''slavepass\n```\n\n+ 配置从数据库,并重启\n\n```\nserver-id=2\n```\n\n+ 开始复制\n\n需要定位位置\n\n```\ncat /data/mysql/data/xtrabackup_binlog_info\nlog-bin.000001     481\n```\n\n+ 在从库执行 \n\n```\nmysql> CHANGE MASTER TO MASTER_HOST='$masterip',\n       MASTER_USER='repl',\n       MASTER_PASSWORD='$slavepass',\n       MASTER_LOG_FILE='log-bin.000001',\n       MASTER_LOG_POS=481;\nmysql> START SLAVE;\nmysql> SHOW SLAVE STATUS \\G\n ```\n\n-----\n\n系统学习的书籍 \n\n[《高性能 mysql》](http://book.douban.com/subject/23008813/)\n \n","slug":"2014-09-07-percona-server-zuo-zhu-cong","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9d002mnctjpe6rcqkd","content":"<p>数据库做主从目的:</p>\n<ul>\n<li>故障恢复， 柔性可用</li>\n<li>也可以做读写分离</li>\n</ul>\n<p>实验过程中 mysql 用的版本是 Percona Server ，</p>\n<p><a href=\"http://www.percona.com/doc/percona-server/5.5/installation/apt_repo.html\" target=\"_blank\" rel=\"noopener\">安装过程</a></p>\n<p>由于修改默认的数据目录，数据文件不再使用 <code>/var/lib/mysql</code>,数据文件夹被我安放位置是 <code>/data/mysql/data</code> 同时log 目录也放在这里 <code>/data/mysql/log</code><br>注意需要修改目录属主</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo chown mysql:mysql  -R /data/mysql</span><br><span class=\"line\">然后执行 sudo mysql_install_db</span><br></pre></td></tr></table></figure>\n<p>这时候会发生 <code>sudo service mysql stop</code> 失败，原因和方法见此 <a href=\"http://serverfault.com/questions/32692/cant-start-stop-mysql-service/420222#420222\" target=\"_blank\" rel=\"noopener\">神贴</a></p>\n<p>好了开始进入正题了，备份数据的原理</p>\n<ul>\n<li>在主库上把数据更改记录到二进制日志 (Binary Log) </li>\n<li>备库将主库的日志复制到自己的中继日志中</li>\n<li>备库读取中继日志的事件，将其重放到备库的数据之上</li>\n</ul>\n<p>从其他服务器克隆备库的方法：</p>\n<ul>\n<li>使用冷备份：关闭主库，将数据复制到备库，重启主库后，会使用一个新的二进制日志文件，在备库执行 CHANGE MASTER TO 指向这个文件的起始处，缺陷在于关闭主库</li>\n<li>使用热备份，如果仅使用，mysqlhotcopy,或rsync来复制数据</li>\n<li>使用快照或备份：需要知道二进制日志坐标，就可以使用主库的快照和备份来初始化备库，只需要把备份或快照恢复到备库，然后使用 CHANGE MASTER TO 指定二进制日志的坐标.</li>\n<li>用<code>Percona Xtrabackup</code>  个人推荐  <a href=\"http://www.percona.com/doc/percona-xtrabackup/2.1/howtos/setting_up_replication.html\" target=\"_blank\" rel=\"noopener\">链接</a></li>\n</ul>\n<hr>\n<h3 id=\"实际的步骤如下\"><a href=\"#实际的步骤如下\" class=\"headerlink\" title=\"实际的步骤如下\"></a>实际的步骤如下</h3><ul>\n<li>备份主库的数据</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innobackupex --user=root --password=xxx /home/zj/backup</span><br></pre></td></tr></table></figure>\n<p>在/home/zj/backup目录下就生成了2014-08-21_10-11-4` 目录</p>\n<ul>\n<li>复制数据到从库，通过<code>scp</code>将上一步生成的目录放置在从库机器(~/tmp`)将原来的data目录备份, 在从库机器执行</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mv /data/mysql/data /data/mysql/data_bak</span><br><span class=\"line\">mv ~/tmp/2014-08-21_10-11-46  /data/mysql/data</span><br><span class=\"line\">chown mysql:mysql -R /data/mysql/data</span><br></pre></td></tr></table></figure>\n<ul>\n<li>配置主服务器</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GRANT REPLICATION SLAVE ON *.*  TO &apos;repl&apos;@&apos;$slaveip&apos; IDENTIFIED BY &apos;&apos;slavepass</span><br></pre></td></tr></table></figure>\n<ul>\n<li>配置从数据库,并重启</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server-id=2</span><br></pre></td></tr></table></figure>\n<ul>\n<li>开始复制</li>\n</ul>\n<p>需要定位位置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /data/mysql/data/xtrabackup_binlog_info</span><br><span class=\"line\">log-bin.000001     481</span><br></pre></td></tr></table></figure>\n<ul>\n<li>在从库执行 </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; CHANGE MASTER TO MASTER_HOST=&apos;$masterip&apos;,</span><br><span class=\"line\">       MASTER_USER=&apos;repl&apos;,</span><br><span class=\"line\">       MASTER_PASSWORD=&apos;$slavepass&apos;,</span><br><span class=\"line\">       MASTER_LOG_FILE=&apos;log-bin.000001&apos;,</span><br><span class=\"line\">       MASTER_LOG_POS=481;</span><br><span class=\"line\">mysql&gt; START SLAVE;</span><br><span class=\"line\">mysql&gt; SHOW SLAVE STATUS \\G</span><br></pre></td></tr></table></figure>\n<hr>\n<p>系统学习的书籍 </p>\n<p><a href=\"http://book.douban.com/subject/23008813/\" target=\"_blank\" rel=\"noopener\">《高性能 mysql》</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>数据库做主从目的:</p>\n<ul>\n<li>故障恢复， 柔性可用</li>\n<li>也可以做读写分离</li>\n</ul>\n<p>实验过程中 mysql 用的版本是 Percona Server ，</p>\n<p><a href=\"http://www.percona.com/doc/percona-server/5.5/installation/apt_repo.html\" target=\"_blank\" rel=\"noopener\">安装过程</a></p>\n<p>由于修改默认的数据目录，数据文件不再使用 <code>/var/lib/mysql</code>,数据文件夹被我安放位置是 <code>/data/mysql/data</code> 同时log 目录也放在这里 <code>/data/mysql/log</code><br>注意需要修改目录属主</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo chown mysql:mysql  -R /data/mysql</span><br><span class=\"line\">然后执行 sudo mysql_install_db</span><br></pre></td></tr></table></figure>\n<p>这时候会发生 <code>sudo service mysql stop</code> 失败，原因和方法见此 <a href=\"http://serverfault.com/questions/32692/cant-start-stop-mysql-service/420222#420222\" target=\"_blank\" rel=\"noopener\">神贴</a></p>\n<p>好了开始进入正题了，备份数据的原理</p>\n<ul>\n<li>在主库上把数据更改记录到二进制日志 (Binary Log) </li>\n<li>备库将主库的日志复制到自己的中继日志中</li>\n<li>备库读取中继日志的事件，将其重放到备库的数据之上</li>\n</ul>\n<p>从其他服务器克隆备库的方法：</p>\n<ul>\n<li>使用冷备份：关闭主库，将数据复制到备库，重启主库后，会使用一个新的二进制日志文件，在备库执行 CHANGE MASTER TO 指向这个文件的起始处，缺陷在于关闭主库</li>\n<li>使用热备份，如果仅使用，mysqlhotcopy,或rsync来复制数据</li>\n<li>使用快照或备份：需要知道二进制日志坐标，就可以使用主库的快照和备份来初始化备库，只需要把备份或快照恢复到备库，然后使用 CHANGE MASTER TO 指定二进制日志的坐标.</li>\n<li>用<code>Percona Xtrabackup</code>  个人推荐  <a href=\"http://www.percona.com/doc/percona-xtrabackup/2.1/howtos/setting_up_replication.html\" target=\"_blank\" rel=\"noopener\">链接</a></li>\n</ul>\n<hr>\n<h3 id=\"实际的步骤如下\"><a href=\"#实际的步骤如下\" class=\"headerlink\" title=\"实际的步骤如下\"></a>实际的步骤如下</h3><ul>\n<li>备份主库的数据</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innobackupex --user=root --password=xxx /home/zj/backup</span><br></pre></td></tr></table></figure>\n<p>在/home/zj/backup目录下就生成了2014-08-21_10-11-4` 目录</p>\n<ul>\n<li>复制数据到从库，通过<code>scp</code>将上一步生成的目录放置在从库机器(~/tmp`)将原来的data目录备份, 在从库机器执行</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mv /data/mysql/data /data/mysql/data_bak</span><br><span class=\"line\">mv ~/tmp/2014-08-21_10-11-46  /data/mysql/data</span><br><span class=\"line\">chown mysql:mysql -R /data/mysql/data</span><br></pre></td></tr></table></figure>\n<ul>\n<li>配置主服务器</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GRANT REPLICATION SLAVE ON *.*  TO &apos;repl&apos;@&apos;$slaveip&apos; IDENTIFIED BY &apos;&apos;slavepass</span><br></pre></td></tr></table></figure>\n<ul>\n<li>配置从数据库,并重启</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server-id=2</span><br></pre></td></tr></table></figure>\n<ul>\n<li>开始复制</li>\n</ul>\n<p>需要定位位置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /data/mysql/data/xtrabackup_binlog_info</span><br><span class=\"line\">log-bin.000001     481</span><br></pre></td></tr></table></figure>\n<ul>\n<li>在从库执行 </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; CHANGE MASTER TO MASTER_HOST=&apos;$masterip&apos;,</span><br><span class=\"line\">       MASTER_USER=&apos;repl&apos;,</span><br><span class=\"line\">       MASTER_PASSWORD=&apos;$slavepass&apos;,</span><br><span class=\"line\">       MASTER_LOG_FILE=&apos;log-bin.000001&apos;,</span><br><span class=\"line\">       MASTER_LOG_POS=481;</span><br><span class=\"line\">mysql&gt; START SLAVE;</span><br><span class=\"line\">mysql&gt; SHOW SLAVE STATUS \\G</span><br></pre></td></tr></table></figure>\n<hr>\n<p>系统学习的书籍 </p>\n<p><a href=\"http://book.douban.com/subject/23008813/\" target=\"_blank\" rel=\"noopener\">《高性能 mysql》</a></p>\n"},{"layout":"post","title":"redis 主从平滑切换","date":"2014-10-04T14:28:00.000Z","comments":1,"description":"Redis slave","_content":"\n业务原来所在的Redis需要做迁移，感谢Redis，主从切换不算太复杂。\n为了可以更好地阐述过程，我们定义了：\n\n* A 服务器，原来拥有 redis 数据库的机器\n* B 服务器，未来取代 A 服务器的 redis 数据库服务器\n\n\n## 主从同步\n\n把 B 服务器的 redis 配置更改为:\n\n```\nslaveof  IP地址 端口\n```\n\n这样就开始同步了，并且只读了。接下来准备把 B 服务器提升为 master,\n\n```\nredis-in-b-host> slaveof no one\n```\n\nB服务器就断掉主从同步，提升为主，并行可读写\n\n## Tips;\n\n我们在停止服务的5分钟，在 A 的命令行，执行\n\n```\nbgsave\n```\n使得内存里的数据，完整地保存于 dumps.rdb\n","source":"_posts/2014-10-04-redisre-bei.markdown","raw":"---\nlayout: post\ntitle: \"redis 主从平滑切换\"\ndate: 2014-10-04 22:28\ncomments: true\ndescription: Redis slave\ncategories: DataBase\n---\n\n业务原来所在的Redis需要做迁移，感谢Redis，主从切换不算太复杂。\n为了可以更好地阐述过程，我们定义了：\n\n* A 服务器，原来拥有 redis 数据库的机器\n* B 服务器，未来取代 A 服务器的 redis 数据库服务器\n\n\n## 主从同步\n\n把 B 服务器的 redis 配置更改为:\n\n```\nslaveof  IP地址 端口\n```\n\n这样就开始同步了，并且只读了。接下来准备把 B 服务器提升为 master,\n\n```\nredis-in-b-host> slaveof no one\n```\n\nB服务器就断掉主从同步，提升为主，并行可读写\n\n## Tips;\n\n我们在停止服务的5分钟，在 A 的命令行，执行\n\n```\nbgsave\n```\n使得内存里的数据，完整地保存于 dumps.rdb\n","slug":"2014-10-04-redisre-bei","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9e002onctjt2u62tv3","content":"<p>业务原来所在的Redis需要做迁移，感谢Redis，主从切换不算太复杂。<br>为了可以更好地阐述过程，我们定义了：</p>\n<ul>\n<li>A 服务器，原来拥有 redis 数据库的机器</li>\n<li>B 服务器，未来取代 A 服务器的 redis 数据库服务器</li>\n</ul>\n<h2 id=\"主从同步\"><a href=\"#主从同步\" class=\"headerlink\" title=\"主从同步\"></a>主从同步</h2><p>把 B 服务器的 redis 配置更改为:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">slaveof  IP地址 端口</span><br></pre></td></tr></table></figure>\n<p>这样就开始同步了，并且只读了。接下来准备把 B 服务器提升为 master,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis-in-b-host&gt; slaveof no one</span><br></pre></td></tr></table></figure>\n<p>B服务器就断掉主从同步，提升为主，并行可读写</p>\n<h2 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips;\"></a>Tips;</h2><p>我们在停止服务的5分钟，在 A 的命令行，执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bgsave</span><br></pre></td></tr></table></figure>\n<p>使得内存里的数据，完整地保存于 dumps.rdb</p>\n","site":{"data":{}},"excerpt":"","more":"<p>业务原来所在的Redis需要做迁移，感谢Redis，主从切换不算太复杂。<br>为了可以更好地阐述过程，我们定义了：</p>\n<ul>\n<li>A 服务器，原来拥有 redis 数据库的机器</li>\n<li>B 服务器，未来取代 A 服务器的 redis 数据库服务器</li>\n</ul>\n<h2 id=\"主从同步\"><a href=\"#主从同步\" class=\"headerlink\" title=\"主从同步\"></a>主从同步</h2><p>把 B 服务器的 redis 配置更改为:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">slaveof  IP地址 端口</span><br></pre></td></tr></table></figure>\n<p>这样就开始同步了，并且只读了。接下来准备把 B 服务器提升为 master,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis-in-b-host&gt; slaveof no one</span><br></pre></td></tr></table></figure>\n<p>B服务器就断掉主从同步，提升为主，并行可读写</p>\n<h2 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips;\"></a>Tips;</h2><p>我们在停止服务的5分钟，在 A 的命令行，执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bgsave</span><br></pre></td></tr></table></figure>\n<p>使得内存里的数据，完整地保存于 dumps.rdb</p>\n"},{"layout":"post","title":"内存都去哪儿啦","date":"2014-10-13T13:20:00.000Z","comments":1,"keywords":"内存 Top","description":"内存","_content":"\n###看到的现象###\n\n今天在游戏服务器上使用了top 命令系统使用参数，发现内存16G 的内存用了12G, 如下\n{% img /images/2014/10/top.png %}\n但是同时在线人数不多，机器的负载并不是很大，并发也不高, 只有900+。\n{% img /images/2014/10/nestat.png %}\n而游戏的服务端代码仅仅使用了7.8G, 我们不禁会问，内存去哪里了？难道是系统自己占用的内存呢，不可能一个8核16G的机器系统自己占用了4G吧?\n\n带着这个疑问，查阅了资料，发现其中并非表明所看到的这么简单. 我们来看以下 使用 `free -m` 命令\n{% img /images/2014/10/free.png %}\n\n### Mem 参数 解释### \n+ total 内存总数: 15875 , total = used + free\n+ used 已经使用的内存数: 11900\n+ free 空闲的内存数: 3975\n+ shared 当前已经废弃不用，总是0\n+ buffers: Buffer Cache内存数: 145\n+ cached: Page Cache内存数: 5561\n\n### -/+ buffers/cache的解惑 ####\n+ -buffers/cache 的内存数: 6193 (大致等于第1行的 used - buffers - cached), 反映的是被程序实实在在吃掉的内存，\n+ +buffers/cache 的内存数: 9682 (大致等于第1行的 free + buffers + cached), 反映的是可以挪用的内存总数\n\n### 两种cache ###\n因为cpu速度明显快过内存， 为了提高磁盘存取效率, Linux做了一些精心的设计, 采取了两种主要Cache方式, 来做速度的过度, 这些Cache有效缩短了 I/O系统调用(如read,write,getdents)的时间。\n\n+ Buffer Cache, 针对磁盘块的读写\n+ Page Cache。针对文件inode的读写。\n\n### 内存解读的区别 ###\n\n第1行`(mem)的used/free`与第2行`(-/+ buffers/cache) used/free`的区别在于角度的不同:\n\n+ 第一行因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是3975M,已用内存是11900MB,其中包括,内核（OS）使用 + 应用使用的+ buffers + cached.\n+ 第2行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是可用的，是为了提高文件读取的性能而设，当应用程序要用到内存的时候，buffer/cached会很快地被回收。所以从应用程序的角度来说，\n\n```\n可用内存=系统free memory + buffers + cached.\n```\n所以，回到话题开头，虽然内存显示用了12.2G，正在被应用程序使用的是7.9G 还有5.6(cache+buffer) +  4G free 可用.内存原来在这里！\n\n获益匪浅 :) \n","source":"_posts/2014-10-13-nei-cun-du-qu-na-er-la.markdown","raw":"---\nlayout: post\ntitle: \"内存都去哪儿啦\"\ndate: 2014-10-13 21:20\ncomments: true\nkeywords: 内存 Top\ndescription: 内存\ncategories: System\n---\n\n###看到的现象###\n\n今天在游戏服务器上使用了top 命令系统使用参数，发现内存16G 的内存用了12G, 如下\n{% img /images/2014/10/top.png %}\n但是同时在线人数不多，机器的负载并不是很大，并发也不高, 只有900+。\n{% img /images/2014/10/nestat.png %}\n而游戏的服务端代码仅仅使用了7.8G, 我们不禁会问，内存去哪里了？难道是系统自己占用的内存呢，不可能一个8核16G的机器系统自己占用了4G吧?\n\n带着这个疑问，查阅了资料，发现其中并非表明所看到的这么简单. 我们来看以下 使用 `free -m` 命令\n{% img /images/2014/10/free.png %}\n\n### Mem 参数 解释### \n+ total 内存总数: 15875 , total = used + free\n+ used 已经使用的内存数: 11900\n+ free 空闲的内存数: 3975\n+ shared 当前已经废弃不用，总是0\n+ buffers: Buffer Cache内存数: 145\n+ cached: Page Cache内存数: 5561\n\n### -/+ buffers/cache的解惑 ####\n+ -buffers/cache 的内存数: 6193 (大致等于第1行的 used - buffers - cached), 反映的是被程序实实在在吃掉的内存，\n+ +buffers/cache 的内存数: 9682 (大致等于第1行的 free + buffers + cached), 反映的是可以挪用的内存总数\n\n### 两种cache ###\n因为cpu速度明显快过内存， 为了提高磁盘存取效率, Linux做了一些精心的设计, 采取了两种主要Cache方式, 来做速度的过度, 这些Cache有效缩短了 I/O系统调用(如read,write,getdents)的时间。\n\n+ Buffer Cache, 针对磁盘块的读写\n+ Page Cache。针对文件inode的读写。\n\n### 内存解读的区别 ###\n\n第1行`(mem)的used/free`与第2行`(-/+ buffers/cache) used/free`的区别在于角度的不同:\n\n+ 第一行因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是3975M,已用内存是11900MB,其中包括,内核（OS）使用 + 应用使用的+ buffers + cached.\n+ 第2行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是可用的，是为了提高文件读取的性能而设，当应用程序要用到内存的时候，buffer/cached会很快地被回收。所以从应用程序的角度来说，\n\n```\n可用内存=系统free memory + buffers + cached.\n```\n所以，回到话题开头，虽然内存显示用了12.2G，正在被应用程序使用的是7.9G 还有5.6(cache+buffer) +  4G free 可用.内存原来在这里！\n\n获益匪浅 :) \n","slug":"2014-10-13-nei-cun-du-qu-na-er-la","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9f002qnctj65loo7tr","content":"<p>###看到的现象###</p>\n<p>今天在游戏服务器上使用了top 命令系统使用参数，发现内存16G 的内存用了12G, 如下<br><img src=\"/images/2014/10/top.png\"><br>但是同时在线人数不多，机器的负载并不是很大，并发也不高, 只有900+。<br><img src=\"/images/2014/10/nestat.png\"><br>而游戏的服务端代码仅仅使用了7.8G, 我们不禁会问，内存去哪里了？难道是系统自己占用的内存呢，不可能一个8核16G的机器系统自己占用了4G吧?</p>\n<p>带着这个疑问，查阅了资料，发现其中并非表明所看到的这么简单. 我们来看以下 使用 <code>free -m</code> 命令<br><img src=\"/images/2014/10/free.png\"></p>\n<h3 id=\"Mem-参数-解释\"><a href=\"#Mem-参数-解释\" class=\"headerlink\" title=\"Mem 参数 解释\"></a>Mem 参数 解释</h3><ul>\n<li>total 内存总数: 15875 , total = used + free</li>\n<li>used 已经使用的内存数: 11900</li>\n<li>free 空闲的内存数: 3975</li>\n<li>shared 当前已经废弃不用，总是0</li>\n<li>buffers: Buffer Cache内存数: 145</li>\n<li>cached: Page Cache内存数: 5561</li>\n</ul>\n<h3 id=\"buffers-cache的解惑\"><a href=\"#buffers-cache的解惑\" class=\"headerlink\" title=\"-/+ buffers/cache的解惑\"></a>-/+ buffers/cache的解惑</h3><ul>\n<li>-buffers/cache 的内存数: 6193 (大致等于第1行的 used - buffers - cached), 反映的是被程序实实在在吃掉的内存，</li>\n<li>+buffers/cache 的内存数: 9682 (大致等于第1行的 free + buffers + cached), 反映的是可以挪用的内存总数</li>\n</ul>\n<h3 id=\"两种cache\"><a href=\"#两种cache\" class=\"headerlink\" title=\"两种cache\"></a>两种cache</h3><p>因为cpu速度明显快过内存， 为了提高磁盘存取效率, Linux做了一些精心的设计, 采取了两种主要Cache方式, 来做速度的过度, 这些Cache有效缩短了 I/O系统调用(如read,write,getdents)的时间。</p>\n<ul>\n<li>Buffer Cache, 针对磁盘块的读写</li>\n<li>Page Cache。针对文件inode的读写。</li>\n</ul>\n<h3 id=\"内存解读的区别\"><a href=\"#内存解读的区别\" class=\"headerlink\" title=\"内存解读的区别\"></a>内存解读的区别</h3><p>第1行<code>(mem)的used/free</code>与第2行<code>(-/+ buffers/cache) used/free</code>的区别在于角度的不同:</p>\n<ul>\n<li>第一行因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是3975M,已用内存是11900MB,其中包括,内核（OS）使用 + 应用使用的+ buffers + cached.</li>\n<li>第2行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是可用的，是为了提高文件读取的性能而设，当应用程序要用到内存的时候，buffer/cached会很快地被回收。所以从应用程序的角度来说，</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">可用内存=系统free memory + buffers + cached.</span><br></pre></td></tr></table></figure>\n<p>所以，回到话题开头，虽然内存显示用了12.2G，正在被应用程序使用的是7.9G 还有5.6(cache+buffer) +  4G free 可用.内存原来在这里！</p>\n<p>获益匪浅 :) </p>\n","site":{"data":{}},"excerpt":"","more":"<p>###看到的现象###</p>\n<p>今天在游戏服务器上使用了top 命令系统使用参数，发现内存16G 的内存用了12G, 如下<br><img src=\"/images/2014/10/top.png\"><br>但是同时在线人数不多，机器的负载并不是很大，并发也不高, 只有900+。<br><img src=\"/images/2014/10/nestat.png\"><br>而游戏的服务端代码仅仅使用了7.8G, 我们不禁会问，内存去哪里了？难道是系统自己占用的内存呢，不可能一个8核16G的机器系统自己占用了4G吧?</p>\n<p>带着这个疑问，查阅了资料，发现其中并非表明所看到的这么简单. 我们来看以下 使用 <code>free -m</code> 命令<br><img src=\"/images/2014/10/free.png\"></p>\n<h3 id=\"Mem-参数-解释\"><a href=\"#Mem-参数-解释\" class=\"headerlink\" title=\"Mem 参数 解释\"></a>Mem 参数 解释</h3><ul>\n<li>total 内存总数: 15875 , total = used + free</li>\n<li>used 已经使用的内存数: 11900</li>\n<li>free 空闲的内存数: 3975</li>\n<li>shared 当前已经废弃不用，总是0</li>\n<li>buffers: Buffer Cache内存数: 145</li>\n<li>cached: Page Cache内存数: 5561</li>\n</ul>\n<h3 id=\"buffers-cache的解惑\"><a href=\"#buffers-cache的解惑\" class=\"headerlink\" title=\"-/+ buffers/cache的解惑\"></a>-/+ buffers/cache的解惑</h3><ul>\n<li>-buffers/cache 的内存数: 6193 (大致等于第1行的 used - buffers - cached), 反映的是被程序实实在在吃掉的内存，</li>\n<li>+buffers/cache 的内存数: 9682 (大致等于第1行的 free + buffers + cached), 反映的是可以挪用的内存总数</li>\n</ul>\n<h3 id=\"两种cache\"><a href=\"#两种cache\" class=\"headerlink\" title=\"两种cache\"></a>两种cache</h3><p>因为cpu速度明显快过内存， 为了提高磁盘存取效率, Linux做了一些精心的设计, 采取了两种主要Cache方式, 来做速度的过度, 这些Cache有效缩短了 I/O系统调用(如read,write,getdents)的时间。</p>\n<ul>\n<li>Buffer Cache, 针对磁盘块的读写</li>\n<li>Page Cache。针对文件inode的读写。</li>\n</ul>\n<h3 id=\"内存解读的区别\"><a href=\"#内存解读的区别\" class=\"headerlink\" title=\"内存解读的区别\"></a>内存解读的区别</h3><p>第1行<code>(mem)的used/free</code>与第2行<code>(-/+ buffers/cache) used/free</code>的区别在于角度的不同:</p>\n<ul>\n<li>第一行因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是3975M,已用内存是11900MB,其中包括,内核（OS）使用 + 应用使用的+ buffers + cached.</li>\n<li>第2行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是可用的，是为了提高文件读取的性能而设，当应用程序要用到内存的时候，buffer/cached会很快地被回收。所以从应用程序的角度来说，</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">可用内存=系统free memory + buffers + cached.</span><br></pre></td></tr></table></figure>\n<p>所以，回到话题开头，虽然内存显示用了12.2G，正在被应用程序使用的是7.9G 还有5.6(cache+buffer) +  4G free 可用.内存原来在这里！</p>\n<p>获益匪浅 :) </p>\n"},{"layout":"post","title":"唯一索引引发的思考","date":"2014-10-23T15:18:00.000Z","comments":1,"keywords":"MySQL Index","description":"MySQL Index","_content":"\n最近需要改动线上一个有千万条记录的表，涉及到加字段操作，这个表有索引，按照经验，为了加速修改表结构,去掉索引。由于我删除的是Unique Index, 而服务一直在写,程序依赖数据库的唯一索引去重,导致瞬间有重复数据,唯一索引重新加上时会报 `Duplicated Key entry Error`,\n\n###回放事件###\n\n\n我们的数据表，之前是有 `UNIQUE INDEX(cuid, aid)`, 因为去掉索引，服务持续写入，导致有重复记录，所幸的是，这是一个统计表, 不影响功能，所以需要找出重复的记录\n\n```\nselect cuid,aid from (\n    select cuid, aid,count(1) as num\n    from register_chn \n    group by cuid,aid having num > 1\n) t;\n```\n\n显示有8条记录,如果手动删除,是很慢且愚蠢的做法,还是用 SQL 执行,镇定之后执行\n\n```\ndelete from register_chn where (cuid,aid) in (\n    select cuid,aid from (\n        select cuid, aid,count(1) as num\n        from register_chn\n        group by cuid,aid having num > 1\n    ) t\n);\n```\n影响了８条记录.然后瞬间加上索引.所幸是成功了, 事实上当时的合理操作应该是用事务。\n\n```\nBEGIN;\ndelete from register_chn where (cuid,aid) in (\n    select cuid,aid from (\n        select cuid, aid,count(1) as num\n        from register_chn\n        group by cuid,aid having num > 1\n    ) t\n);\nalter table register_chn add unique index(cuid, aid);\nCOMMINT;\n```\n\n###引发的思考###\n\n后来想想, 上述方法虽然解决问题了, 但是有点碰运气成分。如果频繁快速地产生重复记录,也许就没那么好运了,事实上可以执行以下 SQL:\n\n```\nalter ignore table register_chn add unique index(cuid, aid)；\n```\n\n如果你以为很简单,那就错了。这个方法在 MySQL 5.0 上使用是没问题的，但是在5.6 之前是有bug的，亲自测试Percona 版本5.5, 的确会失败\n官方的解决方法是：\n\n```\nset session old_alter_table = on;\nalter ignore table register_chn add unique index(cuid, aid);\n```\n\n在有主备的情况,记得执行前设置一下\n\n```\nset session sql_log_bin=off. \n```\n以免备库报错。同样还需要在备库重复一下主库的操作, 这也算是一个不太完美的解决思路。\n\n\n","source":"_posts/2014-10-24-mysql-unique-index.markdown","raw":"---\nlayout: post\ntitle: \"唯一索引引发的思考\"\ndate: 2014-10-23 23:18\ncomments: true\nkeywords: MySQL Index\ndescription: MySQL Index\ncategories: DataBase\n---\n\n最近需要改动线上一个有千万条记录的表，涉及到加字段操作，这个表有索引，按照经验，为了加速修改表结构,去掉索引。由于我删除的是Unique Index, 而服务一直在写,程序依赖数据库的唯一索引去重,导致瞬间有重复数据,唯一索引重新加上时会报 `Duplicated Key entry Error`,\n\n###回放事件###\n\n\n我们的数据表，之前是有 `UNIQUE INDEX(cuid, aid)`, 因为去掉索引，服务持续写入，导致有重复记录，所幸的是，这是一个统计表, 不影响功能，所以需要找出重复的记录\n\n```\nselect cuid,aid from (\n    select cuid, aid,count(1) as num\n    from register_chn \n    group by cuid,aid having num > 1\n) t;\n```\n\n显示有8条记录,如果手动删除,是很慢且愚蠢的做法,还是用 SQL 执行,镇定之后执行\n\n```\ndelete from register_chn where (cuid,aid) in (\n    select cuid,aid from (\n        select cuid, aid,count(1) as num\n        from register_chn\n        group by cuid,aid having num > 1\n    ) t\n);\n```\n影响了８条记录.然后瞬间加上索引.所幸是成功了, 事实上当时的合理操作应该是用事务。\n\n```\nBEGIN;\ndelete from register_chn where (cuid,aid) in (\n    select cuid,aid from (\n        select cuid, aid,count(1) as num\n        from register_chn\n        group by cuid,aid having num > 1\n    ) t\n);\nalter table register_chn add unique index(cuid, aid);\nCOMMINT;\n```\n\n###引发的思考###\n\n后来想想, 上述方法虽然解决问题了, 但是有点碰运气成分。如果频繁快速地产生重复记录,也许就没那么好运了,事实上可以执行以下 SQL:\n\n```\nalter ignore table register_chn add unique index(cuid, aid)；\n```\n\n如果你以为很简单,那就错了。这个方法在 MySQL 5.0 上使用是没问题的，但是在5.6 之前是有bug的，亲自测试Percona 版本5.5, 的确会失败\n官方的解决方法是：\n\n```\nset session old_alter_table = on;\nalter ignore table register_chn add unique index(cuid, aid);\n```\n\n在有主备的情况,记得执行前设置一下\n\n```\nset session sql_log_bin=off. \n```\n以免备库报错。同样还需要在备库重复一下主库的操作, 这也算是一个不太完美的解决思路。\n\n\n","slug":"2014-10-24-mysql-unique-index","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9f002snctjkgu3tzth","content":"<p>最近需要改动线上一个有千万条记录的表，涉及到加字段操作，这个表有索引，按照经验，为了加速修改表结构,去掉索引。由于我删除的是Unique Index, 而服务一直在写,程序依赖数据库的唯一索引去重,导致瞬间有重复数据,唯一索引重新加上时会报 <code>Duplicated Key entry Error</code>,</p>\n<p>###回放事件###</p>\n<p>我们的数据表，之前是有 <code>UNIQUE INDEX(cuid, aid)</code>, 因为去掉索引，服务持续写入，导致有重复记录，所幸的是，这是一个统计表, 不影响功能，所以需要找出重复的记录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select cuid,aid from (</span><br><span class=\"line\">    select cuid, aid,count(1) as num</span><br><span class=\"line\">    from register_chn </span><br><span class=\"line\">    group by cuid,aid having num &gt; 1</span><br><span class=\"line\">) t;</span><br></pre></td></tr></table></figure>\n<p>显示有8条记录,如果手动删除,是很慢且愚蠢的做法,还是用 SQL 执行,镇定之后执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delete from register_chn where (cuid,aid) in (</span><br><span class=\"line\">    select cuid,aid from (</span><br><span class=\"line\">        select cuid, aid,count(1) as num</span><br><span class=\"line\">        from register_chn</span><br><span class=\"line\">        group by cuid,aid having num &gt; 1</span><br><span class=\"line\">    ) t</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<p>影响了８条记录.然后瞬间加上索引.所幸是成功了, 事实上当时的合理操作应该是用事务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BEGIN;</span><br><span class=\"line\">delete from register_chn where (cuid,aid) in (</span><br><span class=\"line\">    select cuid,aid from (</span><br><span class=\"line\">        select cuid, aid,count(1) as num</span><br><span class=\"line\">        from register_chn</span><br><span class=\"line\">        group by cuid,aid having num &gt; 1</span><br><span class=\"line\">    ) t</span><br><span class=\"line\">);</span><br><span class=\"line\">alter table register_chn add unique index(cuid, aid);</span><br><span class=\"line\">COMMINT;</span><br></pre></td></tr></table></figure>\n<p>###引发的思考###</p>\n<p>后来想想, 上述方法虽然解决问题了, 但是有点碰运气成分。如果频繁快速地产生重复记录,也许就没那么好运了,事实上可以执行以下 SQL:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alter ignore table register_chn add unique index(cuid, aid)；</span><br></pre></td></tr></table></figure>\n<p>如果你以为很简单,那就错了。这个方法在 MySQL 5.0 上使用是没问题的，但是在5.6 之前是有bug的，亲自测试Percona 版本5.5, 的确会失败<br>官方的解决方法是：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set session old_alter_table = on;</span><br><span class=\"line\">alter ignore table register_chn add unique index(cuid, aid);</span><br></pre></td></tr></table></figure>\n<p>在有主备的情况,记得执行前设置一下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set session sql_log_bin=off.</span><br></pre></td></tr></table></figure>\n<p>以免备库报错。同样还需要在备库重复一下主库的操作, 这也算是一个不太完美的解决思路。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>最近需要改动线上一个有千万条记录的表，涉及到加字段操作，这个表有索引，按照经验，为了加速修改表结构,去掉索引。由于我删除的是Unique Index, 而服务一直在写,程序依赖数据库的唯一索引去重,导致瞬间有重复数据,唯一索引重新加上时会报 <code>Duplicated Key entry Error</code>,</p>\n<p>###回放事件###</p>\n<p>我们的数据表，之前是有 <code>UNIQUE INDEX(cuid, aid)</code>, 因为去掉索引，服务持续写入，导致有重复记录，所幸的是，这是一个统计表, 不影响功能，所以需要找出重复的记录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select cuid,aid from (</span><br><span class=\"line\">    select cuid, aid,count(1) as num</span><br><span class=\"line\">    from register_chn </span><br><span class=\"line\">    group by cuid,aid having num &gt; 1</span><br><span class=\"line\">) t;</span><br></pre></td></tr></table></figure>\n<p>显示有8条记录,如果手动删除,是很慢且愚蠢的做法,还是用 SQL 执行,镇定之后执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delete from register_chn where (cuid,aid) in (</span><br><span class=\"line\">    select cuid,aid from (</span><br><span class=\"line\">        select cuid, aid,count(1) as num</span><br><span class=\"line\">        from register_chn</span><br><span class=\"line\">        group by cuid,aid having num &gt; 1</span><br><span class=\"line\">    ) t</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n<p>影响了８条记录.然后瞬间加上索引.所幸是成功了, 事实上当时的合理操作应该是用事务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BEGIN;</span><br><span class=\"line\">delete from register_chn where (cuid,aid) in (</span><br><span class=\"line\">    select cuid,aid from (</span><br><span class=\"line\">        select cuid, aid,count(1) as num</span><br><span class=\"line\">        from register_chn</span><br><span class=\"line\">        group by cuid,aid having num &gt; 1</span><br><span class=\"line\">    ) t</span><br><span class=\"line\">);</span><br><span class=\"line\">alter table register_chn add unique index(cuid, aid);</span><br><span class=\"line\">COMMINT;</span><br></pre></td></tr></table></figure>\n<p>###引发的思考###</p>\n<p>后来想想, 上述方法虽然解决问题了, 但是有点碰运气成分。如果频繁快速地产生重复记录,也许就没那么好运了,事实上可以执行以下 SQL:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alter ignore table register_chn add unique index(cuid, aid)；</span><br></pre></td></tr></table></figure>\n<p>如果你以为很简单,那就错了。这个方法在 MySQL 5.0 上使用是没问题的，但是在5.6 之前是有bug的，亲自测试Percona 版本5.5, 的确会失败<br>官方的解决方法是：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set session old_alter_table = on;</span><br><span class=\"line\">alter ignore table register_chn add unique index(cuid, aid);</span><br></pre></td></tr></table></figure>\n<p>在有主备的情况,记得执行前设置一下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set session sql_log_bin=off.</span><br></pre></td></tr></table></figure>\n<p>以免备库报错。同样还需要在备库重复一下主库的操作, 这也算是一个不太完美的解决思路。</p>\n"},{"layout":"post","title":"iptable 之 NAT 转发","date":"2014-10-29T14:38:00.000Z","comments":1,"keywords":"NAT iptables","description":"NAT iptables","_content":"\n简单简述下我遇到的问题:\n\n现在局域网有2台机器, 其中一台机器(下文我们称之为ServerA)可以访问外网,有独立IP,而另外一台机器(ServerB)访问不了外网, 需要想办法让 ServerB 也能上网。\n\n* ServerA 操作\n\n```\nvi /etc/sysctl.conf\nnet.ipv4.ip_forward = 1\niptables -t nat -A POSTROUTING -s 10.4.0.0/16 -j MASQUERADE\n```\n\n\nServerB\n\n编辑 /etc/network/interface\n主要是修改gateway 参数，指向 ServerA 的 IP\n\n```\nsudo ifdown eth0; sudo ifup eth0 ``` \nServerB 就可以连接外网了。\n","source":"_posts/2014-10-29-iptablezuo-natzhuan-fa.markdown","raw":"---\nlayout: post\ntitle: \"iptable 之 NAT 转发\"\ndate: 2014-10-29 22:38\ncomments: true\nkeywords: NAT iptables\ndescription: NAT iptables\ncategories: System\n---\n\n简单简述下我遇到的问题:\n\n现在局域网有2台机器, 其中一台机器(下文我们称之为ServerA)可以访问外网,有独立IP,而另外一台机器(ServerB)访问不了外网, 需要想办法让 ServerB 也能上网。\n\n* ServerA 操作\n\n```\nvi /etc/sysctl.conf\nnet.ipv4.ip_forward = 1\niptables -t nat -A POSTROUTING -s 10.4.0.0/16 -j MASQUERADE\n```\n\n\nServerB\n\n编辑 /etc/network/interface\n主要是修改gateway 参数，指向 ServerA 的 IP\n\n```\nsudo ifdown eth0; sudo ifup eth0 ``` \nServerB 就可以连接外网了。\n","slug":"2014-10-29-iptablezuo-natzhuan-fa","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9i002vnctjhlqryycv","content":"<p>简单简述下我遇到的问题:</p>\n<p>现在局域网有2台机器, 其中一台机器(下文我们称之为ServerA)可以访问外网,有独立IP,而另外一台机器(ServerB)访问不了外网, 需要想办法让 ServerB 也能上网。</p>\n<ul>\n<li>ServerA 操作</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vi /etc/sysctl.conf</span><br><span class=\"line\">net.ipv4.ip_forward = 1</span><br><span class=\"line\">iptables -t nat -A POSTROUTING -s 10.4.0.0/16 -j MASQUERADE</span><br></pre></td></tr></table></figure>\n<p>ServerB</p>\n<p>编辑 /etc/network/interface<br>主要是修改gateway 参数，指向 ServerA 的 IP</p>\n<pre><code>sudo ifdown eth0; sudo ifup eth0\n</code></pre><p>ServerB 就可以连接外网了。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>简单简述下我遇到的问题:</p>\n<p>现在局域网有2台机器, 其中一台机器(下文我们称之为ServerA)可以访问外网,有独立IP,而另外一台机器(ServerB)访问不了外网, 需要想办法让 ServerB 也能上网。</p>\n<ul>\n<li>ServerA 操作</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vi /etc/sysctl.conf</span><br><span class=\"line\">net.ipv4.ip_forward = 1</span><br><span class=\"line\">iptables -t nat -A POSTROUTING -s 10.4.0.0/16 -j MASQUERADE</span><br></pre></td></tr></table></figure>\n<p>ServerB</p>\n<p>编辑 /etc/network/interface<br>主要是修改gateway 参数，指向 ServerA 的 IP</p>\n<pre><code>sudo ifdown eth0; sudo ifup eth0\n</code></pre><p>ServerB 就可以连接外网了。</p>\n"},{"layout":"post","title":"Nginx与php-fpm系统参数配置","date":"2014-11-02T07:46:00.000Z","comments":1,"keywords":"Nginx 调优 PHP 优化","description":"Nginx 调优 PHP 优化","_content":"\n需要为机器调配参数了, 早些时候看过不少文章, 但没经历过始终不深刻, 以下讲的是在 8core 8G，Centos 配置 php-fpm 与 NGINX。\n\n###php-fpm 参数配置### \n\n关于 php-fpm 的配置,Ubuntu系统中 `/etc/php5/fpm/pool.d`目录下, Centos是`/etc/php-fpm.d`目录下编辑`www.conf`\n\n```\nlisten = /var/run/php5-fpm.sock\nlisten.backlog = -1 (on FreeBSD -1 unlimit)\npm = static # 使用静态进程管理\npm.max_children = 128\nrequest_terminate_timeout = 8s #设置太大，会导致work进程过多，来不及kill掉\n```\n\n编辑 `/etc/default/php5-fpm`\n\n```\nulimit -n 655360\n```\n\n###Nginx 配合参数###\n\n* 启用irqbalance\n\n由于精简系统的服务没有开启irqbalance，irqbalance现在被证实为非常有必要的服务，他的主要功能是可以合理的调配使用各个 CPU 核心，特别是对于目前主流多核心的 CPU，简单的说就是能够把压力均匀的分配到各个 CPU 核心上，对提升性能有很大的帮助。\n\n```\nshell> yum -y install irqbalance\nshell> service irqbalance start\ncat /proc/irqbalance #查看中断的分布\n```\n\n* 为nginx 绑定 cpu\n\n```\nworker_rlimit_nofile 300000;\nworker_processes  8;\nworker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;\n```\n\n* 连接数调整，\n\nnginx发起的连接数，远远超过了 php-fpm 所能处理的数目，导致端口（或socket）频繁被锁，造成堵塞。\n\n```\nvi /etc/sysctl.conf 进行了微调\nfs.file-max = 6553600\n\nvim /etc/security/limits.conf\n* soft nofile 655360\n* hard nofile 655360\n\nvim /etc/nginx/nginx.conf\n\nworker_rlimit_nofile 300000;\nevents {\n    worker_connections 300000;\n    use epoll;\n}\nhttp {\n    keepalive_timeout  0; #关闭keepalive_timeout, 快速释放系统资源\n}\n```\n\n从查到的资料看起来 8 核 理論值的最大連線數 = `worker_processes * worker_connections / 8`\n","source":"_posts/2014-11-02-nginxyu-phpxi-tong-can-shu-pei-zhi.markdown","raw":"---\nlayout: post\ntitle: \"Nginx与php-fpm系统参数配置\"\ndate: 2014-11-02 15:46\ncomments: true\nkeywords: Nginx 调优 PHP 优化\ndescription: Nginx 调优 PHP 优化\ncategories: System\n---\n\n需要为机器调配参数了, 早些时候看过不少文章, 但没经历过始终不深刻, 以下讲的是在 8core 8G，Centos 配置 php-fpm 与 NGINX。\n\n###php-fpm 参数配置### \n\n关于 php-fpm 的配置,Ubuntu系统中 `/etc/php5/fpm/pool.d`目录下, Centos是`/etc/php-fpm.d`目录下编辑`www.conf`\n\n```\nlisten = /var/run/php5-fpm.sock\nlisten.backlog = -1 (on FreeBSD -1 unlimit)\npm = static # 使用静态进程管理\npm.max_children = 128\nrequest_terminate_timeout = 8s #设置太大，会导致work进程过多，来不及kill掉\n```\n\n编辑 `/etc/default/php5-fpm`\n\n```\nulimit -n 655360\n```\n\n###Nginx 配合参数###\n\n* 启用irqbalance\n\n由于精简系统的服务没有开启irqbalance，irqbalance现在被证实为非常有必要的服务，他的主要功能是可以合理的调配使用各个 CPU 核心，特别是对于目前主流多核心的 CPU，简单的说就是能够把压力均匀的分配到各个 CPU 核心上，对提升性能有很大的帮助。\n\n```\nshell> yum -y install irqbalance\nshell> service irqbalance start\ncat /proc/irqbalance #查看中断的分布\n```\n\n* 为nginx 绑定 cpu\n\n```\nworker_rlimit_nofile 300000;\nworker_processes  8;\nworker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;\n```\n\n* 连接数调整，\n\nnginx发起的连接数，远远超过了 php-fpm 所能处理的数目，导致端口（或socket）频繁被锁，造成堵塞。\n\n```\nvi /etc/sysctl.conf 进行了微调\nfs.file-max = 6553600\n\nvim /etc/security/limits.conf\n* soft nofile 655360\n* hard nofile 655360\n\nvim /etc/nginx/nginx.conf\n\nworker_rlimit_nofile 300000;\nevents {\n    worker_connections 300000;\n    use epoll;\n}\nhttp {\n    keepalive_timeout  0; #关闭keepalive_timeout, 快速释放系统资源\n}\n```\n\n从查到的资料看起来 8 核 理論值的最大連線數 = `worker_processes * worker_connections / 8`\n","slug":"2014-11-02-nginxyu-phpxi-tong-can-shu-pei-zhi","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9j002xnctj64h0zdp3","content":"<p>需要为机器调配参数了, 早些时候看过不少文章, 但没经历过始终不深刻, 以下讲的是在 8core 8G，Centos 配置 php-fpm 与 NGINX。</p>\n<p>###php-fpm 参数配置### </p>\n<p>关于 php-fpm 的配置,Ubuntu系统中 <code>/etc/php5/fpm/pool.d</code>目录下, Centos是<code>/etc/php-fpm.d</code>目录下编辑<code>www.conf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listen = /var/run/php5-fpm.sock</span><br><span class=\"line\">listen.backlog = -1 (on FreeBSD -1 unlimit)</span><br><span class=\"line\">pm = static # 使用静态进程管理</span><br><span class=\"line\">pm.max_children = 128</span><br><span class=\"line\">request_terminate_timeout = 8s #设置太大，会导致work进程过多，来不及kill掉</span><br></pre></td></tr></table></figure>\n<p>编辑 <code>/etc/default/php5-fpm</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ulimit -n 655360</span><br></pre></td></tr></table></figure>\n<p>###Nginx 配合参数###</p>\n<ul>\n<li>启用irqbalance</li>\n</ul>\n<p>由于精简系统的服务没有开启irqbalance，irqbalance现在被证实为非常有必要的服务，他的主要功能是可以合理的调配使用各个 CPU 核心，特别是对于目前主流多核心的 CPU，简单的说就是能够把压力均匀的分配到各个 CPU 核心上，对提升性能有很大的帮助。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shell&gt; yum -y install irqbalance</span><br><span class=\"line\">shell&gt; service irqbalance start</span><br><span class=\"line\">cat /proc/irqbalance #查看中断的分布</span><br></pre></td></tr></table></figure>\n<ul>\n<li>为nginx 绑定 cpu</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">worker_rlimit_nofile 300000;</span><br><span class=\"line\">worker_processes  8;</span><br><span class=\"line\">worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>连接数调整，</li>\n</ul>\n<p>nginx发起的连接数，远远超过了 php-fpm 所能处理的数目，导致端口（或socket）频繁被锁，造成堵塞。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vi /etc/sysctl.conf 进行了微调</span><br><span class=\"line\">fs.file-max = 6553600</span><br><span class=\"line\"></span><br><span class=\"line\">vim /etc/security/limits.conf</span><br><span class=\"line\">* soft nofile 655360</span><br><span class=\"line\">* hard nofile 655360</span><br><span class=\"line\"></span><br><span class=\"line\">vim /etc/nginx/nginx.conf</span><br><span class=\"line\"></span><br><span class=\"line\">worker_rlimit_nofile 300000;</span><br><span class=\"line\">events &#123;</span><br><span class=\"line\">    worker_connections 300000;</span><br><span class=\"line\">    use epoll;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">http &#123;</span><br><span class=\"line\">    keepalive_timeout  0; #关闭keepalive_timeout, 快速释放系统资源</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>从查到的资料看起来 8 核 理論值的最大連線數 = <code>worker_processes * worker_connections / 8</code></p>\n","site":{"data":{}},"excerpt":"","more":"<p>需要为机器调配参数了, 早些时候看过不少文章, 但没经历过始终不深刻, 以下讲的是在 8core 8G，Centos 配置 php-fpm 与 NGINX。</p>\n<p>###php-fpm 参数配置### </p>\n<p>关于 php-fpm 的配置,Ubuntu系统中 <code>/etc/php5/fpm/pool.d</code>目录下, Centos是<code>/etc/php-fpm.d</code>目录下编辑<code>www.conf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listen = /var/run/php5-fpm.sock</span><br><span class=\"line\">listen.backlog = -1 (on FreeBSD -1 unlimit)</span><br><span class=\"line\">pm = static # 使用静态进程管理</span><br><span class=\"line\">pm.max_children = 128</span><br><span class=\"line\">request_terminate_timeout = 8s #设置太大，会导致work进程过多，来不及kill掉</span><br></pre></td></tr></table></figure>\n<p>编辑 <code>/etc/default/php5-fpm</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ulimit -n 655360</span><br></pre></td></tr></table></figure>\n<p>###Nginx 配合参数###</p>\n<ul>\n<li>启用irqbalance</li>\n</ul>\n<p>由于精简系统的服务没有开启irqbalance，irqbalance现在被证实为非常有必要的服务，他的主要功能是可以合理的调配使用各个 CPU 核心，特别是对于目前主流多核心的 CPU，简单的说就是能够把压力均匀的分配到各个 CPU 核心上，对提升性能有很大的帮助。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shell&gt; yum -y install irqbalance</span><br><span class=\"line\">shell&gt; service irqbalance start</span><br><span class=\"line\">cat /proc/irqbalance #查看中断的分布</span><br></pre></td></tr></table></figure>\n<ul>\n<li>为nginx 绑定 cpu</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">worker_rlimit_nofile 300000;</span><br><span class=\"line\">worker_processes  8;</span><br><span class=\"line\">worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>连接数调整，</li>\n</ul>\n<p>nginx发起的连接数，远远超过了 php-fpm 所能处理的数目，导致端口（或socket）频繁被锁，造成堵塞。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vi /etc/sysctl.conf 进行了微调</span><br><span class=\"line\">fs.file-max = 6553600</span><br><span class=\"line\"></span><br><span class=\"line\">vim /etc/security/limits.conf</span><br><span class=\"line\">* soft nofile 655360</span><br><span class=\"line\">* hard nofile 655360</span><br><span class=\"line\"></span><br><span class=\"line\">vim /etc/nginx/nginx.conf</span><br><span class=\"line\"></span><br><span class=\"line\">worker_rlimit_nofile 300000;</span><br><span class=\"line\">events &#123;</span><br><span class=\"line\">    worker_connections 300000;</span><br><span class=\"line\">    use epoll;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">http &#123;</span><br><span class=\"line\">    keepalive_timeout  0; #关闭keepalive_timeout, 快速释放系统资源</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>从查到的资料看起来 8 核 理論值的最大連線數 = <code>worker_processes * worker_connections / 8</code></p>\n"},{"layout":"post","title":"慢","date":"2014-11-25T14:20:00.000Z","comments":1,"_content":"\n这三个月以来,有30天是凌晨才离开公司的.甚至有好几天都通宵没有睡过,累。\n\n貌似熟悉了凌晨的路灯,和冷冽的寒风。\n\n技术的东西,整理在 EvertNote 里，但想写一些非技术的冲动似乎更强。\n\n生活有很长的路要走, 几乎每天都在发现不足之处,只能让内心更强大, 去接受,去改变, 淡定去拥抱无时不刻的变化, 怀着信念与希望继续走着。\n\n感谢 Everet 一直以来给我的信念, 我们也都在《感谢你让我上场》获得共鸣。我也坚信这位青年会是我们这届的骄傲。\n\n我想让生活慢下来，做一些重要不紧急的事。\n","source":"_posts/2014-11-25-tired.markdown","raw":"---\nlayout: post\ntitle: \"慢\"\ndate: 2014-11-25 22:20\ncomments: true\ncategories: Life\n---\n\n这三个月以来,有30天是凌晨才离开公司的.甚至有好几天都通宵没有睡过,累。\n\n貌似熟悉了凌晨的路灯,和冷冽的寒风。\n\n技术的东西,整理在 EvertNote 里，但想写一些非技术的冲动似乎更强。\n\n生活有很长的路要走, 几乎每天都在发现不足之处,只能让内心更强大, 去接受,去改变, 淡定去拥抱无时不刻的变化, 怀着信念与希望继续走着。\n\n感谢 Everet 一直以来给我的信念, 我们也都在《感谢你让我上场》获得共鸣。我也坚信这位青年会是我们这届的骄傲。\n\n我想让生活慢下来，做一些重要不紧急的事。\n","slug":"2014-11-25-tired","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9l002znctj4rnu1gmx","content":"<p>这三个月以来,有30天是凌晨才离开公司的.甚至有好几天都通宵没有睡过,累。</p>\n<p>貌似熟悉了凌晨的路灯,和冷冽的寒风。</p>\n<p>技术的东西,整理在 EvertNote 里，但想写一些非技术的冲动似乎更强。</p>\n<p>生活有很长的路要走, 几乎每天都在发现不足之处,只能让内心更强大, 去接受,去改变, 淡定去拥抱无时不刻的变化, 怀着信念与希望继续走着。</p>\n<p>感谢 Everet 一直以来给我的信念, 我们也都在《感谢你让我上场》获得共鸣。我也坚信这位青年会是我们这届的骄傲。</p>\n<p>我想让生活慢下来，做一些重要不紧急的事。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>这三个月以来,有30天是凌晨才离开公司的.甚至有好几天都通宵没有睡过,累。</p>\n<p>貌似熟悉了凌晨的路灯,和冷冽的寒风。</p>\n<p>技术的东西,整理在 EvertNote 里，但想写一些非技术的冲动似乎更强。</p>\n<p>生活有很长的路要走, 几乎每天都在发现不足之处,只能让内心更强大, 去接受,去改变, 淡定去拥抱无时不刻的变化, 怀着信念与希望继续走着。</p>\n<p>感谢 Everet 一直以来给我的信念, 我们也都在《感谢你让我上场》获得共鸣。我也坚信这位青年会是我们这届的骄傲。</p>\n<p>我想让生活慢下来，做一些重要不紧急的事。</p>\n"},{"layout":"post","title":"用到的Tcpdump","date":"2014-11-29T06:15:00.000Z","comments":1,"_content":"\n开发中，要定位具体问题，特别是网络问题的时候，多数是要晋出`tcpdump`，遗憾的是我略懂皮毛，有必要深入一些。\n简单说下我常用的 TcpDump的方法\n\n```\ntcpdump -i eth0 -Xxn port 80 -s 0 -c 1024 \n```\n\n如果仅仅是看manual  多数时候还是会忘记，好记性不如烂笔头，上述的选项是我认为很有用的\n\n```\n-i 指定网卡\n-Xxn X使用Ascii和16进制，n 表示 ip 用数字表示\n-s 0 表示整包抓取\n-c 1024 表示包得大小\n```\n\n如果希望将抓包过程中保留下来，可以在上述命令尾部加上 `-w trace.cap`\n这种格式的文件，文本编辑器是无法理解，需要特殊的软件才能回复，比如 `wireshark`\n\nTcpdump 中的 flag 有必要提下：\n\n* PSH 代表要求发送立即发送缓冲区内的其他对应数据包，无需缓冲区满才发送\n* RST 如果RST=1表示连接马上结束，无需等待终止确认手续，发送端已经断线\n* SYNC 表示主动连接到对方，建立连接\n* FIN 表示传送结束，发送方等待对方响应\n\n通过 wireshark 可以再现所谓的三次握手和四次挥手过程。\n","source":"_posts/2014-11-29-yong-dao-de-tcpdump.markdown","raw":"---\nlayout: post\ntitle: \"用到的Tcpdump\"\ndate: 2014-11-29 14:15\ncomments: true\ncategories: System\n---\n\n开发中，要定位具体问题，特别是网络问题的时候，多数是要晋出`tcpdump`，遗憾的是我略懂皮毛，有必要深入一些。\n简单说下我常用的 TcpDump的方法\n\n```\ntcpdump -i eth0 -Xxn port 80 -s 0 -c 1024 \n```\n\n如果仅仅是看manual  多数时候还是会忘记，好记性不如烂笔头，上述的选项是我认为很有用的\n\n```\n-i 指定网卡\n-Xxn X使用Ascii和16进制，n 表示 ip 用数字表示\n-s 0 表示整包抓取\n-c 1024 表示包得大小\n```\n\n如果希望将抓包过程中保留下来，可以在上述命令尾部加上 `-w trace.cap`\n这种格式的文件，文本编辑器是无法理解，需要特殊的软件才能回复，比如 `wireshark`\n\nTcpdump 中的 flag 有必要提下：\n\n* PSH 代表要求发送立即发送缓冲区内的其他对应数据包，无需缓冲区满才发送\n* RST 如果RST=1表示连接马上结束，无需等待终止确认手续，发送端已经断线\n* SYNC 表示主动连接到对方，建立连接\n* FIN 表示传送结束，发送方等待对方响应\n\n通过 wireshark 可以再现所谓的三次握手和四次挥手过程。\n","slug":"2014-11-29-yong-dao-de-tcpdump","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9m0032nctjnrn37qch","content":"<p>开发中，要定位具体问题，特别是网络问题的时候，多数是要晋出<code>tcpdump</code>，遗憾的是我略懂皮毛，有必要深入一些。<br>简单说下我常用的 TcpDump的方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tcpdump -i eth0 -Xxn port 80 -s 0 -c 1024</span><br></pre></td></tr></table></figure>\n<p>如果仅仅是看manual  多数时候还是会忘记，好记性不如烂笔头，上述的选项是我认为很有用的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-i 指定网卡</span><br><span class=\"line\">-Xxn X使用Ascii和16进制，n 表示 ip 用数字表示</span><br><span class=\"line\">-s 0 表示整包抓取</span><br><span class=\"line\">-c 1024 表示包得大小</span><br></pre></td></tr></table></figure>\n<p>如果希望将抓包过程中保留下来，可以在上述命令尾部加上 <code>-w trace.cap</code><br>这种格式的文件，文本编辑器是无法理解，需要特殊的软件才能回复，比如 <code>wireshark</code></p>\n<p>Tcpdump 中的 flag 有必要提下：</p>\n<ul>\n<li>PSH 代表要求发送立即发送缓冲区内的其他对应数据包，无需缓冲区满才发送</li>\n<li>RST 如果RST=1表示连接马上结束，无需等待终止确认手续，发送端已经断线</li>\n<li>SYNC 表示主动连接到对方，建立连接</li>\n<li>FIN 表示传送结束，发送方等待对方响应</li>\n</ul>\n<p>通过 wireshark 可以再现所谓的三次握手和四次挥手过程。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>开发中，要定位具体问题，特别是网络问题的时候，多数是要晋出<code>tcpdump</code>，遗憾的是我略懂皮毛，有必要深入一些。<br>简单说下我常用的 TcpDump的方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tcpdump -i eth0 -Xxn port 80 -s 0 -c 1024</span><br></pre></td></tr></table></figure>\n<p>如果仅仅是看manual  多数时候还是会忘记，好记性不如烂笔头，上述的选项是我认为很有用的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-i 指定网卡</span><br><span class=\"line\">-Xxn X使用Ascii和16进制，n 表示 ip 用数字表示</span><br><span class=\"line\">-s 0 表示整包抓取</span><br><span class=\"line\">-c 1024 表示包得大小</span><br></pre></td></tr></table></figure>\n<p>如果希望将抓包过程中保留下来，可以在上述命令尾部加上 <code>-w trace.cap</code><br>这种格式的文件，文本编辑器是无法理解，需要特殊的软件才能回复，比如 <code>wireshark</code></p>\n<p>Tcpdump 中的 flag 有必要提下：</p>\n<ul>\n<li>PSH 代表要求发送立即发送缓冲区内的其他对应数据包，无需缓冲区满才发送</li>\n<li>RST 如果RST=1表示连接马上结束，无需等待终止确认手续，发送端已经断线</li>\n<li>SYNC 表示主动连接到对方，建立连接</li>\n<li>FIN 表示传送结束，发送方等待对方响应</li>\n</ul>\n<p>通过 wireshark 可以再现所谓的三次握手和四次挥手过程。</p>\n"},{"layout":"post","title":"Nginx 错误码","date":"2014-12-13T07:18:00.000Z","comments":1,"description":"Nginx 错误码","_content":"\n在定位线上服务问题的时候，通常会去查看`Nginx` 的`error log`\n\n那么 error 的定义, 对查找问题就显得很有帮助\n\n* upstream prematurely closed connection\n\n>请求uri的时候出现的异常，是由于 upstream 还未返回应答给用户时用户断掉连接造成的，对系统没有影响，可以忽略\n\n* recv() failed (104: Connection reset by peer) \n\n>服务器的并发连接数超过了其承载量，服务器会将其中一些连接Down掉；客户关掉了浏览器，而服务器还在给客户端发送数据;\n\n* (111: Connection refused) while connecting to upstream \n\n>用户在连接时，若遇到后端 upstream 挂掉或者不通，会收到该错误\n\n* (111: Connection refused) while reading response header from upstream \n\n>用户在连接成功后读取数据时，若遇到后端 upstream 挂掉或者不通，会收到该错误\n\n* (111: Connection refused) while sending request to upstream \n\n>Nginx 和 upstream 连接成功后发送数据时，若遇到后端 upstream 挂掉或者不通，会收到该错误\n\n* (110: Connection timed out) while connecting to upstream \n\n>nginx 连接后面的 upstream 时超时\n\n* (110: Connection timed out) while reading upstream \n\n>nginx 读取来自 upstream 的响应时超时 \n\n* (110: Connection timed out) while reading response header from upstream \n\n>nginx 读取来自 upstream 的响应头时超时\n\n* (110: Connection timed out) while reading upstream \n\n>nginx读取来自 upstream 的响应时超时\n\n* (104: Connection reset by peer) while connecting to upstream \n\n>upstream发送了 RST，将连接重置\n\n* upstream sent invalid header while reading response header from upstream \n\n>upstream 发送的响应头无效\n\n* upstream sent no valid HTTP/1.0 header while reading response header from upstream\n\n>upstream 发送的响应头无效\n\n* client intended to send too large body \n\n>用于设置允许接受的客户端请求内容的最大值，默认值是1M，client 发送的 body 超过了设置值\n\n* reopening logs \n\n>用户发送kill  -USR1命令\n\n* gracefully shutting down\n\n>用户发送kill  -WINCH命令\n\n* no live upstreams while connecting to upstream \n\n>upstream 下的 server 全都挂了\n\n\n* SSL_do_handshake() failed\n\n>SSL握手失败\n\n* ngx_slab_alloc() failed: no memory in SSL session shared cache\n\n>ssl_session_cache大小不够等原因造成\n\n* could not add new SSL session to the session cache while SSL handshaking\n\n>ssl_session_cache 大小不够等原因造成\n","source":"_posts/2014-12-13-nginxcuo-wu-ma.markdown","raw":"---\nlayout: post\ntitle: \"Nginx 错误码\"\ndate: 2014-12-13 15:18\ncomments: true\ncategories: System\ndescription: Nginx 错误码\n---\n\n在定位线上服务问题的时候，通常会去查看`Nginx` 的`error log`\n\n那么 error 的定义, 对查找问题就显得很有帮助\n\n* upstream prematurely closed connection\n\n>请求uri的时候出现的异常，是由于 upstream 还未返回应答给用户时用户断掉连接造成的，对系统没有影响，可以忽略\n\n* recv() failed (104: Connection reset by peer) \n\n>服务器的并发连接数超过了其承载量，服务器会将其中一些连接Down掉；客户关掉了浏览器，而服务器还在给客户端发送数据;\n\n* (111: Connection refused) while connecting to upstream \n\n>用户在连接时，若遇到后端 upstream 挂掉或者不通，会收到该错误\n\n* (111: Connection refused) while reading response header from upstream \n\n>用户在连接成功后读取数据时，若遇到后端 upstream 挂掉或者不通，会收到该错误\n\n* (111: Connection refused) while sending request to upstream \n\n>Nginx 和 upstream 连接成功后发送数据时，若遇到后端 upstream 挂掉或者不通，会收到该错误\n\n* (110: Connection timed out) while connecting to upstream \n\n>nginx 连接后面的 upstream 时超时\n\n* (110: Connection timed out) while reading upstream \n\n>nginx 读取来自 upstream 的响应时超时 \n\n* (110: Connection timed out) while reading response header from upstream \n\n>nginx 读取来自 upstream 的响应头时超时\n\n* (110: Connection timed out) while reading upstream \n\n>nginx读取来自 upstream 的响应时超时\n\n* (104: Connection reset by peer) while connecting to upstream \n\n>upstream发送了 RST，将连接重置\n\n* upstream sent invalid header while reading response header from upstream \n\n>upstream 发送的响应头无效\n\n* upstream sent no valid HTTP/1.0 header while reading response header from upstream\n\n>upstream 发送的响应头无效\n\n* client intended to send too large body \n\n>用于设置允许接受的客户端请求内容的最大值，默认值是1M，client 发送的 body 超过了设置值\n\n* reopening logs \n\n>用户发送kill  -USR1命令\n\n* gracefully shutting down\n\n>用户发送kill  -WINCH命令\n\n* no live upstreams while connecting to upstream \n\n>upstream 下的 server 全都挂了\n\n\n* SSL_do_handshake() failed\n\n>SSL握手失败\n\n* ngx_slab_alloc() failed: no memory in SSL session shared cache\n\n>ssl_session_cache大小不够等原因造成\n\n* could not add new SSL session to the session cache while SSL handshaking\n\n>ssl_session_cache 大小不够等原因造成\n","slug":"2014-12-13-nginxcuo-wu-ma","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9n0034nctjue5f3i2i","content":"<p>在定位线上服务问题的时候，通常会去查看<code>Nginx</code> 的<code>error log</code></p>\n<p>那么 error 的定义, 对查找问题就显得很有帮助</p>\n<ul>\n<li>upstream prematurely closed connection</li>\n</ul>\n<blockquote>\n<p>请求uri的时候出现的异常，是由于 upstream 还未返回应答给用户时用户断掉连接造成的，对系统没有影响，可以忽略</p>\n</blockquote>\n<ul>\n<li>recv() failed (104: Connection reset by peer) </li>\n</ul>\n<blockquote>\n<p>服务器的并发连接数超过了其承载量，服务器会将其中一些连接Down掉；客户关掉了浏览器，而服务器还在给客户端发送数据;</p>\n</blockquote>\n<ul>\n<li>(111: Connection refused) while connecting to upstream </li>\n</ul>\n<blockquote>\n<p>用户在连接时，若遇到后端 upstream 挂掉或者不通，会收到该错误</p>\n</blockquote>\n<ul>\n<li>(111: Connection refused) while reading response header from upstream </li>\n</ul>\n<blockquote>\n<p>用户在连接成功后读取数据时，若遇到后端 upstream 挂掉或者不通，会收到该错误</p>\n</blockquote>\n<ul>\n<li>(111: Connection refused) while sending request to upstream </li>\n</ul>\n<blockquote>\n<p>Nginx 和 upstream 连接成功后发送数据时，若遇到后端 upstream 挂掉或者不通，会收到该错误</p>\n</blockquote>\n<ul>\n<li>(110: Connection timed out) while connecting to upstream </li>\n</ul>\n<blockquote>\n<p>nginx 连接后面的 upstream 时超时</p>\n</blockquote>\n<ul>\n<li>(110: Connection timed out) while reading upstream </li>\n</ul>\n<blockquote>\n<p>nginx 读取来自 upstream 的响应时超时 </p>\n</blockquote>\n<ul>\n<li>(110: Connection timed out) while reading response header from upstream </li>\n</ul>\n<blockquote>\n<p>nginx 读取来自 upstream 的响应头时超时</p>\n</blockquote>\n<ul>\n<li>(110: Connection timed out) while reading upstream </li>\n</ul>\n<blockquote>\n<p>nginx读取来自 upstream 的响应时超时</p>\n</blockquote>\n<ul>\n<li>(104: Connection reset by peer) while connecting to upstream </li>\n</ul>\n<blockquote>\n<p>upstream发送了 RST，将连接重置</p>\n</blockquote>\n<ul>\n<li>upstream sent invalid header while reading response header from upstream </li>\n</ul>\n<blockquote>\n<p>upstream 发送的响应头无效</p>\n</blockquote>\n<ul>\n<li>upstream sent no valid HTTP/1.0 header while reading response header from upstream</li>\n</ul>\n<blockquote>\n<p>upstream 发送的响应头无效</p>\n</blockquote>\n<ul>\n<li>client intended to send too large body </li>\n</ul>\n<blockquote>\n<p>用于设置允许接受的客户端请求内容的最大值，默认值是1M，client 发送的 body 超过了设置值</p>\n</blockquote>\n<ul>\n<li>reopening logs </li>\n</ul>\n<blockquote>\n<p>用户发送kill  -USR1命令</p>\n</blockquote>\n<ul>\n<li>gracefully shutting down</li>\n</ul>\n<blockquote>\n<p>用户发送kill  -WINCH命令</p>\n</blockquote>\n<ul>\n<li>no live upstreams while connecting to upstream </li>\n</ul>\n<blockquote>\n<p>upstream 下的 server 全都挂了</p>\n</blockquote>\n<ul>\n<li>SSL_do_handshake() failed</li>\n</ul>\n<blockquote>\n<p>SSL握手失败</p>\n</blockquote>\n<ul>\n<li>ngx_slab_alloc() failed: no memory in SSL session shared cache</li>\n</ul>\n<blockquote>\n<p>ssl_session_cache大小不够等原因造成</p>\n</blockquote>\n<ul>\n<li>could not add new SSL session to the session cache while SSL handshaking</li>\n</ul>\n<blockquote>\n<p>ssl_session_cache 大小不够等原因造成</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p>在定位线上服务问题的时候，通常会去查看<code>Nginx</code> 的<code>error log</code></p>\n<p>那么 error 的定义, 对查找问题就显得很有帮助</p>\n<ul>\n<li>upstream prematurely closed connection</li>\n</ul>\n<blockquote>\n<p>请求uri的时候出现的异常，是由于 upstream 还未返回应答给用户时用户断掉连接造成的，对系统没有影响，可以忽略</p>\n</blockquote>\n<ul>\n<li>recv() failed (104: Connection reset by peer) </li>\n</ul>\n<blockquote>\n<p>服务器的并发连接数超过了其承载量，服务器会将其中一些连接Down掉；客户关掉了浏览器，而服务器还在给客户端发送数据;</p>\n</blockquote>\n<ul>\n<li>(111: Connection refused) while connecting to upstream </li>\n</ul>\n<blockquote>\n<p>用户在连接时，若遇到后端 upstream 挂掉或者不通，会收到该错误</p>\n</blockquote>\n<ul>\n<li>(111: Connection refused) while reading response header from upstream </li>\n</ul>\n<blockquote>\n<p>用户在连接成功后读取数据时，若遇到后端 upstream 挂掉或者不通，会收到该错误</p>\n</blockquote>\n<ul>\n<li>(111: Connection refused) while sending request to upstream </li>\n</ul>\n<blockquote>\n<p>Nginx 和 upstream 连接成功后发送数据时，若遇到后端 upstream 挂掉或者不通，会收到该错误</p>\n</blockquote>\n<ul>\n<li>(110: Connection timed out) while connecting to upstream </li>\n</ul>\n<blockquote>\n<p>nginx 连接后面的 upstream 时超时</p>\n</blockquote>\n<ul>\n<li>(110: Connection timed out) while reading upstream </li>\n</ul>\n<blockquote>\n<p>nginx 读取来自 upstream 的响应时超时 </p>\n</blockquote>\n<ul>\n<li>(110: Connection timed out) while reading response header from upstream </li>\n</ul>\n<blockquote>\n<p>nginx 读取来自 upstream 的响应头时超时</p>\n</blockquote>\n<ul>\n<li>(110: Connection timed out) while reading upstream </li>\n</ul>\n<blockquote>\n<p>nginx读取来自 upstream 的响应时超时</p>\n</blockquote>\n<ul>\n<li>(104: Connection reset by peer) while connecting to upstream </li>\n</ul>\n<blockquote>\n<p>upstream发送了 RST，将连接重置</p>\n</blockquote>\n<ul>\n<li>upstream sent invalid header while reading response header from upstream </li>\n</ul>\n<blockquote>\n<p>upstream 发送的响应头无效</p>\n</blockquote>\n<ul>\n<li>upstream sent no valid HTTP/1.0 header while reading response header from upstream</li>\n</ul>\n<blockquote>\n<p>upstream 发送的响应头无效</p>\n</blockquote>\n<ul>\n<li>client intended to send too large body </li>\n</ul>\n<blockquote>\n<p>用于设置允许接受的客户端请求内容的最大值，默认值是1M，client 发送的 body 超过了设置值</p>\n</blockquote>\n<ul>\n<li>reopening logs </li>\n</ul>\n<blockquote>\n<p>用户发送kill  -USR1命令</p>\n</blockquote>\n<ul>\n<li>gracefully shutting down</li>\n</ul>\n<blockquote>\n<p>用户发送kill  -WINCH命令</p>\n</blockquote>\n<ul>\n<li>no live upstreams while connecting to upstream </li>\n</ul>\n<blockquote>\n<p>upstream 下的 server 全都挂了</p>\n</blockquote>\n<ul>\n<li>SSL_do_handshake() failed</li>\n</ul>\n<blockquote>\n<p>SSL握手失败</p>\n</blockquote>\n<ul>\n<li>ngx_slab_alloc() failed: no memory in SSL session shared cache</li>\n</ul>\n<blockquote>\n<p>ssl_session_cache大小不够等原因造成</p>\n</blockquote>\n<ul>\n<li>could not add new SSL session to the session cache while SSL handshaking</li>\n</ul>\n<blockquote>\n<p>ssl_session_cache 大小不够等原因造成</p>\n</blockquote>\n"},{"layout":"post","title":"Percona 小箱里的pt-archiver","date":"2015-01-21T15:27:00.000Z","comments":1,"keywords":"MySQL pt-archiver","_content":"\n在管理线上数据库，时常要做一些数据归档操作，在没有了解 `Percona toolkit` 之前，第一个想到的是在夜深人静的时候使用 `MySqlDump` 来完成这件事情。但它不是我们的优质选择，理由有：\n\n+ `MySqlDump` 只能备份在本机，不能直接做远端备份\n+  导出数据量太大的时候会锁表, 即使它的速度很快，但是在线上服务这是很危险的操作\n+  它仅仅只能导出，无法做到同时删除(可能不是太有必要)\n\n面对上述的场景，`Percona Toolkit` 让DBA 有了更好地选择，[pt-archiver](http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html) 应时而生。\n\n## pt-archiver 介绍：\n\n根据官方文档的说法，几乎不会对线上的OTLP操作有影响：\n\n> The goal is a low-impact, forward-only job to nibble old data out of the table without impacting OLTP queries much\n\n它可以帮助我们将数据归档到文件, 另一个数据库，或者同一个数据库的另一个表, 亦或是用于合并两个表的内容。\n\n## 用法介绍：\n\n```\npt-archiver [OPTION...] --source DSN --where WHERE\n```\n\n归档的文件方便使用 load data infile 命令导入数据。另外你还可以用它来执行 delete 操作。这个工具默认的会删除源中的数据，使用的时候请注意。\n\n假如我们将数据库里符合条件的记录归档到文件，并不做删除操作。\n\n```\npt-archiver --ask-pass --progress 100000 --no-delete --no-check-charset --source h=localhost,u=root,D=blog,t=comment--file /home/ubuntu/tmp/comment--where 'time < \"2013-12-31h\"'\n```\n\n注意的选项参数：\n\n```\n--ask-pass        提示要求输密码\n--progress num    执行num行在界面通知我们\n--source h,D,t    数据源\n--no-delete       加上这个参数并不会执行删除操作\n--dry-run         仅仅将执行语句打印在终端，事实上并不执行。可以用于检测执行过程\n--where           执行语句，需要用冒号包围起来\n--limit           批量操作的数量，合理提高这个数值可以加快archive速度\n```\n\n### 小总结\n\n  通过开启 mysql 的 `general log`, 可以发现pt-archiver 执行时，是分批commit 的事务，因此执行效率会慢，在8核16G 内存的生产环境机器备份 1kw 条记录, 耗时150 分钟。 但基本不对服务造成影响，而且可以不用深夜进行, 值得一用。\n\n  最近攒了好多好工具和经验，要好好整理搬上来和大家分享才是。\n","source":"_posts/2015-01-21-percona-toolkitxiao-xiang-li-di-pt-archiver.markdown","raw":"---\nlayout: post\ntitle: \"Percona 小箱里的pt-archiver\"\ndate: 2015-01-21 23:27\ncomments: true\nkeywords: MySQL pt-archiver\ncategories: DataBase\n---\n\n在管理线上数据库，时常要做一些数据归档操作，在没有了解 `Percona toolkit` 之前，第一个想到的是在夜深人静的时候使用 `MySqlDump` 来完成这件事情。但它不是我们的优质选择，理由有：\n\n+ `MySqlDump` 只能备份在本机，不能直接做远端备份\n+  导出数据量太大的时候会锁表, 即使它的速度很快，但是在线上服务这是很危险的操作\n+  它仅仅只能导出，无法做到同时删除(可能不是太有必要)\n\n面对上述的场景，`Percona Toolkit` 让DBA 有了更好地选择，[pt-archiver](http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html) 应时而生。\n\n## pt-archiver 介绍：\n\n根据官方文档的说法，几乎不会对线上的OTLP操作有影响：\n\n> The goal is a low-impact, forward-only job to nibble old data out of the table without impacting OLTP queries much\n\n它可以帮助我们将数据归档到文件, 另一个数据库，或者同一个数据库的另一个表, 亦或是用于合并两个表的内容。\n\n## 用法介绍：\n\n```\npt-archiver [OPTION...] --source DSN --where WHERE\n```\n\n归档的文件方便使用 load data infile 命令导入数据。另外你还可以用它来执行 delete 操作。这个工具默认的会删除源中的数据，使用的时候请注意。\n\n假如我们将数据库里符合条件的记录归档到文件，并不做删除操作。\n\n```\npt-archiver --ask-pass --progress 100000 --no-delete --no-check-charset --source h=localhost,u=root,D=blog,t=comment--file /home/ubuntu/tmp/comment--where 'time < \"2013-12-31h\"'\n```\n\n注意的选项参数：\n\n```\n--ask-pass        提示要求输密码\n--progress num    执行num行在界面通知我们\n--source h,D,t    数据源\n--no-delete       加上这个参数并不会执行删除操作\n--dry-run         仅仅将执行语句打印在终端，事实上并不执行。可以用于检测执行过程\n--where           执行语句，需要用冒号包围起来\n--limit           批量操作的数量，合理提高这个数值可以加快archive速度\n```\n\n### 小总结\n\n  通过开启 mysql 的 `general log`, 可以发现pt-archiver 执行时，是分批commit 的事务，因此执行效率会慢，在8核16G 内存的生产环境机器备份 1kw 条记录, 耗时150 分钟。 但基本不对服务造成影响，而且可以不用深夜进行, 值得一用。\n\n  最近攒了好多好工具和经验，要好好整理搬上来和大家分享才是。\n","slug":"2015-01-21-percona-toolkitxiao-xiang-li-di-pt-archiver","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9o0036nctju1dcfj8n","content":"<p>在管理线上数据库，时常要做一些数据归档操作，在没有了解 <code>Percona toolkit</code> 之前，第一个想到的是在夜深人静的时候使用 <code>MySqlDump</code> 来完成这件事情。但它不是我们的优质选择，理由有：</p>\n<ul>\n<li><code>MySqlDump</code> 只能备份在本机，不能直接做远端备份</li>\n<li>导出数据量太大的时候会锁表, 即使它的速度很快，但是在线上服务这是很危险的操作</li>\n<li>它仅仅只能导出，无法做到同时删除(可能不是太有必要)</li>\n</ul>\n<p>面对上述的场景，<code>Percona Toolkit</code> 让DBA 有了更好地选择，<a href=\"http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html\" target=\"_blank\" rel=\"noopener\">pt-archiver</a> 应时而生。</p>\n<h2 id=\"pt-archiver-介绍：\"><a href=\"#pt-archiver-介绍：\" class=\"headerlink\" title=\"pt-archiver 介绍：\"></a>pt-archiver 介绍：</h2><p>根据官方文档的说法，几乎不会对线上的OTLP操作有影响：</p>\n<blockquote>\n<p>The goal is a low-impact, forward-only job to nibble old data out of the table without impacting OLTP queries much</p>\n</blockquote>\n<p>它可以帮助我们将数据归档到文件, 另一个数据库，或者同一个数据库的另一个表, 亦或是用于合并两个表的内容。</p>\n<h2 id=\"用法介绍：\"><a href=\"#用法介绍：\" class=\"headerlink\" title=\"用法介绍：\"></a>用法介绍：</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pt-archiver [OPTION...] --source DSN --where WHERE</span><br></pre></td></tr></table></figure>\n<p>归档的文件方便使用 load data infile 命令导入数据。另外你还可以用它来执行 delete 操作。这个工具默认的会删除源中的数据，使用的时候请注意。</p>\n<p>假如我们将数据库里符合条件的记录归档到文件，并不做删除操作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pt-archiver --ask-pass --progress 100000 --no-delete --no-check-charset --source h=localhost,u=root,D=blog,t=comment--file /home/ubuntu/tmp/comment--where &apos;time &lt; &quot;2013-12-31h&quot;&apos;</span><br></pre></td></tr></table></figure>\n<p>注意的选项参数：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--ask-pass        提示要求输密码</span><br><span class=\"line\">--progress num    执行num行在界面通知我们</span><br><span class=\"line\">--source h,D,t    数据源</span><br><span class=\"line\">--no-delete       加上这个参数并不会执行删除操作</span><br><span class=\"line\">--dry-run         仅仅将执行语句打印在终端，事实上并不执行。可以用于检测执行过程</span><br><span class=\"line\">--where           执行语句，需要用冒号包围起来</span><br><span class=\"line\">--limit           批量操作的数量，合理提高这个数值可以加快archive速度</span><br></pre></td></tr></table></figure>\n<h3 id=\"小总结\"><a href=\"#小总结\" class=\"headerlink\" title=\"小总结\"></a>小总结</h3><p>  通过开启 mysql 的 <code>general log</code>, 可以发现pt-archiver 执行时，是分批commit 的事务，因此执行效率会慢，在8核16G 内存的生产环境机器备份 1kw 条记录, 耗时150 分钟。 但基本不对服务造成影响，而且可以不用深夜进行, 值得一用。</p>\n<p>  最近攒了好多好工具和经验，要好好整理搬上来和大家分享才是。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在管理线上数据库，时常要做一些数据归档操作，在没有了解 <code>Percona toolkit</code> 之前，第一个想到的是在夜深人静的时候使用 <code>MySqlDump</code> 来完成这件事情。但它不是我们的优质选择，理由有：</p>\n<ul>\n<li><code>MySqlDump</code> 只能备份在本机，不能直接做远端备份</li>\n<li>导出数据量太大的时候会锁表, 即使它的速度很快，但是在线上服务这是很危险的操作</li>\n<li>它仅仅只能导出，无法做到同时删除(可能不是太有必要)</li>\n</ul>\n<p>面对上述的场景，<code>Percona Toolkit</code> 让DBA 有了更好地选择，<a href=\"http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html\" target=\"_blank\" rel=\"noopener\">pt-archiver</a> 应时而生。</p>\n<h2 id=\"pt-archiver-介绍：\"><a href=\"#pt-archiver-介绍：\" class=\"headerlink\" title=\"pt-archiver 介绍：\"></a>pt-archiver 介绍：</h2><p>根据官方文档的说法，几乎不会对线上的OTLP操作有影响：</p>\n<blockquote>\n<p>The goal is a low-impact, forward-only job to nibble old data out of the table without impacting OLTP queries much</p>\n</blockquote>\n<p>它可以帮助我们将数据归档到文件, 另一个数据库，或者同一个数据库的另一个表, 亦或是用于合并两个表的内容。</p>\n<h2 id=\"用法介绍：\"><a href=\"#用法介绍：\" class=\"headerlink\" title=\"用法介绍：\"></a>用法介绍：</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pt-archiver [OPTION...] --source DSN --where WHERE</span><br></pre></td></tr></table></figure>\n<p>归档的文件方便使用 load data infile 命令导入数据。另外你还可以用它来执行 delete 操作。这个工具默认的会删除源中的数据，使用的时候请注意。</p>\n<p>假如我们将数据库里符合条件的记录归档到文件，并不做删除操作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pt-archiver --ask-pass --progress 100000 --no-delete --no-check-charset --source h=localhost,u=root,D=blog,t=comment--file /home/ubuntu/tmp/comment--where &apos;time &lt; &quot;2013-12-31h&quot;&apos;</span><br></pre></td></tr></table></figure>\n<p>注意的选项参数：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--ask-pass        提示要求输密码</span><br><span class=\"line\">--progress num    执行num行在界面通知我们</span><br><span class=\"line\">--source h,D,t    数据源</span><br><span class=\"line\">--no-delete       加上这个参数并不会执行删除操作</span><br><span class=\"line\">--dry-run         仅仅将执行语句打印在终端，事实上并不执行。可以用于检测执行过程</span><br><span class=\"line\">--where           执行语句，需要用冒号包围起来</span><br><span class=\"line\">--limit           批量操作的数量，合理提高这个数值可以加快archive速度</span><br></pre></td></tr></table></figure>\n<h3 id=\"小总结\"><a href=\"#小总结\" class=\"headerlink\" title=\"小总结\"></a>小总结</h3><p>  通过开启 mysql 的 <code>general log</code>, 可以发现pt-archiver 执行时，是分批commit 的事务，因此执行效率会慢，在8核16G 内存的生产环境机器备份 1kw 条记录, 耗时150 分钟。 但基本不对服务造成影响，而且可以不用深夜进行, 值得一用。</p>\n<p>  最近攒了好多好工具和经验，要好好整理搬上来和大家分享才是。</p>\n"},{"layout":"post","title":"搭建elasticsearch与kibana","date":"2015-01-31T04:52:00.000Z","comments":1,"keywords":"elasticsearch kibana","_content":"\nElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速,\nKibana 是一个与之配套的 web 界面。\n\n \n### 安装所需的：\n\n+ 需要openJDK\n+ 下载并安装 [elasticsearch-1.4.2.deb](http://www.elasticsearch.org/overview/elkdownloads/)\n+ 下载并安装 [kibana-4.0.0-beta3.tar.gz](http://www.elasticsearch.org/overview/elkdownloads/)\n\n### 配置相关\n启动 elasticsearch 方式如下\n\n```\nsudo service elasticsearch restart\n```\n\n* 我是使用 [supervisor](http://wiki.zheng-ji.info/Sys/supervisor.html) 启动 kibana, \n* 同时使用 [monit](http://wiki.zheng-ji.info/Sys/monit.html) 监控elasticsearch \n\n在/etc/defaut/elasticsearch 配置数据文件目录的地址，log 地址，调整内存和堆栈大小，个人认为机器配置的50% 就可以了。\n\nNginx 配置，使得kibanan可以被外部访问，eleasticsearch 默认监听的是5601：\n\n```\nserver {\n        listen 80;\n        #auth_basic_user_file /home/ymserver/auth/kibana-user;\n        error_log /home/ymserver/log/nginx/kibana.err.log;\n        location / {\n            proxy_pass http://127.0.0.1:5601$request_uri;\n            proxy_set_header Host $http_host;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; \n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n}\n```\n \n\n### 使用过程\nPython 有支持elasticsearch 的库 [elasticsearch-py](https://github.com/elasticsearch/elasticsearch-py)，\n用其导数据进入elasticsearch,需要指定好索引。\n\n使用restful[查询](http://www.elasticsearch.org/guide/en/elasticsearch/reference/)， \n如下例子：其中'2014-12-18'是索引名，q后面是查询条件，_all表示全部索引\n\n```\ncurl -XGET 'http://localhost:9200/2014-12-18/_search/?q=name:861160022835011'\ncurl -XGET 'http://localhost:9200/_all/_search/?q=name:861160022835011'\ncurl -XGET localhost:9200/_search -d '\n{\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n            {\n                \"term\": {\n                    \"field1\": \"X\"\n                }\n            },\n            {\n                \"term\": {\n                    \"field3\": \"Z\"\n                }\n            }\n            ],\n            \"must_not\": {\n                \"term\": {\n                    \"field2\": \"Y\"\n                }\n            }\n        }\n    }\n}'\n```\n\n### 性能概述\n导入1个月的日志4.2G，31天的文件，每天一个索引，用了6个小时，elasticsearch用了 6.7G 的空间，在海量数据查询1s内响应。\n","source":"_posts/2015-01-31-da-jian-elasticsearchyu-kibana.markdown","raw":"---\nlayout: post\ntitle: \"搭建elasticsearch与kibana\"\ndate: 2015-01-31 12:52\ncomments: true\nkeywords: elasticsearch kibana\ncategories: DataBase\n---\n\nElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速,\nKibana 是一个与之配套的 web 界面。\n\n \n### 安装所需的：\n\n+ 需要openJDK\n+ 下载并安装 [elasticsearch-1.4.2.deb](http://www.elasticsearch.org/overview/elkdownloads/)\n+ 下载并安装 [kibana-4.0.0-beta3.tar.gz](http://www.elasticsearch.org/overview/elkdownloads/)\n\n### 配置相关\n启动 elasticsearch 方式如下\n\n```\nsudo service elasticsearch restart\n```\n\n* 我是使用 [supervisor](http://wiki.zheng-ji.info/Sys/supervisor.html) 启动 kibana, \n* 同时使用 [monit](http://wiki.zheng-ji.info/Sys/monit.html) 监控elasticsearch \n\n在/etc/defaut/elasticsearch 配置数据文件目录的地址，log 地址，调整内存和堆栈大小，个人认为机器配置的50% 就可以了。\n\nNginx 配置，使得kibanan可以被外部访问，eleasticsearch 默认监听的是5601：\n\n```\nserver {\n        listen 80;\n        #auth_basic_user_file /home/ymserver/auth/kibana-user;\n        error_log /home/ymserver/log/nginx/kibana.err.log;\n        location / {\n            proxy_pass http://127.0.0.1:5601$request_uri;\n            proxy_set_header Host $http_host;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; \n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n}\n```\n \n\n### 使用过程\nPython 有支持elasticsearch 的库 [elasticsearch-py](https://github.com/elasticsearch/elasticsearch-py)，\n用其导数据进入elasticsearch,需要指定好索引。\n\n使用restful[查询](http://www.elasticsearch.org/guide/en/elasticsearch/reference/)， \n如下例子：其中'2014-12-18'是索引名，q后面是查询条件，_all表示全部索引\n\n```\ncurl -XGET 'http://localhost:9200/2014-12-18/_search/?q=name:861160022835011'\ncurl -XGET 'http://localhost:9200/_all/_search/?q=name:861160022835011'\ncurl -XGET localhost:9200/_search -d '\n{\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n            {\n                \"term\": {\n                    \"field1\": \"X\"\n                }\n            },\n            {\n                \"term\": {\n                    \"field3\": \"Z\"\n                }\n            }\n            ],\n            \"must_not\": {\n                \"term\": {\n                    \"field2\": \"Y\"\n                }\n            }\n        }\n    }\n}'\n```\n\n### 性能概述\n导入1个月的日志4.2G，31天的文件，每天一个索引，用了6个小时，elasticsearch用了 6.7G 的空间，在海量数据查询1s内响应。\n","slug":"2015-01-31-da-jian-elasticsearchyu-kibana","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9q0038nctj2qh7b95r","content":"<p>ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速,<br>Kibana 是一个与之配套的 web 界面。</p>\n<h3 id=\"安装所需的：\"><a href=\"#安装所需的：\" class=\"headerlink\" title=\"安装所需的：\"></a>安装所需的：</h3><ul>\n<li>需要openJDK</li>\n<li>下载并安装 <a href=\"http://www.elasticsearch.org/overview/elkdownloads/\" target=\"_blank\" rel=\"noopener\">elasticsearch-1.4.2.deb</a></li>\n<li>下载并安装 <a href=\"http://www.elasticsearch.org/overview/elkdownloads/\" target=\"_blank\" rel=\"noopener\">kibana-4.0.0-beta3.tar.gz</a></li>\n</ul>\n<h3 id=\"配置相关\"><a href=\"#配置相关\" class=\"headerlink\" title=\"配置相关\"></a>配置相关</h3><p>启动 elasticsearch 方式如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo service elasticsearch restart</span><br></pre></td></tr></table></figure>\n<ul>\n<li>我是使用 <a href=\"http://wiki.zheng-ji.info/Sys/supervisor.html\" target=\"_blank\" rel=\"noopener\">supervisor</a> 启动 kibana, </li>\n<li>同时使用 <a href=\"http://wiki.zheng-ji.info/Sys/monit.html\" target=\"_blank\" rel=\"noopener\">monit</a> 监控elasticsearch </li>\n</ul>\n<p>在/etc/defaut/elasticsearch 配置数据文件目录的地址，log 地址，调整内存和堆栈大小，个人认为机器配置的50% 就可以了。</p>\n<p>Nginx 配置，使得kibanan可以被外部访问，eleasticsearch 默认监听的是5601：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen 80;</span><br><span class=\"line\">        #auth_basic_user_file /home/ymserver/auth/kibana-user;</span><br><span class=\"line\">        error_log /home/ymserver/log/nginx/kibana.err.log;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            proxy_pass http://127.0.0.1:5601$request_uri;</span><br><span class=\"line\">            proxy_set_header Host $http_host;</span><br><span class=\"line\">            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; </span><br><span class=\"line\">            proxy_set_header X-Forwarded-Proto $scheme;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"使用过程\"><a href=\"#使用过程\" class=\"headerlink\" title=\"使用过程\"></a>使用过程</h3><p>Python 有支持elasticsearch 的库 <a href=\"https://github.com/elasticsearch/elasticsearch-py\" target=\"_blank\" rel=\"noopener\">elasticsearch-py</a>，<br>用其导数据进入elasticsearch,需要指定好索引。</p>\n<p>使用restful<a href=\"http://www.elasticsearch.org/guide/en/elasticsearch/reference/\" target=\"_blank\" rel=\"noopener\">查询</a>，<br>如下例子：其中’2014-12-18’是索引名，q后面是查询条件，_all表示全部索引</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -XGET &apos;http://localhost:9200/2014-12-18/_search/?q=name:861160022835011&apos;</span><br><span class=\"line\">curl -XGET &apos;http://localhost:9200/_all/_search/?q=name:861160022835011&apos;</span><br><span class=\"line\">curl -XGET localhost:9200/_search -d &apos;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;query&quot;: &#123;</span><br><span class=\"line\">        &quot;bool&quot;: &#123;</span><br><span class=\"line\">            &quot;must&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;term&quot;: &#123;</span><br><span class=\"line\">                    &quot;field1&quot;: &quot;X&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;term&quot;: &#123;</span><br><span class=\"line\">                    &quot;field3&quot;: &quot;Z&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            ],</span><br><span class=\"line\">            &quot;must_not&quot;: &#123;</span><br><span class=\"line\">                &quot;term&quot;: &#123;</span><br><span class=\"line\">                    &quot;field2&quot;: &quot;Y&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;&apos;</span><br></pre></td></tr></table></figure>\n<h3 id=\"性能概述\"><a href=\"#性能概述\" class=\"headerlink\" title=\"性能概述\"></a>性能概述</h3><p>导入1个月的日志4.2G，31天的文件，每天一个索引，用了6个小时，elasticsearch用了 6.7G 的空间，在海量数据查询1s内响应。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速,<br>Kibana 是一个与之配套的 web 界面。</p>\n<h3 id=\"安装所需的：\"><a href=\"#安装所需的：\" class=\"headerlink\" title=\"安装所需的：\"></a>安装所需的：</h3><ul>\n<li>需要openJDK</li>\n<li>下载并安装 <a href=\"http://www.elasticsearch.org/overview/elkdownloads/\" target=\"_blank\" rel=\"noopener\">elasticsearch-1.4.2.deb</a></li>\n<li>下载并安装 <a href=\"http://www.elasticsearch.org/overview/elkdownloads/\" target=\"_blank\" rel=\"noopener\">kibana-4.0.0-beta3.tar.gz</a></li>\n</ul>\n<h3 id=\"配置相关\"><a href=\"#配置相关\" class=\"headerlink\" title=\"配置相关\"></a>配置相关</h3><p>启动 elasticsearch 方式如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo service elasticsearch restart</span><br></pre></td></tr></table></figure>\n<ul>\n<li>我是使用 <a href=\"http://wiki.zheng-ji.info/Sys/supervisor.html\" target=\"_blank\" rel=\"noopener\">supervisor</a> 启动 kibana, </li>\n<li>同时使用 <a href=\"http://wiki.zheng-ji.info/Sys/monit.html\" target=\"_blank\" rel=\"noopener\">monit</a> 监控elasticsearch </li>\n</ul>\n<p>在/etc/defaut/elasticsearch 配置数据文件目录的地址，log 地址，调整内存和堆栈大小，个人认为机器配置的50% 就可以了。</p>\n<p>Nginx 配置，使得kibanan可以被外部访问，eleasticsearch 默认监听的是5601：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen 80;</span><br><span class=\"line\">        #auth_basic_user_file /home/ymserver/auth/kibana-user;</span><br><span class=\"line\">        error_log /home/ymserver/log/nginx/kibana.err.log;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            proxy_pass http://127.0.0.1:5601$request_uri;</span><br><span class=\"line\">            proxy_set_header Host $http_host;</span><br><span class=\"line\">            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; </span><br><span class=\"line\">            proxy_set_header X-Forwarded-Proto $scheme;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"使用过程\"><a href=\"#使用过程\" class=\"headerlink\" title=\"使用过程\"></a>使用过程</h3><p>Python 有支持elasticsearch 的库 <a href=\"https://github.com/elasticsearch/elasticsearch-py\" target=\"_blank\" rel=\"noopener\">elasticsearch-py</a>，<br>用其导数据进入elasticsearch,需要指定好索引。</p>\n<p>使用restful<a href=\"http://www.elasticsearch.org/guide/en/elasticsearch/reference/\" target=\"_blank\" rel=\"noopener\">查询</a>，<br>如下例子：其中’2014-12-18’是索引名，q后面是查询条件，_all表示全部索引</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -XGET &apos;http://localhost:9200/2014-12-18/_search/?q=name:861160022835011&apos;</span><br><span class=\"line\">curl -XGET &apos;http://localhost:9200/_all/_search/?q=name:861160022835011&apos;</span><br><span class=\"line\">curl -XGET localhost:9200/_search -d &apos;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;query&quot;: &#123;</span><br><span class=\"line\">        &quot;bool&quot;: &#123;</span><br><span class=\"line\">            &quot;must&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;term&quot;: &#123;</span><br><span class=\"line\">                    &quot;field1&quot;: &quot;X&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;term&quot;: &#123;</span><br><span class=\"line\">                    &quot;field3&quot;: &quot;Z&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            ],</span><br><span class=\"line\">            &quot;must_not&quot;: &#123;</span><br><span class=\"line\">                &quot;term&quot;: &#123;</span><br><span class=\"line\">                    &quot;field2&quot;: &quot;Y&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;&apos;</span><br></pre></td></tr></table></figure>\n<h3 id=\"性能概述\"><a href=\"#性能概述\" class=\"headerlink\" title=\"性能概述\"></a>性能概述</h3><p>导入1个月的日志4.2G，31天的文件，每天一个索引，用了6个小时，elasticsearch用了 6.7G 的空间，在海量数据查询1s内响应。</p>\n"},{"layout":"post","title":"haproxy - MySQl 的负载均衡","date":"2015-02-03T15:17:00.000Z","keywords":"haproxy","description":"haproxy mysql","_content":"\n服务器上每个PHP进程占用一个数据库链接，当有 n 台服务器, 每台服务器用用100 * m 个PHP 进程的时候，数据库的压力是有点小大。\n\n为了解决这个问题, 可以有的选择是：\n\n+ 业内炒的比较火的有，奇虎[Atlas](https://github.com/Qihoo360/Atlas), 淘宝前架构师写的[OneProxy](http://weibo.com/dbatools), 官方的MySQL-Proxy;\n+ 从连接层解决负载均衡的压力，Haproxy 所擅长的事情\n\n对于第一个选择，同事做过调研，使用起来不太放心。官方库就无人维护, 于是，最后选择了 Haproxy 来承担数据库的前端代理.链接数下降明显。\n\n----\n\n### 一些关键的配置\n\n参考[连接](http://www.sysads.co.uk/2014/08/install-haproxy-1-5-6-on-ubuntu-14-04/):\n\n以下是配置内容\n\n```\nlisten mysql-cluster\n    bind 127.0.0.1:3306  # 连接本地3306 到后端的DB\n    mode tcp\n    option mysql-check user haproxy_check # haproxy_check 是该haproxy用户\n    balance roundrobin\n    server mysql-1 10.0.0.1:3306 check # 后端DB\n    server mysql-2 10.0.0.2:3306 check # 后端DB\n\nlisten 0.0.0.0:8080 # 监控页面\n    mode http\n    stats enable\n    stats uri /\n    stats realm Strictly\\ Private\n    stats auth A_Username:YourPassword\n    stats auth Another_User:passwd\n```\n\n值得注意的是，我们需要在DB 里面添加用户 haproxy_check,使得它有权限访问这个数据库。一开始我习惯用\n\n```\n假设我的内网ip是 192.168.1.5\ncreate user 'haproxy_check'@'192.168.1.5' identified by 'xxx';\nflush privileges;\n```\n事实上这样连接 haproxy 会报：\n\n```\nmysql -h127.0.0.1 -uusername -p\nlost connection to mysql server at 'reading initial communication packet'\n```\n\n后来老实按照 digitalocean 的文章修改成\n\n```\nINSERT INTO mysql.user (Host,User) values ('192.168.1.5','haproxy_check');\nflush privileges;\n```\n\n测试就通过了.好奇怪，在我的理解中很不应该, 明天继续看看为什么会这么奇怪。\n\n\n\n\n\n\n\n","source":"_posts/2015-02-03-haproxy-plus-mysql.markdown","raw":"---\nlayout: post\ntitle: \"haproxy - MySQl 的负载均衡\"\ndate: 2015-02-03 23:17\nkeywords: haproxy\ndescription: haproxy mysql \ncategories: DataBase\n---\n\n服务器上每个PHP进程占用一个数据库链接，当有 n 台服务器, 每台服务器用用100 * m 个PHP 进程的时候，数据库的压力是有点小大。\n\n为了解决这个问题, 可以有的选择是：\n\n+ 业内炒的比较火的有，奇虎[Atlas](https://github.com/Qihoo360/Atlas), 淘宝前架构师写的[OneProxy](http://weibo.com/dbatools), 官方的MySQL-Proxy;\n+ 从连接层解决负载均衡的压力，Haproxy 所擅长的事情\n\n对于第一个选择，同事做过调研，使用起来不太放心。官方库就无人维护, 于是，最后选择了 Haproxy 来承担数据库的前端代理.链接数下降明显。\n\n----\n\n### 一些关键的配置\n\n参考[连接](http://www.sysads.co.uk/2014/08/install-haproxy-1-5-6-on-ubuntu-14-04/):\n\n以下是配置内容\n\n```\nlisten mysql-cluster\n    bind 127.0.0.1:3306  # 连接本地3306 到后端的DB\n    mode tcp\n    option mysql-check user haproxy_check # haproxy_check 是该haproxy用户\n    balance roundrobin\n    server mysql-1 10.0.0.1:3306 check # 后端DB\n    server mysql-2 10.0.0.2:3306 check # 后端DB\n\nlisten 0.0.0.0:8080 # 监控页面\n    mode http\n    stats enable\n    stats uri /\n    stats realm Strictly\\ Private\n    stats auth A_Username:YourPassword\n    stats auth Another_User:passwd\n```\n\n值得注意的是，我们需要在DB 里面添加用户 haproxy_check,使得它有权限访问这个数据库。一开始我习惯用\n\n```\n假设我的内网ip是 192.168.1.5\ncreate user 'haproxy_check'@'192.168.1.5' identified by 'xxx';\nflush privileges;\n```\n事实上这样连接 haproxy 会报：\n\n```\nmysql -h127.0.0.1 -uusername -p\nlost connection to mysql server at 'reading initial communication packet'\n```\n\n后来老实按照 digitalocean 的文章修改成\n\n```\nINSERT INTO mysql.user (Host,User) values ('192.168.1.5','haproxy_check');\nflush privileges;\n```\n\n测试就通过了.好奇怪，在我的理解中很不应该, 明天继续看看为什么会这么奇怪。\n\n\n\n\n\n\n\n","slug":"2015-02-03-haproxy-plus-mysql","published":1,"updated":"2018-06-17T10:38:56.000Z","comments":1,"photos":[],"link":"","_id":"cjijzgd9r003anctjpvo9prnl","content":"<p>服务器上每个PHP进程占用一个数据库链接，当有 n 台服务器, 每台服务器用用100 * m 个PHP 进程的时候，数据库的压力是有点小大。</p>\n<p>为了解决这个问题, 可以有的选择是：</p>\n<ul>\n<li>业内炒的比较火的有，奇虎<a href=\"https://github.com/Qihoo360/Atlas\" target=\"_blank\" rel=\"noopener\">Atlas</a>, 淘宝前架构师写的<a href=\"http://weibo.com/dbatools\" target=\"_blank\" rel=\"noopener\">OneProxy</a>, 官方的MySQL-Proxy;</li>\n<li>从连接层解决负载均衡的压力，Haproxy 所擅长的事情</li>\n</ul>\n<p>对于第一个选择，同事做过调研，使用起来不太放心。官方库就无人维护, 于是，最后选择了 Haproxy 来承担数据库的前端代理.链接数下降明显。</p>\n<hr>\n<h3 id=\"一些关键的配置\"><a href=\"#一些关键的配置\" class=\"headerlink\" title=\"一些关键的配置\"></a>一些关键的配置</h3><p>参考<a href=\"http://www.sysads.co.uk/2014/08/install-haproxy-1-5-6-on-ubuntu-14-04/\" target=\"_blank\" rel=\"noopener\">连接</a>:</p>\n<p>以下是配置内容</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listen mysql-cluster</span><br><span class=\"line\">    bind 127.0.0.1:3306  # 连接本地3306 到后端的DB</span><br><span class=\"line\">    mode tcp</span><br><span class=\"line\">    option mysql-check user haproxy_check # haproxy_check 是该haproxy用户</span><br><span class=\"line\">    balance roundrobin</span><br><span class=\"line\">    server mysql-1 10.0.0.1:3306 check # 后端DB</span><br><span class=\"line\">    server mysql-2 10.0.0.2:3306 check # 后端DB</span><br><span class=\"line\"></span><br><span class=\"line\">listen 0.0.0.0:8080 # 监控页面</span><br><span class=\"line\">    mode http</span><br><span class=\"line\">    stats enable</span><br><span class=\"line\">    stats uri /</span><br><span class=\"line\">    stats realm Strictly\\ Private</span><br><span class=\"line\">    stats auth A_Username:YourPassword</span><br><span class=\"line\">    stats auth Another_User:passwd</span><br></pre></td></tr></table></figure>\n<p>值得注意的是，我们需要在DB 里面添加用户 haproxy_check,使得它有权限访问这个数据库。一开始我习惯用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">假设我的内网ip是 192.168.1.5</span><br><span class=\"line\">create user &apos;haproxy_check&apos;@&apos;192.168.1.5&apos; identified by &apos;xxx&apos;;</span><br><span class=\"line\">flush privileges;</span><br></pre></td></tr></table></figure>\n<p>事实上这样连接 haproxy 会报：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -h127.0.0.1 -uusername -p</span><br><span class=\"line\">lost connection to mysql server at &apos;reading initial communication packet&apos;</span><br></pre></td></tr></table></figure>\n<p>后来老实按照 digitalocean 的文章修改成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INSERT INTO mysql.user (Host,User) values (&apos;192.168.1.5&apos;,&apos;haproxy_check&apos;);</span><br><span class=\"line\">flush privileges;</span><br></pre></td></tr></table></figure>\n<p>测试就通过了.好奇怪，在我的理解中很不应该, 明天继续看看为什么会这么奇怪。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>服务器上每个PHP进程占用一个数据库链接，当有 n 台服务器, 每台服务器用用100 * m 个PHP 进程的时候，数据库的压力是有点小大。</p>\n<p>为了解决这个问题, 可以有的选择是：</p>\n<ul>\n<li>业内炒的比较火的有，奇虎<a href=\"https://github.com/Qihoo360/Atlas\" target=\"_blank\" rel=\"noopener\">Atlas</a>, 淘宝前架构师写的<a href=\"http://weibo.com/dbatools\" target=\"_blank\" rel=\"noopener\">OneProxy</a>, 官方的MySQL-Proxy;</li>\n<li>从连接层解决负载均衡的压力，Haproxy 所擅长的事情</li>\n</ul>\n<p>对于第一个选择，同事做过调研，使用起来不太放心。官方库就无人维护, 于是，最后选择了 Haproxy 来承担数据库的前端代理.链接数下降明显。</p>\n<hr>\n<h3 id=\"一些关键的配置\"><a href=\"#一些关键的配置\" class=\"headerlink\" title=\"一些关键的配置\"></a>一些关键的配置</h3><p>参考<a href=\"http://www.sysads.co.uk/2014/08/install-haproxy-1-5-6-on-ubuntu-14-04/\" target=\"_blank\" rel=\"noopener\">连接</a>:</p>\n<p>以下是配置内容</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">listen mysql-cluster</span><br><span class=\"line\">    bind 127.0.0.1:3306  # 连接本地3306 到后端的DB</span><br><span class=\"line\">    mode tcp</span><br><span class=\"line\">    option mysql-check user haproxy_check # haproxy_check 是该haproxy用户</span><br><span class=\"line\">    balance roundrobin</span><br><span class=\"line\">    server mysql-1 10.0.0.1:3306 check # 后端DB</span><br><span class=\"line\">    server mysql-2 10.0.0.2:3306 check # 后端DB</span><br><span class=\"line\"></span><br><span class=\"line\">listen 0.0.0.0:8080 # 监控页面</span><br><span class=\"line\">    mode http</span><br><span class=\"line\">    stats enable</span><br><span class=\"line\">    stats uri /</span><br><span class=\"line\">    stats realm Strictly\\ Private</span><br><span class=\"line\">    stats auth A_Username:YourPassword</span><br><span class=\"line\">    stats auth Another_User:passwd</span><br></pre></td></tr></table></figure>\n<p>值得注意的是，我们需要在DB 里面添加用户 haproxy_check,使得它有权限访问这个数据库。一开始我习惯用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">假设我的内网ip是 192.168.1.5</span><br><span class=\"line\">create user &apos;haproxy_check&apos;@&apos;192.168.1.5&apos; identified by &apos;xxx&apos;;</span><br><span class=\"line\">flush privileges;</span><br></pre></td></tr></table></figure>\n<p>事实上这样连接 haproxy 会报：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql -h127.0.0.1 -uusername -p</span><br><span class=\"line\">lost connection to mysql server at &apos;reading initial communication packet&apos;</span><br></pre></td></tr></table></figure>\n<p>后来老实按照 digitalocean 的文章修改成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INSERT INTO mysql.user (Host,User) values (&apos;192.168.1.5&apos;,&apos;haproxy_check&apos;);</span><br><span class=\"line\">flush privileges;</span><br></pre></td></tr></table></figure>\n<p>测试就通过了.好奇怪，在我的理解中很不应该, 明天继续看看为什么会这么奇怪。</p>\n"},{"layout":"post","title":"实现一个智能提示框功能","date":"2015-02-08T05:40:00.000Z","comments":1,"description":"golang trie","_content":"\n耗了3个夜晚出来的东西.\n\n先上图吧：\n\n{% img /images/2015/02/suggest.png %}\n\n是的，就是这样一个类似百度框的联想提升功能，让我纠结了几个晚上，在实现成功的那一瞬间，着实感受到编程之美。很享受为了一个小idea折腾的酣畅淋漓的过程。\n\n起因: 在公司`GitLab`看到有这人对内部管理系统提出了这个需求，但是一直没有被`close`, 我觉得应该挺有趣的，好奇心驱动下就开始搞了。\n\n如果仅仅是实现这个需求，应该有很多种\n\n* 方法一：使用一个hash,将关键字填入key，如果采用此法，数据量大的时候估计堪忧，以一个汉字2个Byte计算的话，1kw个词条，1个词条10个词语的话需要占用大于200M内存。\n* 方法二：前缀匹配，那么应该怎么选择数据结构,朴素的做法是O(N^N),我们肯定采用复杂度较优的Trie树  O(1)\n* 方法三：Radix Tree 据说这个是linux cache的一个算法。看了几个小时，真心复杂，不得不佩服内核开发者！\n\n\n### 讲一讲`trie`树吧\n\n{% img /images/2015/02/triestruct.png %}\n\n* 根节点不包含字符，除根节点外的每一个子节点都包含一个字符。\n* 根节点到某一节点，路径上经过的字符连接起来，就是该节点对应的字符串。\n* 每个单词的公共前缀作为一个字符节点保存。\n* 叶子节点的指针是空的\n\n以下是具体的数据结构代码\n\n```\ntype Node struct {\n    Link     map[string]*Node  #指针\n    Key      string                     #每个节点的字符\n    IsLeaf   bool                       #是否叶子节点 \n    Weight   float64                    #权重\n    LongWord string                     #从根节点到该节点的长字符\n}\n```\n\n围绕这个数据结构做了\n构建树，删除节点，添加节点，获取子节点等\n\n### 知识铺垫：\n在用 Go 语言处理中文字符的时候，需要特别使用 []rune数组，看以下示范代码就知道了,他把中文处理成1个字符表现的编码方式了。正式我们下列处理Trie需要用到的。\n\n```\npackage main\nimport \"fmt\"\n\nfunc main () {\n    m_str := \"编程\"\n    fmt.Println(\"fmt:\", m_str)\n    m_str_rune := []rune(m_str)\n    fmt.Println(\"fmt:\", m_str_rune)\n    m_str_byte := []byte(m_str)\n    fmt.Println(\"fmt:\", m_str_byte)\n}\n\n$ ./test_rune\nfmt: 编程\nfmt: [32534 31243]\nfmt: [231 188 150 231 168 139]\n```\n\n### 测试结果：\n导入100W条词条,搜索的反应是瞬秒，1ms返回响应，在4G的机器上，整个程序占用内存0.3%。\n\n---\n\n\n每个成熟的互联网产品，背后都是工程师耗费一点一滴思维的结晶构建而成的。对待技术不得不敬畏。\n\n[代码](https://github.com/zheng-ji/trietips)\n","source":"_posts/2015-02-08-trie-suggestion.markdown","raw":"---\nlayout: post\ntitle: \"实现一个智能提示框功能\"\ndate: 2015-02-08 13:40\ncomments: true\ndescription: golang trie\ncategories: Programe\n---\n\n耗了3个夜晚出来的东西.\n\n先上图吧：\n\n{% img /images/2015/02/suggest.png %}\n\n是的，就是这样一个类似百度框的联想提升功能，让我纠结了几个晚上，在实现成功的那一瞬间，着实感受到编程之美。很享受为了一个小idea折腾的酣畅淋漓的过程。\n\n起因: 在公司`GitLab`看到有这人对内部管理系统提出了这个需求，但是一直没有被`close`, 我觉得应该挺有趣的，好奇心驱动下就开始搞了。\n\n如果仅仅是实现这个需求，应该有很多种\n\n* 方法一：使用一个hash,将关键字填入key，如果采用此法，数据量大的时候估计堪忧，以一个汉字2个Byte计算的话，1kw个词条，1个词条10个词语的话需要占用大于200M内存。\n* 方法二：前缀匹配，那么应该怎么选择数据结构,朴素的做法是O(N^N),我们肯定采用复杂度较优的Trie树  O(1)\n* 方法三：Radix Tree 据说这个是linux cache的一个算法。看了几个小时，真心复杂，不得不佩服内核开发者！\n\n\n### 讲一讲`trie`树吧\n\n{% img /images/2015/02/triestruct.png %}\n\n* 根节点不包含字符，除根节点外的每一个子节点都包含一个字符。\n* 根节点到某一节点，路径上经过的字符连接起来，就是该节点对应的字符串。\n* 每个单词的公共前缀作为一个字符节点保存。\n* 叶子节点的指针是空的\n\n以下是具体的数据结构代码\n\n```\ntype Node struct {\n    Link     map[string]*Node  #指针\n    Key      string                     #每个节点的字符\n    IsLeaf   bool                       #是否叶子节点 \n    Weight   float64                    #权重\n    LongWord string                     #从根节点到该节点的长字符\n}\n```\n\n围绕这个数据结构做了\n构建树，删除节点，添加节点，获取子节点等\n\n### 知识铺垫：\n在用 Go 语言处理中文字符的时候，需要特别使用 []rune数组，看以下示范代码就知道了,他把中文处理成1个字符表现的编码方式了。正式我们下列处理Trie需要用到的。\n\n```\npackage main\nimport \"fmt\"\n\nfunc main () {\n    m_str := \"编程\"\n    fmt.Println(\"fmt:\", m_str)\n    m_str_rune := []rune(m_str)\n    fmt.Println(\"fmt:\", m_str_rune)\n    m_str_byte := []byte(m_str)\n    fmt.Println(\"fmt:\", m_str_byte)\n}\n\n$ ./test_rune\nfmt: 编程\nfmt: [32534 31243]\nfmt: [231 188 150 231 168 139]\n```\n\n### 测试结果：\n导入100W条词条,搜索的反应是瞬秒，1ms返回响应，在4G的机器上，整个程序占用内存0.3%。\n\n---\n\n\n每个成熟的互联网产品，背后都是工程师耗费一点一滴思维的结晶构建而成的。对待技术不得不敬畏。\n\n[代码](https://github.com/zheng-ji/trietips)\n","slug":"2015-02-08-trie-suggestion","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9t003cnctjku0tc75j","content":"<p>耗了3个夜晚出来的东西.</p>\n<p>先上图吧：</p>\n<img src=\"/images/2015/02/suggest.png\">\n<p>是的，就是这样一个类似百度框的联想提升功能，让我纠结了几个晚上，在实现成功的那一瞬间，着实感受到编程之美。很享受为了一个小idea折腾的酣畅淋漓的过程。</p>\n<p>起因: 在公司<code>GitLab</code>看到有这人对内部管理系统提出了这个需求，但是一直没有被<code>close</code>, 我觉得应该挺有趣的，好奇心驱动下就开始搞了。</p>\n<p>如果仅仅是实现这个需求，应该有很多种</p>\n<ul>\n<li>方法一：使用一个hash,将关键字填入key，如果采用此法，数据量大的时候估计堪忧，以一个汉字2个Byte计算的话，1kw个词条，1个词条10个词语的话需要占用大于200M内存。</li>\n<li>方法二：前缀匹配，那么应该怎么选择数据结构,朴素的做法是O(N^N),我们肯定采用复杂度较优的Trie树  O(1)</li>\n<li>方法三：Radix Tree 据说这个是linux cache的一个算法。看了几个小时，真心复杂，不得不佩服内核开发者！</li>\n</ul>\n<h3 id=\"讲一讲trie树吧\"><a href=\"#讲一讲trie树吧\" class=\"headerlink\" title=\"讲一讲trie树吧\"></a>讲一讲<code>trie</code>树吧</h3><img src=\"/images/2015/02/triestruct.png\">\n<ul>\n<li>根节点不包含字符，除根节点外的每一个子节点都包含一个字符。</li>\n<li>根节点到某一节点，路径上经过的字符连接起来，就是该节点对应的字符串。</li>\n<li>每个单词的公共前缀作为一个字符节点保存。</li>\n<li>叶子节点的指针是空的</li>\n</ul>\n<p>以下是具体的数据结构代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Node struct &#123;</span><br><span class=\"line\">    Link     map[string]*Node  #指针</span><br><span class=\"line\">    Key      string                     #每个节点的字符</span><br><span class=\"line\">    IsLeaf   bool                       #是否叶子节点 </span><br><span class=\"line\">    Weight   float64                    #权重</span><br><span class=\"line\">    LongWord string                     #从根节点到该节点的长字符</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>围绕这个数据结构做了<br>构建树，删除节点，添加节点，获取子节点等</p>\n<h3 id=\"知识铺垫：\"><a href=\"#知识铺垫：\" class=\"headerlink\" title=\"知识铺垫：\"></a>知识铺垫：</h3><p>在用 Go 语言处理中文字符的时候，需要特别使用 []rune数组，看以下示范代码就知道了,他把中文处理成1个字符表现的编码方式了。正式我们下列处理Trie需要用到的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\">import &quot;fmt&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">func main () &#123;</span><br><span class=\"line\">    m_str := &quot;编程&quot;</span><br><span class=\"line\">    fmt.Println(&quot;fmt:&quot;, m_str)</span><br><span class=\"line\">    m_str_rune := []rune(m_str)</span><br><span class=\"line\">    fmt.Println(&quot;fmt:&quot;, m_str_rune)</span><br><span class=\"line\">    m_str_byte := []byte(m_str)</span><br><span class=\"line\">    fmt.Println(&quot;fmt:&quot;, m_str_byte)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">$ ./test_rune</span><br><span class=\"line\">fmt: 编程</span><br><span class=\"line\">fmt: [32534 31243]</span><br><span class=\"line\">fmt: [231 188 150 231 168 139]</span><br></pre></td></tr></table></figure>\n<h3 id=\"测试结果：\"><a href=\"#测试结果：\" class=\"headerlink\" title=\"测试结果：\"></a>测试结果：</h3><p>导入100W条词条,搜索的反应是瞬秒，1ms返回响应，在4G的机器上，整个程序占用内存0.3%。</p>\n<hr>\n<p>每个成熟的互联网产品，背后都是工程师耗费一点一滴思维的结晶构建而成的。对待技术不得不敬畏。</p>\n<p><a href=\"https://github.com/zheng-ji/trietips\" target=\"_blank\" rel=\"noopener\">代码</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>耗了3个夜晚出来的东西.</p>\n<p>先上图吧：</p>\n<img src=\"/images/2015/02/suggest.png\">\n<p>是的，就是这样一个类似百度框的联想提升功能，让我纠结了几个晚上，在实现成功的那一瞬间，着实感受到编程之美。很享受为了一个小idea折腾的酣畅淋漓的过程。</p>\n<p>起因: 在公司<code>GitLab</code>看到有这人对内部管理系统提出了这个需求，但是一直没有被<code>close</code>, 我觉得应该挺有趣的，好奇心驱动下就开始搞了。</p>\n<p>如果仅仅是实现这个需求，应该有很多种</p>\n<ul>\n<li>方法一：使用一个hash,将关键字填入key，如果采用此法，数据量大的时候估计堪忧，以一个汉字2个Byte计算的话，1kw个词条，1个词条10个词语的话需要占用大于200M内存。</li>\n<li>方法二：前缀匹配，那么应该怎么选择数据结构,朴素的做法是O(N^N),我们肯定采用复杂度较优的Trie树  O(1)</li>\n<li>方法三：Radix Tree 据说这个是linux cache的一个算法。看了几个小时，真心复杂，不得不佩服内核开发者！</li>\n</ul>\n<h3 id=\"讲一讲trie树吧\"><a href=\"#讲一讲trie树吧\" class=\"headerlink\" title=\"讲一讲trie树吧\"></a>讲一讲<code>trie</code>树吧</h3><img src=\"/images/2015/02/triestruct.png\">\n<ul>\n<li>根节点不包含字符，除根节点外的每一个子节点都包含一个字符。</li>\n<li>根节点到某一节点，路径上经过的字符连接起来，就是该节点对应的字符串。</li>\n<li>每个单词的公共前缀作为一个字符节点保存。</li>\n<li>叶子节点的指针是空的</li>\n</ul>\n<p>以下是具体的数据结构代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Node struct &#123;</span><br><span class=\"line\">    Link     map[string]*Node  #指针</span><br><span class=\"line\">    Key      string                     #每个节点的字符</span><br><span class=\"line\">    IsLeaf   bool                       #是否叶子节点 </span><br><span class=\"line\">    Weight   float64                    #权重</span><br><span class=\"line\">    LongWord string                     #从根节点到该节点的长字符</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>围绕这个数据结构做了<br>构建树，删除节点，添加节点，获取子节点等</p>\n<h3 id=\"知识铺垫：\"><a href=\"#知识铺垫：\" class=\"headerlink\" title=\"知识铺垫：\"></a>知识铺垫：</h3><p>在用 Go 语言处理中文字符的时候，需要特别使用 []rune数组，看以下示范代码就知道了,他把中文处理成1个字符表现的编码方式了。正式我们下列处理Trie需要用到的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\">import &quot;fmt&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">func main () &#123;</span><br><span class=\"line\">    m_str := &quot;编程&quot;</span><br><span class=\"line\">    fmt.Println(&quot;fmt:&quot;, m_str)</span><br><span class=\"line\">    m_str_rune := []rune(m_str)</span><br><span class=\"line\">    fmt.Println(&quot;fmt:&quot;, m_str_rune)</span><br><span class=\"line\">    m_str_byte := []byte(m_str)</span><br><span class=\"line\">    fmt.Println(&quot;fmt:&quot;, m_str_byte)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">$ ./test_rune</span><br><span class=\"line\">fmt: 编程</span><br><span class=\"line\">fmt: [32534 31243]</span><br><span class=\"line\">fmt: [231 188 150 231 168 139]</span><br></pre></td></tr></table></figure>\n<h3 id=\"测试结果：\"><a href=\"#测试结果：\" class=\"headerlink\" title=\"测试结果：\"></a>测试结果：</h3><p>导入100W条词条,搜索的反应是瞬秒，1ms返回响应，在4G的机器上，整个程序占用内存0.3%。</p>\n<hr>\n<p>每个成熟的互联网产品，背后都是工程师耗费一点一滴思维的结晶构建而成的。对待技术不得不敬畏。</p>\n<p><a href=\"https://github.com/zheng-ji/trietips\" target=\"_blank\" rel=\"noopener\">代码</a></p>\n"},{"layout":"post","title":"为服务端程序构建 Docker","date":"2015-04-05T12:24:00.000Z","comments":1,"description":"Docker, 自动化运维","_content":"\nDocker 的优点自从问世就一直被工业界热论。\n\n平时工作中，所部署的大多数`Python`项目都会用上 [virtualenv](http://wiki.zheng-ji.info/Python/virtualenv-py.html), \n沙箱隔离带来的好处不言而喻。我也希望静态编译的服务，比如 `Golang` `C++` 的项目\n同样能使用上沙箱环境。得益于`Docker`，我们仍然可以做到。\n\n\n这个过程没有想象中的简单，需要一番折腾，我以最近写的 KafkServer 为例，叙述我是怎么构建的，需要读者具备一定的 Docker 基础. 或许这不是最好的方法。\n\n\n### 一览该 Docker 项目\n\n```\nzj@zheng-ji:~/workspace/gocode/src/kafconsumer/docker$ tree\n.\n├── Dockerfile\n├── kafConsumer\n│   ├── consumer\n│   ├── etc\n│   │   ├── config.yml\n│   │   └── logger.xml\n│   └── script\n│       └── start.sh\n└── kafConsumer.tar.gz\n```\n\n以上的截图，是一个完整的 `Docker` 项目，包含了：\n\n* `Dockerfile`,\n* `kafCounsumer`(服务端程序，里面附带的启动脚本，配置程序，以及二进制文件)，\n* 还有它被压缩而成的 `kafConsumer.tar.gz`\n\n---\n\n### Dockerfile 的内容\n\n\n```\nFROM ubuntu:14.04                                                         \nMAINTAINER zheng-ji <zheng-ji.info>                                     \nRUN echo Asia/Shanghai > /etc/timezone                   \nRUN sed -i \"s/archive\\.ubuntu/mirrors.163/\" /etc/apt/sources.list          \nRUN apt-get update                                                         \nCOPY kafConsumer.tar.gz /                                                  \nRUN tar xvf kafConsumer.tar.gz                                         \nVOLUME /data                   \nWORKDIR /kafConsumer                                                   \nENTRYPOINT [\"./script/start.sh\"]\n```\n\n`Dockerfile` 可以理解为`makefile` 之类的文件，Docker 可以依照文件中的内容，构建镜像.\n\n```\nsudo docker -t build Server/KafConsumer .\n```\n\n这样就生成了`Tag` 为 `Server/KafConsumer` 的镜像，待会儿我们会使用它\n\n\n以上 `Dockerfile` 的具体内容的意义是:\n\n>\n>* 第一行：拉取ubuntu 14:04的镜像源\n>* 第二行：维护者\n>* 第三行：调整时区\n>* 第四行：更新源地址\n>* 第五行：更新源\n>* 第六行：复制项目下的压缩包到虚拟机根目录\n>* 第七行：解压\n>* 第八行：项目中使用/data数据卷\n>* 第九行：进入工作目录\n>* 第十行：Docker的入口执行文件是start.sh\n\n---\n\n\n### 入口文件的内容\n\n```\n#!/bin/bash\nulimit -a\nif [ ! -d /data/ad ];  then\n    mkdir /data/ad\nfi\nexec ./consumer -c=etc/config.yml\n```\n\n这是一个shell的启动文件，因此一定要在开头写明 #!/bin/bash, 使用exec 执行程序\n\n\n---\n\n### 启动镜像\n\n```\nsudo docker run -i -t  -v /path/to/data:/data Server/kafConsumer\n```\n这样就执行了，-v 可以映射你的本地文件到虚拟机的某个数据卷，这样我们就能从外面看到程序产生的文件.\n\n###如果你想关闭或者重启该服务的怎么办\n\n```\nsudo docker ps -a\n\n找到你的 Docker 容器\n\nCONTAINER ID    IMAGE           COMMAND                CREATED        STATUS        PORTS    NAMES\n5b39d0d5cb85    Server/kafkaconsumer:latest   \"./script/start.sh\"    3 hours ago    tender_bohr \n```\n\n启动或者关闭\n\n```\nsudo docker start tender_bohr\nsudo docker stop tender_bohr\n```\n\n---\n\n### Daocloud  加速\n\n功夫墙的原因，国外很多镜像被墙，因此构建镜像很慢，使用 Daocloud 服务可以加速,注册后就有该服务了\n\n```\ncat /etc/default/docker\nDOCKER_OPTS=\"$DOCKER_OPTS --registry-mirror=http://xxxxxx.m.daocloud.io\"\n```\n","source":"_posts/2015-04-05-yong-bao-docker.markdown","raw":"---\nlayout: post\ntitle: \"为服务端程序构建 Docker\"\ndate: 2015-04-05 20:24\ncomments: true\ncategories: Server\ndescription: Docker, 自动化运维\n---\n\nDocker 的优点自从问世就一直被工业界热论。\n\n平时工作中，所部署的大多数`Python`项目都会用上 [virtualenv](http://wiki.zheng-ji.info/Python/virtualenv-py.html), \n沙箱隔离带来的好处不言而喻。我也希望静态编译的服务，比如 `Golang` `C++` 的项目\n同样能使用上沙箱环境。得益于`Docker`，我们仍然可以做到。\n\n\n这个过程没有想象中的简单，需要一番折腾，我以最近写的 KafkServer 为例，叙述我是怎么构建的，需要读者具备一定的 Docker 基础. 或许这不是最好的方法。\n\n\n### 一览该 Docker 项目\n\n```\nzj@zheng-ji:~/workspace/gocode/src/kafconsumer/docker$ tree\n.\n├── Dockerfile\n├── kafConsumer\n│   ├── consumer\n│   ├── etc\n│   │   ├── config.yml\n│   │   └── logger.xml\n│   └── script\n│       └── start.sh\n└── kafConsumer.tar.gz\n```\n\n以上的截图，是一个完整的 `Docker` 项目，包含了：\n\n* `Dockerfile`,\n* `kafCounsumer`(服务端程序，里面附带的启动脚本，配置程序，以及二进制文件)，\n* 还有它被压缩而成的 `kafConsumer.tar.gz`\n\n---\n\n### Dockerfile 的内容\n\n\n```\nFROM ubuntu:14.04                                                         \nMAINTAINER zheng-ji <zheng-ji.info>                                     \nRUN echo Asia/Shanghai > /etc/timezone                   \nRUN sed -i \"s/archive\\.ubuntu/mirrors.163/\" /etc/apt/sources.list          \nRUN apt-get update                                                         \nCOPY kafConsumer.tar.gz /                                                  \nRUN tar xvf kafConsumer.tar.gz                                         \nVOLUME /data                   \nWORKDIR /kafConsumer                                                   \nENTRYPOINT [\"./script/start.sh\"]\n```\n\n`Dockerfile` 可以理解为`makefile` 之类的文件，Docker 可以依照文件中的内容，构建镜像.\n\n```\nsudo docker -t build Server/KafConsumer .\n```\n\n这样就生成了`Tag` 为 `Server/KafConsumer` 的镜像，待会儿我们会使用它\n\n\n以上 `Dockerfile` 的具体内容的意义是:\n\n>\n>* 第一行：拉取ubuntu 14:04的镜像源\n>* 第二行：维护者\n>* 第三行：调整时区\n>* 第四行：更新源地址\n>* 第五行：更新源\n>* 第六行：复制项目下的压缩包到虚拟机根目录\n>* 第七行：解压\n>* 第八行：项目中使用/data数据卷\n>* 第九行：进入工作目录\n>* 第十行：Docker的入口执行文件是start.sh\n\n---\n\n\n### 入口文件的内容\n\n```\n#!/bin/bash\nulimit -a\nif [ ! -d /data/ad ];  then\n    mkdir /data/ad\nfi\nexec ./consumer -c=etc/config.yml\n```\n\n这是一个shell的启动文件，因此一定要在开头写明 #!/bin/bash, 使用exec 执行程序\n\n\n---\n\n### 启动镜像\n\n```\nsudo docker run -i -t  -v /path/to/data:/data Server/kafConsumer\n```\n这样就执行了，-v 可以映射你的本地文件到虚拟机的某个数据卷，这样我们就能从外面看到程序产生的文件.\n\n###如果你想关闭或者重启该服务的怎么办\n\n```\nsudo docker ps -a\n\n找到你的 Docker 容器\n\nCONTAINER ID    IMAGE           COMMAND                CREATED        STATUS        PORTS    NAMES\n5b39d0d5cb85    Server/kafkaconsumer:latest   \"./script/start.sh\"    3 hours ago    tender_bohr \n```\n\n启动或者关闭\n\n```\nsudo docker start tender_bohr\nsudo docker stop tender_bohr\n```\n\n---\n\n### Daocloud  加速\n\n功夫墙的原因，国外很多镜像被墙，因此构建镜像很慢，使用 Daocloud 服务可以加速,注册后就有该服务了\n\n```\ncat /etc/default/docker\nDOCKER_OPTS=\"$DOCKER_OPTS --registry-mirror=http://xxxxxx.m.daocloud.io\"\n```\n","slug":"2015-04-05-yong-bao-docker","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9u003enctjqi3esvw7","content":"<p>Docker 的优点自从问世就一直被工业界热论。</p>\n<p>平时工作中，所部署的大多数<code>Python</code>项目都会用上 <a href=\"http://wiki.zheng-ji.info/Python/virtualenv-py.html\" target=\"_blank\" rel=\"noopener\">virtualenv</a>,<br>沙箱隔离带来的好处不言而喻。我也希望静态编译的服务，比如 <code>Golang</code> <code>C++</code> 的项目<br>同样能使用上沙箱环境。得益于<code>Docker</code>，我们仍然可以做到。</p>\n<p>这个过程没有想象中的简单，需要一番折腾，我以最近写的 KafkServer 为例，叙述我是怎么构建的，需要读者具备一定的 Docker 基础. 或许这不是最好的方法。</p>\n<h3 id=\"一览该-Docker-项目\"><a href=\"#一览该-Docker-项目\" class=\"headerlink\" title=\"一览该 Docker 项目\"></a>一览该 Docker 项目</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~/workspace/gocode/src/kafconsumer/docker$ tree</span><br><span class=\"line\">.</span><br><span class=\"line\">├── Dockerfile</span><br><span class=\"line\">├── kafConsumer</span><br><span class=\"line\">│   ├── consumer</span><br><span class=\"line\">│   ├── etc</span><br><span class=\"line\">│   │   ├── config.yml</span><br><span class=\"line\">│   │   └── logger.xml</span><br><span class=\"line\">│   └── script</span><br><span class=\"line\">│       └── start.sh</span><br><span class=\"line\">└── kafConsumer.tar.gz</span><br></pre></td></tr></table></figure>\n<p>以上的截图，是一个完整的 <code>Docker</code> 项目，包含了：</p>\n<ul>\n<li><code>Dockerfile</code>,</li>\n<li><code>kafCounsumer</code>(服务端程序，里面附带的启动脚本，配置程序，以及二进制文件)，</li>\n<li>还有它被压缩而成的 <code>kafConsumer.tar.gz</code></li>\n</ul>\n<hr>\n<h3 id=\"Dockerfile-的内容\"><a href=\"#Dockerfile-的内容\" class=\"headerlink\" title=\"Dockerfile 的内容\"></a>Dockerfile 的内容</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM ubuntu:14.04                                                         </span><br><span class=\"line\">MAINTAINER zheng-ji &lt;zheng-ji.info&gt;                                     </span><br><span class=\"line\">RUN echo Asia/Shanghai &gt; /etc/timezone                   </span><br><span class=\"line\">RUN sed -i &quot;s/archive\\.ubuntu/mirrors.163/&quot; /etc/apt/sources.list          </span><br><span class=\"line\">RUN apt-get update                                                         </span><br><span class=\"line\">COPY kafConsumer.tar.gz /                                                  </span><br><span class=\"line\">RUN tar xvf kafConsumer.tar.gz                                         </span><br><span class=\"line\">VOLUME /data                   </span><br><span class=\"line\">WORKDIR /kafConsumer                                                   </span><br><span class=\"line\">ENTRYPOINT [&quot;./script/start.sh&quot;]</span><br></pre></td></tr></table></figure>\n<p><code>Dockerfile</code> 可以理解为<code>makefile</code> 之类的文件，Docker 可以依照文件中的内容，构建镜像.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker -t build Server/KafConsumer .</span><br></pre></td></tr></table></figure>\n<p>这样就生成了<code>Tag</code> 为 <code>Server/KafConsumer</code> 的镜像，待会儿我们会使用它</p>\n<p>以上 <code>Dockerfile</code> 的具体内容的意义是:</p>\n<blockquote>\n<ul>\n<li>第一行：拉取ubuntu 14:04的镜像源</li>\n<li>第二行：维护者</li>\n<li>第三行：调整时区</li>\n<li>第四行：更新源地址</li>\n<li>第五行：更新源</li>\n<li>第六行：复制项目下的压缩包到虚拟机根目录</li>\n<li>第七行：解压</li>\n<li>第八行：项目中使用/data数据卷</li>\n<li>第九行：进入工作目录</li>\n<li>第十行：Docker的入口执行文件是start.sh</li>\n</ul>\n</blockquote>\n<hr>\n<h3 id=\"入口文件的内容\"><a href=\"#入口文件的内容\" class=\"headerlink\" title=\"入口文件的内容\"></a>入口文件的内容</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">ulimit -a</span><br><span class=\"line\">if [ ! -d /data/ad ];  then</span><br><span class=\"line\">    mkdir /data/ad</span><br><span class=\"line\">fi</span><br><span class=\"line\">exec ./consumer -c=etc/config.yml</span><br></pre></td></tr></table></figure>\n<p>这是一个shell的启动文件，因此一定要在开头写明 #!/bin/bash, 使用exec 执行程序</p>\n<hr>\n<h3 id=\"启动镜像\"><a href=\"#启动镜像\" class=\"headerlink\" title=\"启动镜像\"></a>启动镜像</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker run -i -t  -v /path/to/data:/data Server/kafConsumer</span><br></pre></td></tr></table></figure>\n<p>这样就执行了，-v 可以映射你的本地文件到虚拟机的某个数据卷，这样我们就能从外面看到程序产生的文件.</p>\n<p>###如果你想关闭或者重启该服务的怎么办</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker ps -a</span><br><span class=\"line\"></span><br><span class=\"line\">找到你的 Docker 容器</span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER ID    IMAGE           COMMAND                CREATED        STATUS        PORTS    NAMES</span><br><span class=\"line\">5b39d0d5cb85    Server/kafkaconsumer:latest   &quot;./script/start.sh&quot;    3 hours ago    tender_bohr</span><br></pre></td></tr></table></figure>\n<p>启动或者关闭</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker start tender_bohr</span><br><span class=\"line\">sudo docker stop tender_bohr</span><br></pre></td></tr></table></figure>\n<hr>\n<h3 id=\"Daocloud-加速\"><a href=\"#Daocloud-加速\" class=\"headerlink\" title=\"Daocloud  加速\"></a>Daocloud  加速</h3><p>功夫墙的原因，国外很多镜像被墙，因此构建镜像很慢，使用 Daocloud 服务可以加速,注册后就有该服务了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /etc/default/docker</span><br><span class=\"line\">DOCKER_OPTS=&quot;$DOCKER_OPTS --registry-mirror=http://xxxxxx.m.daocloud.io&quot;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>Docker 的优点自从问世就一直被工业界热论。</p>\n<p>平时工作中，所部署的大多数<code>Python</code>项目都会用上 <a href=\"http://wiki.zheng-ji.info/Python/virtualenv-py.html\" target=\"_blank\" rel=\"noopener\">virtualenv</a>,<br>沙箱隔离带来的好处不言而喻。我也希望静态编译的服务，比如 <code>Golang</code> <code>C++</code> 的项目<br>同样能使用上沙箱环境。得益于<code>Docker</code>，我们仍然可以做到。</p>\n<p>这个过程没有想象中的简单，需要一番折腾，我以最近写的 KafkServer 为例，叙述我是怎么构建的，需要读者具备一定的 Docker 基础. 或许这不是最好的方法。</p>\n<h3 id=\"一览该-Docker-项目\"><a href=\"#一览该-Docker-项目\" class=\"headerlink\" title=\"一览该 Docker 项目\"></a>一览该 Docker 项目</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji:~/workspace/gocode/src/kafconsumer/docker$ tree</span><br><span class=\"line\">.</span><br><span class=\"line\">├── Dockerfile</span><br><span class=\"line\">├── kafConsumer</span><br><span class=\"line\">│   ├── consumer</span><br><span class=\"line\">│   ├── etc</span><br><span class=\"line\">│   │   ├── config.yml</span><br><span class=\"line\">│   │   └── logger.xml</span><br><span class=\"line\">│   └── script</span><br><span class=\"line\">│       └── start.sh</span><br><span class=\"line\">└── kafConsumer.tar.gz</span><br></pre></td></tr></table></figure>\n<p>以上的截图，是一个完整的 <code>Docker</code> 项目，包含了：</p>\n<ul>\n<li><code>Dockerfile</code>,</li>\n<li><code>kafCounsumer</code>(服务端程序，里面附带的启动脚本，配置程序，以及二进制文件)，</li>\n<li>还有它被压缩而成的 <code>kafConsumer.tar.gz</code></li>\n</ul>\n<hr>\n<h3 id=\"Dockerfile-的内容\"><a href=\"#Dockerfile-的内容\" class=\"headerlink\" title=\"Dockerfile 的内容\"></a>Dockerfile 的内容</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM ubuntu:14.04                                                         </span><br><span class=\"line\">MAINTAINER zheng-ji &lt;zheng-ji.info&gt;                                     </span><br><span class=\"line\">RUN echo Asia/Shanghai &gt; /etc/timezone                   </span><br><span class=\"line\">RUN sed -i &quot;s/archive\\.ubuntu/mirrors.163/&quot; /etc/apt/sources.list          </span><br><span class=\"line\">RUN apt-get update                                                         </span><br><span class=\"line\">COPY kafConsumer.tar.gz /                                                  </span><br><span class=\"line\">RUN tar xvf kafConsumer.tar.gz                                         </span><br><span class=\"line\">VOLUME /data                   </span><br><span class=\"line\">WORKDIR /kafConsumer                                                   </span><br><span class=\"line\">ENTRYPOINT [&quot;./script/start.sh&quot;]</span><br></pre></td></tr></table></figure>\n<p><code>Dockerfile</code> 可以理解为<code>makefile</code> 之类的文件，Docker 可以依照文件中的内容，构建镜像.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker -t build Server/KafConsumer .</span><br></pre></td></tr></table></figure>\n<p>这样就生成了<code>Tag</code> 为 <code>Server/KafConsumer</code> 的镜像，待会儿我们会使用它</p>\n<p>以上 <code>Dockerfile</code> 的具体内容的意义是:</p>\n<blockquote>\n<ul>\n<li>第一行：拉取ubuntu 14:04的镜像源</li>\n<li>第二行：维护者</li>\n<li>第三行：调整时区</li>\n<li>第四行：更新源地址</li>\n<li>第五行：更新源</li>\n<li>第六行：复制项目下的压缩包到虚拟机根目录</li>\n<li>第七行：解压</li>\n<li>第八行：项目中使用/data数据卷</li>\n<li>第九行：进入工作目录</li>\n<li>第十行：Docker的入口执行文件是start.sh</li>\n</ul>\n</blockquote>\n<hr>\n<h3 id=\"入口文件的内容\"><a href=\"#入口文件的内容\" class=\"headerlink\" title=\"入口文件的内容\"></a>入口文件的内容</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">ulimit -a</span><br><span class=\"line\">if [ ! -d /data/ad ];  then</span><br><span class=\"line\">    mkdir /data/ad</span><br><span class=\"line\">fi</span><br><span class=\"line\">exec ./consumer -c=etc/config.yml</span><br></pre></td></tr></table></figure>\n<p>这是一个shell的启动文件，因此一定要在开头写明 #!/bin/bash, 使用exec 执行程序</p>\n<hr>\n<h3 id=\"启动镜像\"><a href=\"#启动镜像\" class=\"headerlink\" title=\"启动镜像\"></a>启动镜像</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker run -i -t  -v /path/to/data:/data Server/kafConsumer</span><br></pre></td></tr></table></figure>\n<p>这样就执行了，-v 可以映射你的本地文件到虚拟机的某个数据卷，这样我们就能从外面看到程序产生的文件.</p>\n<p>###如果你想关闭或者重启该服务的怎么办</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker ps -a</span><br><span class=\"line\"></span><br><span class=\"line\">找到你的 Docker 容器</span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER ID    IMAGE           COMMAND                CREATED        STATUS        PORTS    NAMES</span><br><span class=\"line\">5b39d0d5cb85    Server/kafkaconsumer:latest   &quot;./script/start.sh&quot;    3 hours ago    tender_bohr</span><br></pre></td></tr></table></figure>\n<p>启动或者关闭</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker start tender_bohr</span><br><span class=\"line\">sudo docker stop tender_bohr</span><br></pre></td></tr></table></figure>\n<hr>\n<h3 id=\"Daocloud-加速\"><a href=\"#Daocloud-加速\" class=\"headerlink\" title=\"Daocloud  加速\"></a>Daocloud  加速</h3><p>功夫墙的原因，国外很多镜像被墙，因此构建镜像很慢，使用 Daocloud 服务可以加速,注册后就有该服务了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /etc/default/docker</span><br><span class=\"line\">DOCKER_OPTS=&quot;$DOCKER_OPTS --registry-mirror=http://xxxxxx.m.daocloud.io&quot;</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"MySQL Slave Relay log Corrupt 恢复","date":"2015-05-10T12:02:00.000Z","comments":1,"description":"mys1l slave relay log","_content":"\n### 现象 ### \n周日早晨收到 `ganglia` 报警, 内容是：\n\n```\nMySQL_Slave_SQL is 0.00\n```\n意味着从库同步有问题了。这时候进入从库看看状态\n\n```\nshow slave status\\G;\n```\n\n看到\n\n```\nSlave_IO_State: Waiting for master to send event\n   Master_Host: xxx.xxx.xxx\n   Master_User: replication\n   Master_Port: 3306\n   Connect_Retry: 60\n   Master_Log_File: mysql-bin.000028\n   ad_Master_Log_Pos: 982714864\n   Relay_Log_File: relay-bin.000143\n   Relay_Master_Log_File: mysql-bin.000028\n   Slave_IO_Running: Yes\n   Slave_SQL_Running: No\n   Replicate_Do_DB:\n Replicate_Ignore_DB:\n Replicate_Do_Table:\n Replicate_Ignore_Table:\n Replicate_Wild_Do_Table:\n Replicate_Wild_Ignore_Table:\n Last_Errno: 1594\n Last_Error: Relay log read failure: Could not parse relay log event entry. The possible reasons are: the master's binary log is corrupted (you can check this by running 'mysqlbinlog' on the binary log), the slave's relay log is corrupted (you can check this by running 'mysqlbinlog' on the relay log), a network problem, or a bug in the master's or slave's MySQL code. If you want to check the master's binary log or slave's relay log, you will be able to know their names by issuing 'SHOW SLAVE STATUS' on this slave.\n Skip_Counter: 3\n Exec_Master_Log_Pos: 974999870\n Relay_Log_Space: 399910514\n Until_Condition: None\n```\n \n是因为从库的 relay log 损坏导致的从库停止执行同步, 后面从 MySQL 的错误日志发现是由几个没经过优化的大查询导致从库内存使用较大，mysqld_safe 被迫重启了。\n\n### 解决方法 ###\n\n找到：\n\n```\nRelay_Master_Log_File: mysql-bin.000028\nExec_Master_Log_Pos: 974999870\n```\n\n执行\n\n```\nmysql> stop slave ;\nmysql> change master to master_log_file='mysql-bin.000028',master_log_pos=974999870;\nmysql> start slave;\n```\n                                                                                  \n这样就重新追上了。以后还是要提高周围同事使用 MySQL 的优化意识啊。\n","source":"_posts/2015-05-10-mysql-slave-relay-log-corrupt-chu-li-he-hui-fu.markdown","raw":"---\nlayout: post\ntitle: \"MySQL Slave Relay log Corrupt 恢复\"\ndate: 2015-05-10 20:02\ncomments: true\ncategories: DataBase\ndescription: mys1l slave relay log\n---\n\n### 现象 ### \n周日早晨收到 `ganglia` 报警, 内容是：\n\n```\nMySQL_Slave_SQL is 0.00\n```\n意味着从库同步有问题了。这时候进入从库看看状态\n\n```\nshow slave status\\G;\n```\n\n看到\n\n```\nSlave_IO_State: Waiting for master to send event\n   Master_Host: xxx.xxx.xxx\n   Master_User: replication\n   Master_Port: 3306\n   Connect_Retry: 60\n   Master_Log_File: mysql-bin.000028\n   ad_Master_Log_Pos: 982714864\n   Relay_Log_File: relay-bin.000143\n   Relay_Master_Log_File: mysql-bin.000028\n   Slave_IO_Running: Yes\n   Slave_SQL_Running: No\n   Replicate_Do_DB:\n Replicate_Ignore_DB:\n Replicate_Do_Table:\n Replicate_Ignore_Table:\n Replicate_Wild_Do_Table:\n Replicate_Wild_Ignore_Table:\n Last_Errno: 1594\n Last_Error: Relay log read failure: Could not parse relay log event entry. The possible reasons are: the master's binary log is corrupted (you can check this by running 'mysqlbinlog' on the binary log), the slave's relay log is corrupted (you can check this by running 'mysqlbinlog' on the relay log), a network problem, or a bug in the master's or slave's MySQL code. If you want to check the master's binary log or slave's relay log, you will be able to know their names by issuing 'SHOW SLAVE STATUS' on this slave.\n Skip_Counter: 3\n Exec_Master_Log_Pos: 974999870\n Relay_Log_Space: 399910514\n Until_Condition: None\n```\n \n是因为从库的 relay log 损坏导致的从库停止执行同步, 后面从 MySQL 的错误日志发现是由几个没经过优化的大查询导致从库内存使用较大，mysqld_safe 被迫重启了。\n\n### 解决方法 ###\n\n找到：\n\n```\nRelay_Master_Log_File: mysql-bin.000028\nExec_Master_Log_Pos: 974999870\n```\n\n执行\n\n```\nmysql> stop slave ;\nmysql> change master to master_log_file='mysql-bin.000028',master_log_pos=974999870;\nmysql> start slave;\n```\n                                                                                  \n这样就重新追上了。以后还是要提高周围同事使用 MySQL 的优化意识啊。\n","slug":"2015-05-10-mysql-slave-relay-log-corrupt-chu-li-he-hui-fu","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9v003gnctjf228p45d","content":"<h3 id=\"现象\"><a href=\"#现象\" class=\"headerlink\" title=\"现象\"></a>现象</h3><p>周日早晨收到 <code>ganglia</code> 报警, 内容是：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MySQL_Slave_SQL is 0.00</span><br></pre></td></tr></table></figure>\n<p>意味着从库同步有问题了。这时候进入从库看看状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show slave status\\G;</span><br></pre></td></tr></table></figure>\n<p>看到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Slave_IO_State: Waiting for master to send event</span><br><span class=\"line\">   Master_Host: xxx.xxx.xxx</span><br><span class=\"line\">   Master_User: replication</span><br><span class=\"line\">   Master_Port: 3306</span><br><span class=\"line\">   Connect_Retry: 60</span><br><span class=\"line\">   Master_Log_File: mysql-bin.000028</span><br><span class=\"line\">   ad_Master_Log_Pos: 982714864</span><br><span class=\"line\">   Relay_Log_File: relay-bin.000143</span><br><span class=\"line\">   Relay_Master_Log_File: mysql-bin.000028</span><br><span class=\"line\">   Slave_IO_Running: Yes</span><br><span class=\"line\">   Slave_SQL_Running: No</span><br><span class=\"line\">   Replicate_Do_DB:</span><br><span class=\"line\"> Replicate_Ignore_DB:</span><br><span class=\"line\"> Replicate_Do_Table:</span><br><span class=\"line\"> Replicate_Ignore_Table:</span><br><span class=\"line\"> Replicate_Wild_Do_Table:</span><br><span class=\"line\"> Replicate_Wild_Ignore_Table:</span><br><span class=\"line\"> Last_Errno: 1594</span><br><span class=\"line\"> Last_Error: Relay log read failure: Could not parse relay log event entry. The possible reasons are: the master&apos;s binary log is corrupted (you can check this by running &apos;mysqlbinlog&apos; on the binary log), the slave&apos;s relay log is corrupted (you can check this by running &apos;mysqlbinlog&apos; on the relay log), a network problem, or a bug in the master&apos;s or slave&apos;s MySQL code. If you want to check the master&apos;s binary log or slave&apos;s relay log, you will be able to know their names by issuing &apos;SHOW SLAVE STATUS&apos; on this slave.</span><br><span class=\"line\"> Skip_Counter: 3</span><br><span class=\"line\"> Exec_Master_Log_Pos: 974999870</span><br><span class=\"line\"> Relay_Log_Space: 399910514</span><br><span class=\"line\"> Until_Condition: None</span><br></pre></td></tr></table></figure>\n<p>是因为从库的 relay log 损坏导致的从库停止执行同步, 后面从 MySQL 的错误日志发现是由几个没经过优化的大查询导致从库内存使用较大，mysqld_safe 被迫重启了。</p>\n<h3 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h3><p>找到：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Relay_Master_Log_File: mysql-bin.000028</span><br><span class=\"line\">Exec_Master_Log_Pos: 974999870</span><br></pre></td></tr></table></figure>\n<p>执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; stop slave ;</span><br><span class=\"line\">mysql&gt; change master to master_log_file=&apos;mysql-bin.000028&apos;,master_log_pos=974999870;</span><br><span class=\"line\">mysql&gt; start slave;</span><br></pre></td></tr></table></figure>\n<p>这样就重新追上了。以后还是要提高周围同事使用 MySQL 的优化意识啊。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"现象\"><a href=\"#现象\" class=\"headerlink\" title=\"现象\"></a>现象</h3><p>周日早晨收到 <code>ganglia</code> 报警, 内容是：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MySQL_Slave_SQL is 0.00</span><br></pre></td></tr></table></figure>\n<p>意味着从库同步有问题了。这时候进入从库看看状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show slave status\\G;</span><br></pre></td></tr></table></figure>\n<p>看到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Slave_IO_State: Waiting for master to send event</span><br><span class=\"line\">   Master_Host: xxx.xxx.xxx</span><br><span class=\"line\">   Master_User: replication</span><br><span class=\"line\">   Master_Port: 3306</span><br><span class=\"line\">   Connect_Retry: 60</span><br><span class=\"line\">   Master_Log_File: mysql-bin.000028</span><br><span class=\"line\">   ad_Master_Log_Pos: 982714864</span><br><span class=\"line\">   Relay_Log_File: relay-bin.000143</span><br><span class=\"line\">   Relay_Master_Log_File: mysql-bin.000028</span><br><span class=\"line\">   Slave_IO_Running: Yes</span><br><span class=\"line\">   Slave_SQL_Running: No</span><br><span class=\"line\">   Replicate_Do_DB:</span><br><span class=\"line\"> Replicate_Ignore_DB:</span><br><span class=\"line\"> Replicate_Do_Table:</span><br><span class=\"line\"> Replicate_Ignore_Table:</span><br><span class=\"line\"> Replicate_Wild_Do_Table:</span><br><span class=\"line\"> Replicate_Wild_Ignore_Table:</span><br><span class=\"line\"> Last_Errno: 1594</span><br><span class=\"line\"> Last_Error: Relay log read failure: Could not parse relay log event entry. The possible reasons are: the master&apos;s binary log is corrupted (you can check this by running &apos;mysqlbinlog&apos; on the binary log), the slave&apos;s relay log is corrupted (you can check this by running &apos;mysqlbinlog&apos; on the relay log), a network problem, or a bug in the master&apos;s or slave&apos;s MySQL code. If you want to check the master&apos;s binary log or slave&apos;s relay log, you will be able to know their names by issuing &apos;SHOW SLAVE STATUS&apos; on this slave.</span><br><span class=\"line\"> Skip_Counter: 3</span><br><span class=\"line\"> Exec_Master_Log_Pos: 974999870</span><br><span class=\"line\"> Relay_Log_Space: 399910514</span><br><span class=\"line\"> Until_Condition: None</span><br></pre></td></tr></table></figure>\n<p>是因为从库的 relay log 损坏导致的从库停止执行同步, 后面从 MySQL 的错误日志发现是由几个没经过优化的大查询导致从库内存使用较大，mysqld_safe 被迫重启了。</p>\n<h3 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h3><p>找到：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Relay_Master_Log_File: mysql-bin.000028</span><br><span class=\"line\">Exec_Master_Log_Pos: 974999870</span><br></pre></td></tr></table></figure>\n<p>执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; stop slave ;</span><br><span class=\"line\">mysql&gt; change master to master_log_file=&apos;mysql-bin.000028&apos;,master_log_pos=974999870;</span><br><span class=\"line\">mysql&gt; start slave;</span><br></pre></td></tr></table></figure>\n<p>这样就重新追上了。以后还是要提高周围同事使用 MySQL 的优化意识啊。</p>\n"},{"layout":"post","title":"搭建 Postfix","date":"2015-05-16T16:25:00.000Z","comments":1,"description":"Postfix","_content":"\n我们需要搭建邮件服务，采用Postfix服务, 坑点不少，遂记录。\n现在我们决定在 `IP：1.2.3.4` 的机器上部署`Postfix`服务，让它可以发邮件\n\n### 安装 ### \n\n```\nsudo apt-get install postfix\n```\n\n### 配置 ### \n\n编辑 `/etc/postfix/main.cnf`\n\n```\nsmtpd_banner = $myhostname ESMTP $mail_name (Ubuntu)\nbiff = no\nappend_dot_mydomain = no\nreadme_directory = no\nsmtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem\nsmtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key\nsmtpd_use_tls=yes\nsmtpd_tls_session_cache_database = btree:${data_directory}/smtpd_scache\nsmtp_tls_session_cache_database = btree:${data_directory}/smtp_scache\nmyhostname = mail.zheng-ji.info 邮箱服务器域名\nalias_maps = hash:/etc/aliases\nalias_database = hash:/etc/aliases\nmyorigin = $myhostname\nmydestination = mail.zheng-ji.info, localhost.localdomain, localhost\nmynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128, hash:/etc/postfix/access 可以使用这个邮箱服务的外部地址\nrelay_domains = $mydestination\ninet_interfaces = all\ninet_protocols = all\n```\n\n### 授权 ### \n\n为了让邮件能真正到达对方邮箱而不被视为垃圾邮件， 我们需要进行DNS权威认证\n\n```\nA 记录指向 1.2.3.4\nMX 记录也指向 1.2.3.4\nTXT 记录 v=spf1 ip4:1.2.3.4 ~all\n```\n\n以上操作是防止被认为垃圾邮件。\n\n外部需要访问该Postfix 服务发送邮件，需要有access权限,\n编辑/etc/postfix/access, 假设 `IP:5.6.7.8` 的机器想访问该服务\n\n```\n5.6.7.8  OK\n```\n\n重启并授权生效\n\n```\nsudo service postfix restart\npostmap access\n```\n","source":"_posts/2015-05-17-da-jian-postfix.markdown","raw":"---\nlayout: post\ntitle: \"搭建 Postfix\"\ndate: 2015-05-17 00:25\ncomments: true\ncategories: System\ndescription: Postfix\n---\n\n我们需要搭建邮件服务，采用Postfix服务, 坑点不少，遂记录。\n现在我们决定在 `IP：1.2.3.4` 的机器上部署`Postfix`服务，让它可以发邮件\n\n### 安装 ### \n\n```\nsudo apt-get install postfix\n```\n\n### 配置 ### \n\n编辑 `/etc/postfix/main.cnf`\n\n```\nsmtpd_banner = $myhostname ESMTP $mail_name (Ubuntu)\nbiff = no\nappend_dot_mydomain = no\nreadme_directory = no\nsmtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem\nsmtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key\nsmtpd_use_tls=yes\nsmtpd_tls_session_cache_database = btree:${data_directory}/smtpd_scache\nsmtp_tls_session_cache_database = btree:${data_directory}/smtp_scache\nmyhostname = mail.zheng-ji.info 邮箱服务器域名\nalias_maps = hash:/etc/aliases\nalias_database = hash:/etc/aliases\nmyorigin = $myhostname\nmydestination = mail.zheng-ji.info, localhost.localdomain, localhost\nmynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128, hash:/etc/postfix/access 可以使用这个邮箱服务的外部地址\nrelay_domains = $mydestination\ninet_interfaces = all\ninet_protocols = all\n```\n\n### 授权 ### \n\n为了让邮件能真正到达对方邮箱而不被视为垃圾邮件， 我们需要进行DNS权威认证\n\n```\nA 记录指向 1.2.3.4\nMX 记录也指向 1.2.3.4\nTXT 记录 v=spf1 ip4:1.2.3.4 ~all\n```\n\n以上操作是防止被认为垃圾邮件。\n\n外部需要访问该Postfix 服务发送邮件，需要有access权限,\n编辑/etc/postfix/access, 假设 `IP:5.6.7.8` 的机器想访问该服务\n\n```\n5.6.7.8  OK\n```\n\n重启并授权生效\n\n```\nsudo service postfix restart\npostmap access\n```\n","slug":"2015-05-17-da-jian-postfix","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9x003inctjsxqdk30n","content":"<p>我们需要搭建邮件服务，采用Postfix服务, 坑点不少，遂记录。<br>现在我们决定在 <code>IP：1.2.3.4</code> 的机器上部署<code>Postfix</code>服务，让它可以发邮件</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install postfix</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>编辑 <code>/etc/postfix/main.cnf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">smtpd_banner = $myhostname ESMTP $mail_name (Ubuntu)</span><br><span class=\"line\">biff = no</span><br><span class=\"line\">append_dot_mydomain = no</span><br><span class=\"line\">readme_directory = no</span><br><span class=\"line\">smtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem</span><br><span class=\"line\">smtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key</span><br><span class=\"line\">smtpd_use_tls=yes</span><br><span class=\"line\">smtpd_tls_session_cache_database = btree:$&#123;data_directory&#125;/smtpd_scache</span><br><span class=\"line\">smtp_tls_session_cache_database = btree:$&#123;data_directory&#125;/smtp_scache</span><br><span class=\"line\">myhostname = mail.zheng-ji.info 邮箱服务器域名</span><br><span class=\"line\">alias_maps = hash:/etc/aliases</span><br><span class=\"line\">alias_database = hash:/etc/aliases</span><br><span class=\"line\">myorigin = $myhostname</span><br><span class=\"line\">mydestination = mail.zheng-ji.info, localhost.localdomain, localhost</span><br><span class=\"line\">mynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128, hash:/etc/postfix/access 可以使用这个邮箱服务的外部地址</span><br><span class=\"line\">relay_domains = $mydestination</span><br><span class=\"line\">inet_interfaces = all</span><br><span class=\"line\">inet_protocols = all</span><br></pre></td></tr></table></figure>\n<h3 id=\"授权\"><a href=\"#授权\" class=\"headerlink\" title=\"授权\"></a>授权</h3><p>为了让邮件能真正到达对方邮箱而不被视为垃圾邮件， 我们需要进行DNS权威认证</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A 记录指向 1.2.3.4</span><br><span class=\"line\">MX 记录也指向 1.2.3.4</span><br><span class=\"line\">TXT 记录 v=spf1 ip4:1.2.3.4 ~all</span><br></pre></td></tr></table></figure>\n<p>以上操作是防止被认为垃圾邮件。</p>\n<p>外部需要访问该Postfix 服务发送邮件，需要有access权限,<br>编辑/etc/postfix/access, 假设 <code>IP:5.6.7.8</code> 的机器想访问该服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">5.6.7.8  OK</span><br></pre></td></tr></table></figure>\n<p>重启并授权生效</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo service postfix restart</span><br><span class=\"line\">postmap access</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>我们需要搭建邮件服务，采用Postfix服务, 坑点不少，遂记录。<br>现在我们决定在 <code>IP：1.2.3.4</code> 的机器上部署<code>Postfix</code>服务，让它可以发邮件</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install postfix</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>编辑 <code>/etc/postfix/main.cnf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">smtpd_banner = $myhostname ESMTP $mail_name (Ubuntu)</span><br><span class=\"line\">biff = no</span><br><span class=\"line\">append_dot_mydomain = no</span><br><span class=\"line\">readme_directory = no</span><br><span class=\"line\">smtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem</span><br><span class=\"line\">smtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key</span><br><span class=\"line\">smtpd_use_tls=yes</span><br><span class=\"line\">smtpd_tls_session_cache_database = btree:$&#123;data_directory&#125;/smtpd_scache</span><br><span class=\"line\">smtp_tls_session_cache_database = btree:$&#123;data_directory&#125;/smtp_scache</span><br><span class=\"line\">myhostname = mail.zheng-ji.info 邮箱服务器域名</span><br><span class=\"line\">alias_maps = hash:/etc/aliases</span><br><span class=\"line\">alias_database = hash:/etc/aliases</span><br><span class=\"line\">myorigin = $myhostname</span><br><span class=\"line\">mydestination = mail.zheng-ji.info, localhost.localdomain, localhost</span><br><span class=\"line\">mynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128, hash:/etc/postfix/access 可以使用这个邮箱服务的外部地址</span><br><span class=\"line\">relay_domains = $mydestination</span><br><span class=\"line\">inet_interfaces = all</span><br><span class=\"line\">inet_protocols = all</span><br></pre></td></tr></table></figure>\n<h3 id=\"授权\"><a href=\"#授权\" class=\"headerlink\" title=\"授权\"></a>授权</h3><p>为了让邮件能真正到达对方邮箱而不被视为垃圾邮件， 我们需要进行DNS权威认证</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A 记录指向 1.2.3.4</span><br><span class=\"line\">MX 记录也指向 1.2.3.4</span><br><span class=\"line\">TXT 记录 v=spf1 ip4:1.2.3.4 ~all</span><br></pre></td></tr></table></figure>\n<p>以上操作是防止被认为垃圾邮件。</p>\n<p>外部需要访问该Postfix 服务发送邮件，需要有access权限,<br>编辑/etc/postfix/access, 假设 <code>IP:5.6.7.8</code> 的机器想访问该服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">5.6.7.8  OK</span><br></pre></td></tr></table></figure>\n<p>重启并授权生效</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo service postfix restart</span><br><span class=\"line\">postmap access</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"轻巧实时统计用户数","date":"2015-06-11T15:14:00.000Z","comments":1,"description":"Redis bitset","_content":"\n## 背景 ##\n\n最近在优化一个短地址的统计服务，之前是使用 Cookie 来做统计每天的UV，而且这个需求是近乎实时的，\n业务方需要每5分钟就能看到最新统计结果。但有些情况我们是取不到Cookie的，比如服务器对服务器的狂刷访问，那么UV就计算不准确，\n是时候要改造方案了。\n\n后来我用 IP+UserAgent 来识别用户，从而统计 UV。好了，接下来你会怎么做这个实时统计呢？\n\n##两个方案的选择##\n\n* Plan A：\n\n将每天的 `IP+UA` 存进 Redis 的 Set 集合里，它会自动去重，然后计算该集合里元素的个数得到结果，此方案似乎不错，\n但真的好吗？假如每天大概有200W个UV，1个用户标识`IP+UA`需要大概150个字节，那么大约要耗费300MB的内存。\n\n觉得内存太宝贵，应该有更好的方法，想起了位运算， 于是就有了\n\n* Plan B:\n\n将 `IP+UA` 组合成的字符串哈希成一个数值，然后借助 Redis 的 BitSet 数据结构求出`UV`。以下是伪代码\n\n```\nconn = redis()\nindex = hash(UA+IP)\nkey = \"xxx_2015-05-10\"\nconn.do('SETBIT', key, index, 1) # 将该hash值对应的位赋值为1\n\nrealtime_uv = conn.do('BITCOUNT', key) # 得到实时的uv\n```\n\n根据业务的情况，我的hash桶开了200W个位，大概需要消耗2M的内存，的确节约不少空间，位运算的效率也很快。\n于是欣然选择 Plan B\n\n\n## 一些链接 ##\n\n* [Redis Set](https://redis.readthedocs.org/en/2.4/set.html)\n* [Redis BitSet](http://redis.io/commands/SETBIT)\n* [NoSQLFan 一个文章](http://blog.nosqlfan.com/html/3501.html)\n\n","source":"_posts/2015-06-11-qing-qiao-shi-shi-tong-ji-yong-hu-shu.markdown","raw":"---\nlayout: post\ntitle: \"轻巧实时统计用户数\"\ndate: 2015-06-11 23:14\ncomments: true\ncategories: Programe\ndescription: Redis bitset\n---\n\n## 背景 ##\n\n最近在优化一个短地址的统计服务，之前是使用 Cookie 来做统计每天的UV，而且这个需求是近乎实时的，\n业务方需要每5分钟就能看到最新统计结果。但有些情况我们是取不到Cookie的，比如服务器对服务器的狂刷访问，那么UV就计算不准确，\n是时候要改造方案了。\n\n后来我用 IP+UserAgent 来识别用户，从而统计 UV。好了，接下来你会怎么做这个实时统计呢？\n\n##两个方案的选择##\n\n* Plan A：\n\n将每天的 `IP+UA` 存进 Redis 的 Set 集合里，它会自动去重，然后计算该集合里元素的个数得到结果，此方案似乎不错，\n但真的好吗？假如每天大概有200W个UV，1个用户标识`IP+UA`需要大概150个字节，那么大约要耗费300MB的内存。\n\n觉得内存太宝贵，应该有更好的方法，想起了位运算， 于是就有了\n\n* Plan B:\n\n将 `IP+UA` 组合成的字符串哈希成一个数值，然后借助 Redis 的 BitSet 数据结构求出`UV`。以下是伪代码\n\n```\nconn = redis()\nindex = hash(UA+IP)\nkey = \"xxx_2015-05-10\"\nconn.do('SETBIT', key, index, 1) # 将该hash值对应的位赋值为1\n\nrealtime_uv = conn.do('BITCOUNT', key) # 得到实时的uv\n```\n\n根据业务的情况，我的hash桶开了200W个位，大概需要消耗2M的内存，的确节约不少空间，位运算的效率也很快。\n于是欣然选择 Plan B\n\n\n## 一些链接 ##\n\n* [Redis Set](https://redis.readthedocs.org/en/2.4/set.html)\n* [Redis BitSet](http://redis.io/commands/SETBIT)\n* [NoSQLFan 一个文章](http://blog.nosqlfan.com/html/3501.html)\n\n","slug":"2015-06-11-qing-qiao-shi-shi-tong-ji-yong-hu-shu","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgd9y003knctjgtijwaqz","content":"<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>最近在优化一个短地址的统计服务，之前是使用 Cookie 来做统计每天的UV，而且这个需求是近乎实时的，<br>业务方需要每5分钟就能看到最新统计结果。但有些情况我们是取不到Cookie的，比如服务器对服务器的狂刷访问，那么UV就计算不准确，<br>是时候要改造方案了。</p>\n<p>后来我用 IP+UserAgent 来识别用户，从而统计 UV。好了，接下来你会怎么做这个实时统计呢？</p>\n<p>##两个方案的选择##</p>\n<ul>\n<li>Plan A：</li>\n</ul>\n<p>将每天的 <code>IP+UA</code> 存进 Redis 的 Set 集合里，它会自动去重，然后计算该集合里元素的个数得到结果，此方案似乎不错，<br>但真的好吗？假如每天大概有200W个UV，1个用户标识<code>IP+UA</code>需要大概150个字节，那么大约要耗费300MB的内存。</p>\n<p>觉得内存太宝贵，应该有更好的方法，想起了位运算， 于是就有了</p>\n<ul>\n<li>Plan B:</li>\n</ul>\n<p>将 <code>IP+UA</code> 组合成的字符串哈希成一个数值，然后借助 Redis 的 BitSet 数据结构求出<code>UV</code>。以下是伪代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conn = redis()</span><br><span class=\"line\">index = hash(UA+IP)</span><br><span class=\"line\">key = &quot;xxx_2015-05-10&quot;</span><br><span class=\"line\">conn.do(&apos;SETBIT&apos;, key, index, 1) # 将该hash值对应的位赋值为1</span><br><span class=\"line\"></span><br><span class=\"line\">realtime_uv = conn.do(&apos;BITCOUNT&apos;, key) # 得到实时的uv</span><br></pre></td></tr></table></figure>\n<p>根据业务的情况，我的hash桶开了200W个位，大概需要消耗2M的内存，的确节约不少空间，位运算的效率也很快。<br>于是欣然选择 Plan B</p>\n<h2 id=\"一些链接\"><a href=\"#一些链接\" class=\"headerlink\" title=\"一些链接\"></a>一些链接</h2><ul>\n<li><a href=\"https://redis.readthedocs.org/en/2.4/set.html\" target=\"_blank\" rel=\"noopener\">Redis Set</a></li>\n<li><a href=\"http://redis.io/commands/SETBIT\" target=\"_blank\" rel=\"noopener\">Redis BitSet</a></li>\n<li><a href=\"http://blog.nosqlfan.com/html/3501.html\" target=\"_blank\" rel=\"noopener\">NoSQLFan 一个文章</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>最近在优化一个短地址的统计服务，之前是使用 Cookie 来做统计每天的UV，而且这个需求是近乎实时的，<br>业务方需要每5分钟就能看到最新统计结果。但有些情况我们是取不到Cookie的，比如服务器对服务器的狂刷访问，那么UV就计算不准确，<br>是时候要改造方案了。</p>\n<p>后来我用 IP+UserAgent 来识别用户，从而统计 UV。好了，接下来你会怎么做这个实时统计呢？</p>\n<p>##两个方案的选择##</p>\n<ul>\n<li>Plan A：</li>\n</ul>\n<p>将每天的 <code>IP+UA</code> 存进 Redis 的 Set 集合里，它会自动去重，然后计算该集合里元素的个数得到结果，此方案似乎不错，<br>但真的好吗？假如每天大概有200W个UV，1个用户标识<code>IP+UA</code>需要大概150个字节，那么大约要耗费300MB的内存。</p>\n<p>觉得内存太宝贵，应该有更好的方法，想起了位运算， 于是就有了</p>\n<ul>\n<li>Plan B:</li>\n</ul>\n<p>将 <code>IP+UA</code> 组合成的字符串哈希成一个数值，然后借助 Redis 的 BitSet 数据结构求出<code>UV</code>。以下是伪代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conn = redis()</span><br><span class=\"line\">index = hash(UA+IP)</span><br><span class=\"line\">key = &quot;xxx_2015-05-10&quot;</span><br><span class=\"line\">conn.do(&apos;SETBIT&apos;, key, index, 1) # 将该hash值对应的位赋值为1</span><br><span class=\"line\"></span><br><span class=\"line\">realtime_uv = conn.do(&apos;BITCOUNT&apos;, key) # 得到实时的uv</span><br></pre></td></tr></table></figure>\n<p>根据业务的情况，我的hash桶开了200W个位，大概需要消耗2M的内存，的确节约不少空间，位运算的效率也很快。<br>于是欣然选择 Plan B</p>\n<h2 id=\"一些链接\"><a href=\"#一些链接\" class=\"headerlink\" title=\"一些链接\"></a>一些链接</h2><ul>\n<li><a href=\"https://redis.readthedocs.org/en/2.4/set.html\" target=\"_blank\" rel=\"noopener\">Redis Set</a></li>\n<li><a href=\"http://redis.io/commands/SETBIT\" target=\"_blank\" rel=\"noopener\">Redis BitSet</a></li>\n<li><a href=\"http://blog.nosqlfan.com/html/3501.html\" target=\"_blank\" rel=\"noopener\">NoSQLFan 一个文章</a></li>\n</ul>\n"},{"layout":"post","title":"my.cnf 配置依据","date":"2015-07-12T00:35:00.000Z","comments":1,"description":"MySQL my.cnf","_content":"\n阅读完[构建高性能服务器](http://book.douban.com/subject/6873681/) 一书，书中对 `MySQL` 配置做了讲解，我用烂笔头记录一番，明白它们这么配置的真正意义，形成系统的认知。\n\n* [通用配置](#第一节)\n* [innodb_pool_buffer 合理配置](#第二节)\n* [文件打开数的合理设置](#第三节)\n* [打开表优化设置](#第四节)\n* [临时表的设置](#第五节)\n* [查看索引命中率](#第六节)\n\n\n<h3 id=\"第一节\">通用配置</h3>\n\n```\nskip-name-resolve:\n```\n\n禁止 MySQL 对外连接 DNS 解析 ,这一选项可以消除 MySQL 进行DNS解析时间，开启该选项，所有远程主机连接授权都要使用 IP。\n\n```\nback_log=512\n```\n\n指出在 MySQL 暂停响应之前，有多少个请求被存在堆栈中。\n\n```\nkey_buffer_size\n```\n\n指定用于索引的缓冲区大小，增加它可得到更好的索引处理能力，对于内存 4G 左右，可设置为 256MB。\n\n```\nmax_allowed_packet=4M\n```\n设定在一次网络传输中的最大值。\n\n```\nthread_stack=256k\n```\n设置每个线程的堆栈大小，可满足普通操作。\n\n```\ntable_cache=614k\n```\n高速缓冲区的大小，当mysql访问一个表示，缓冲区还有空间，那么这个表就会被放入缓冲区，一般看峰值时间状态值，open_tables与open_cache，用于判断是否需要增加table_cache，如果open_Table接近table_cache就要增加了。\n\n```\nsort_buffer_size=6M\n```\n设定查询排序所用的缓冲区大小，是对每个链接而言，如果有100个连接，那么分配的总缓存是100*6=600M。\nread_buffer_size,join_buffer_size 都是对单个链接而言。\n\n```\nthread_cache_size=64\n```\n设置缓存中的链接线程的最大数量,4GB内存以上的我们会给64或者更大。\n\n```\nquery_cache_size=64M\n```\n\n如果该值比较小反而会影响效率，可以考虑不用。如果太大，缓存区中碎片会很多。\n\n```\ntmp_table_size\n```\n\n设置内存临时表的最大值，如果超过改制，就会将临时表写入磁盘，范围是1kB-4GB。\n\n```\nmax_connection\n```\n\n如果超过该值，会出现`too many connections`。\n\n```\nmax_connect_errors\n```\n设置每个主机中连接请求异常中断最大次数，如果超过，MySQL禁止host连接请求，直到MySQL重启。\n\n```\nwait_timeout = 120\n```\n一个请求的最大链接时间。\n\n```\nthread_concurrency=8\n```\n该参数为服务器逻辑CPU * 2。\n\n```\nskip-networking\n```\n该选项可以关闭连接方式，如果需要远程连接，不要开启。\n\n```\ninnodb_flush_log_at_trx_commit = 1\n```\n设置为0就是等到 innodb_log_buffer_size 队列满了之后再统一存储，默认是1，是最安全的设置。\n\n```\ninnodb_thread_concurrency = 8\n```\n服务器几个CPU就设置多少。\n\n```\nread_rnd_buffer_Size = 16M\n```\n\n设置随机读的使用的缓冲区。\n\n<h3 id=\"第二节\">innodb_buffer_pool 的合理设置</h3>\n\n不要武断的把innodb_buffer pool 配置为内存的50-80% 应具体而定。\n\n```\nshow status like 'innodb_buffer_pool_%'\n\n关注的有\ninnodb_buffer_pool_pages_data;\ninnodb_buffer_pool_page_total;\ninnodb_buffer_pool_read_request;\ninnodb_buffer_pool_reads;\n```\n\n然后看\n\n```\n读命中率 (innodb_buffer_pool_read_request - innodb_buffer_pool_reads) / innodb_buffer_pool_read_request;\n写命中率 innodb_buffer_pool_pages_data /innodb_buffer_pool_page_total;\n```\n如果读写命中率都能在95%以上就很好了。\n\n\n<h3 id=\"第三节\">文件打开数的合理设置依据</h3>\n\n```\nshow global status like 'open_files'\nshow variables like 'open_file_limit';\n```\n比较合适的设置是 Open_files / open_files_limit * 100% <= 75;\n\n\n<h3 id=\"第四节\">打开表优化设置依据</h3>\n\n```\nshow global status like 'open%tables';\nshow variable like 'table_cache';\n```\n比较合适\n\n```\nopen_tables / opende_tables * 100 > 85%;\nopen_Tables / table_Cache* 100% < 95%；\n```\n\n<h3 id=\"第五节\">临时表的设置依据</h3>\n\n每次执行语句，关于已经被创造了的临时表的数量，可以这么设置:\n\n```\nshow gloabl status like 'created_tmp5';\nCreated_tmp_disk_table / Created_tmp_tables * 100% <= 25 %\n```\n\n\n<h3 id=\"第六节\">查看索引命中率</h3>\n\n```\nshow global status like 'key_read%';\n```\nkey_cache_miss_rate = key_Read / key_read_request * 100% 小于 1% 是很好的，\n意味着1000个请求有一个直接读硬盘。\n","source":"_posts/2015-07-12-my-dot-cnfpei-zhi-yi-ju.markdown","raw":"---\nlayout: post\ntitle: \"my.cnf 配置依据\"\ndate: 2015-07-12 08:35\ncomments: true\ncategories: DataBase\ndescription: MySQL my.cnf\n---\n\n阅读完[构建高性能服务器](http://book.douban.com/subject/6873681/) 一书，书中对 `MySQL` 配置做了讲解，我用烂笔头记录一番，明白它们这么配置的真正意义，形成系统的认知。\n\n* [通用配置](#第一节)\n* [innodb_pool_buffer 合理配置](#第二节)\n* [文件打开数的合理设置](#第三节)\n* [打开表优化设置](#第四节)\n* [临时表的设置](#第五节)\n* [查看索引命中率](#第六节)\n\n\n<h3 id=\"第一节\">通用配置</h3>\n\n```\nskip-name-resolve:\n```\n\n禁止 MySQL 对外连接 DNS 解析 ,这一选项可以消除 MySQL 进行DNS解析时间，开启该选项，所有远程主机连接授权都要使用 IP。\n\n```\nback_log=512\n```\n\n指出在 MySQL 暂停响应之前，有多少个请求被存在堆栈中。\n\n```\nkey_buffer_size\n```\n\n指定用于索引的缓冲区大小，增加它可得到更好的索引处理能力，对于内存 4G 左右，可设置为 256MB。\n\n```\nmax_allowed_packet=4M\n```\n设定在一次网络传输中的最大值。\n\n```\nthread_stack=256k\n```\n设置每个线程的堆栈大小，可满足普通操作。\n\n```\ntable_cache=614k\n```\n高速缓冲区的大小，当mysql访问一个表示，缓冲区还有空间，那么这个表就会被放入缓冲区，一般看峰值时间状态值，open_tables与open_cache，用于判断是否需要增加table_cache，如果open_Table接近table_cache就要增加了。\n\n```\nsort_buffer_size=6M\n```\n设定查询排序所用的缓冲区大小，是对每个链接而言，如果有100个连接，那么分配的总缓存是100*6=600M。\nread_buffer_size,join_buffer_size 都是对单个链接而言。\n\n```\nthread_cache_size=64\n```\n设置缓存中的链接线程的最大数量,4GB内存以上的我们会给64或者更大。\n\n```\nquery_cache_size=64M\n```\n\n如果该值比较小反而会影响效率，可以考虑不用。如果太大，缓存区中碎片会很多。\n\n```\ntmp_table_size\n```\n\n设置内存临时表的最大值，如果超过改制，就会将临时表写入磁盘，范围是1kB-4GB。\n\n```\nmax_connection\n```\n\n如果超过该值，会出现`too many connections`。\n\n```\nmax_connect_errors\n```\n设置每个主机中连接请求异常中断最大次数，如果超过，MySQL禁止host连接请求，直到MySQL重启。\n\n```\nwait_timeout = 120\n```\n一个请求的最大链接时间。\n\n```\nthread_concurrency=8\n```\n该参数为服务器逻辑CPU * 2。\n\n```\nskip-networking\n```\n该选项可以关闭连接方式，如果需要远程连接，不要开启。\n\n```\ninnodb_flush_log_at_trx_commit = 1\n```\n设置为0就是等到 innodb_log_buffer_size 队列满了之后再统一存储，默认是1，是最安全的设置。\n\n```\ninnodb_thread_concurrency = 8\n```\n服务器几个CPU就设置多少。\n\n```\nread_rnd_buffer_Size = 16M\n```\n\n设置随机读的使用的缓冲区。\n\n<h3 id=\"第二节\">innodb_buffer_pool 的合理设置</h3>\n\n不要武断的把innodb_buffer pool 配置为内存的50-80% 应具体而定。\n\n```\nshow status like 'innodb_buffer_pool_%'\n\n关注的有\ninnodb_buffer_pool_pages_data;\ninnodb_buffer_pool_page_total;\ninnodb_buffer_pool_read_request;\ninnodb_buffer_pool_reads;\n```\n\n然后看\n\n```\n读命中率 (innodb_buffer_pool_read_request - innodb_buffer_pool_reads) / innodb_buffer_pool_read_request;\n写命中率 innodb_buffer_pool_pages_data /innodb_buffer_pool_page_total;\n```\n如果读写命中率都能在95%以上就很好了。\n\n\n<h3 id=\"第三节\">文件打开数的合理设置依据</h3>\n\n```\nshow global status like 'open_files'\nshow variables like 'open_file_limit';\n```\n比较合适的设置是 Open_files / open_files_limit * 100% <= 75;\n\n\n<h3 id=\"第四节\">打开表优化设置依据</h3>\n\n```\nshow global status like 'open%tables';\nshow variable like 'table_cache';\n```\n比较合适\n\n```\nopen_tables / opende_tables * 100 > 85%;\nopen_Tables / table_Cache* 100% < 95%；\n```\n\n<h3 id=\"第五节\">临时表的设置依据</h3>\n\n每次执行语句，关于已经被创造了的临时表的数量，可以这么设置:\n\n```\nshow gloabl status like 'created_tmp5';\nCreated_tmp_disk_table / Created_tmp_tables * 100% <= 25 %\n```\n\n\n<h3 id=\"第六节\">查看索引命中率</h3>\n\n```\nshow global status like 'key_read%';\n```\nkey_cache_miss_rate = key_Read / key_read_request * 100% 小于 1% 是很好的，\n意味着1000个请求有一个直接读硬盘。\n","slug":"2015-07-12-my-dot-cnfpei-zhi-yi-ju","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgda0003mnctj2k6ncbdf","content":"<p>阅读完<a href=\"http://book.douban.com/subject/6873681/\" target=\"_blank\" rel=\"noopener\">构建高性能服务器</a> 一书，书中对 <code>MySQL</code> 配置做了讲解，我用烂笔头记录一番，明白它们这么配置的真正意义，形成系统的认知。</p>\n<ul>\n<li><a href=\"#第一节\">通用配置</a></li>\n<li><a href=\"#第二节\">innodb_pool_buffer 合理配置</a></li>\n<li><a href=\"#第三节\">文件打开数的合理设置</a></li>\n<li><a href=\"#第四节\">打开表优化设置</a></li>\n<li><a href=\"#第五节\">临时表的设置</a></li>\n<li><a href=\"#第六节\">查看索引命中率</a></li>\n</ul>\n<h3 id=\"第一节\">通用配置</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">skip-name-resolve:</span><br></pre></td></tr></table></figure>\n<p>禁止 MySQL 对外连接 DNS 解析 ,这一选项可以消除 MySQL 进行DNS解析时间，开启该选项，所有远程主机连接授权都要使用 IP。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">back_log=512</span><br></pre></td></tr></table></figure>\n<p>指出在 MySQL 暂停响应之前，有多少个请求被存在堆栈中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">key_buffer_size</span><br></pre></td></tr></table></figure>\n<p>指定用于索引的缓冲区大小，增加它可得到更好的索引处理能力，对于内存 4G 左右，可设置为 256MB。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">max_allowed_packet=4M</span><br></pre></td></tr></table></figure>\n<p>设定在一次网络传输中的最大值。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">thread_stack=256k</span><br></pre></td></tr></table></figure>\n<p>设置每个线程的堆栈大小，可满足普通操作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">table_cache=614k</span><br></pre></td></tr></table></figure>\n<p>高速缓冲区的大小，当mysql访问一个表示，缓冲区还有空间，那么这个表就会被放入缓冲区，一般看峰值时间状态值，open_tables与open_cache，用于判断是否需要增加table_cache，如果open_Table接近table_cache就要增加了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sort_buffer_size=6M</span><br></pre></td></tr></table></figure>\n<p>设定查询排序所用的缓冲区大小，是对每个链接而言，如果有100个连接，那么分配的总缓存是100*6=600M。<br>read_buffer_size,join_buffer_size 都是对单个链接而言。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">thread_cache_size=64</span><br></pre></td></tr></table></figure>\n<p>设置缓存中的链接线程的最大数量,4GB内存以上的我们会给64或者更大。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">query_cache_size=64M</span><br></pre></td></tr></table></figure>\n<p>如果该值比较小反而会影响效率，可以考虑不用。如果太大，缓存区中碎片会很多。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tmp_table_size</span><br></pre></td></tr></table></figure>\n<p>设置内存临时表的最大值，如果超过改制，就会将临时表写入磁盘，范围是1kB-4GB。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">max_connection</span><br></pre></td></tr></table></figure>\n<p>如果超过该值，会出现<code>too many connections</code>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">max_connect_errors</span><br></pre></td></tr></table></figure>\n<p>设置每个主机中连接请求异常中断最大次数，如果超过，MySQL禁止host连接请求，直到MySQL重启。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wait_timeout = 120</span><br></pre></td></tr></table></figure>\n<p>一个请求的最大链接时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">thread_concurrency=8</span><br></pre></td></tr></table></figure>\n<p>该参数为服务器逻辑CPU * 2。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">skip-networking</span><br></pre></td></tr></table></figure>\n<p>该选项可以关闭连接方式，如果需要远程连接，不要开启。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_flush_log_at_trx_commit = 1</span><br></pre></td></tr></table></figure>\n<p>设置为0就是等到 innodb_log_buffer_size 队列满了之后再统一存储，默认是1，是最安全的设置。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_thread_concurrency = 8</span><br></pre></td></tr></table></figure>\n<p>服务器几个CPU就设置多少。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">read_rnd_buffer_Size = 16M</span><br></pre></td></tr></table></figure>\n<p>设置随机读的使用的缓冲区。</p>\n<h3 id=\"第二节\">innodb_buffer_pool 的合理设置</h3>\n\n<p>不要武断的把innodb_buffer pool 配置为内存的50-80% 应具体而定。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show status like &apos;innodb_buffer_pool_%&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">关注的有</span><br><span class=\"line\">innodb_buffer_pool_pages_data;</span><br><span class=\"line\">innodb_buffer_pool_page_total;</span><br><span class=\"line\">innodb_buffer_pool_read_request;</span><br><span class=\"line\">innodb_buffer_pool_reads;</span><br></pre></td></tr></table></figure>\n<p>然后看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">读命中率 (innodb_buffer_pool_read_request - innodb_buffer_pool_reads) / innodb_buffer_pool_read_request;</span><br><span class=\"line\">写命中率 innodb_buffer_pool_pages_data /innodb_buffer_pool_page_total;</span><br></pre></td></tr></table></figure>\n<p>如果读写命中率都能在95%以上就很好了。</p>\n<h3 id=\"第三节\">文件打开数的合理设置依据</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show global status like &apos;open_files&apos;</span><br><span class=\"line\">show variables like &apos;open_file_limit&apos;;</span><br></pre></td></tr></table></figure>\n<p>比较合适的设置是 Open_files / open_files_limit * 100% &lt;= 75;</p>\n<h3 id=\"第四节\">打开表优化设置依据</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show global status like &apos;open%tables&apos;;</span><br><span class=\"line\">show variable like &apos;table_cache&apos;;</span><br></pre></td></tr></table></figure>\n<p>比较合适</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">open_tables / opende_tables * 100 &gt; 85%;</span><br><span class=\"line\">open_Tables / table_Cache* 100% &lt; 95%；</span><br></pre></td></tr></table></figure>\n<h3 id=\"第五节\">临时表的设置依据</h3>\n\n<p>每次执行语句，关于已经被创造了的临时表的数量，可以这么设置:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show gloabl status like &apos;created_tmp5&apos;;</span><br><span class=\"line\">Created_tmp_disk_table / Created_tmp_tables * 100% &lt;= 25 %</span><br></pre></td></tr></table></figure>\n<h3 id=\"第六节\">查看索引命中率</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show global status like &apos;key_read%&apos;;</span><br></pre></td></tr></table></figure>\n<p>key_cache_miss_rate = key_Read / key_read_request * 100% 小于 1% 是很好的，<br>意味着1000个请求有一个直接读硬盘。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>阅读完<a href=\"http://book.douban.com/subject/6873681/\" target=\"_blank\" rel=\"noopener\">构建高性能服务器</a> 一书，书中对 <code>MySQL</code> 配置做了讲解，我用烂笔头记录一番，明白它们这么配置的真正意义，形成系统的认知。</p>\n<ul>\n<li><a href=\"#第一节\">通用配置</a></li>\n<li><a href=\"#第二节\">innodb_pool_buffer 合理配置</a></li>\n<li><a href=\"#第三节\">文件打开数的合理设置</a></li>\n<li><a href=\"#第四节\">打开表优化设置</a></li>\n<li><a href=\"#第五节\">临时表的设置</a></li>\n<li><a href=\"#第六节\">查看索引命中率</a></li>\n</ul>\n<h3 id=\"第一节\">通用配置</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">skip-name-resolve:</span><br></pre></td></tr></table></figure>\n<p>禁止 MySQL 对外连接 DNS 解析 ,这一选项可以消除 MySQL 进行DNS解析时间，开启该选项，所有远程主机连接授权都要使用 IP。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">back_log=512</span><br></pre></td></tr></table></figure>\n<p>指出在 MySQL 暂停响应之前，有多少个请求被存在堆栈中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">key_buffer_size</span><br></pre></td></tr></table></figure>\n<p>指定用于索引的缓冲区大小，增加它可得到更好的索引处理能力，对于内存 4G 左右，可设置为 256MB。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">max_allowed_packet=4M</span><br></pre></td></tr></table></figure>\n<p>设定在一次网络传输中的最大值。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">thread_stack=256k</span><br></pre></td></tr></table></figure>\n<p>设置每个线程的堆栈大小，可满足普通操作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">table_cache=614k</span><br></pre></td></tr></table></figure>\n<p>高速缓冲区的大小，当mysql访问一个表示，缓冲区还有空间，那么这个表就会被放入缓冲区，一般看峰值时间状态值，open_tables与open_cache，用于判断是否需要增加table_cache，如果open_Table接近table_cache就要增加了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sort_buffer_size=6M</span><br></pre></td></tr></table></figure>\n<p>设定查询排序所用的缓冲区大小，是对每个链接而言，如果有100个连接，那么分配的总缓存是100*6=600M。<br>read_buffer_size,join_buffer_size 都是对单个链接而言。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">thread_cache_size=64</span><br></pre></td></tr></table></figure>\n<p>设置缓存中的链接线程的最大数量,4GB内存以上的我们会给64或者更大。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">query_cache_size=64M</span><br></pre></td></tr></table></figure>\n<p>如果该值比较小反而会影响效率，可以考虑不用。如果太大，缓存区中碎片会很多。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tmp_table_size</span><br></pre></td></tr></table></figure>\n<p>设置内存临时表的最大值，如果超过改制，就会将临时表写入磁盘，范围是1kB-4GB。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">max_connection</span><br></pre></td></tr></table></figure>\n<p>如果超过该值，会出现<code>too many connections</code>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">max_connect_errors</span><br></pre></td></tr></table></figure>\n<p>设置每个主机中连接请求异常中断最大次数，如果超过，MySQL禁止host连接请求，直到MySQL重启。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wait_timeout = 120</span><br></pre></td></tr></table></figure>\n<p>一个请求的最大链接时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">thread_concurrency=8</span><br></pre></td></tr></table></figure>\n<p>该参数为服务器逻辑CPU * 2。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">skip-networking</span><br></pre></td></tr></table></figure>\n<p>该选项可以关闭连接方式，如果需要远程连接，不要开启。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_flush_log_at_trx_commit = 1</span><br></pre></td></tr></table></figure>\n<p>设置为0就是等到 innodb_log_buffer_size 队列满了之后再统一存储，默认是1，是最安全的设置。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_thread_concurrency = 8</span><br></pre></td></tr></table></figure>\n<p>服务器几个CPU就设置多少。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">read_rnd_buffer_Size = 16M</span><br></pre></td></tr></table></figure>\n<p>设置随机读的使用的缓冲区。</p>\n<h3 id=\"第二节\">innodb_buffer_pool 的合理设置</h3>\n\n<p>不要武断的把innodb_buffer pool 配置为内存的50-80% 应具体而定。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show status like &apos;innodb_buffer_pool_%&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">关注的有</span><br><span class=\"line\">innodb_buffer_pool_pages_data;</span><br><span class=\"line\">innodb_buffer_pool_page_total;</span><br><span class=\"line\">innodb_buffer_pool_read_request;</span><br><span class=\"line\">innodb_buffer_pool_reads;</span><br></pre></td></tr></table></figure>\n<p>然后看</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">读命中率 (innodb_buffer_pool_read_request - innodb_buffer_pool_reads) / innodb_buffer_pool_read_request;</span><br><span class=\"line\">写命中率 innodb_buffer_pool_pages_data /innodb_buffer_pool_page_total;</span><br></pre></td></tr></table></figure>\n<p>如果读写命中率都能在95%以上就很好了。</p>\n<h3 id=\"第三节\">文件打开数的合理设置依据</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show global status like &apos;open_files&apos;</span><br><span class=\"line\">show variables like &apos;open_file_limit&apos;;</span><br></pre></td></tr></table></figure>\n<p>比较合适的设置是 Open_files / open_files_limit * 100% &lt;= 75;</p>\n<h3 id=\"第四节\">打开表优化设置依据</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show global status like &apos;open%tables&apos;;</span><br><span class=\"line\">show variable like &apos;table_cache&apos;;</span><br></pre></td></tr></table></figure>\n<p>比较合适</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">open_tables / opende_tables * 100 &gt; 85%;</span><br><span class=\"line\">open_Tables / table_Cache* 100% &lt; 95%；</span><br></pre></td></tr></table></figure>\n<h3 id=\"第五节\">临时表的设置依据</h3>\n\n<p>每次执行语句，关于已经被创造了的临时表的数量，可以这么设置:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show gloabl status like &apos;created_tmp5&apos;;</span><br><span class=\"line\">Created_tmp_disk_table / Created_tmp_tables * 100% &lt;= 25 %</span><br></pre></td></tr></table></figure>\n<h3 id=\"第六节\">查看索引命中率</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show global status like &apos;key_read%&apos;;</span><br></pre></td></tr></table></figure>\n<p>key_cache_miss_rate = key_Read / key_read_request * 100% 小于 1% 是很好的，<br>意味着1000个请求有一个直接读硬盘。</p>\n"},{"layout":"post","title":"记录错误登陆的 btmp 文件","date":"2015-07-24T15:06:00.000Z","comments":1,"description":"linux","_content":"\n今天查看了服务器时，发现 `/var/log/btmp` 日志文件较大。\n\n此文件是记录错误登录的日志， 文件较大意味着有人使用密码字典登录ssh服务，\n这个文件是需要用 `lastb` 命令才可读的。\n\n查看尝试恶意登陆的前十个IP\n\n```\nsudo lastb | awk '{ print $3}' | awk '{++S[$NF]} END {for(a in S) print a, S[a]}' | sort -rk2 |head\n```\n\n如果有有必要封阻IP的话，可以执行：\n\n```\niptables -A INPUT -i eth0 -s *.*.*.0/24 -j DROP\n```\n","source":"_posts/2015-07-24-ji-lu-cuo-wu-deng-lu-de-btmpwen-jian.markdown","raw":"---\nlayout: post\ntitle: \"记录错误登陆的 btmp 文件\"\ndate: 2015-07-24 23:06\ncomments: true\ncategories: System\ndescription: linux\n---\n\n今天查看了服务器时，发现 `/var/log/btmp` 日志文件较大。\n\n此文件是记录错误登录的日志， 文件较大意味着有人使用密码字典登录ssh服务，\n这个文件是需要用 `lastb` 命令才可读的。\n\n查看尝试恶意登陆的前十个IP\n\n```\nsudo lastb | awk '{ print $3}' | awk '{++S[$NF]} END {for(a in S) print a, S[a]}' | sort -rk2 |head\n```\n\n如果有有必要封阻IP的话，可以执行：\n\n```\niptables -A INPUT -i eth0 -s *.*.*.0/24 -j DROP\n```\n","slug":"2015-07-24-ji-lu-cuo-wu-deng-lu-de-btmpwen-jian","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgda1003onctjf8yz2i1l","content":"<p>今天查看了服务器时，发现 <code>/var/log/btmp</code> 日志文件较大。</p>\n<p>此文件是记录错误登录的日志， 文件较大意味着有人使用密码字典登录ssh服务，<br>这个文件是需要用 <code>lastb</code> 命令才可读的。</p>\n<p>查看尝试恶意登陆的前十个IP</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lastb | awk &apos;&#123; print $3&#125;&apos; | awk &apos;&#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos; | sort -rk2 |head</span><br></pre></td></tr></table></figure>\n<p>如果有有必要封阻IP的话，可以执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iptables -A INPUT -i eth0 -s *.*.*.0/24 -j DROP</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>今天查看了服务器时，发现 <code>/var/log/btmp</code> 日志文件较大。</p>\n<p>此文件是记录错误登录的日志， 文件较大意味着有人使用密码字典登录ssh服务，<br>这个文件是需要用 <code>lastb</code> 命令才可读的。</p>\n<p>查看尝试恶意登陆的前十个IP</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo lastb | awk &apos;&#123; print $3&#125;&apos; | awk &apos;&#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos; | sort -rk2 |head</span><br></pre></td></tr></table></figure>\n<p>如果有有必要封阻IP的话，可以执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iptables -A INPUT -i eth0 -s *.*.*.0/24 -j DROP</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"黑客马拉松","date":"2015-08-10T14:24:00.000Z","comments":1,"_content":"\n周末参加了公司组织的黑客马拉松比赛, \n    \n通宵达旦完成了作品是个值得纪念的经历, 我们的产品叫做：[正义的朋友](http://pact.im) \n\n* 我们想要实现的功能是让人在紧急关头用最快速的方式联系到可以帮助你的人，于是我们通过锁屏应用来实现; \n* 用户在锁屏状态，画一个v手势，会把自己的地理位置发送给设置好的联系人，并持续每十秒发送一次周围的声音给联系人；\n* 用户在锁屏状态，画一个w手势，会发出专业的求救声\n\n这次比赛的感觉, 与当年`叫神马`团队的似曾相识, 队友非常给力, 大家都很拼, 我喜欢这种感觉, 事实上，在比赛之前，为了工作上的项目我已经几乎透支了, 队友也是一样。 但周六上午我们还是快速进入状态, 被逼的潜力果然不容小觑.  晒一张我们队伍合照.\n\n{% img /images/2015/08/teammate.png %}\n\n","source":"_posts/2015-08-10-hackthon.markdown","raw":"---\nlayout: post\ntitle: \"黑客马拉松\"\ndate: 2015-08-10 22:24\ncomments: true\ncategories: Product\n---\n\n周末参加了公司组织的黑客马拉松比赛, \n    \n通宵达旦完成了作品是个值得纪念的经历, 我们的产品叫做：[正义的朋友](http://pact.im) \n\n* 我们想要实现的功能是让人在紧急关头用最快速的方式联系到可以帮助你的人，于是我们通过锁屏应用来实现; \n* 用户在锁屏状态，画一个v手势，会把自己的地理位置发送给设置好的联系人，并持续每十秒发送一次周围的声音给联系人；\n* 用户在锁屏状态，画一个w手势，会发出专业的求救声\n\n这次比赛的感觉, 与当年`叫神马`团队的似曾相识, 队友非常给力, 大家都很拼, 我喜欢这种感觉, 事实上，在比赛之前，为了工作上的项目我已经几乎透支了, 队友也是一样。 但周六上午我们还是快速进入状态, 被逼的潜力果然不容小觑.  晒一张我们队伍合照.\n\n{% img /images/2015/08/teammate.png %}\n\n","slug":"2015-08-10-hackthon","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgda1003qnctjt0oebs1m","content":"<p>周末参加了公司组织的黑客马拉松比赛, </p>\n<p>通宵达旦完成了作品是个值得纪念的经历, 我们的产品叫做：<a href=\"http://pact.im\" target=\"_blank\" rel=\"noopener\">正义的朋友</a> </p>\n<ul>\n<li>我们想要实现的功能是让人在紧急关头用最快速的方式联系到可以帮助你的人，于是我们通过锁屏应用来实现; </li>\n<li>用户在锁屏状态，画一个v手势，会把自己的地理位置发送给设置好的联系人，并持续每十秒发送一次周围的声音给联系人；</li>\n<li>用户在锁屏状态，画一个w手势，会发出专业的求救声</li>\n</ul>\n<p>这次比赛的感觉, 与当年<code>叫神马</code>团队的似曾相识, 队友非常给力, 大家都很拼, 我喜欢这种感觉, 事实上，在比赛之前，为了工作上的项目我已经几乎透支了, 队友也是一样。 但周六上午我们还是快速进入状态, 被逼的潜力果然不容小觑.  晒一张我们队伍合照.</p>\n<img src=\"/images/2015/08/teammate.png\">\n","site":{"data":{}},"excerpt":"","more":"<p>周末参加了公司组织的黑客马拉松比赛, </p>\n<p>通宵达旦完成了作品是个值得纪念的经历, 我们的产品叫做：<a href=\"http://pact.im\" target=\"_blank\" rel=\"noopener\">正义的朋友</a> </p>\n<ul>\n<li>我们想要实现的功能是让人在紧急关头用最快速的方式联系到可以帮助你的人，于是我们通过锁屏应用来实现; </li>\n<li>用户在锁屏状态，画一个v手势，会把自己的地理位置发送给设置好的联系人，并持续每十秒发送一次周围的声音给联系人；</li>\n<li>用户在锁屏状态，画一个w手势，会发出专业的求救声</li>\n</ul>\n<p>这次比赛的感觉, 与当年<code>叫神马</code>团队的似曾相识, 队友非常给力, 大家都很拼, 我喜欢这种感觉, 事实上，在比赛之前，为了工作上的项目我已经几乎透支了, 队友也是一样。 但周六上午我们还是快速进入状态, 被逼的潜力果然不容小觑.  晒一张我们队伍合照.</p>\n<img src=\"/images/2015/08/teammate.png\">\n"},{"layout":"post","title":"Twemproxy 一个 Redis 代理","date":"2015-08-16T04:11:00.000Z","comments":1,"description":"redis proxy twemproxy","_content":"\n为解决线上 Redis 服务直连出现链接数爆棚而做的调研， 对 Twitter 开源的 twemproxy 做一些记录。 我们之所以放弃官方的 RedisCLuster 是因为不太满意其性能\n\n: [初窥原理](#第一节)\n* [安装与配置](#第二节)\n* [不支持的操作](#第三节)\n* [压力测试](#第四节)\n* [摘自极光博客的评论](#第五节)\n\n<h3 id=\"第一节\">初窥原理</h3>\n\n* Twitter 出品的轻量级 Redis，memcached 代理，使用它可以减少缓存服务器的连接数，并且利用它来作分片。\n* 作是说最差情况下，性能损耗不会多于20%。背后是用了pipeline，redis是支持使用pipeline批处理的。\n* twemproxy 与每个 redis 服务器都会建立一个连接，每个连接实现了两个 FIFO 的队列， 通过这两个队列实现对 redis 的 pipeline 访问，将多个客户端的访问合并到一个连接，这样既减少了redis服务器的连接数，又提高了访问性能。\n\n<h3 id=\"第二节\">安装与配置</h3>\n\n* 安装\n\n```\napt-get install automake\napt-get install libtool\ngit clone git://github.com/twitter/twemproxy.git\ncd twemproxy\nautoreconf -fvi\n./configure\nmake\nsudo make install\n```\n默认的可执行文件在 /usr/local/sbin/nutcracker\n\n* 配置文件 /etc/nutcracker/nutcracker.yml\n\n```\nalpha:\n    listen: 127.0.0.1:8877\n    hash: fnv1a_64\n    distribution: ketama\n    auto_eject_hosts: true\n    redis: true\n    server_retry_timeout: 30000\n    server_failure_limit: 3\n    servers:\n        - 127.0.0.1:6379:1 master0  #后端的redis-server\n        - 127.0.0.1:6380:1 master1\n```\n\n当 redis 做缓存的使用的时候应该启用 auto_eject_hosts， 如果某个节点失败的时候将该节点删除，虽然丧失了数据的一致性，但作为缓存使用，保证了这个集群的高可用性。当redis做存储的使用时为了保持数据的一致性，应该禁用 auto_eject_hosts,也就是当某个节点失败之后并不删除该节点。\n\n<h3 id=\"第三节\">不支持的操作</h3>\n\n```\nkeys command: keys,migrate,move object,randomkey,rename,renamenx,\nsort strings command: bitop,mset,msetnx\nlist command: blpop,brpop,brpoplpush\nscripting command: script exists,script flush,script kill,script load\npub/sub command:(全部不支持)psubscribe,publish,punsubscribe,subscribe,unsubscribe\n```\n\n<h3 id=\"第四节\">压测</h3>\n\n感谢 redis 提供的 redis-benchmark 工具，用它来做压测挺好的。\n\n* n 表示多少个连接\n* r 表示多少个 key,\n* t 代表命令\n\n```\nzj@zheng-ji.info:~$ redis-benchmark -p 6700 -t smembers,hexists,get,hget,lrange,ltrim,zcard,setex,sadd -n 1000000 -r 100000000\n\n====== GET ======\n1000000 requests completed in 12.95 seconds\n50 parallel clients\n3 bytes payload\nkeep alive: 1\n\n99.19% <= 1 milliseconds\n99.93% <= 2 milliseconds\n100.00% <= 2 milliseconds\n77220.08 requests per second\n\n====== SADD ======\n1000000 requests completed in 10.74 seconds\n50 parallel clients\n3 bytes payload\nkeep alive: 1\n\n99.88% <= 1 milliseconds\n99.95% <= 2 milliseconds\n99.97% <= 3 milliseconds\n99.99% <= 4 milliseconds\n100.00% <= 4 milliseconds\n93144.56 requests per second\n```\n\n如作者所言, 性能几乎可以跟直连redis比拟，背后的数据也很均匀,使用twemproxy 观察连接数, 一直都保持在个位数左右。\n\n\n<h3 id=\"第五节\">摘自极光博客的评论</h3>\n\n* 前端使用 Twemproxy 做代理，后端的 Redis 数据能基本上根据 key 来进行比较均衡的分布。\n* 后端一台 Redis 挂掉后，Twemproxy 能够自动摘除。恢复后，Twemproxy 能够自动识别、恢复并重新加入到 Redis 组中重新使用。\n* Redis 挂掉后，后端数据是否丢失依据 Redis 本身的策略配置，与 Twemproxy 基本无关。\n* 如果要新增加一台 Redis，Twemproxy 需要重启才能生效；并且数据不会自动重新 Reblance，需要人工单独写脚本来实现。\n* 如同时部署多个 Twemproxy，配置文件一致（测试配置为distribution：ketama,modula），则可以从任意一个读取，都可以正确读取 key对应的值。\n* 多台 Twemproxy 配置一样，客户端分别连接多台 Twemproxy可以在一定条件下提高性能。根据 Server 数量，提高比例在 110-150%之间。\n* 如原来已经有 2 个节点 Redis，后续有增加 2 个 Redis，则数据分布计算与原来的 Redis 分布无关，现有数据如果需要分布均匀的话，需要人工单独处理。\n* 如果 Twemproxy 的后端节点数量发生变化，Twemproxy 相同算法的前提下，原来的数据必须重新处理分布，否则会存在找不到key值的情况。\n\n------\n\n\n参考链接\n\n[极光推送的博客](http://blog.jpush.cn/redis-twemproxy-benchmark/)\n","source":"_posts/2015-08-16-twemproxy.markdown","raw":"---\nlayout: post\ntitle: \"Twemproxy 一个 Redis 代理\"\ndate: 2015-08-16 12:11\ncomments: true\ncategories: Server\ndescription: redis proxy twemproxy \n---\n\n为解决线上 Redis 服务直连出现链接数爆棚而做的调研， 对 Twitter 开源的 twemproxy 做一些记录。 我们之所以放弃官方的 RedisCLuster 是因为不太满意其性能\n\n: [初窥原理](#第一节)\n* [安装与配置](#第二节)\n* [不支持的操作](#第三节)\n* [压力测试](#第四节)\n* [摘自极光博客的评论](#第五节)\n\n<h3 id=\"第一节\">初窥原理</h3>\n\n* Twitter 出品的轻量级 Redis，memcached 代理，使用它可以减少缓存服务器的连接数，并且利用它来作分片。\n* 作是说最差情况下，性能损耗不会多于20%。背后是用了pipeline，redis是支持使用pipeline批处理的。\n* twemproxy 与每个 redis 服务器都会建立一个连接，每个连接实现了两个 FIFO 的队列， 通过这两个队列实现对 redis 的 pipeline 访问，将多个客户端的访问合并到一个连接，这样既减少了redis服务器的连接数，又提高了访问性能。\n\n<h3 id=\"第二节\">安装与配置</h3>\n\n* 安装\n\n```\napt-get install automake\napt-get install libtool\ngit clone git://github.com/twitter/twemproxy.git\ncd twemproxy\nautoreconf -fvi\n./configure\nmake\nsudo make install\n```\n默认的可执行文件在 /usr/local/sbin/nutcracker\n\n* 配置文件 /etc/nutcracker/nutcracker.yml\n\n```\nalpha:\n    listen: 127.0.0.1:8877\n    hash: fnv1a_64\n    distribution: ketama\n    auto_eject_hosts: true\n    redis: true\n    server_retry_timeout: 30000\n    server_failure_limit: 3\n    servers:\n        - 127.0.0.1:6379:1 master0  #后端的redis-server\n        - 127.0.0.1:6380:1 master1\n```\n\n当 redis 做缓存的使用的时候应该启用 auto_eject_hosts， 如果某个节点失败的时候将该节点删除，虽然丧失了数据的一致性，但作为缓存使用，保证了这个集群的高可用性。当redis做存储的使用时为了保持数据的一致性，应该禁用 auto_eject_hosts,也就是当某个节点失败之后并不删除该节点。\n\n<h3 id=\"第三节\">不支持的操作</h3>\n\n```\nkeys command: keys,migrate,move object,randomkey,rename,renamenx,\nsort strings command: bitop,mset,msetnx\nlist command: blpop,brpop,brpoplpush\nscripting command: script exists,script flush,script kill,script load\npub/sub command:(全部不支持)psubscribe,publish,punsubscribe,subscribe,unsubscribe\n```\n\n<h3 id=\"第四节\">压测</h3>\n\n感谢 redis 提供的 redis-benchmark 工具，用它来做压测挺好的。\n\n* n 表示多少个连接\n* r 表示多少个 key,\n* t 代表命令\n\n```\nzj@zheng-ji.info:~$ redis-benchmark -p 6700 -t smembers,hexists,get,hget,lrange,ltrim,zcard,setex,sadd -n 1000000 -r 100000000\n\n====== GET ======\n1000000 requests completed in 12.95 seconds\n50 parallel clients\n3 bytes payload\nkeep alive: 1\n\n99.19% <= 1 milliseconds\n99.93% <= 2 milliseconds\n100.00% <= 2 milliseconds\n77220.08 requests per second\n\n====== SADD ======\n1000000 requests completed in 10.74 seconds\n50 parallel clients\n3 bytes payload\nkeep alive: 1\n\n99.88% <= 1 milliseconds\n99.95% <= 2 milliseconds\n99.97% <= 3 milliseconds\n99.99% <= 4 milliseconds\n100.00% <= 4 milliseconds\n93144.56 requests per second\n```\n\n如作者所言, 性能几乎可以跟直连redis比拟，背后的数据也很均匀,使用twemproxy 观察连接数, 一直都保持在个位数左右。\n\n\n<h3 id=\"第五节\">摘自极光博客的评论</h3>\n\n* 前端使用 Twemproxy 做代理，后端的 Redis 数据能基本上根据 key 来进行比较均衡的分布。\n* 后端一台 Redis 挂掉后，Twemproxy 能够自动摘除。恢复后，Twemproxy 能够自动识别、恢复并重新加入到 Redis 组中重新使用。\n* Redis 挂掉后，后端数据是否丢失依据 Redis 本身的策略配置，与 Twemproxy 基本无关。\n* 如果要新增加一台 Redis，Twemproxy 需要重启才能生效；并且数据不会自动重新 Reblance，需要人工单独写脚本来实现。\n* 如同时部署多个 Twemproxy，配置文件一致（测试配置为distribution：ketama,modula），则可以从任意一个读取，都可以正确读取 key对应的值。\n* 多台 Twemproxy 配置一样，客户端分别连接多台 Twemproxy可以在一定条件下提高性能。根据 Server 数量，提高比例在 110-150%之间。\n* 如原来已经有 2 个节点 Redis，后续有增加 2 个 Redis，则数据分布计算与原来的 Redis 分布无关，现有数据如果需要分布均匀的话，需要人工单独处理。\n* 如果 Twemproxy 的后端节点数量发生变化，Twemproxy 相同算法的前提下，原来的数据必须重新处理分布，否则会存在找不到key值的情况。\n\n------\n\n\n参考链接\n\n[极光推送的博客](http://blog.jpush.cn/redis-twemproxy-benchmark/)\n","slug":"2015-08-16-twemproxy","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgda2003snctj8xc2z3ll","content":"<p>为解决线上 Redis 服务直连出现链接数爆棚而做的调研， 对 Twitter 开源的 twemproxy 做一些记录。 我们之所以放弃官方的 RedisCLuster 是因为不太满意其性能</p>\n<p>: <a href=\"#第一节\">初窥原理</a></p>\n<ul>\n<li><a href=\"#第二节\">安装与配置</a></li>\n<li><a href=\"#第三节\">不支持的操作</a></li>\n<li><a href=\"#第四节\">压力测试</a></li>\n<li><a href=\"#第五节\">摘自极光博客的评论</a></li>\n</ul>\n<h3 id=\"第一节\">初窥原理</h3>\n\n<ul>\n<li>Twitter 出品的轻量级 Redis，memcached 代理，使用它可以减少缓存服务器的连接数，并且利用它来作分片。</li>\n<li>作是说最差情况下，性能损耗不会多于20%。背后是用了pipeline，redis是支持使用pipeline批处理的。</li>\n<li>twemproxy 与每个 redis 服务器都会建立一个连接，每个连接实现了两个 FIFO 的队列， 通过这两个队列实现对 redis 的 pipeline 访问，将多个客户端的访问合并到一个连接，这样既减少了redis服务器的连接数，又提高了访问性能。</li>\n</ul>\n<h3 id=\"第二节\">安装与配置</h3>\n\n<ul>\n<li>安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get install automake</span><br><span class=\"line\">apt-get install libtool</span><br><span class=\"line\">git clone git://github.com/twitter/twemproxy.git</span><br><span class=\"line\">cd twemproxy</span><br><span class=\"line\">autoreconf -fvi</span><br><span class=\"line\">./configure</span><br><span class=\"line\">make</span><br><span class=\"line\">sudo make install</span><br></pre></td></tr></table></figure>\n<p>默认的可执行文件在 /usr/local/sbin/nutcracker</p>\n<ul>\n<li>配置文件 /etc/nutcracker/nutcracker.yml</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alpha:</span><br><span class=\"line\">    listen: 127.0.0.1:8877</span><br><span class=\"line\">    hash: fnv1a_64</span><br><span class=\"line\">    distribution: ketama</span><br><span class=\"line\">    auto_eject_hosts: true</span><br><span class=\"line\">    redis: true</span><br><span class=\"line\">    server_retry_timeout: 30000</span><br><span class=\"line\">    server_failure_limit: 3</span><br><span class=\"line\">    servers:</span><br><span class=\"line\">        - 127.0.0.1:6379:1 master0  #后端的redis-server</span><br><span class=\"line\">        - 127.0.0.1:6380:1 master1</span><br></pre></td></tr></table></figure>\n<p>当 redis 做缓存的使用的时候应该启用 auto_eject_hosts， 如果某个节点失败的时候将该节点删除，虽然丧失了数据的一致性，但作为缓存使用，保证了这个集群的高可用性。当redis做存储的使用时为了保持数据的一致性，应该禁用 auto_eject_hosts,也就是当某个节点失败之后并不删除该节点。</p>\n<h3 id=\"第三节\">不支持的操作</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keys command: keys,migrate,move object,randomkey,rename,renamenx,</span><br><span class=\"line\">sort strings command: bitop,mset,msetnx</span><br><span class=\"line\">list command: blpop,brpop,brpoplpush</span><br><span class=\"line\">scripting command: script exists,script flush,script kill,script load</span><br><span class=\"line\">pub/sub command:(全部不支持)psubscribe,publish,punsubscribe,subscribe,unsubscribe</span><br></pre></td></tr></table></figure>\n<h3 id=\"第四节\">压测</h3>\n\n<p>感谢 redis 提供的 redis-benchmark 工具，用它来做压测挺好的。</p>\n<ul>\n<li>n 表示多少个连接</li>\n<li>r 表示多少个 key,</li>\n<li>t 代表命令</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji.info:~$ redis-benchmark -p 6700 -t smembers,hexists,get,hget,lrange,ltrim,zcard,setex,sadd -n 1000000 -r 100000000</span><br><span class=\"line\"></span><br><span class=\"line\">====== GET ======</span><br><span class=\"line\">1000000 requests completed in 12.95 seconds</span><br><span class=\"line\">50 parallel clients</span><br><span class=\"line\">3 bytes payload</span><br><span class=\"line\">keep alive: 1</span><br><span class=\"line\"></span><br><span class=\"line\">99.19% &lt;= 1 milliseconds</span><br><span class=\"line\">99.93% &lt;= 2 milliseconds</span><br><span class=\"line\">100.00% &lt;= 2 milliseconds</span><br><span class=\"line\">77220.08 requests per second</span><br><span class=\"line\"></span><br><span class=\"line\">====== SADD ======</span><br><span class=\"line\">1000000 requests completed in 10.74 seconds</span><br><span class=\"line\">50 parallel clients</span><br><span class=\"line\">3 bytes payload</span><br><span class=\"line\">keep alive: 1</span><br><span class=\"line\"></span><br><span class=\"line\">99.88% &lt;= 1 milliseconds</span><br><span class=\"line\">99.95% &lt;= 2 milliseconds</span><br><span class=\"line\">99.97% &lt;= 3 milliseconds</span><br><span class=\"line\">99.99% &lt;= 4 milliseconds</span><br><span class=\"line\">100.00% &lt;= 4 milliseconds</span><br><span class=\"line\">93144.56 requests per second</span><br></pre></td></tr></table></figure>\n<p>如作者所言, 性能几乎可以跟直连redis比拟，背后的数据也很均匀,使用twemproxy 观察连接数, 一直都保持在个位数左右。</p>\n<h3 id=\"第五节\">摘自极光博客的评论</h3>\n\n<ul>\n<li>前端使用 Twemproxy 做代理，后端的 Redis 数据能基本上根据 key 来进行比较均衡的分布。</li>\n<li>后端一台 Redis 挂掉后，Twemproxy 能够自动摘除。恢复后，Twemproxy 能够自动识别、恢复并重新加入到 Redis 组中重新使用。</li>\n<li>Redis 挂掉后，后端数据是否丢失依据 Redis 本身的策略配置，与 Twemproxy 基本无关。</li>\n<li>如果要新增加一台 Redis，Twemproxy 需要重启才能生效；并且数据不会自动重新 Reblance，需要人工单独写脚本来实现。</li>\n<li>如同时部署多个 Twemproxy，配置文件一致（测试配置为distribution：ketama,modula），则可以从任意一个读取，都可以正确读取 key对应的值。</li>\n<li>多台 Twemproxy 配置一样，客户端分别连接多台 Twemproxy可以在一定条件下提高性能。根据 Server 数量，提高比例在 110-150%之间。</li>\n<li>如原来已经有 2 个节点 Redis，后续有增加 2 个 Redis，则数据分布计算与原来的 Redis 分布无关，现有数据如果需要分布均匀的话，需要人工单独处理。</li>\n<li>如果 Twemproxy 的后端节点数量发生变化，Twemproxy 相同算法的前提下，原来的数据必须重新处理分布，否则会存在找不到key值的情况。</li>\n</ul>\n<hr>\n<p>参考链接</p>\n<p><a href=\"http://blog.jpush.cn/redis-twemproxy-benchmark/\" target=\"_blank\" rel=\"noopener\">极光推送的博客</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>为解决线上 Redis 服务直连出现链接数爆棚而做的调研， 对 Twitter 开源的 twemproxy 做一些记录。 我们之所以放弃官方的 RedisCLuster 是因为不太满意其性能</p>\n<p>: <a href=\"#第一节\">初窥原理</a></p>\n<ul>\n<li><a href=\"#第二节\">安装与配置</a></li>\n<li><a href=\"#第三节\">不支持的操作</a></li>\n<li><a href=\"#第四节\">压力测试</a></li>\n<li><a href=\"#第五节\">摘自极光博客的评论</a></li>\n</ul>\n<h3 id=\"第一节\">初窥原理</h3>\n\n<ul>\n<li>Twitter 出品的轻量级 Redis，memcached 代理，使用它可以减少缓存服务器的连接数，并且利用它来作分片。</li>\n<li>作是说最差情况下，性能损耗不会多于20%。背后是用了pipeline，redis是支持使用pipeline批处理的。</li>\n<li>twemproxy 与每个 redis 服务器都会建立一个连接，每个连接实现了两个 FIFO 的队列， 通过这两个队列实现对 redis 的 pipeline 访问，将多个客户端的访问合并到一个连接，这样既减少了redis服务器的连接数，又提高了访问性能。</li>\n</ul>\n<h3 id=\"第二节\">安装与配置</h3>\n\n<ul>\n<li>安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get install automake</span><br><span class=\"line\">apt-get install libtool</span><br><span class=\"line\">git clone git://github.com/twitter/twemproxy.git</span><br><span class=\"line\">cd twemproxy</span><br><span class=\"line\">autoreconf -fvi</span><br><span class=\"line\">./configure</span><br><span class=\"line\">make</span><br><span class=\"line\">sudo make install</span><br></pre></td></tr></table></figure>\n<p>默认的可执行文件在 /usr/local/sbin/nutcracker</p>\n<ul>\n<li>配置文件 /etc/nutcracker/nutcracker.yml</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alpha:</span><br><span class=\"line\">    listen: 127.0.0.1:8877</span><br><span class=\"line\">    hash: fnv1a_64</span><br><span class=\"line\">    distribution: ketama</span><br><span class=\"line\">    auto_eject_hosts: true</span><br><span class=\"line\">    redis: true</span><br><span class=\"line\">    server_retry_timeout: 30000</span><br><span class=\"line\">    server_failure_limit: 3</span><br><span class=\"line\">    servers:</span><br><span class=\"line\">        - 127.0.0.1:6379:1 master0  #后端的redis-server</span><br><span class=\"line\">        - 127.0.0.1:6380:1 master1</span><br></pre></td></tr></table></figure>\n<p>当 redis 做缓存的使用的时候应该启用 auto_eject_hosts， 如果某个节点失败的时候将该节点删除，虽然丧失了数据的一致性，但作为缓存使用，保证了这个集群的高可用性。当redis做存储的使用时为了保持数据的一致性，应该禁用 auto_eject_hosts,也就是当某个节点失败之后并不删除该节点。</p>\n<h3 id=\"第三节\">不支持的操作</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keys command: keys,migrate,move object,randomkey,rename,renamenx,</span><br><span class=\"line\">sort strings command: bitop,mset,msetnx</span><br><span class=\"line\">list command: blpop,brpop,brpoplpush</span><br><span class=\"line\">scripting command: script exists,script flush,script kill,script load</span><br><span class=\"line\">pub/sub command:(全部不支持)psubscribe,publish,punsubscribe,subscribe,unsubscribe</span><br></pre></td></tr></table></figure>\n<h3 id=\"第四节\">压测</h3>\n\n<p>感谢 redis 提供的 redis-benchmark 工具，用它来做压测挺好的。</p>\n<ul>\n<li>n 表示多少个连接</li>\n<li>r 表示多少个 key,</li>\n<li>t 代表命令</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zheng-ji.info:~$ redis-benchmark -p 6700 -t smembers,hexists,get,hget,lrange,ltrim,zcard,setex,sadd -n 1000000 -r 100000000</span><br><span class=\"line\"></span><br><span class=\"line\">====== GET ======</span><br><span class=\"line\">1000000 requests completed in 12.95 seconds</span><br><span class=\"line\">50 parallel clients</span><br><span class=\"line\">3 bytes payload</span><br><span class=\"line\">keep alive: 1</span><br><span class=\"line\"></span><br><span class=\"line\">99.19% &lt;= 1 milliseconds</span><br><span class=\"line\">99.93% &lt;= 2 milliseconds</span><br><span class=\"line\">100.00% &lt;= 2 milliseconds</span><br><span class=\"line\">77220.08 requests per second</span><br><span class=\"line\"></span><br><span class=\"line\">====== SADD ======</span><br><span class=\"line\">1000000 requests completed in 10.74 seconds</span><br><span class=\"line\">50 parallel clients</span><br><span class=\"line\">3 bytes payload</span><br><span class=\"line\">keep alive: 1</span><br><span class=\"line\"></span><br><span class=\"line\">99.88% &lt;= 1 milliseconds</span><br><span class=\"line\">99.95% &lt;= 2 milliseconds</span><br><span class=\"line\">99.97% &lt;= 3 milliseconds</span><br><span class=\"line\">99.99% &lt;= 4 milliseconds</span><br><span class=\"line\">100.00% &lt;= 4 milliseconds</span><br><span class=\"line\">93144.56 requests per second</span><br></pre></td></tr></table></figure>\n<p>如作者所言, 性能几乎可以跟直连redis比拟，背后的数据也很均匀,使用twemproxy 观察连接数, 一直都保持在个位数左右。</p>\n<h3 id=\"第五节\">摘自极光博客的评论</h3>\n\n<ul>\n<li>前端使用 Twemproxy 做代理，后端的 Redis 数据能基本上根据 key 来进行比较均衡的分布。</li>\n<li>后端一台 Redis 挂掉后，Twemproxy 能够自动摘除。恢复后，Twemproxy 能够自动识别、恢复并重新加入到 Redis 组中重新使用。</li>\n<li>Redis 挂掉后，后端数据是否丢失依据 Redis 本身的策略配置，与 Twemproxy 基本无关。</li>\n<li>如果要新增加一台 Redis，Twemproxy 需要重启才能生效；并且数据不会自动重新 Reblance，需要人工单独写脚本来实现。</li>\n<li>如同时部署多个 Twemproxy，配置文件一致（测试配置为distribution：ketama,modula），则可以从任意一个读取，都可以正确读取 key对应的值。</li>\n<li>多台 Twemproxy 配置一样，客户端分别连接多台 Twemproxy可以在一定条件下提高性能。根据 Server 数量，提高比例在 110-150%之间。</li>\n<li>如原来已经有 2 个节点 Redis，后续有增加 2 个 Redis，则数据分布计算与原来的 Redis 分布无关，现有数据如果需要分布均匀的话，需要人工单独处理。</li>\n<li>如果 Twemproxy 的后端节点数量发生变化，Twemproxy 相同算法的前提下，原来的数据必须重新处理分布，否则会存在找不到key值的情况。</li>\n</ul>\n<hr>\n<p>参考链接</p>\n<p><a href=\"http://blog.jpush.cn/redis-twemproxy-benchmark/\" target=\"_blank\" rel=\"noopener\">极光推送的博客</a></p>\n"},{"layout":"post","title":"Supervisor 监听器","date":"2015-08-21T08:36:00.000Z","comments":1,"description":"supervisor 监控","_content":"\n我们服务多是用 supervisor 启动的， 但监控多数是用 `monit`, 如果我们能通过监测 supervisor 事件变化来做监控，就可以写一套通用的监控程序。\n\n庆幸的是，supervisor 的 `eventListener` 支持我的设想。\n\n这个监控程序需要用 supervisor 启动，类型不再是`program`, 而是`eventlistener`，这里有几个比较耗时的地方需要记录下。\n\n* supervisor 有独特的通信协议,需要遵循，否则通讯不会被触发\n\n```\ndef write_stdout(self, s):\n    sys.stdout.write(s)\n    sys.stdout.flush()\n\nwrite_stdout('READY\\n') //类似开始握手\nwrite_stdout('RESULT 2\\nOK') //结束通讯\n```\n\n* 需要从标准输入端读取事件,而且他是个阻塞的事件模型\n\n```\nwhile 1:\n    self.write_stdout('READY\\n')\n    line = sys.stdin.readline()\n    do_some_thing()\n    self.write_stdout('RESULT 2\\nOK')\n```\n\n* supervisor 配置文件需要订阅事件\n\n```\n[eventlistener:alarm]\nuser=zj\ncommand=/usr/bin/python /home/ymserver/bin/alarm/main.py\nevents=PROCESS_STATE_EXITED,PROCESS_STATE_STOPPED,PROCESS_STATE_FATAL\n\n# 记录控制台输出的日志位置\nstderr_logfile=/home/zj/log/supervisor/alarm.err.log\nstdout_logfile=/home/zj/log/supervisor/alarm.output.log\n```\n\n弄好 supervisor 配置，以及部署好代码之后，需要重启 supervisor 才会真正的订阅事件。\n从此 supervisor 管理的程序一旦有 `FATAL`,`EXIT` 等状态就会触发程序，程序中就会触发自定义的报警。\n\n----\n\n\n[代码](https://github.com/zheng-ji/ToyCollection/tree/master/supervisor-listener)\n\nHappy Hack!\n\n","source":"_posts/2015-08-21-supervisorjian-ting-qi.markdown","raw":"---\nlayout: post\ntitle: \"Supervisor 监听器\"\ndate: 2015-08-21 16:36\ncomments: true\ncategories: Server\ndescription: supervisor 监控 \n---\n\n我们服务多是用 supervisor 启动的， 但监控多数是用 `monit`, 如果我们能通过监测 supervisor 事件变化来做监控，就可以写一套通用的监控程序。\n\n庆幸的是，supervisor 的 `eventListener` 支持我的设想。\n\n这个监控程序需要用 supervisor 启动，类型不再是`program`, 而是`eventlistener`，这里有几个比较耗时的地方需要记录下。\n\n* supervisor 有独特的通信协议,需要遵循，否则通讯不会被触发\n\n```\ndef write_stdout(self, s):\n    sys.stdout.write(s)\n    sys.stdout.flush()\n\nwrite_stdout('READY\\n') //类似开始握手\nwrite_stdout('RESULT 2\\nOK') //结束通讯\n```\n\n* 需要从标准输入端读取事件,而且他是个阻塞的事件模型\n\n```\nwhile 1:\n    self.write_stdout('READY\\n')\n    line = sys.stdin.readline()\n    do_some_thing()\n    self.write_stdout('RESULT 2\\nOK')\n```\n\n* supervisor 配置文件需要订阅事件\n\n```\n[eventlistener:alarm]\nuser=zj\ncommand=/usr/bin/python /home/ymserver/bin/alarm/main.py\nevents=PROCESS_STATE_EXITED,PROCESS_STATE_STOPPED,PROCESS_STATE_FATAL\n\n# 记录控制台输出的日志位置\nstderr_logfile=/home/zj/log/supervisor/alarm.err.log\nstdout_logfile=/home/zj/log/supervisor/alarm.output.log\n```\n\n弄好 supervisor 配置，以及部署好代码之后，需要重启 supervisor 才会真正的订阅事件。\n从此 supervisor 管理的程序一旦有 `FATAL`,`EXIT` 等状态就会触发程序，程序中就会触发自定义的报警。\n\n----\n\n\n[代码](https://github.com/zheng-ji/ToyCollection/tree/master/supervisor-listener)\n\nHappy Hack!\n\n","slug":"2015-08-21-supervisorjian-ting-qi","published":1,"updated":"2018-06-17T11:10:52.000Z","photos":[],"link":"","_id":"cjijzgda3003unctj49eef2tn","content":"<p>我们服务多是用 supervisor 启动的， 但监控多数是用 <code>monit</code>, 如果我们能通过监测 supervisor 事件变化来做监控，就可以写一套通用的监控程序。</p>\n<p>庆幸的是，supervisor 的 <code>eventListener</code> 支持我的设想。</p>\n<p>这个监控程序需要用 supervisor 启动，类型不再是<code>program</code>, 而是<code>eventlistener</code>，这里有几个比较耗时的地方需要记录下。</p>\n<ul>\n<li>supervisor 有独特的通信协议,需要遵循，否则通讯不会被触发</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def write_stdout(self, s):</span><br><span class=\"line\">    sys.stdout.write(s)</span><br><span class=\"line\">    sys.stdout.flush()</span><br><span class=\"line\"></span><br><span class=\"line\">write_stdout(&apos;READY\\n&apos;) //类似开始握手</span><br><span class=\"line\">write_stdout(&apos;RESULT 2\\nOK&apos;) //结束通讯</span><br></pre></td></tr></table></figure>\n<ul>\n<li>需要从标准输入端读取事件,而且他是个阻塞的事件模型</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while 1:</span><br><span class=\"line\">    self.write_stdout(&apos;READY\\n&apos;)</span><br><span class=\"line\">    line = sys.stdin.readline()</span><br><span class=\"line\">    do_some_thing()</span><br><span class=\"line\">    self.write_stdout(&apos;RESULT 2\\nOK&apos;)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>supervisor 配置文件需要订阅事件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[eventlistener:alarm]</span><br><span class=\"line\">user=zj</span><br><span class=\"line\">command=/usr/bin/python /home/ymserver/bin/alarm/main.py</span><br><span class=\"line\">events=PROCESS_STATE_EXITED,PROCESS_STATE_STOPPED,PROCESS_STATE_FATAL</span><br><span class=\"line\"></span><br><span class=\"line\"># 记录控制台输出的日志位置</span><br><span class=\"line\">stderr_logfile=/home/zj/log/supervisor/alarm.err.log</span><br><span class=\"line\">stdout_logfile=/home/zj/log/supervisor/alarm.output.log</span><br></pre></td></tr></table></figure>\n<p>弄好 supervisor 配置，以及部署好代码之后，需要重启 supervisor 才会真正的订阅事件。<br>从此 supervisor 管理的程序一旦有 <code>FATAL</code>,<code>EXIT</code> 等状态就会触发程序，程序中就会触发自定义的报警。</p>\n<hr>\n<p><a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/supervisor-listener\" target=\"_blank\" rel=\"noopener\">代码</a></p>\n<p>Happy Hack!</p>\n","site":{"data":{}},"excerpt":"","more":"<p>我们服务多是用 supervisor 启动的， 但监控多数是用 <code>monit</code>, 如果我们能通过监测 supervisor 事件变化来做监控，就可以写一套通用的监控程序。</p>\n<p>庆幸的是，supervisor 的 <code>eventListener</code> 支持我的设想。</p>\n<p>这个监控程序需要用 supervisor 启动，类型不再是<code>program</code>, 而是<code>eventlistener</code>，这里有几个比较耗时的地方需要记录下。</p>\n<ul>\n<li>supervisor 有独特的通信协议,需要遵循，否则通讯不会被触发</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def write_stdout(self, s):</span><br><span class=\"line\">    sys.stdout.write(s)</span><br><span class=\"line\">    sys.stdout.flush()</span><br><span class=\"line\"></span><br><span class=\"line\">write_stdout(&apos;READY\\n&apos;) //类似开始握手</span><br><span class=\"line\">write_stdout(&apos;RESULT 2\\nOK&apos;) //结束通讯</span><br></pre></td></tr></table></figure>\n<ul>\n<li>需要从标准输入端读取事件,而且他是个阻塞的事件模型</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while 1:</span><br><span class=\"line\">    self.write_stdout(&apos;READY\\n&apos;)</span><br><span class=\"line\">    line = sys.stdin.readline()</span><br><span class=\"line\">    do_some_thing()</span><br><span class=\"line\">    self.write_stdout(&apos;RESULT 2\\nOK&apos;)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>supervisor 配置文件需要订阅事件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[eventlistener:alarm]</span><br><span class=\"line\">user=zj</span><br><span class=\"line\">command=/usr/bin/python /home/ymserver/bin/alarm/main.py</span><br><span class=\"line\">events=PROCESS_STATE_EXITED,PROCESS_STATE_STOPPED,PROCESS_STATE_FATAL</span><br><span class=\"line\"></span><br><span class=\"line\"># 记录控制台输出的日志位置</span><br><span class=\"line\">stderr_logfile=/home/zj/log/supervisor/alarm.err.log</span><br><span class=\"line\">stdout_logfile=/home/zj/log/supervisor/alarm.output.log</span><br></pre></td></tr></table></figure>\n<p>弄好 supervisor 配置，以及部署好代码之后，需要重启 supervisor 才会真正的订阅事件。<br>从此 supervisor 管理的程序一旦有 <code>FATAL</code>,<code>EXIT</code> 等状态就会触发程序，程序中就会触发自定义的报警。</p>\n<hr>\n<p><a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/supervisor-listener\" target=\"_blank\" rel=\"noopener\">代码</a></p>\n<p>Happy Hack!</p>\n"},{"layout":"post","title":"Ansible 使用经验","date":"2015-09-05T10:09:00.000Z","comments":1,"description":"ansible role","_content":"\n\n当你只有一两台服务器的情况下，可以直接登上服务器，手敲命令完成软件部署，代码发布等工作。但假如你有10台，100台的时候，这种方式不仅浪费大量时间，而且给人为犯错带来了可能。于是我们选择 Ansible 来做自动化批量操作。\n    \n之前有记录一些 Ansible 入门的使用,请看[这里](http://wiki.zheng-ji.info/Sys/ansible.html), 这半年的积累, 总结一些实用的经验, 记录了一把。\n\n* [配置 ansible.cfg 文件](#第一节)\n* [使用 ansible role 来区分业务](#第二节)\n* [files 目录的路径定位](#第三节)\n* [使用 tags 区分不同操作](#第四节)\n* [规划 ansible roles 的 tasks 文件](#第五节)\n* [ansible-play-book 一些常用的选项](#第六节)\n\n<h3 id=\"第一节\">更好地配置文件</h3>\n\n我们会如下配置 /etc/ansible/host, 特意指明用户与 端口\n\n```\n[web-cluster]\n<node-1-IP> ansible_ssh_port=<Your Port> ansible_ssh_user=zj\n<node-2-IP> ansible_ssh_port=<Your Port> ansible_ssh_user=zj\n```\n\n在 /etc/ansible/ansible.cfg 文件里\n我们特意提及了 ansible-role 的配置，未来我们会使用这个东西\n\n```\nroles_path    = /home/zj/my-ansible/roles\n```\n\n\n<h3 id=\"第二节\">使用 ansible role 来区分业务</h3>\n\n打开 ansible 部署脚本的文件夹, 目录树如下\n\n\n```\ncd /home/zj/my-ansible/\nhaproxy\n     - entry.yaml\nroles\n     - haproxy\n        - files\n        - handlers\n        - vars\n        - tasks\n```\n\n我用一个管理 haproxy 的例子来讲解这种方式。\n在 roles 目录下创建 haproxy, 如上所示，需要有四个目录;\n\n* files 目录下放置需要被传输到远端的文件;\n* vars  目录下有一个 main.yml 文件,可以定义一些通用的配置变量，可以在 ansbile 脚本中使用;\n* handlers 目录下有一个 main.yml, 可以定义一些通用的操作，比如重启服务等;\n* tasks 目录下是我们编写 main.yml 脚本，执行业务逻辑的地方;\n\n> 那么 ansible role 的入口在哪呢？\n\n在 ~/my-ansible/haproxy/entry.yml 中，指定了roles的角色，如此一来， \nansible-playbook 就会去 /home/zj/my-ansible/roles/haproxy 准备执行 tasks/main.yml \n\n```\n- hosts: web-cluster\n  roles:\n    - haproxy\n```\n\n<h3 id=\"第三节\">files 目录的路径定位</h3>\n\n摘取 ~/my-ansible/roles/haproxy/tasks/main.yml\n\n```\n- name: copy haproxy conf\n  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root\n  sudo: yes\n```\n\n这里的 src=haproxy.cfg 意味着 ~/my-ansible/roles/haproxy/files/haproxy.cfg\n\n<h3 id=\"第四节\">使用 tags 区分不同操作</h3>\n\n```\n- name: install ppa\n  shell: add-apt-repository -y ppa:vbernat/haproxy-1.5\n  sudo: yes\n  tags:\n    - install-haproxy\n```\n\n以下命令，是使用 tags 参数区分操作的例子\n\n```\ncd ~/my-ansible/haproxy\nansible-playbook entry.yml -v -K --tags \"install-haproxy\"\n```\n\n<h3 id=\"第五节\">规划 ansible roles 的 tasks 目录</h3>\n\ntasks 目录有一个主执行文件 main.yml, 因为业务操作步骤太多，导致 main.yml 文件很长，那么可读性就下降了。为此，我们使用了 include 语法。\n\ncat ~/my-ansible/roles/haproxy/tasks/main.yml\n\n```\n- include: 'install-haproxy.yml'\n```\n\ninclude 上述文件，这样 main.yml 就显得简洁，我们可以将相关的操作写在对应的 yml 文件里\n\ncat ~/my-ansible/roles/haproxy/tasks/install-haproxy.yml\n\n```\n- name: copy haproxy conf\n  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root\n  sudo: yes\n  tags:\n     - install-haproxy\n```\ntags 最好也与该 yml 文件名一致，清晰分明\n\n<h3 id=\"第六节\">ansible-play-book 一些常用的选项</h3>\n\n\n* -K 需要 sudo 权限去客户机执行命令，会提示你输入密码\n* -v 可以输出冗余的执行过程\n* --check 可以测试脚本执行情况，但实际并未在远程机器执行\n* --tags 提示 ansible-play-book 调用哪些 tags 命令\n\n使用过ansible roles 之后，最大的体会是操作调理化，甚至编程化，合理的利用 handler, vars, 能更加优雅抽象。\n\n----\n\n上述的例子在 Github 有代码, 结合本文阅读可能更容易上手\n[Link](https://github.com/zheng-ji/ToyCollection/tree/master/my-ansible) \n\n\n","source":"_posts/2015-09-05-ansiblede-shi-yong-jing-yan.markdown","raw":"---\nlayout: post\ntitle: \"Ansible 使用经验\"\ndate: 2015-09-05 18:09\ncomments: true\ncategories: System\ndescription: ansible role\n---\n\n\n当你只有一两台服务器的情况下，可以直接登上服务器，手敲命令完成软件部署，代码发布等工作。但假如你有10台，100台的时候，这种方式不仅浪费大量时间，而且给人为犯错带来了可能。于是我们选择 Ansible 来做自动化批量操作。\n    \n之前有记录一些 Ansible 入门的使用,请看[这里](http://wiki.zheng-ji.info/Sys/ansible.html), 这半年的积累, 总结一些实用的经验, 记录了一把。\n\n* [配置 ansible.cfg 文件](#第一节)\n* [使用 ansible role 来区分业务](#第二节)\n* [files 目录的路径定位](#第三节)\n* [使用 tags 区分不同操作](#第四节)\n* [规划 ansible roles 的 tasks 文件](#第五节)\n* [ansible-play-book 一些常用的选项](#第六节)\n\n<h3 id=\"第一节\">更好地配置文件</h3>\n\n我们会如下配置 /etc/ansible/host, 特意指明用户与 端口\n\n```\n[web-cluster]\n<node-1-IP> ansible_ssh_port=<Your Port> ansible_ssh_user=zj\n<node-2-IP> ansible_ssh_port=<Your Port> ansible_ssh_user=zj\n```\n\n在 /etc/ansible/ansible.cfg 文件里\n我们特意提及了 ansible-role 的配置，未来我们会使用这个东西\n\n```\nroles_path    = /home/zj/my-ansible/roles\n```\n\n\n<h3 id=\"第二节\">使用 ansible role 来区分业务</h3>\n\n打开 ansible 部署脚本的文件夹, 目录树如下\n\n\n```\ncd /home/zj/my-ansible/\nhaproxy\n     - entry.yaml\nroles\n     - haproxy\n        - files\n        - handlers\n        - vars\n        - tasks\n```\n\n我用一个管理 haproxy 的例子来讲解这种方式。\n在 roles 目录下创建 haproxy, 如上所示，需要有四个目录;\n\n* files 目录下放置需要被传输到远端的文件;\n* vars  目录下有一个 main.yml 文件,可以定义一些通用的配置变量，可以在 ansbile 脚本中使用;\n* handlers 目录下有一个 main.yml, 可以定义一些通用的操作，比如重启服务等;\n* tasks 目录下是我们编写 main.yml 脚本，执行业务逻辑的地方;\n\n> 那么 ansible role 的入口在哪呢？\n\n在 ~/my-ansible/haproxy/entry.yml 中，指定了roles的角色，如此一来， \nansible-playbook 就会去 /home/zj/my-ansible/roles/haproxy 准备执行 tasks/main.yml \n\n```\n- hosts: web-cluster\n  roles:\n    - haproxy\n```\n\n<h3 id=\"第三节\">files 目录的路径定位</h3>\n\n摘取 ~/my-ansible/roles/haproxy/tasks/main.yml\n\n```\n- name: copy haproxy conf\n  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root\n  sudo: yes\n```\n\n这里的 src=haproxy.cfg 意味着 ~/my-ansible/roles/haproxy/files/haproxy.cfg\n\n<h3 id=\"第四节\">使用 tags 区分不同操作</h3>\n\n```\n- name: install ppa\n  shell: add-apt-repository -y ppa:vbernat/haproxy-1.5\n  sudo: yes\n  tags:\n    - install-haproxy\n```\n\n以下命令，是使用 tags 参数区分操作的例子\n\n```\ncd ~/my-ansible/haproxy\nansible-playbook entry.yml -v -K --tags \"install-haproxy\"\n```\n\n<h3 id=\"第五节\">规划 ansible roles 的 tasks 目录</h3>\n\ntasks 目录有一个主执行文件 main.yml, 因为业务操作步骤太多，导致 main.yml 文件很长，那么可读性就下降了。为此，我们使用了 include 语法。\n\ncat ~/my-ansible/roles/haproxy/tasks/main.yml\n\n```\n- include: 'install-haproxy.yml'\n```\n\ninclude 上述文件，这样 main.yml 就显得简洁，我们可以将相关的操作写在对应的 yml 文件里\n\ncat ~/my-ansible/roles/haproxy/tasks/install-haproxy.yml\n\n```\n- name: copy haproxy conf\n  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root\n  sudo: yes\n  tags:\n     - install-haproxy\n```\ntags 最好也与该 yml 文件名一致，清晰分明\n\n<h3 id=\"第六节\">ansible-play-book 一些常用的选项</h3>\n\n\n* -K 需要 sudo 权限去客户机执行命令，会提示你输入密码\n* -v 可以输出冗余的执行过程\n* --check 可以测试脚本执行情况，但实际并未在远程机器执行\n* --tags 提示 ansible-play-book 调用哪些 tags 命令\n\n使用过ansible roles 之后，最大的体会是操作调理化，甚至编程化，合理的利用 handler, vars, 能更加优雅抽象。\n\n----\n\n上述的例子在 Github 有代码, 结合本文阅读可能更容易上手\n[Link](https://github.com/zheng-ji/ToyCollection/tree/master/my-ansible) \n\n\n","slug":"2015-09-05-ansiblede-shi-yong-jing-yan","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgda5003wnctjy92s83hz","content":"<p>当你只有一两台服务器的情况下，可以直接登上服务器，手敲命令完成软件部署，代码发布等工作。但假如你有10台，100台的时候，这种方式不仅浪费大量时间，而且给人为犯错带来了可能。于是我们选择 Ansible 来做自动化批量操作。</p>\n<p>之前有记录一些 Ansible 入门的使用,请看<a href=\"http://wiki.zheng-ji.info/Sys/ansible.html\" target=\"_blank\" rel=\"noopener\">这里</a>, 这半年的积累, 总结一些实用的经验, 记录了一把。</p>\n<ul>\n<li><a href=\"#第一节\">配置 ansible.cfg 文件</a></li>\n<li><a href=\"#第二节\">使用 ansible role 来区分业务</a></li>\n<li><a href=\"#第三节\">files 目录的路径定位</a></li>\n<li><a href=\"#第四节\">使用 tags 区分不同操作</a></li>\n<li><a href=\"#第五节\">规划 ansible roles 的 tasks 文件</a></li>\n<li><a href=\"#第六节\">ansible-play-book 一些常用的选项</a></li>\n</ul>\n<h3 id=\"第一节\">更好地配置文件</h3>\n\n<p>我们会如下配置 /etc/ansible/host, 特意指明用户与 端口</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[web-cluster]</span><br><span class=\"line\">&lt;node-1-IP&gt; ansible_ssh_port=&lt;Your Port&gt; ansible_ssh_user=zj</span><br><span class=\"line\">&lt;node-2-IP&gt; ansible_ssh_port=&lt;Your Port&gt; ansible_ssh_user=zj</span><br></pre></td></tr></table></figure>\n<p>在 /etc/ansible/ansible.cfg 文件里<br>我们特意提及了 ansible-role 的配置，未来我们会使用这个东西</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roles_path    = /home/zj/my-ansible/roles</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二节\">使用 ansible role 来区分业务</h3>\n\n<p>打开 ansible 部署脚本的文件夹, 目录树如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /home/zj/my-ansible/</span><br><span class=\"line\">haproxy</span><br><span class=\"line\">     - entry.yaml</span><br><span class=\"line\">roles</span><br><span class=\"line\">     - haproxy</span><br><span class=\"line\">        - files</span><br><span class=\"line\">        - handlers</span><br><span class=\"line\">        - vars</span><br><span class=\"line\">        - tasks</span><br></pre></td></tr></table></figure>\n<p>我用一个管理 haproxy 的例子来讲解这种方式。<br>在 roles 目录下创建 haproxy, 如上所示，需要有四个目录;</p>\n<ul>\n<li>files 目录下放置需要被传输到远端的文件;</li>\n<li>vars  目录下有一个 main.yml 文件,可以定义一些通用的配置变量，可以在 ansbile 脚本中使用;</li>\n<li>handlers 目录下有一个 main.yml, 可以定义一些通用的操作，比如重启服务等;</li>\n<li>tasks 目录下是我们编写 main.yml 脚本，执行业务逻辑的地方;</li>\n</ul>\n<blockquote>\n<p>那么 ansible role 的入口在哪呢？</p>\n</blockquote>\n<p>在 ~/my-ansible/haproxy/entry.yml 中，指定了roles的角色，如此一来，<br>ansible-playbook 就会去 /home/zj/my-ansible/roles/haproxy 准备执行 tasks/main.yml </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- hosts: web-cluster</span><br><span class=\"line\">  roles:</span><br><span class=\"line\">    - haproxy</span><br></pre></td></tr></table></figure>\n<h3 id=\"第三节\">files 目录的路径定位</h3>\n\n<p>摘取 ~/my-ansible/roles/haproxy/tasks/main.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- name: copy haproxy conf</span><br><span class=\"line\">  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root</span><br><span class=\"line\">  sudo: yes</span><br></pre></td></tr></table></figure>\n<p>这里的 src=haproxy.cfg 意味着 ~/my-ansible/roles/haproxy/files/haproxy.cfg</p>\n<h3 id=\"第四节\">使用 tags 区分不同操作</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- name: install ppa</span><br><span class=\"line\">  shell: add-apt-repository -y ppa:vbernat/haproxy-1.5</span><br><span class=\"line\">  sudo: yes</span><br><span class=\"line\">  tags:</span><br><span class=\"line\">    - install-haproxy</span><br></pre></td></tr></table></figure>\n<p>以下命令，是使用 tags 参数区分操作的例子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/my-ansible/haproxy</span><br><span class=\"line\">ansible-playbook entry.yml -v -K --tags &quot;install-haproxy&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"第五节\">规划 ansible roles 的 tasks 目录</h3>\n\n<p>tasks 目录有一个主执行文件 main.yml, 因为业务操作步骤太多，导致 main.yml 文件很长，那么可读性就下降了。为此，我们使用了 include 语法。</p>\n<p>cat ~/my-ansible/roles/haproxy/tasks/main.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- include: &apos;install-haproxy.yml&apos;</span><br></pre></td></tr></table></figure>\n<p>include 上述文件，这样 main.yml 就显得简洁，我们可以将相关的操作写在对应的 yml 文件里</p>\n<p>cat ~/my-ansible/roles/haproxy/tasks/install-haproxy.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- name: copy haproxy conf</span><br><span class=\"line\">  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root</span><br><span class=\"line\">  sudo: yes</span><br><span class=\"line\">  tags:</span><br><span class=\"line\">     - install-haproxy</span><br></pre></td></tr></table></figure>\n<p>tags 最好也与该 yml 文件名一致，清晰分明</p>\n<h3 id=\"第六节\">ansible-play-book 一些常用的选项</h3>\n\n\n<ul>\n<li>-K 需要 sudo 权限去客户机执行命令，会提示你输入密码</li>\n<li>-v 可以输出冗余的执行过程</li>\n<li>–check 可以测试脚本执行情况，但实际并未在远程机器执行</li>\n<li>–tags 提示 ansible-play-book 调用哪些 tags 命令</li>\n</ul>\n<p>使用过ansible roles 之后，最大的体会是操作调理化，甚至编程化，合理的利用 handler, vars, 能更加优雅抽象。</p>\n<hr>\n<p>上述的例子在 Github 有代码, 结合本文阅读可能更容易上手<br><a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/my-ansible\" target=\"_blank\" rel=\"noopener\">Link</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>当你只有一两台服务器的情况下，可以直接登上服务器，手敲命令完成软件部署，代码发布等工作。但假如你有10台，100台的时候，这种方式不仅浪费大量时间，而且给人为犯错带来了可能。于是我们选择 Ansible 来做自动化批量操作。</p>\n<p>之前有记录一些 Ansible 入门的使用,请看<a href=\"http://wiki.zheng-ji.info/Sys/ansible.html\" target=\"_blank\" rel=\"noopener\">这里</a>, 这半年的积累, 总结一些实用的经验, 记录了一把。</p>\n<ul>\n<li><a href=\"#第一节\">配置 ansible.cfg 文件</a></li>\n<li><a href=\"#第二节\">使用 ansible role 来区分业务</a></li>\n<li><a href=\"#第三节\">files 目录的路径定位</a></li>\n<li><a href=\"#第四节\">使用 tags 区分不同操作</a></li>\n<li><a href=\"#第五节\">规划 ansible roles 的 tasks 文件</a></li>\n<li><a href=\"#第六节\">ansible-play-book 一些常用的选项</a></li>\n</ul>\n<h3 id=\"第一节\">更好地配置文件</h3>\n\n<p>我们会如下配置 /etc/ansible/host, 特意指明用户与 端口</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[web-cluster]</span><br><span class=\"line\">&lt;node-1-IP&gt; ansible_ssh_port=&lt;Your Port&gt; ansible_ssh_user=zj</span><br><span class=\"line\">&lt;node-2-IP&gt; ansible_ssh_port=&lt;Your Port&gt; ansible_ssh_user=zj</span><br></pre></td></tr></table></figure>\n<p>在 /etc/ansible/ansible.cfg 文件里<br>我们特意提及了 ansible-role 的配置，未来我们会使用这个东西</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roles_path    = /home/zj/my-ansible/roles</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二节\">使用 ansible role 来区分业务</h3>\n\n<p>打开 ansible 部署脚本的文件夹, 目录树如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /home/zj/my-ansible/</span><br><span class=\"line\">haproxy</span><br><span class=\"line\">     - entry.yaml</span><br><span class=\"line\">roles</span><br><span class=\"line\">     - haproxy</span><br><span class=\"line\">        - files</span><br><span class=\"line\">        - handlers</span><br><span class=\"line\">        - vars</span><br><span class=\"line\">        - tasks</span><br></pre></td></tr></table></figure>\n<p>我用一个管理 haproxy 的例子来讲解这种方式。<br>在 roles 目录下创建 haproxy, 如上所示，需要有四个目录;</p>\n<ul>\n<li>files 目录下放置需要被传输到远端的文件;</li>\n<li>vars  目录下有一个 main.yml 文件,可以定义一些通用的配置变量，可以在 ansbile 脚本中使用;</li>\n<li>handlers 目录下有一个 main.yml, 可以定义一些通用的操作，比如重启服务等;</li>\n<li>tasks 目录下是我们编写 main.yml 脚本，执行业务逻辑的地方;</li>\n</ul>\n<blockquote>\n<p>那么 ansible role 的入口在哪呢？</p>\n</blockquote>\n<p>在 ~/my-ansible/haproxy/entry.yml 中，指定了roles的角色，如此一来，<br>ansible-playbook 就会去 /home/zj/my-ansible/roles/haproxy 准备执行 tasks/main.yml </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- hosts: web-cluster</span><br><span class=\"line\">  roles:</span><br><span class=\"line\">    - haproxy</span><br></pre></td></tr></table></figure>\n<h3 id=\"第三节\">files 目录的路径定位</h3>\n\n<p>摘取 ~/my-ansible/roles/haproxy/tasks/main.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- name: copy haproxy conf</span><br><span class=\"line\">  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root</span><br><span class=\"line\">  sudo: yes</span><br></pre></td></tr></table></figure>\n<p>这里的 src=haproxy.cfg 意味着 ~/my-ansible/roles/haproxy/files/haproxy.cfg</p>\n<h3 id=\"第四节\">使用 tags 区分不同操作</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- name: install ppa</span><br><span class=\"line\">  shell: add-apt-repository -y ppa:vbernat/haproxy-1.5</span><br><span class=\"line\">  sudo: yes</span><br><span class=\"line\">  tags:</span><br><span class=\"line\">    - install-haproxy</span><br></pre></td></tr></table></figure>\n<p>以下命令，是使用 tags 参数区分操作的例子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/my-ansible/haproxy</span><br><span class=\"line\">ansible-playbook entry.yml -v -K --tags &quot;install-haproxy&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"第五节\">规划 ansible roles 的 tasks 目录</h3>\n\n<p>tasks 目录有一个主执行文件 main.yml, 因为业务操作步骤太多，导致 main.yml 文件很长，那么可读性就下降了。为此，我们使用了 include 语法。</p>\n<p>cat ~/my-ansible/roles/haproxy/tasks/main.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- include: &apos;install-haproxy.yml&apos;</span><br></pre></td></tr></table></figure>\n<p>include 上述文件，这样 main.yml 就显得简洁，我们可以将相关的操作写在对应的 yml 文件里</p>\n<p>cat ~/my-ansible/roles/haproxy/tasks/install-haproxy.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- name: copy haproxy conf</span><br><span class=\"line\">  copy: src=haproxy.cfg dest=/etc/haproxy/haproxy.cfg owner=root group=root</span><br><span class=\"line\">  sudo: yes</span><br><span class=\"line\">  tags:</span><br><span class=\"line\">     - install-haproxy</span><br></pre></td></tr></table></figure>\n<p>tags 最好也与该 yml 文件名一致，清晰分明</p>\n<h3 id=\"第六节\">ansible-play-book 一些常用的选项</h3>\n\n\n<ul>\n<li>-K 需要 sudo 权限去客户机执行命令，会提示你输入密码</li>\n<li>-v 可以输出冗余的执行过程</li>\n<li>–check 可以测试脚本执行情况，但实际并未在远程机器执行</li>\n<li>–tags 提示 ansible-play-book 调用哪些 tags 命令</li>\n</ul>\n<p>使用过ansible roles 之后，最大的体会是操作调理化，甚至编程化，合理的利用 handler, vars, 能更加优雅抽象。</p>\n<hr>\n<p>上述的例子在 Github 有代码, 结合本文阅读可能更容易上手<br><a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/my-ansible\" target=\"_blank\" rel=\"noopener\">Link</a> </p>\n"},{"layout":"post","title":"Sysdig 值得拥有","date":"2015-09-10T15:10:00.000Z","comments":1,"description":"sysdig","_content":"\n定位服务器问题时,  我们需要各式各样的武器, 诸如 iftop, ifstat, netstat, tcpdump, iostat。dstat 等, 因此工具箱需要装满很多工具, 在面对问题的时候才能显得不费吹灰之力, 迅速定位问题并解决, 保障服务稳定运行。Sysdig 的横空出世, 对我们而言, 就是一把瑞士军刀, 灵活小巧, 武艺多端.\n\n* [安装](#第一节)\n* [常用操作](#第二节)\n* [高效的实战](#第三节)\n\n<h3 id=\"第一节\">安装</h3>\n\n```\ncurl -s https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public | apt-key add -\ncurl -s -o /etc/apt/sources.list.d/draios.list http://download.draios.com/stable/deb/draios.list\napt-get update\napt-get -y install sysdig\n```\n\n<h3 id=\"第二节\">常用操作</h3>\n\nsysdig 有很多 chisel, chisel 意为 铲子, 可以理解为定位某类问题的工具, sysdig 采用 Lua 编写的。\n\n* 查看 chisel 列表\n\n```\nsysdig -cl  \n```\n\n* 查看具体某个 chisel 的提示\n\n```\nsysdig -i spy_logs\n```\n\n* 使用某个 chisel\n\n```\nsysdig -c spy_logs\n```\n\n* 过滤器可以帮助我们从各种输出信息中, 筛选出我们需要的, 比如 \n`proc.name=foo` , \n如果你记住不了太多过滤器也无妨,  我们可以借助如下命令查看过滤器\n\n```\nsysdig -l\n```\n\n* 记录定位信息到文本, 以及从文本读取信息\n\n```\nsysdig -w tracefile.cap\nsysdig -r tracefile.dump proc.name=sshd\n```\n\n<h3 id=\"第三节\">高效的实战</h3>\n\n* 服务器上经常需要查看哪个服务带宽占用使用较高, 特别是被 DDOS 的时候。\n\n```\nsudo sysdig -c topprocs_net\n```\n\n* 查看某个IP的通讯数据,并以ASCII 码输出\n\n```\nsudo sysdig -s2000 -A -c echo_fds fd.cip=127.0.0.1\n```\n\n* 查看非请求 redis-server 的其他请求进程和句柄\n\n```\nsudo sysdig -p\"%proc.name %fd.name\" \"evt.type=accept and proc.name!=redis-server\"\n```\n\n* 查看访问该服务器的所有 GET 请求数据\n\n```\nsudo sysdig -s 2000 -A -c echo_fds fd.port=80 and evt.buffer contains GET\n```\n\n* 查看访问该服务器的 SQL 语句\n\n```\nsudo sysdig -s 2000 -A -c echo_fds evt.buffer contains SELECT\n```\n\n* 查看磁盘读写最高的进程\n\n```\nsysdig -c topprocs_file\n```\n\n* 查看延迟最大的系统调用\n\n```\nsysdig -c topscalls_time\n```\n\n* 查看具体文件的操作细节\n\n```\nsysdig -A -c echo_fds \"fd.filename=syslog\"\n```\n\n* 查看 IO 延迟大于 1ms 的文件\n\n```\nsudo sysdig -c fileslower 1\n```\n\n* 监视某个文件是否被操作, 从安全出发想象空间很大哦\n\n```\nsudo sysdig evt.type=open and fd.name contains /etc\n```\n\n---\n\n[Sysdig 官网](http://www.sysdig.org/wiki/)\n","source":"_posts/2015-09-10-sysdig-zhi-de-yong-you.markdown","raw":"---\nlayout: post\ntitle: \"Sysdig 值得拥有\"\ndate: 2015-09-10 23:10\ncomments: true\ncategories: System\ndescription: sysdig\n---\n\n定位服务器问题时,  我们需要各式各样的武器, 诸如 iftop, ifstat, netstat, tcpdump, iostat。dstat 等, 因此工具箱需要装满很多工具, 在面对问题的时候才能显得不费吹灰之力, 迅速定位问题并解决, 保障服务稳定运行。Sysdig 的横空出世, 对我们而言, 就是一把瑞士军刀, 灵活小巧, 武艺多端.\n\n* [安装](#第一节)\n* [常用操作](#第二节)\n* [高效的实战](#第三节)\n\n<h3 id=\"第一节\">安装</h3>\n\n```\ncurl -s https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public | apt-key add -\ncurl -s -o /etc/apt/sources.list.d/draios.list http://download.draios.com/stable/deb/draios.list\napt-get update\napt-get -y install sysdig\n```\n\n<h3 id=\"第二节\">常用操作</h3>\n\nsysdig 有很多 chisel, chisel 意为 铲子, 可以理解为定位某类问题的工具, sysdig 采用 Lua 编写的。\n\n* 查看 chisel 列表\n\n```\nsysdig -cl  \n```\n\n* 查看具体某个 chisel 的提示\n\n```\nsysdig -i spy_logs\n```\n\n* 使用某个 chisel\n\n```\nsysdig -c spy_logs\n```\n\n* 过滤器可以帮助我们从各种输出信息中, 筛选出我们需要的, 比如 \n`proc.name=foo` , \n如果你记住不了太多过滤器也无妨,  我们可以借助如下命令查看过滤器\n\n```\nsysdig -l\n```\n\n* 记录定位信息到文本, 以及从文本读取信息\n\n```\nsysdig -w tracefile.cap\nsysdig -r tracefile.dump proc.name=sshd\n```\n\n<h3 id=\"第三节\">高效的实战</h3>\n\n* 服务器上经常需要查看哪个服务带宽占用使用较高, 特别是被 DDOS 的时候。\n\n```\nsudo sysdig -c topprocs_net\n```\n\n* 查看某个IP的通讯数据,并以ASCII 码输出\n\n```\nsudo sysdig -s2000 -A -c echo_fds fd.cip=127.0.0.1\n```\n\n* 查看非请求 redis-server 的其他请求进程和句柄\n\n```\nsudo sysdig -p\"%proc.name %fd.name\" \"evt.type=accept and proc.name!=redis-server\"\n```\n\n* 查看访问该服务器的所有 GET 请求数据\n\n```\nsudo sysdig -s 2000 -A -c echo_fds fd.port=80 and evt.buffer contains GET\n```\n\n* 查看访问该服务器的 SQL 语句\n\n```\nsudo sysdig -s 2000 -A -c echo_fds evt.buffer contains SELECT\n```\n\n* 查看磁盘读写最高的进程\n\n```\nsysdig -c topprocs_file\n```\n\n* 查看延迟最大的系统调用\n\n```\nsysdig -c topscalls_time\n```\n\n* 查看具体文件的操作细节\n\n```\nsysdig -A -c echo_fds \"fd.filename=syslog\"\n```\n\n* 查看 IO 延迟大于 1ms 的文件\n\n```\nsudo sysdig -c fileslower 1\n```\n\n* 监视某个文件是否被操作, 从安全出发想象空间很大哦\n\n```\nsudo sysdig evt.type=open and fd.name contains /etc\n```\n\n---\n\n[Sysdig 官网](http://www.sysdig.org/wiki/)\n","slug":"2015-09-10-sysdig-zhi-de-yong-you","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgda5003ynctjwt84kiu4","content":"<p>定位服务器问题时,  我们需要各式各样的武器, 诸如 iftop, ifstat, netstat, tcpdump, iostat。dstat 等, 因此工具箱需要装满很多工具, 在面对问题的时候才能显得不费吹灰之力, 迅速定位问题并解决, 保障服务稳定运行。Sysdig 的横空出世, 对我们而言, 就是一把瑞士军刀, 灵活小巧, 武艺多端.</p>\n<ul>\n<li><a href=\"#第一节\">安装</a></li>\n<li><a href=\"#第二节\">常用操作</a></li>\n<li><a href=\"#第三节\">高效的实战</a></li>\n</ul>\n<h3 id=\"第一节\">安装</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -s https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public | apt-key add -</span><br><span class=\"line\">curl -s -o /etc/apt/sources.list.d/draios.list http://download.draios.com/stable/deb/draios.list</span><br><span class=\"line\">apt-get update</span><br><span class=\"line\">apt-get -y install sysdig</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二节\">常用操作</h3>\n\n<p>sysdig 有很多 chisel, chisel 意为 铲子, 可以理解为定位某类问题的工具, sysdig 采用 Lua 编写的。</p>\n<ul>\n<li>查看 chisel 列表</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -cl</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看具体某个 chisel 的提示</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -i spy_logs</span><br></pre></td></tr></table></figure>\n<ul>\n<li>使用某个 chisel</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -c spy_logs</span><br></pre></td></tr></table></figure>\n<ul>\n<li>过滤器可以帮助我们从各种输出信息中, 筛选出我们需要的, 比如<br><code>proc.name=foo</code> ,<br>如果你记住不了太多过滤器也无妨,  我们可以借助如下命令查看过滤器</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -l</span><br></pre></td></tr></table></figure>\n<ul>\n<li>记录定位信息到文本, 以及从文本读取信息</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -w tracefile.cap</span><br><span class=\"line\">sysdig -r tracefile.dump proc.name=sshd</span><br></pre></td></tr></table></figure>\n<h3 id=\"第三节\">高效的实战</h3>\n\n<ul>\n<li>服务器上经常需要查看哪个服务带宽占用使用较高, 特别是被 DDOS 的时候。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -c topprocs_net</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看某个IP的通讯数据,并以ASCII 码输出</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -s2000 -A -c echo_fds fd.cip=127.0.0.1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看非请求 redis-server 的其他请求进程和句柄</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -p&quot;%proc.name %fd.name&quot; &quot;evt.type=accept and proc.name!=redis-server&quot;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看访问该服务器的所有 GET 请求数据</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -s 2000 -A -c echo_fds fd.port=80 and evt.buffer contains GET</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看访问该服务器的 SQL 语句</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -s 2000 -A -c echo_fds evt.buffer contains SELECT</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看磁盘读写最高的进程</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -c topprocs_file</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看延迟最大的系统调用</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -c topscalls_time</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看具体文件的操作细节</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -A -c echo_fds &quot;fd.filename=syslog&quot;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看 IO 延迟大于 1ms 的文件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -c fileslower 1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>监视某个文件是否被操作, 从安全出发想象空间很大哦</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig evt.type=open and fd.name contains /etc</span><br></pre></td></tr></table></figure>\n<hr>\n<p><a href=\"http://www.sysdig.org/wiki/\" target=\"_blank\" rel=\"noopener\">Sysdig 官网</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>定位服务器问题时,  我们需要各式各样的武器, 诸如 iftop, ifstat, netstat, tcpdump, iostat。dstat 等, 因此工具箱需要装满很多工具, 在面对问题的时候才能显得不费吹灰之力, 迅速定位问题并解决, 保障服务稳定运行。Sysdig 的横空出世, 对我们而言, 就是一把瑞士军刀, 灵活小巧, 武艺多端.</p>\n<ul>\n<li><a href=\"#第一节\">安装</a></li>\n<li><a href=\"#第二节\">常用操作</a></li>\n<li><a href=\"#第三节\">高效的实战</a></li>\n</ul>\n<h3 id=\"第一节\">安装</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -s https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public | apt-key add -</span><br><span class=\"line\">curl -s -o /etc/apt/sources.list.d/draios.list http://download.draios.com/stable/deb/draios.list</span><br><span class=\"line\">apt-get update</span><br><span class=\"line\">apt-get -y install sysdig</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二节\">常用操作</h3>\n\n<p>sysdig 有很多 chisel, chisel 意为 铲子, 可以理解为定位某类问题的工具, sysdig 采用 Lua 编写的。</p>\n<ul>\n<li>查看 chisel 列表</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -cl</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看具体某个 chisel 的提示</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -i spy_logs</span><br></pre></td></tr></table></figure>\n<ul>\n<li>使用某个 chisel</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -c spy_logs</span><br></pre></td></tr></table></figure>\n<ul>\n<li>过滤器可以帮助我们从各种输出信息中, 筛选出我们需要的, 比如<br><code>proc.name=foo</code> ,<br>如果你记住不了太多过滤器也无妨,  我们可以借助如下命令查看过滤器</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -l</span><br></pre></td></tr></table></figure>\n<ul>\n<li>记录定位信息到文本, 以及从文本读取信息</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -w tracefile.cap</span><br><span class=\"line\">sysdig -r tracefile.dump proc.name=sshd</span><br></pre></td></tr></table></figure>\n<h3 id=\"第三节\">高效的实战</h3>\n\n<ul>\n<li>服务器上经常需要查看哪个服务带宽占用使用较高, 特别是被 DDOS 的时候。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -c topprocs_net</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看某个IP的通讯数据,并以ASCII 码输出</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -s2000 -A -c echo_fds fd.cip=127.0.0.1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看非请求 redis-server 的其他请求进程和句柄</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -p&quot;%proc.name %fd.name&quot; &quot;evt.type=accept and proc.name!=redis-server&quot;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看访问该服务器的所有 GET 请求数据</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -s 2000 -A -c echo_fds fd.port=80 and evt.buffer contains GET</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看访问该服务器的 SQL 语句</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -s 2000 -A -c echo_fds evt.buffer contains SELECT</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看磁盘读写最高的进程</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -c topprocs_file</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看延迟最大的系统调用</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -c topscalls_time</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看具体文件的操作细节</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sysdig -A -c echo_fds &quot;fd.filename=syslog&quot;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看 IO 延迟大于 1ms 的文件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig -c fileslower 1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>监视某个文件是否被操作, 从安全出发想象空间很大哦</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sysdig evt.type=open and fd.name contains /etc</span><br></pre></td></tr></table></figure>\n<hr>\n<p><a href=\"http://www.sysdig.org/wiki/\" target=\"_blank\" rel=\"noopener\">Sysdig 官网</a></p>\n"},{"layout":"post","title":"Python 使用 LDAP","date":"2015-10-01T01:49:00.000Z","comments":1,"description":"python ldap","_content":"\n## 写在开头\n\n过去的两个多星期，几位小伙伴同心协力完成一个自研的，类似[pushover](http://pushover.net)的产品。感谢 Leader 的信任，让我在负责开发的同时也兼顾了一把项目经理。谢谢 IOS, Android 客户端的兄弟，设计师的支持，还有一位实习生，开心看到他的点滴成长。\n\n提下背景，我们之前使用 `pushover` 来做报警推送，但是它对天朝用户不友好，Android 用户需要翻墙才能使用，有时候不稳定，体现为会收不到信息。pushove 需要付费。我们的受众不仅有程序汪，还有运营产品汪，他们需要一款更容易上手的推送软件，至少不需要番羽墙。于是自己开发一个很有必要。\n\n为最大程度降低用户使用门槛，同时保证用户信息的安全，我们用了 LDAP 账户登陆，严格控制权限，以及 HTTPS 协议开发。下面提一提 LDAP 这个东西。\n\n## LDAP 是什么\n\n[LDAP维基百科](https://zh.wikipedia.org/wiki/%E8%BD%BB%E5%9E%8B%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE)\n\n简单地讲，它是以目录树的方式存放账户信息。\n\n这次项目中，我们不希望用户重新注册账户，而是采用原有的用户体系，这样对单点登录以及权限控制的好处不严而喻, LDAP 协议呼之欲出。\n\n\n## virtualenv 下安装 python-ldap\n\n我们采用 Python 开发，这就需要 python-ldap 的帮助了, 记下安装笔记的好处是下次不用在此纠结太长时间。\n\n```\napt-get install libsasl2-dev python-dev libldap2-dev libssl-dev\npip install python-ldap\n```\n\n## 身份验证\n\n```\n# LDAP 服务的域名和端口\nSERVER_NAME = 'xxxx'\nSERVER_PORT = xxx\ntry:\n    conn = ldap.open(SERVER_NAME, SERVER_PORT)  \n    conn.protocol_version = ldap.VERSION3 #设置ldap协议版本 \n    username = \"user=xxx,dc=company,dc=com\" #身份信息\n    password = \"xxx\" #访问密码\n    conn.simple_bind_s(username,password) # 开始绑定，验证成功的话不会抛出异常\nexcept ldap.LDAPError, e: #捕获出错信息\n    print e\n```\n\n## 一点感悟\n\n鄙人觉得，技术领导要带领项目成长, 除了有责任把控项目风险，推进项目进度。\n还必须要花很多的心血在驾驭技术上,  身先士卒去调研可行性, 以及做技术攻关，\n而非命令式地分配任务，让同事干活, 只问责结果。\n否则很容易导致凝聚力不足,团队技术氛围不足，这样的团队易消极，也易滋生失败的项目。\n然而在天朝, 很多人存在一个潜意识:写好代码是为了以后不写代码，这种阶级思想让我反感。\n\n以前看过一个新闻, 硅谷在面试技术 VP ，仍然要求其在各位工程师面前手写代码，以此作为面试的重要环节, 不得不点赞。\n\n","source":"_posts/2015-10-01-python-shi-yong-ldap.markdown","raw":"---\nlayout: post\ntitle: \"Python 使用 LDAP\"\ndate: 2015-10-01 09:49\ncomments: true\ncategories: Programe\ndescription: python ldap\n---\n\n## 写在开头\n\n过去的两个多星期，几位小伙伴同心协力完成一个自研的，类似[pushover](http://pushover.net)的产品。感谢 Leader 的信任，让我在负责开发的同时也兼顾了一把项目经理。谢谢 IOS, Android 客户端的兄弟，设计师的支持，还有一位实习生，开心看到他的点滴成长。\n\n提下背景，我们之前使用 `pushover` 来做报警推送，但是它对天朝用户不友好，Android 用户需要翻墙才能使用，有时候不稳定，体现为会收不到信息。pushove 需要付费。我们的受众不仅有程序汪，还有运营产品汪，他们需要一款更容易上手的推送软件，至少不需要番羽墙。于是自己开发一个很有必要。\n\n为最大程度降低用户使用门槛，同时保证用户信息的安全，我们用了 LDAP 账户登陆，严格控制权限，以及 HTTPS 协议开发。下面提一提 LDAP 这个东西。\n\n## LDAP 是什么\n\n[LDAP维基百科](https://zh.wikipedia.org/wiki/%E8%BD%BB%E5%9E%8B%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE)\n\n简单地讲，它是以目录树的方式存放账户信息。\n\n这次项目中，我们不希望用户重新注册账户，而是采用原有的用户体系，这样对单点登录以及权限控制的好处不严而喻, LDAP 协议呼之欲出。\n\n\n## virtualenv 下安装 python-ldap\n\n我们采用 Python 开发，这就需要 python-ldap 的帮助了, 记下安装笔记的好处是下次不用在此纠结太长时间。\n\n```\napt-get install libsasl2-dev python-dev libldap2-dev libssl-dev\npip install python-ldap\n```\n\n## 身份验证\n\n```\n# LDAP 服务的域名和端口\nSERVER_NAME = 'xxxx'\nSERVER_PORT = xxx\ntry:\n    conn = ldap.open(SERVER_NAME, SERVER_PORT)  \n    conn.protocol_version = ldap.VERSION3 #设置ldap协议版本 \n    username = \"user=xxx,dc=company,dc=com\" #身份信息\n    password = \"xxx\" #访问密码\n    conn.simple_bind_s(username,password) # 开始绑定，验证成功的话不会抛出异常\nexcept ldap.LDAPError, e: #捕获出错信息\n    print e\n```\n\n## 一点感悟\n\n鄙人觉得，技术领导要带领项目成长, 除了有责任把控项目风险，推进项目进度。\n还必须要花很多的心血在驾驭技术上,  身先士卒去调研可行性, 以及做技术攻关，\n而非命令式地分配任务，让同事干活, 只问责结果。\n否则很容易导致凝聚力不足,团队技术氛围不足，这样的团队易消极，也易滋生失败的项目。\n然而在天朝, 很多人存在一个潜意识:写好代码是为了以后不写代码，这种阶级思想让我反感。\n\n以前看过一个新闻, 硅谷在面试技术 VP ，仍然要求其在各位工程师面前手写代码，以此作为面试的重要环节, 不得不点赞。\n\n","slug":"2015-10-01-python-shi-yong-ldap","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgda60040nctjvyyea7vn","content":"<h2 id=\"写在开头\"><a href=\"#写在开头\" class=\"headerlink\" title=\"写在开头\"></a>写在开头</h2><p>过去的两个多星期，几位小伙伴同心协力完成一个自研的，类似<a href=\"http://pushover.net\" target=\"_blank\" rel=\"noopener\">pushover</a>的产品。感谢 Leader 的信任，让我在负责开发的同时也兼顾了一把项目经理。谢谢 IOS, Android 客户端的兄弟，设计师的支持，还有一位实习生，开心看到他的点滴成长。</p>\n<p>提下背景，我们之前使用 <code>pushover</code> 来做报警推送，但是它对天朝用户不友好，Android 用户需要翻墙才能使用，有时候不稳定，体现为会收不到信息。pushove 需要付费。我们的受众不仅有程序汪，还有运营产品汪，他们需要一款更容易上手的推送软件，至少不需要番羽墙。于是自己开发一个很有必要。</p>\n<p>为最大程度降低用户使用门槛，同时保证用户信息的安全，我们用了 LDAP 账户登陆，严格控制权限，以及 HTTPS 协议开发。下面提一提 LDAP 这个东西。</p>\n<h2 id=\"LDAP-是什么\"><a href=\"#LDAP-是什么\" class=\"headerlink\" title=\"LDAP 是什么\"></a>LDAP 是什么</h2><p><a href=\"https://zh.wikipedia.org/wiki/%E8%BD%BB%E5%9E%8B%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE\" target=\"_blank\" rel=\"noopener\">LDAP维基百科</a></p>\n<p>简单地讲，它是以目录树的方式存放账户信息。</p>\n<p>这次项目中，我们不希望用户重新注册账户，而是采用原有的用户体系，这样对单点登录以及权限控制的好处不严而喻, LDAP 协议呼之欲出。</p>\n<h2 id=\"virtualenv-下安装-python-ldap\"><a href=\"#virtualenv-下安装-python-ldap\" class=\"headerlink\" title=\"virtualenv 下安装 python-ldap\"></a>virtualenv 下安装 python-ldap</h2><p>我们采用 Python 开发，这就需要 python-ldap 的帮助了, 记下安装笔记的好处是下次不用在此纠结太长时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get install libsasl2-dev python-dev libldap2-dev libssl-dev</span><br><span class=\"line\">pip install python-ldap</span><br></pre></td></tr></table></figure>\n<h2 id=\"身份验证\"><a href=\"#身份验证\" class=\"headerlink\" title=\"身份验证\"></a>身份验证</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># LDAP 服务的域名和端口</span><br><span class=\"line\">SERVER_NAME = &apos;xxxx&apos;</span><br><span class=\"line\">SERVER_PORT = xxx</span><br><span class=\"line\">try:</span><br><span class=\"line\">    conn = ldap.open(SERVER_NAME, SERVER_PORT)  </span><br><span class=\"line\">    conn.protocol_version = ldap.VERSION3 #设置ldap协议版本 </span><br><span class=\"line\">    username = &quot;user=xxx,dc=company,dc=com&quot; #身份信息</span><br><span class=\"line\">    password = &quot;xxx&quot; #访问密码</span><br><span class=\"line\">    conn.simple_bind_s(username,password) # 开始绑定，验证成功的话不会抛出异常</span><br><span class=\"line\">except ldap.LDAPError, e: #捕获出错信息</span><br><span class=\"line\">    print e</span><br></pre></td></tr></table></figure>\n<h2 id=\"一点感悟\"><a href=\"#一点感悟\" class=\"headerlink\" title=\"一点感悟\"></a>一点感悟</h2><p>鄙人觉得，技术领导要带领项目成长, 除了有责任把控项目风险，推进项目进度。<br>还必须要花很多的心血在驾驭技术上,  身先士卒去调研可行性, 以及做技术攻关，<br>而非命令式地分配任务，让同事干活, 只问责结果。<br>否则很容易导致凝聚力不足,团队技术氛围不足，这样的团队易消极，也易滋生失败的项目。<br>然而在天朝, 很多人存在一个潜意识:写好代码是为了以后不写代码，这种阶级思想让我反感。</p>\n<p>以前看过一个新闻, 硅谷在面试技术 VP ，仍然要求其在各位工程师面前手写代码，以此作为面试的重要环节, 不得不点赞。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"写在开头\"><a href=\"#写在开头\" class=\"headerlink\" title=\"写在开头\"></a>写在开头</h2><p>过去的两个多星期，几位小伙伴同心协力完成一个自研的，类似<a href=\"http://pushover.net\" target=\"_blank\" rel=\"noopener\">pushover</a>的产品。感谢 Leader 的信任，让我在负责开发的同时也兼顾了一把项目经理。谢谢 IOS, Android 客户端的兄弟，设计师的支持，还有一位实习生，开心看到他的点滴成长。</p>\n<p>提下背景，我们之前使用 <code>pushover</code> 来做报警推送，但是它对天朝用户不友好，Android 用户需要翻墙才能使用，有时候不稳定，体现为会收不到信息。pushove 需要付费。我们的受众不仅有程序汪，还有运营产品汪，他们需要一款更容易上手的推送软件，至少不需要番羽墙。于是自己开发一个很有必要。</p>\n<p>为最大程度降低用户使用门槛，同时保证用户信息的安全，我们用了 LDAP 账户登陆，严格控制权限，以及 HTTPS 协议开发。下面提一提 LDAP 这个东西。</p>\n<h2 id=\"LDAP-是什么\"><a href=\"#LDAP-是什么\" class=\"headerlink\" title=\"LDAP 是什么\"></a>LDAP 是什么</h2><p><a href=\"https://zh.wikipedia.org/wiki/%E8%BD%BB%E5%9E%8B%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE\" target=\"_blank\" rel=\"noopener\">LDAP维基百科</a></p>\n<p>简单地讲，它是以目录树的方式存放账户信息。</p>\n<p>这次项目中，我们不希望用户重新注册账户，而是采用原有的用户体系，这样对单点登录以及权限控制的好处不严而喻, LDAP 协议呼之欲出。</p>\n<h2 id=\"virtualenv-下安装-python-ldap\"><a href=\"#virtualenv-下安装-python-ldap\" class=\"headerlink\" title=\"virtualenv 下安装 python-ldap\"></a>virtualenv 下安装 python-ldap</h2><p>我们采用 Python 开发，这就需要 python-ldap 的帮助了, 记下安装笔记的好处是下次不用在此纠结太长时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get install libsasl2-dev python-dev libldap2-dev libssl-dev</span><br><span class=\"line\">pip install python-ldap</span><br></pre></td></tr></table></figure>\n<h2 id=\"身份验证\"><a href=\"#身份验证\" class=\"headerlink\" title=\"身份验证\"></a>身份验证</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># LDAP 服务的域名和端口</span><br><span class=\"line\">SERVER_NAME = &apos;xxxx&apos;</span><br><span class=\"line\">SERVER_PORT = xxx</span><br><span class=\"line\">try:</span><br><span class=\"line\">    conn = ldap.open(SERVER_NAME, SERVER_PORT)  </span><br><span class=\"line\">    conn.protocol_version = ldap.VERSION3 #设置ldap协议版本 </span><br><span class=\"line\">    username = &quot;user=xxx,dc=company,dc=com&quot; #身份信息</span><br><span class=\"line\">    password = &quot;xxx&quot; #访问密码</span><br><span class=\"line\">    conn.simple_bind_s(username,password) # 开始绑定，验证成功的话不会抛出异常</span><br><span class=\"line\">except ldap.LDAPError, e: #捕获出错信息</span><br><span class=\"line\">    print e</span><br></pre></td></tr></table></figure>\n<h2 id=\"一点感悟\"><a href=\"#一点感悟\" class=\"headerlink\" title=\"一点感悟\"></a>一点感悟</h2><p>鄙人觉得，技术领导要带领项目成长, 除了有责任把控项目风险，推进项目进度。<br>还必须要花很多的心血在驾驭技术上,  身先士卒去调研可行性, 以及做技术攻关，<br>而非命令式地分配任务，让同事干活, 只问责结果。<br>否则很容易导致凝聚力不足,团队技术氛围不足，这样的团队易消极，也易滋生失败的项目。<br>然而在天朝, 很多人存在一个潜意识:写好代码是为了以后不写代码，这种阶级思想让我反感。</p>\n<p>以前看过一个新闻, 硅谷在面试技术 VP ，仍然要求其在各位工程师面前手写代码，以此作为面试的重要环节, 不得不点赞。</p>\n"},{"layout":"post","title":"记录使用 Flask 的点滴","date":"2015-10-06T05:21:00.000Z","comments":1,"description":"flask 经验","_content":"\n喜欢 Flask 经典的 RestFul 设计风格，以及它与 Gevent 的优雅结合，可以帮助我们轻松构建异步非阻塞应用，烂笔头记下一些较好的实践。\n\n* [消息反馈](#第一节)\n* [Flask 上下文](#第二节)\n* [注册 JinJia 模板过滤器](#第三节)\n* [itsdangerous 生成过期时间 Json 签名](#第四节)\n* [一种较好的项目组织方式](#第五节)\n* [BluePrint 的好](#第六节)\n* [Json 返回](#第七节)\n* [自定义出错页面](#第八节)\n* [WTF 跨站脚本防御](#第九节)\n\n\n<h3 id=\"第一节\">消息反馈</h3>\n\nFlask 提供了一个非常简单的方法来使用闪现系统向用户反馈信息。\n闪现系统使得在一个请求结束的时候记录一个信息，然后在且仅仅在下一个请求中访问这个数据。这通常配合一个布局模板实现\n\n[文档链接](http://docs.jinkan.org/docs/flask/patterns/flashing.html)\n\n```\n# 视图函数需要调用\nflash('your response message for user')\n\n# 前端页面调用\nfor message in get_flashed_messages()\n就可以输出反馈信息\n```\n\n<h3 id=\"第二节\">Flask 上下文</h3>\n\n有两种上下文：程序上下文，请求上下文\n\n* current_app： 程序级别上下文，当前激活程序的实例。\n* g: 请求级别的上下文\n* request: 是请求级别的上下文，封装了客户端发出的 Http 请求中的内容\n* session: 用户会话，用于存储请求之间需要记住的键值对\n\n<h3 id=\"第三节\">注册 JinJia 模板过滤</h3>\n\n```\ndef reverse_filter(s):\n    return s[::-1]\n\napp.jinja_env.filters['reverse'] = reverse_filter\n```\n\n<h3 id=\"第四节\">itsdangerous 生成过期时间 Json 签名</h3>\n\n```\nserialaizer = Serializer(SECRET_KEY, expires_in=EXPIRES)\ninfo = {'id':'xxx'}\nsession = serialaizer.dumps(info)\n\n# 判断 session 时间\ninfo = None\ntry:\n    info = serialaizer.loads(session)\nexcept Exception:\n    return jsonify(ERR_SESS_TIMEOUT)\n```\n\n用途：生成一个有时间限制的签名，用于API 访问的验证码，如果过期，提醒用户重新登录\n\n<h3 id=\"第五节\">一种较好的项目组织方式</h3>\n\n```\n▾ app/\n    ▾ controlers/\n        ▾ admin/                    #管理后台的蓝图控制器\n            ▾ forms/                #表单限制文件\n                __init__.py　　　　　\n                xx.py　　　         # blueprint 文件\n            __init__.py\n            administrator.py\n        ▾ api/                      # API 控制器\n            __init__.py\n        ▾ site/                     # 站点控制器\n            __init__.py             # blueprint 文件\n            xx.py\n        __init__.py\n        error.py\n    ▸ models/         # SQLAlchemy 的各类模型\n    ▸ static/         # 需要的静态资源，css, js, imgs\n    ▾ templates/　　　# 前端页面，跟 controller 分类一一对应\n        ▸ admin/\n        ▸ error/\n        ▸ site/\n    ▸ utilities/　　　　#  功能函数\n      __init__.py       #　初始化app需要的各种插件，比如 redis, db, 注册蓝图\nrun.py                  #　相当于 main 函数,创建 app, 执行app.run() 函数\nsettings.py             #　配置文件\n```\n\n<h3 id=\"第六节\">BluePrint 的好 </h3>\n\n每个 Blueprint 就像独立的 Application, 可以管理自己的模板, 路由, 反向路由url_for, 甚至是静态文件，最后统一挂载到 Application 下。从头到尾都是 RestFul。\n\n在创建 app (app/__init__.py) 的时候调用如下:\n\n```\nfrom app.controllers.site.console import console \napp.register_blueprint(console, url_prefix='/console')\n```\n\n视图文件 (app/controllers/site/console.py):\n\n```\nconsole = BLueprint('console', __name__)\n```\n\n<h3 id=\"第七节\">Json 返回</h3>\n\n```\nfrom flask import jsonify\nreturn jsonify({'code': 0})\n```\n\n<h3 id=\"第八节\">自定义出错页面</h3>\n\n```\n@app.errorhandler(404)\ndef not_found(error):\n    return render_template('404.html'), 404\n\n@app.errorhandler(500)\ndef crash(error):\n    return render_template('5xx.html'), 500\n```\n\n<h3 id=\"第九节\">WTF 跨站脚本防御</h3>\n\nFlask-WTF 能保护表单免受跨站请求伪造的攻击,恶意网站把请求发送到被攻击者已经登录的其他玩战会引发 CSRF 攻击\n\n* app config 文件中，开启 CSRF 开关并配置密钥\n\n```\nCSRF_ENABLED = True\nSECRET_KEY = 'you-will-never-guess'\n```\n\n* 表单的定义\n\n```\nfrom flask.ext.wtf import Form, TextField, BooleanField\nfrom flask.ext.wtf import Required\nclass LoginForm(Form):\n    openid = TextField('openid', validators = [Required()])\n    remember_me = BooleanField('remember_me', default = False)\n```\n\n* 页面渲染\n\n```\n<form action=\"\" method=\"post\" name=\"login\">\n    form.hidden_tag()\n    <p> Please enter your OpenID:form.openid(size=80)<br></p>\n    <p>form.remember_me </p>\n    <p><input type=\"submit\" value=\"Sign In\"></p>\n</form>\n```\n\n* 控制器函数\n\n```\n@app.route('/login', methods = ['GET', 'POST'])\ndef login():\n    form = LoginForm()\n    if form.validate_on_submit():\n        flash('Login requested for OpenID=\"' + form.openid.data))\n        return redirect('/index')\n    return render_template('login.html', title = 'Sign In',form = form)\n```\n\n我们在配置中开启了CSRF(跨站伪造请求)功能，模板参数 form.hidden_tag() 会被替换成一个具有防止CSRF功能的隐藏表单字段。 在开启了CSRF功能后，所有模板的表单中都需要添加这个模板参数\n","source":"_posts/2015-10-06-ji-lu-shi-yong-flaskde-dian-di.markdown","raw":"---\nlayout: post\ntitle: \"记录使用 Flask 的点滴\"\ndate: 2015-10-06 13:21\ncomments: true\ncategories: Programe\ndescription: flask 经验\n---\n\n喜欢 Flask 经典的 RestFul 设计风格，以及它与 Gevent 的优雅结合，可以帮助我们轻松构建异步非阻塞应用，烂笔头记下一些较好的实践。\n\n* [消息反馈](#第一节)\n* [Flask 上下文](#第二节)\n* [注册 JinJia 模板过滤器](#第三节)\n* [itsdangerous 生成过期时间 Json 签名](#第四节)\n* [一种较好的项目组织方式](#第五节)\n* [BluePrint 的好](#第六节)\n* [Json 返回](#第七节)\n* [自定义出错页面](#第八节)\n* [WTF 跨站脚本防御](#第九节)\n\n\n<h3 id=\"第一节\">消息反馈</h3>\n\nFlask 提供了一个非常简单的方法来使用闪现系统向用户反馈信息。\n闪现系统使得在一个请求结束的时候记录一个信息，然后在且仅仅在下一个请求中访问这个数据。这通常配合一个布局模板实现\n\n[文档链接](http://docs.jinkan.org/docs/flask/patterns/flashing.html)\n\n```\n# 视图函数需要调用\nflash('your response message for user')\n\n# 前端页面调用\nfor message in get_flashed_messages()\n就可以输出反馈信息\n```\n\n<h3 id=\"第二节\">Flask 上下文</h3>\n\n有两种上下文：程序上下文，请求上下文\n\n* current_app： 程序级别上下文，当前激活程序的实例。\n* g: 请求级别的上下文\n* request: 是请求级别的上下文，封装了客户端发出的 Http 请求中的内容\n* session: 用户会话，用于存储请求之间需要记住的键值对\n\n<h3 id=\"第三节\">注册 JinJia 模板过滤</h3>\n\n```\ndef reverse_filter(s):\n    return s[::-1]\n\napp.jinja_env.filters['reverse'] = reverse_filter\n```\n\n<h3 id=\"第四节\">itsdangerous 生成过期时间 Json 签名</h3>\n\n```\nserialaizer = Serializer(SECRET_KEY, expires_in=EXPIRES)\ninfo = {'id':'xxx'}\nsession = serialaizer.dumps(info)\n\n# 判断 session 时间\ninfo = None\ntry:\n    info = serialaizer.loads(session)\nexcept Exception:\n    return jsonify(ERR_SESS_TIMEOUT)\n```\n\n用途：生成一个有时间限制的签名，用于API 访问的验证码，如果过期，提醒用户重新登录\n\n<h3 id=\"第五节\">一种较好的项目组织方式</h3>\n\n```\n▾ app/\n    ▾ controlers/\n        ▾ admin/                    #管理后台的蓝图控制器\n            ▾ forms/                #表单限制文件\n                __init__.py　　　　　\n                xx.py　　　         # blueprint 文件\n            __init__.py\n            administrator.py\n        ▾ api/                      # API 控制器\n            __init__.py\n        ▾ site/                     # 站点控制器\n            __init__.py             # blueprint 文件\n            xx.py\n        __init__.py\n        error.py\n    ▸ models/         # SQLAlchemy 的各类模型\n    ▸ static/         # 需要的静态资源，css, js, imgs\n    ▾ templates/　　　# 前端页面，跟 controller 分类一一对应\n        ▸ admin/\n        ▸ error/\n        ▸ site/\n    ▸ utilities/　　　　#  功能函数\n      __init__.py       #　初始化app需要的各种插件，比如 redis, db, 注册蓝图\nrun.py                  #　相当于 main 函数,创建 app, 执行app.run() 函数\nsettings.py             #　配置文件\n```\n\n<h3 id=\"第六节\">BluePrint 的好 </h3>\n\n每个 Blueprint 就像独立的 Application, 可以管理自己的模板, 路由, 反向路由url_for, 甚至是静态文件，最后统一挂载到 Application 下。从头到尾都是 RestFul。\n\n在创建 app (app/__init__.py) 的时候调用如下:\n\n```\nfrom app.controllers.site.console import console \napp.register_blueprint(console, url_prefix='/console')\n```\n\n视图文件 (app/controllers/site/console.py):\n\n```\nconsole = BLueprint('console', __name__)\n```\n\n<h3 id=\"第七节\">Json 返回</h3>\n\n```\nfrom flask import jsonify\nreturn jsonify({'code': 0})\n```\n\n<h3 id=\"第八节\">自定义出错页面</h3>\n\n```\n@app.errorhandler(404)\ndef not_found(error):\n    return render_template('404.html'), 404\n\n@app.errorhandler(500)\ndef crash(error):\n    return render_template('5xx.html'), 500\n```\n\n<h3 id=\"第九节\">WTF 跨站脚本防御</h3>\n\nFlask-WTF 能保护表单免受跨站请求伪造的攻击,恶意网站把请求发送到被攻击者已经登录的其他玩战会引发 CSRF 攻击\n\n* app config 文件中，开启 CSRF 开关并配置密钥\n\n```\nCSRF_ENABLED = True\nSECRET_KEY = 'you-will-never-guess'\n```\n\n* 表单的定义\n\n```\nfrom flask.ext.wtf import Form, TextField, BooleanField\nfrom flask.ext.wtf import Required\nclass LoginForm(Form):\n    openid = TextField('openid', validators = [Required()])\n    remember_me = BooleanField('remember_me', default = False)\n```\n\n* 页面渲染\n\n```\n<form action=\"\" method=\"post\" name=\"login\">\n    form.hidden_tag()\n    <p> Please enter your OpenID:form.openid(size=80)<br></p>\n    <p>form.remember_me </p>\n    <p><input type=\"submit\" value=\"Sign In\"></p>\n</form>\n```\n\n* 控制器函数\n\n```\n@app.route('/login', methods = ['GET', 'POST'])\ndef login():\n    form = LoginForm()\n    if form.validate_on_submit():\n        flash('Login requested for OpenID=\"' + form.openid.data))\n        return redirect('/index')\n    return render_template('login.html', title = 'Sign In',form = form)\n```\n\n我们在配置中开启了CSRF(跨站伪造请求)功能，模板参数 form.hidden_tag() 会被替换成一个具有防止CSRF功能的隐藏表单字段。 在开启了CSRF功能后，所有模板的表单中都需要添加这个模板参数\n","slug":"2015-10-06-ji-lu-shi-yong-flaskde-dian-di","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgda70042nctjbnzaad93","content":"<p>喜欢 Flask 经典的 RestFul 设计风格，以及它与 Gevent 的优雅结合，可以帮助我们轻松构建异步非阻塞应用，烂笔头记下一些较好的实践。</p>\n<ul>\n<li><a href=\"#第一节\">消息反馈</a></li>\n<li><a href=\"#第二节\">Flask 上下文</a></li>\n<li><a href=\"#第三节\">注册 JinJia 模板过滤器</a></li>\n<li><a href=\"#第四节\">itsdangerous 生成过期时间 Json 签名</a></li>\n<li><a href=\"#第五节\">一种较好的项目组织方式</a></li>\n<li><a href=\"#第六节\">BluePrint 的好</a></li>\n<li><a href=\"#第七节\">Json 返回</a></li>\n<li><a href=\"#第八节\">自定义出错页面</a></li>\n<li><a href=\"#第九节\">WTF 跨站脚本防御</a></li>\n</ul>\n<h3 id=\"第一节\">消息反馈</h3>\n\n<p>Flask 提供了一个非常简单的方法来使用闪现系统向用户反馈信息。<br>闪现系统使得在一个请求结束的时候记录一个信息，然后在且仅仅在下一个请求中访问这个数据。这通常配合一个布局模板实现</p>\n<p><a href=\"http://docs.jinkan.org/docs/flask/patterns/flashing.html\" target=\"_blank\" rel=\"noopener\">文档链接</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 视图函数需要调用</span><br><span class=\"line\">flash(&apos;your response message for user&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\"># 前端页面调用</span><br><span class=\"line\">for message in get_flashed_messages()</span><br><span class=\"line\">就可以输出反馈信息</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二节\">Flask 上下文</h3>\n\n<p>有两种上下文：程序上下文，请求上下文</p>\n<ul>\n<li>current_app： 程序级别上下文，当前激活程序的实例。</li>\n<li>g: 请求级别的上下文</li>\n<li>request: 是请求级别的上下文，封装了客户端发出的 Http 请求中的内容</li>\n<li>session: 用户会话，用于存储请求之间需要记住的键值对</li>\n</ul>\n<h3 id=\"第三节\">注册 JinJia 模板过滤</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def reverse_filter(s):</span><br><span class=\"line\">    return s[::-1]</span><br><span class=\"line\"></span><br><span class=\"line\">app.jinja_env.filters[&apos;reverse&apos;] = reverse_filter</span><br></pre></td></tr></table></figure>\n<h3 id=\"第四节\">itsdangerous 生成过期时间 Json 签名</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">serialaizer = Serializer(SECRET_KEY, expires_in=EXPIRES)</span><br><span class=\"line\">info = &#123;&apos;id&apos;:&apos;xxx&apos;&#125;</span><br><span class=\"line\">session = serialaizer.dumps(info)</span><br><span class=\"line\"></span><br><span class=\"line\"># 判断 session 时间</span><br><span class=\"line\">info = None</span><br><span class=\"line\">try:</span><br><span class=\"line\">    info = serialaizer.loads(session)</span><br><span class=\"line\">except Exception:</span><br><span class=\"line\">    return jsonify(ERR_SESS_TIMEOUT)</span><br></pre></td></tr></table></figure>\n<p>用途：生成一个有时间限制的签名，用于API 访问的验证码，如果过期，提醒用户重新登录</p>\n<h3 id=\"第五节\">一种较好的项目组织方式</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">▾ app/</span><br><span class=\"line\">    ▾ controlers/</span><br><span class=\"line\">        ▾ admin/                    #管理后台的蓝图控制器</span><br><span class=\"line\">            ▾ forms/                #表单限制文件</span><br><span class=\"line\">                __init__.py　　　　　</span><br><span class=\"line\">                xx.py　　　         # blueprint 文件</span><br><span class=\"line\">            __init__.py</span><br><span class=\"line\">            administrator.py</span><br><span class=\"line\">        ▾ api/                      # API 控制器</span><br><span class=\"line\">            __init__.py</span><br><span class=\"line\">        ▾ site/                     # 站点控制器</span><br><span class=\"line\">            __init__.py             # blueprint 文件</span><br><span class=\"line\">            xx.py</span><br><span class=\"line\">        __init__.py</span><br><span class=\"line\">        error.py</span><br><span class=\"line\">    ▸ models/         # SQLAlchemy 的各类模型</span><br><span class=\"line\">    ▸ static/         # 需要的静态资源，css, js, imgs</span><br><span class=\"line\">    ▾ templates/　　　# 前端页面，跟 controller 分类一一对应</span><br><span class=\"line\">        ▸ admin/</span><br><span class=\"line\">        ▸ error/</span><br><span class=\"line\">        ▸ site/</span><br><span class=\"line\">    ▸ utilities/　　　　#  功能函数</span><br><span class=\"line\">      __init__.py       #　初始化app需要的各种插件，比如 redis, db, 注册蓝图</span><br><span class=\"line\">run.py                  #　相当于 main 函数,创建 app, 执行app.run() 函数</span><br><span class=\"line\">settings.py             #　配置文件</span><br></pre></td></tr></table></figure>\n<h3 id=\"第六节\">BluePrint 的好 </h3>\n\n<p>每个 Blueprint 就像独立的 Application, 可以管理自己的模板, 路由, 反向路由url_for, 甚至是静态文件，最后统一挂载到 Application 下。从头到尾都是 RestFul。</p>\n<p>在创建 app (app/<strong>init</strong>.py) 的时候调用如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from app.controllers.site.console import console </span><br><span class=\"line\">app.register_blueprint(console, url_prefix=&apos;/console&apos;)</span><br></pre></td></tr></table></figure>\n<p>视图文件 (app/controllers/site/console.py):</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console = BLueprint(&apos;console&apos;, __name__)</span><br></pre></td></tr></table></figure>\n<h3 id=\"第七节\">Json 返回</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from flask import jsonify</span><br><span class=\"line\">return jsonify(&#123;&apos;code&apos;: 0&#125;)</span><br></pre></td></tr></table></figure>\n<h3 id=\"第八节\">自定义出错页面</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@app.errorhandler(404)</span><br><span class=\"line\">def not_found(error):</span><br><span class=\"line\">    return render_template(&apos;404.html&apos;), 404</span><br><span class=\"line\"></span><br><span class=\"line\">@app.errorhandler(500)</span><br><span class=\"line\">def crash(error):</span><br><span class=\"line\">    return render_template(&apos;5xx.html&apos;), 500</span><br></pre></td></tr></table></figure>\n<h3 id=\"第九节\">WTF 跨站脚本防御</h3>\n\n<p>Flask-WTF 能保护表单免受跨站请求伪造的攻击,恶意网站把请求发送到被攻击者已经登录的其他玩战会引发 CSRF 攻击</p>\n<ul>\n<li>app config 文件中，开启 CSRF 开关并配置密钥</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CSRF_ENABLED = True</span><br><span class=\"line\">SECRET_KEY = &apos;you-will-never-guess&apos;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>表单的定义</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from flask.ext.wtf import Form, TextField, BooleanField</span><br><span class=\"line\">from flask.ext.wtf import Required</span><br><span class=\"line\">class LoginForm(Form):</span><br><span class=\"line\">    openid = TextField(&apos;openid&apos;, validators = [Required()])</span><br><span class=\"line\">    remember_me = BooleanField(&apos;remember_me&apos;, default = False)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>页面渲染</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;form action=&quot;&quot; method=&quot;post&quot; name=&quot;login&quot;&gt;</span><br><span class=\"line\">    form.hidden_tag()</span><br><span class=\"line\">    &lt;p&gt; Please enter your OpenID:form.openid(size=80)&lt;br&gt;&lt;/p&gt;</span><br><span class=\"line\">    &lt;p&gt;form.remember_me &lt;/p&gt;</span><br><span class=\"line\">    &lt;p&gt;&lt;input type=&quot;submit&quot; value=&quot;Sign In&quot;&gt;&lt;/p&gt;</span><br><span class=\"line\">&lt;/form&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>控制器函数</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@app.route(&apos;/login&apos;, methods = [&apos;GET&apos;, &apos;POST&apos;])</span><br><span class=\"line\">def login():</span><br><span class=\"line\">    form = LoginForm()</span><br><span class=\"line\">    if form.validate_on_submit():</span><br><span class=\"line\">        flash(&apos;Login requested for OpenID=&quot;&apos; + form.openid.data))</span><br><span class=\"line\">        return redirect(&apos;/index&apos;)</span><br><span class=\"line\">    return render_template(&apos;login.html&apos;, title = &apos;Sign In&apos;,form = form)</span><br></pre></td></tr></table></figure>\n<p>我们在配置中开启了CSRF(跨站伪造请求)功能，模板参数 form.hidden_tag() 会被替换成一个具有防止CSRF功能的隐藏表单字段。 在开启了CSRF功能后，所有模板的表单中都需要添加这个模板参数</p>\n","site":{"data":{}},"excerpt":"","more":"<p>喜欢 Flask 经典的 RestFul 设计风格，以及它与 Gevent 的优雅结合，可以帮助我们轻松构建异步非阻塞应用，烂笔头记下一些较好的实践。</p>\n<ul>\n<li><a href=\"#第一节\">消息反馈</a></li>\n<li><a href=\"#第二节\">Flask 上下文</a></li>\n<li><a href=\"#第三节\">注册 JinJia 模板过滤器</a></li>\n<li><a href=\"#第四节\">itsdangerous 生成过期时间 Json 签名</a></li>\n<li><a href=\"#第五节\">一种较好的项目组织方式</a></li>\n<li><a href=\"#第六节\">BluePrint 的好</a></li>\n<li><a href=\"#第七节\">Json 返回</a></li>\n<li><a href=\"#第八节\">自定义出错页面</a></li>\n<li><a href=\"#第九节\">WTF 跨站脚本防御</a></li>\n</ul>\n<h3 id=\"第一节\">消息反馈</h3>\n\n<p>Flask 提供了一个非常简单的方法来使用闪现系统向用户反馈信息。<br>闪现系统使得在一个请求结束的时候记录一个信息，然后在且仅仅在下一个请求中访问这个数据。这通常配合一个布局模板实现</p>\n<p><a href=\"http://docs.jinkan.org/docs/flask/patterns/flashing.html\" target=\"_blank\" rel=\"noopener\">文档链接</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 视图函数需要调用</span><br><span class=\"line\">flash(&apos;your response message for user&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\"># 前端页面调用</span><br><span class=\"line\">for message in get_flashed_messages()</span><br><span class=\"line\">就可以输出反馈信息</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二节\">Flask 上下文</h3>\n\n<p>有两种上下文：程序上下文，请求上下文</p>\n<ul>\n<li>current_app： 程序级别上下文，当前激活程序的实例。</li>\n<li>g: 请求级别的上下文</li>\n<li>request: 是请求级别的上下文，封装了客户端发出的 Http 请求中的内容</li>\n<li>session: 用户会话，用于存储请求之间需要记住的键值对</li>\n</ul>\n<h3 id=\"第三节\">注册 JinJia 模板过滤</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def reverse_filter(s):</span><br><span class=\"line\">    return s[::-1]</span><br><span class=\"line\"></span><br><span class=\"line\">app.jinja_env.filters[&apos;reverse&apos;] = reverse_filter</span><br></pre></td></tr></table></figure>\n<h3 id=\"第四节\">itsdangerous 生成过期时间 Json 签名</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">serialaizer = Serializer(SECRET_KEY, expires_in=EXPIRES)</span><br><span class=\"line\">info = &#123;&apos;id&apos;:&apos;xxx&apos;&#125;</span><br><span class=\"line\">session = serialaizer.dumps(info)</span><br><span class=\"line\"></span><br><span class=\"line\"># 判断 session 时间</span><br><span class=\"line\">info = None</span><br><span class=\"line\">try:</span><br><span class=\"line\">    info = serialaizer.loads(session)</span><br><span class=\"line\">except Exception:</span><br><span class=\"line\">    return jsonify(ERR_SESS_TIMEOUT)</span><br></pre></td></tr></table></figure>\n<p>用途：生成一个有时间限制的签名，用于API 访问的验证码，如果过期，提醒用户重新登录</p>\n<h3 id=\"第五节\">一种较好的项目组织方式</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">▾ app/</span><br><span class=\"line\">    ▾ controlers/</span><br><span class=\"line\">        ▾ admin/                    #管理后台的蓝图控制器</span><br><span class=\"line\">            ▾ forms/                #表单限制文件</span><br><span class=\"line\">                __init__.py　　　　　</span><br><span class=\"line\">                xx.py　　　         # blueprint 文件</span><br><span class=\"line\">            __init__.py</span><br><span class=\"line\">            administrator.py</span><br><span class=\"line\">        ▾ api/                      # API 控制器</span><br><span class=\"line\">            __init__.py</span><br><span class=\"line\">        ▾ site/                     # 站点控制器</span><br><span class=\"line\">            __init__.py             # blueprint 文件</span><br><span class=\"line\">            xx.py</span><br><span class=\"line\">        __init__.py</span><br><span class=\"line\">        error.py</span><br><span class=\"line\">    ▸ models/         # SQLAlchemy 的各类模型</span><br><span class=\"line\">    ▸ static/         # 需要的静态资源，css, js, imgs</span><br><span class=\"line\">    ▾ templates/　　　# 前端页面，跟 controller 分类一一对应</span><br><span class=\"line\">        ▸ admin/</span><br><span class=\"line\">        ▸ error/</span><br><span class=\"line\">        ▸ site/</span><br><span class=\"line\">    ▸ utilities/　　　　#  功能函数</span><br><span class=\"line\">      __init__.py       #　初始化app需要的各种插件，比如 redis, db, 注册蓝图</span><br><span class=\"line\">run.py                  #　相当于 main 函数,创建 app, 执行app.run() 函数</span><br><span class=\"line\">settings.py             #　配置文件</span><br></pre></td></tr></table></figure>\n<h3 id=\"第六节\">BluePrint 的好 </h3>\n\n<p>每个 Blueprint 就像独立的 Application, 可以管理自己的模板, 路由, 反向路由url_for, 甚至是静态文件，最后统一挂载到 Application 下。从头到尾都是 RestFul。</p>\n<p>在创建 app (app/<strong>init</strong>.py) 的时候调用如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from app.controllers.site.console import console </span><br><span class=\"line\">app.register_blueprint(console, url_prefix=&apos;/console&apos;)</span><br></pre></td></tr></table></figure>\n<p>视图文件 (app/controllers/site/console.py):</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console = BLueprint(&apos;console&apos;, __name__)</span><br></pre></td></tr></table></figure>\n<h3 id=\"第七节\">Json 返回</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from flask import jsonify</span><br><span class=\"line\">return jsonify(&#123;&apos;code&apos;: 0&#125;)</span><br></pre></td></tr></table></figure>\n<h3 id=\"第八节\">自定义出错页面</h3>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@app.errorhandler(404)</span><br><span class=\"line\">def not_found(error):</span><br><span class=\"line\">    return render_template(&apos;404.html&apos;), 404</span><br><span class=\"line\"></span><br><span class=\"line\">@app.errorhandler(500)</span><br><span class=\"line\">def crash(error):</span><br><span class=\"line\">    return render_template(&apos;5xx.html&apos;), 500</span><br></pre></td></tr></table></figure>\n<h3 id=\"第九节\">WTF 跨站脚本防御</h3>\n\n<p>Flask-WTF 能保护表单免受跨站请求伪造的攻击,恶意网站把请求发送到被攻击者已经登录的其他玩战会引发 CSRF 攻击</p>\n<ul>\n<li>app config 文件中，开启 CSRF 开关并配置密钥</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CSRF_ENABLED = True</span><br><span class=\"line\">SECRET_KEY = &apos;you-will-never-guess&apos;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>表单的定义</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from flask.ext.wtf import Form, TextField, BooleanField</span><br><span class=\"line\">from flask.ext.wtf import Required</span><br><span class=\"line\">class LoginForm(Form):</span><br><span class=\"line\">    openid = TextField(&apos;openid&apos;, validators = [Required()])</span><br><span class=\"line\">    remember_me = BooleanField(&apos;remember_me&apos;, default = False)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>页面渲染</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;form action=&quot;&quot; method=&quot;post&quot; name=&quot;login&quot;&gt;</span><br><span class=\"line\">    form.hidden_tag()</span><br><span class=\"line\">    &lt;p&gt; Please enter your OpenID:form.openid(size=80)&lt;br&gt;&lt;/p&gt;</span><br><span class=\"line\">    &lt;p&gt;form.remember_me &lt;/p&gt;</span><br><span class=\"line\">    &lt;p&gt;&lt;input type=&quot;submit&quot; value=&quot;Sign In&quot;&gt;&lt;/p&gt;</span><br><span class=\"line\">&lt;/form&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>控制器函数</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@app.route(&apos;/login&apos;, methods = [&apos;GET&apos;, &apos;POST&apos;])</span><br><span class=\"line\">def login():</span><br><span class=\"line\">    form = LoginForm()</span><br><span class=\"line\">    if form.validate_on_submit():</span><br><span class=\"line\">        flash(&apos;Login requested for OpenID=&quot;&apos; + form.openid.data))</span><br><span class=\"line\">        return redirect(&apos;/index&apos;)</span><br><span class=\"line\">    return render_template(&apos;login.html&apos;, title = &apos;Sign In&apos;,form = form)</span><br></pre></td></tr></table></figure>\n<p>我们在配置中开启了CSRF(跨站伪造请求)功能，模板参数 form.hidden_tag() 会被替换成一个具有防止CSRF功能的隐藏表单字段。 在开启了CSRF功能后，所有模板的表单中都需要添加这个模板参数</p>\n"},{"layout":"post","title":"给 Tengine 加上 lua 拓展","date":"2015-10-29T14:45:00.000Z","comments":1,"description":"Tengine, lua-nginx-module","_content":"\n\nTengine 能动态加载第三方模块，成为我们青睐的选择，我们可以编译动态链接文件，而不需要重新安装 Nginx, 这对在线增强 webservice 很有帮助. \n感谢 agentzh, [lua-nginx-module](https://github.com/openresty/lua-nginx-module), 可以让我们使用 lua 增强nginx的功能, 不言而喻，我们必须现有 Lua 的环境，才能运行 ngx_lua;\n\n## 编译 nginx_lua\n\n官方推荐使用LuaJit,虽然也可以使用Lua，但是即时编译(Just-In-Time Compiler)混合了动态编译和静态编译，一句一句编译源代码，但是会将翻译过的代码缓存起来以降低性能损耗。\n\n* 下载安装\n\n```\nwget http://luajit.org/download/LuaJIT-2.0.4.tar.gz\ntar zxvf LuaJIT-2.0.4.tar.gz\ncd LuaJIT-2.0.4\nmake\nmake install\n```\n\n* 设置环境变量\n\n```\nexport LUAJIT_LIB=/usr/local/lib\nexport LUAJIT_INC=/usr/local/include/luajit-2.0\n```\n\n\n* 然后编译ngx-lua-module.so\n\n```\n/usr/local/share/dso_tool/ --path=/Path/To/Lua-Nginx-module\n```\n\n* 设置动态库\n\n```\n> echo \"/usr/local/lib\" > /etc/ld.so.conf.d/usr_local_lib.conf\n> ldconfig\n```\n\n### 在 Tengine 中启用\n\n`nginx.conf` 中先加载动态库\n\n```\ndso {\n    load ngx_load_module;\n}\n```\n\n在 nginx.conf 中添加\n\n```\nlua_code_cache on/off;\n```\n\n来开启是否将代码缓存，所以每次变更 \"*.lua\" 文件时，必须重启 nginx 才可生效.\n\n\n### 使用 ngx_lua_waf\n\n有了基础环境，我们要开始发挥 ngx lua 的优点了, 我用他安装了 waf (web application firework)\n[ngx_lua_waf](https://github.com/loveshell/ngx_lua_waf)，这是一个通过 ngx_lua 编写的 web 应用防火墙, 在使用过程中也发现了 ngx_lua_waf 一个bug，给他提了一个[Pull Request](https://github.com/loveshell/ngx_lua_waf/pull/70), 码农生涯第一个 PR.\n\n\n----\n\n注：\n静态编译的程序在执行前全部被翻译为机器码，而动态直译执行的则是一句一句边运行边翻译。\n\n\n\n","source":"_posts/2015-10-29-gei-tengine-jia-shang-lua-tuo-zhan.markdown","raw":"---\nlayout: post\ntitle: \"给 Tengine 加上 lua 拓展\"\ndate: 2015-10-29 22:45\ncomments: true\ncategories: System\ndescription: Tengine, lua-nginx-module\n---\n\n\nTengine 能动态加载第三方模块，成为我们青睐的选择，我们可以编译动态链接文件，而不需要重新安装 Nginx, 这对在线增强 webservice 很有帮助. \n感谢 agentzh, [lua-nginx-module](https://github.com/openresty/lua-nginx-module), 可以让我们使用 lua 增强nginx的功能, 不言而喻，我们必须现有 Lua 的环境，才能运行 ngx_lua;\n\n## 编译 nginx_lua\n\n官方推荐使用LuaJit,虽然也可以使用Lua，但是即时编译(Just-In-Time Compiler)混合了动态编译和静态编译，一句一句编译源代码，但是会将翻译过的代码缓存起来以降低性能损耗。\n\n* 下载安装\n\n```\nwget http://luajit.org/download/LuaJIT-2.0.4.tar.gz\ntar zxvf LuaJIT-2.0.4.tar.gz\ncd LuaJIT-2.0.4\nmake\nmake install\n```\n\n* 设置环境变量\n\n```\nexport LUAJIT_LIB=/usr/local/lib\nexport LUAJIT_INC=/usr/local/include/luajit-2.0\n```\n\n\n* 然后编译ngx-lua-module.so\n\n```\n/usr/local/share/dso_tool/ --path=/Path/To/Lua-Nginx-module\n```\n\n* 设置动态库\n\n```\n> echo \"/usr/local/lib\" > /etc/ld.so.conf.d/usr_local_lib.conf\n> ldconfig\n```\n\n### 在 Tengine 中启用\n\n`nginx.conf` 中先加载动态库\n\n```\ndso {\n    load ngx_load_module;\n}\n```\n\n在 nginx.conf 中添加\n\n```\nlua_code_cache on/off;\n```\n\n来开启是否将代码缓存，所以每次变更 \"*.lua\" 文件时，必须重启 nginx 才可生效.\n\n\n### 使用 ngx_lua_waf\n\n有了基础环境，我们要开始发挥 ngx lua 的优点了, 我用他安装了 waf (web application firework)\n[ngx_lua_waf](https://github.com/loveshell/ngx_lua_waf)，这是一个通过 ngx_lua 编写的 web 应用防火墙, 在使用过程中也发现了 ngx_lua_waf 一个bug，给他提了一个[Pull Request](https://github.com/loveshell/ngx_lua_waf/pull/70), 码农生涯第一个 PR.\n\n\n----\n\n注：\n静态编译的程序在执行前全部被翻译为机器码，而动态直译执行的则是一句一句边运行边翻译。\n\n\n\n","slug":"2015-10-29-gei-tengine-jia-shang-lua-tuo-zhan","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgda90044nctj8skehxzw","content":"<p>Tengine 能动态加载第三方模块，成为我们青睐的选择，我们可以编译动态链接文件，而不需要重新安装 Nginx, 这对在线增强 webservice 很有帮助.<br>感谢 agentzh, <a href=\"https://github.com/openresty/lua-nginx-module\" target=\"_blank\" rel=\"noopener\">lua-nginx-module</a>, 可以让我们使用 lua 增强nginx的功能, 不言而喻，我们必须现有 Lua 的环境，才能运行 ngx_lua;</p>\n<h2 id=\"编译-nginx-lua\"><a href=\"#编译-nginx-lua\" class=\"headerlink\" title=\"编译 nginx_lua\"></a>编译 nginx_lua</h2><p>官方推荐使用LuaJit,虽然也可以使用Lua，但是即时编译(Just-In-Time Compiler)混合了动态编译和静态编译，一句一句编译源代码，但是会将翻译过的代码缓存起来以降低性能损耗。</p>\n<ul>\n<li>下载安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://luajit.org/download/LuaJIT-2.0.4.tar.gz</span><br><span class=\"line\">tar zxvf LuaJIT-2.0.4.tar.gz</span><br><span class=\"line\">cd LuaJIT-2.0.4</span><br><span class=\"line\">make</span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<ul>\n<li>设置环境变量</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export LUAJIT_LIB=/usr/local/lib</span><br><span class=\"line\">export LUAJIT_INC=/usr/local/include/luajit-2.0</span><br></pre></td></tr></table></figure>\n<ul>\n<li>然后编译ngx-lua-module.so</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/local/share/dso_tool/ --path=/Path/To/Lua-Nginx-module</span><br></pre></td></tr></table></figure>\n<ul>\n<li>设置动态库</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; echo &quot;/usr/local/lib&quot; &gt; /etc/ld.so.conf.d/usr_local_lib.conf</span><br><span class=\"line\">&gt; ldconfig</span><br></pre></td></tr></table></figure>\n<h3 id=\"在-Tengine-中启用\"><a href=\"#在-Tengine-中启用\" class=\"headerlink\" title=\"在 Tengine 中启用\"></a>在 Tengine 中启用</h3><p><code>nginx.conf</code> 中先加载动态库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dso &#123;</span><br><span class=\"line\">    load ngx_load_module;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在 nginx.conf 中添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lua_code_cache on/off;</span><br></pre></td></tr></table></figure>\n<p>来开启是否将代码缓存，所以每次变更 “*.lua” 文件时，必须重启 nginx 才可生效.</p>\n<h3 id=\"使用-ngx-lua-waf\"><a href=\"#使用-ngx-lua-waf\" class=\"headerlink\" title=\"使用 ngx_lua_waf\"></a>使用 ngx_lua_waf</h3><p>有了基础环境，我们要开始发挥 ngx lua 的优点了, 我用他安装了 waf (web application firework)<br><a href=\"https://github.com/loveshell/ngx_lua_waf\" target=\"_blank\" rel=\"noopener\">ngx_lua_waf</a>，这是一个通过 ngx_lua 编写的 web 应用防火墙, 在使用过程中也发现了 ngx_lua_waf 一个bug，给他提了一个<a href=\"https://github.com/loveshell/ngx_lua_waf/pull/70\" target=\"_blank\" rel=\"noopener\">Pull Request</a>, 码农生涯第一个 PR.</p>\n<hr>\n<p>注：<br>静态编译的程序在执行前全部被翻译为机器码，而动态直译执行的则是一句一句边运行边翻译。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Tengine 能动态加载第三方模块，成为我们青睐的选择，我们可以编译动态链接文件，而不需要重新安装 Nginx, 这对在线增强 webservice 很有帮助.<br>感谢 agentzh, <a href=\"https://github.com/openresty/lua-nginx-module\" target=\"_blank\" rel=\"noopener\">lua-nginx-module</a>, 可以让我们使用 lua 增强nginx的功能, 不言而喻，我们必须现有 Lua 的环境，才能运行 ngx_lua;</p>\n<h2 id=\"编译-nginx-lua\"><a href=\"#编译-nginx-lua\" class=\"headerlink\" title=\"编译 nginx_lua\"></a>编译 nginx_lua</h2><p>官方推荐使用LuaJit,虽然也可以使用Lua，但是即时编译(Just-In-Time Compiler)混合了动态编译和静态编译，一句一句编译源代码，但是会将翻译过的代码缓存起来以降低性能损耗。</p>\n<ul>\n<li>下载安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://luajit.org/download/LuaJIT-2.0.4.tar.gz</span><br><span class=\"line\">tar zxvf LuaJIT-2.0.4.tar.gz</span><br><span class=\"line\">cd LuaJIT-2.0.4</span><br><span class=\"line\">make</span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<ul>\n<li>设置环境变量</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export LUAJIT_LIB=/usr/local/lib</span><br><span class=\"line\">export LUAJIT_INC=/usr/local/include/luajit-2.0</span><br></pre></td></tr></table></figure>\n<ul>\n<li>然后编译ngx-lua-module.so</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/local/share/dso_tool/ --path=/Path/To/Lua-Nginx-module</span><br></pre></td></tr></table></figure>\n<ul>\n<li>设置动态库</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; echo &quot;/usr/local/lib&quot; &gt; /etc/ld.so.conf.d/usr_local_lib.conf</span><br><span class=\"line\">&gt; ldconfig</span><br></pre></td></tr></table></figure>\n<h3 id=\"在-Tengine-中启用\"><a href=\"#在-Tengine-中启用\" class=\"headerlink\" title=\"在 Tengine 中启用\"></a>在 Tengine 中启用</h3><p><code>nginx.conf</code> 中先加载动态库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dso &#123;</span><br><span class=\"line\">    load ngx_load_module;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在 nginx.conf 中添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lua_code_cache on/off;</span><br></pre></td></tr></table></figure>\n<p>来开启是否将代码缓存，所以每次变更 “*.lua” 文件时，必须重启 nginx 才可生效.</p>\n<h3 id=\"使用-ngx-lua-waf\"><a href=\"#使用-ngx-lua-waf\" class=\"headerlink\" title=\"使用 ngx_lua_waf\"></a>使用 ngx_lua_waf</h3><p>有了基础环境，我们要开始发挥 ngx lua 的优点了, 我用他安装了 waf (web application firework)<br><a href=\"https://github.com/loveshell/ngx_lua_waf\" target=\"_blank\" rel=\"noopener\">ngx_lua_waf</a>，这是一个通过 ngx_lua 编写的 web 应用防火墙, 在使用过程中也发现了 ngx_lua_waf 一个bug，给他提了一个<a href=\"https://github.com/loveshell/ngx_lua_waf/pull/70\" target=\"_blank\" rel=\"noopener\">Pull Request</a>, 码农生涯第一个 PR.</p>\n<hr>\n<p>注：<br>静态编译的程序在执行前全部被翻译为机器码，而动态直译执行的则是一句一句边运行边翻译。</p>\n"},{"layout":"post","title":"Gre 隧道与 Keepalived","date":"2015-12-05T02:29:00.000Z","comments":1,"description":"keepalived","_content":"\n这一篇文章是做了不少功课的。\n\n* [什么是 Gre 隧道](#第一节)\n* [什么是 Vrrp ](#第二节)\n* [KeepAlived 是什么](#第三节)\n* [用Keepalived 怎么玩](#第四节)\n* [附录](#第五节)\n\n\n<h3 id=\"第一节\">什么是 Gre 隧道 </h3>\n\nGRE 隧道是一种 IP-2-IP 的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在 IPv4/IPv6 网络中传输。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。Linux 上创建 GRE 隧道，需要 ip_gre 内核模块，它是Pv4 隧道的驱动程序。\n\n假设我有2台服务器，想做这两台之间创建 GRE 隧道\n\n* $server_A_ip 表示服务器A的IP\n* $server_B_ip 服务器B 的内网IP\n\n```\n# 在 A 机器上执行\n# 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP\nsudo ip link add gretap1 type gretap local $server_a_ip remote $server_b_ip \nsudo ip link set dev gretap1 up  # 启动该设备\nsudo ip addr add dev gretap1 10.1.1.2/24 # 给该设备一个虚拟网络地址\n\n# 在 B 机器上执行\n# 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP\nsudo ip link add gretap1 type gretap local $server_b_ip remote $server_a_ip \nsudo ip link set dev gretap1 up  # 启动该设备\nsudo ip addr add dev gretap1 10.1.1.3/24 # 给该设备一个虚拟网络地址\n```\n\n如果想停止或者删除上述网卡\n\n```\nip link set gretap1 down\nip tunnel del gretap1\n```\n\n至此点到点得隧道建立。\n\n\n<h3 id=\"第二节\">什么是 vrrp 协议 </h3>\n\nVRRP(Virtual Router Redundancy Protocol), 即虚拟路由冗余协议。是实现路由器高可用的容错协议。\n\n即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个 master 和多个 backup， 但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip），占有这个IP 的 master 实际负责 ARP 相应和转发 IP 数据包， 组中的其它路由器作为备份的角色处于待命状态。 master 会发组播消息，当 backup 在超时时间内收不到 vrrp 包时就认为 master 宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。\n\n\n<h3 id=\"第三节\"> Keepalived 是什么 </h3>\n\nKeepalived 是一个基于 VRRP 协议来实现的服务高可用方案，可以利用其来避免IP单点故障。\n\n* 一个经典的案例\n\n一个WEB服务至少会有2台服务器运行 Keepalived，一台为主服务器，一台为备份服务器, 但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。\n\n\n<h3 id=\"第四节\">怎么玩 Keepalived</h3>\n\n* 安装\n\n```\nsudo apt-get install keepalived\n```\n\n之前提到的，我们在 A, B 两台服务器建立起了 GRE 隧道了。 现在我们有一个虚拟的内网IP， 姑且叫做 $virtual_third_ip\n接着在 A 服务器上\n\n* 配置\n\n编辑服务器 A, B 的 `/etc/keepalived/keepalived.conf`\n\n```\n\nglobal_defs {\n    router_id LVS_DEVEL\n}\n\nvrrp_instance VI_1 {\n    state MASTER\n    interface gretap1 # 绑在建立起来的隧道上\n    virtual_router_id 51\n    # 优先级别,越高的设备会被弄成主设备, A,B 服务器要有所差别，其他都一样\n    priority 100          advert_int 1      # 广播时间间隔\n    authentication {  #  验证相关\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n        $virtual_third_ip dev eth0\n    }\n}\n```\n\n我们将服务器  A 作为 Master, 服务器 B 当做 Backup, 当服务器 A 需要停机的时候，$virtual_third_ip 就会漂移到服务器 B 上面。 我们两台机器都有相同配置的 Nginx 服务，就可以保障机器出现故障的时候，Nginx 服务丝毫不受影响。\n\n\n<h3 id=\"第五节\"> 附录 </h3>\n\n* [鸟哥的网络知识](http://linux.vbird.org/linux_server/0140networkcommand.php)\n* [GRE tuneling](http://www.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.tunnel.gre.html)\n* [VRRP](http://baike.baidu.com/link?url=N1-VGuzQC0PJ2bCnOzYn-XRTlN8eFGCvIJQlTI6KDL5Fx3EQxoRGTrxazb11jfZQqlfeA6q2Ka0VKRVEc0Kdu3GEyhqe1W_Ae2h0Tqu5NacIjOSaSnUVeOe-9QV5dB8q0Wv_uq8-vqdnQICt39UZFK)\n","source":"_posts/2015-12-05-gre-tuning-and-keepalived.markdown","raw":"---\nlayout: post\ntitle: \"Gre 隧道与 Keepalived\"\ndate: 2015-12-05 10:29\ncomments: true\ncategories: System\ndescription: keepalived\n---\n\n这一篇文章是做了不少功课的。\n\n* [什么是 Gre 隧道](#第一节)\n* [什么是 Vrrp ](#第二节)\n* [KeepAlived 是什么](#第三节)\n* [用Keepalived 怎么玩](#第四节)\n* [附录](#第五节)\n\n\n<h3 id=\"第一节\">什么是 Gre 隧道 </h3>\n\nGRE 隧道是一种 IP-2-IP 的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在 IPv4/IPv6 网络中传输。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。Linux 上创建 GRE 隧道，需要 ip_gre 内核模块，它是Pv4 隧道的驱动程序。\n\n假设我有2台服务器，想做这两台之间创建 GRE 隧道\n\n* $server_A_ip 表示服务器A的IP\n* $server_B_ip 服务器B 的内网IP\n\n```\n# 在 A 机器上执行\n# 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP\nsudo ip link add gretap1 type gretap local $server_a_ip remote $server_b_ip \nsudo ip link set dev gretap1 up  # 启动该设备\nsudo ip addr add dev gretap1 10.1.1.2/24 # 给该设备一个虚拟网络地址\n\n# 在 B 机器上执行\n# 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP\nsudo ip link add gretap1 type gretap local $server_b_ip remote $server_a_ip \nsudo ip link set dev gretap1 up  # 启动该设备\nsudo ip addr add dev gretap1 10.1.1.3/24 # 给该设备一个虚拟网络地址\n```\n\n如果想停止或者删除上述网卡\n\n```\nip link set gretap1 down\nip tunnel del gretap1\n```\n\n至此点到点得隧道建立。\n\n\n<h3 id=\"第二节\">什么是 vrrp 协议 </h3>\n\nVRRP(Virtual Router Redundancy Protocol), 即虚拟路由冗余协议。是实现路由器高可用的容错协议。\n\n即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个 master 和多个 backup， 但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip），占有这个IP 的 master 实际负责 ARP 相应和转发 IP 数据包， 组中的其它路由器作为备份的角色处于待命状态。 master 会发组播消息，当 backup 在超时时间内收不到 vrrp 包时就认为 master 宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。\n\n\n<h3 id=\"第三节\"> Keepalived 是什么 </h3>\n\nKeepalived 是一个基于 VRRP 协议来实现的服务高可用方案，可以利用其来避免IP单点故障。\n\n* 一个经典的案例\n\n一个WEB服务至少会有2台服务器运行 Keepalived，一台为主服务器，一台为备份服务器, 但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。\n\n\n<h3 id=\"第四节\">怎么玩 Keepalived</h3>\n\n* 安装\n\n```\nsudo apt-get install keepalived\n```\n\n之前提到的，我们在 A, B 两台服务器建立起了 GRE 隧道了。 现在我们有一个虚拟的内网IP， 姑且叫做 $virtual_third_ip\n接着在 A 服务器上\n\n* 配置\n\n编辑服务器 A, B 的 `/etc/keepalived/keepalived.conf`\n\n```\n\nglobal_defs {\n    router_id LVS_DEVEL\n}\n\nvrrp_instance VI_1 {\n    state MASTER\n    interface gretap1 # 绑在建立起来的隧道上\n    virtual_router_id 51\n    # 优先级别,越高的设备会被弄成主设备, A,B 服务器要有所差别，其他都一样\n    priority 100          advert_int 1      # 广播时间间隔\n    authentication {  #  验证相关\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n        $virtual_third_ip dev eth0\n    }\n}\n```\n\n我们将服务器  A 作为 Master, 服务器 B 当做 Backup, 当服务器 A 需要停机的时候，$virtual_third_ip 就会漂移到服务器 B 上面。 我们两台机器都有相同配置的 Nginx 服务，就可以保障机器出现故障的时候，Nginx 服务丝毫不受影响。\n\n\n<h3 id=\"第五节\"> 附录 </h3>\n\n* [鸟哥的网络知识](http://linux.vbird.org/linux_server/0140networkcommand.php)\n* [GRE tuneling](http://www.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.tunnel.gre.html)\n* [VRRP](http://baike.baidu.com/link?url=N1-VGuzQC0PJ2bCnOzYn-XRTlN8eFGCvIJQlTI6KDL5Fx3EQxoRGTrxazb11jfZQqlfeA6q2Ka0VKRVEc0Kdu3GEyhqe1W_Ae2h0Tqu5NacIjOSaSnUVeOe-9QV5dB8q0Wv_uq8-vqdnQICt39UZFK)\n","slug":"2015-12-05-gre-tuning-and-keepalived","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdaa0046nctj4zgd5hrh","content":"<p>这一篇文章是做了不少功课的。</p>\n<ul>\n<li><a href=\"#第一节\">什么是 Gre 隧道</a></li>\n<li><a href=\"#第二节\">什么是 Vrrp </a></li>\n<li><a href=\"#第三节\">KeepAlived 是什么</a></li>\n<li><a href=\"#第四节\">用Keepalived 怎么玩</a></li>\n<li><a href=\"#第五节\">附录</a></li>\n</ul>\n<h3 id=\"第一节\">什么是 Gre 隧道 </h3>\n\n<p>GRE 隧道是一种 IP-2-IP 的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在 IPv4/IPv6 网络中传输。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。Linux 上创建 GRE 隧道，需要 ip_gre 内核模块，它是Pv4 隧道的驱动程序。</p>\n<p>假设我有2台服务器，想做这两台之间创建 GRE 隧道</p>\n<ul>\n<li>$server_A_ip 表示服务器A的IP</li>\n<li>$server_B_ip 服务器B 的内网IP</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 在 A 机器上执行</span><br><span class=\"line\"># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP</span><br><span class=\"line\">sudo ip link add gretap1 type gretap local $server_a_ip remote $server_b_ip </span><br><span class=\"line\">sudo ip link set dev gretap1 up  # 启动该设备</span><br><span class=\"line\">sudo ip addr add dev gretap1 10.1.1.2/24 # 给该设备一个虚拟网络地址</span><br><span class=\"line\"></span><br><span class=\"line\"># 在 B 机器上执行</span><br><span class=\"line\"># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP</span><br><span class=\"line\">sudo ip link add gretap1 type gretap local $server_b_ip remote $server_a_ip </span><br><span class=\"line\">sudo ip link set dev gretap1 up  # 启动该设备</span><br><span class=\"line\">sudo ip addr add dev gretap1 10.1.1.3/24 # 给该设备一个虚拟网络地址</span><br></pre></td></tr></table></figure>\n<p>如果想停止或者删除上述网卡</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ip link set gretap1 down</span><br><span class=\"line\">ip tunnel del gretap1</span><br></pre></td></tr></table></figure>\n<p>至此点到点得隧道建立。</p>\n<h3 id=\"第二节\">什么是 vrrp 协议 </h3>\n\n<p>VRRP(Virtual Router Redundancy Protocol), 即虚拟路由冗余协议。是实现路由器高可用的容错协议。</p>\n<p>即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个 master 和多个 backup， 但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip），占有这个IP 的 master 实际负责 ARP 相应和转发 IP 数据包， 组中的其它路由器作为备份的角色处于待命状态。 master 会发组播消息，当 backup 在超时时间内收不到 vrrp 包时就认为 master 宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。</p>\n<h3 id=\"第三节\"> Keepalived 是什么 </h3>\n\n<p>Keepalived 是一个基于 VRRP 协议来实现的服务高可用方案，可以利用其来避免IP单点故障。</p>\n<ul>\n<li>一个经典的案例</li>\n</ul>\n<p>一个WEB服务至少会有2台服务器运行 Keepalived，一台为主服务器，一台为备份服务器, 但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。</p>\n<h3 id=\"第四节\">怎么玩 Keepalived</h3>\n\n<ul>\n<li>安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install keepalived</span><br></pre></td></tr></table></figure>\n<p>之前提到的，我们在 A, B 两台服务器建立起了 GRE 隧道了。 现在我们有一个虚拟的内网IP， 姑且叫做 $virtual_third_ip<br>接着在 A 服务器上</p>\n<ul>\n<li>配置</li>\n</ul>\n<p>编辑服务器 A, B 的 <code>/etc/keepalived/keepalived.conf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">global_defs &#123;</span><br><span class=\"line\">    router_id LVS_DEVEL</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">vrrp_instance VI_1 &#123;</span><br><span class=\"line\">    state MASTER</span><br><span class=\"line\">    interface gretap1 # 绑在建立起来的隧道上</span><br><span class=\"line\">    virtual_router_id 51</span><br><span class=\"line\">    # 优先级别,越高的设备会被弄成主设备, A,B 服务器要有所差别，其他都一样</span><br><span class=\"line\">    priority 100          advert_int 1      # 广播时间间隔</span><br><span class=\"line\">    authentication &#123;  #  验证相关</span><br><span class=\"line\">        auth_type PASS</span><br><span class=\"line\">        auth_pass 1111</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    virtual_ipaddress &#123;</span><br><span class=\"line\">        $virtual_third_ip dev eth0</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>我们将服务器  A 作为 Master, 服务器 B 当做 Backup, 当服务器 A 需要停机的时候，$virtual_third_ip 就会漂移到服务器 B 上面。 我们两台机器都有相同配置的 Nginx 服务，就可以保障机器出现故障的时候，Nginx 服务丝毫不受影响。</p>\n<h3 id=\"第五节\"> 附录 </h3>\n\n<ul>\n<li><a href=\"http://linux.vbird.org/linux_server/0140networkcommand.php\" target=\"_blank\" rel=\"noopener\">鸟哥的网络知识</a></li>\n<li><a href=\"http://www.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.tunnel.gre.html\" target=\"_blank\" rel=\"noopener\">GRE tuneling</a></li>\n<li><a href=\"http://baike.baidu.com/link?url=N1-VGuzQC0PJ2bCnOzYn-XRTlN8eFGCvIJQlTI6KDL5Fx3EQxoRGTrxazb11jfZQqlfeA6q2Ka0VKRVEc0Kdu3GEyhqe1W_Ae2h0Tqu5NacIjOSaSnUVeOe-9QV5dB8q0Wv_uq8-vqdnQICt39UZFK\" target=\"_blank\" rel=\"noopener\">VRRP</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>这一篇文章是做了不少功课的。</p>\n<ul>\n<li><a href=\"#第一节\">什么是 Gre 隧道</a></li>\n<li><a href=\"#第二节\">什么是 Vrrp </a></li>\n<li><a href=\"#第三节\">KeepAlived 是什么</a></li>\n<li><a href=\"#第四节\">用Keepalived 怎么玩</a></li>\n<li><a href=\"#第五节\">附录</a></li>\n</ul>\n<h3 id=\"第一节\">什么是 Gre 隧道 </h3>\n\n<p>GRE 隧道是一种 IP-2-IP 的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在 IPv4/IPv6 网络中传输。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。Linux 上创建 GRE 隧道，需要 ip_gre 内核模块，它是Pv4 隧道的驱动程序。</p>\n<p>假设我有2台服务器，想做这两台之间创建 GRE 隧道</p>\n<ul>\n<li>$server_A_ip 表示服务器A的IP</li>\n<li>$server_B_ip 服务器B 的内网IP</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 在 A 机器上执行</span><br><span class=\"line\"># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP</span><br><span class=\"line\">sudo ip link add gretap1 type gretap local $server_a_ip remote $server_b_ip </span><br><span class=\"line\">sudo ip link set dev gretap1 up  # 启动该设备</span><br><span class=\"line\">sudo ip addr add dev gretap1 10.1.1.2/24 # 给该设备一个虚拟网络地址</span><br><span class=\"line\"></span><br><span class=\"line\"># 在 B 机器上执行</span><br><span class=\"line\"># 创建 GRE 协议的 虚拟网络设备, 指定本地和对端 IP</span><br><span class=\"line\">sudo ip link add gretap1 type gretap local $server_b_ip remote $server_a_ip </span><br><span class=\"line\">sudo ip link set dev gretap1 up  # 启动该设备</span><br><span class=\"line\">sudo ip addr add dev gretap1 10.1.1.3/24 # 给该设备一个虚拟网络地址</span><br></pre></td></tr></table></figure>\n<p>如果想停止或者删除上述网卡</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ip link set gretap1 down</span><br><span class=\"line\">ip tunnel del gretap1</span><br></pre></td></tr></table></figure>\n<p>至此点到点得隧道建立。</p>\n<h3 id=\"第二节\">什么是 vrrp 协议 </h3>\n\n<p>VRRP(Virtual Router Redundancy Protocol), 即虚拟路由冗余协议。是实现路由器高可用的容错协议。</p>\n<p>即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个 master 和多个 backup， 但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip），占有这个IP 的 master 实际负责 ARP 相应和转发 IP 数据包， 组中的其它路由器作为备份的角色处于待命状态。 master 会发组播消息，当 backup 在超时时间内收不到 vrrp 包时就认为 master 宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。</p>\n<h3 id=\"第三节\"> Keepalived 是什么 </h3>\n\n<p>Keepalived 是一个基于 VRRP 协议来实现的服务高可用方案，可以利用其来避免IP单点故障。</p>\n<ul>\n<li>一个经典的案例</li>\n</ul>\n<p>一个WEB服务至少会有2台服务器运行 Keepalived，一台为主服务器，一台为备份服务器, 但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。</p>\n<h3 id=\"第四节\">怎么玩 Keepalived</h3>\n\n<ul>\n<li>安装</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install keepalived</span><br></pre></td></tr></table></figure>\n<p>之前提到的，我们在 A, B 两台服务器建立起了 GRE 隧道了。 现在我们有一个虚拟的内网IP， 姑且叫做 $virtual_third_ip<br>接着在 A 服务器上</p>\n<ul>\n<li>配置</li>\n</ul>\n<p>编辑服务器 A, B 的 <code>/etc/keepalived/keepalived.conf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">global_defs &#123;</span><br><span class=\"line\">    router_id LVS_DEVEL</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">vrrp_instance VI_1 &#123;</span><br><span class=\"line\">    state MASTER</span><br><span class=\"line\">    interface gretap1 # 绑在建立起来的隧道上</span><br><span class=\"line\">    virtual_router_id 51</span><br><span class=\"line\">    # 优先级别,越高的设备会被弄成主设备, A,B 服务器要有所差别，其他都一样</span><br><span class=\"line\">    priority 100          advert_int 1      # 广播时间间隔</span><br><span class=\"line\">    authentication &#123;  #  验证相关</span><br><span class=\"line\">        auth_type PASS</span><br><span class=\"line\">        auth_pass 1111</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    virtual_ipaddress &#123;</span><br><span class=\"line\">        $virtual_third_ip dev eth0</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>我们将服务器  A 作为 Master, 服务器 B 当做 Backup, 当服务器 A 需要停机的时候，$virtual_third_ip 就会漂移到服务器 B 上面。 我们两台机器都有相同配置的 Nginx 服务，就可以保障机器出现故障的时候，Nginx 服务丝毫不受影响。</p>\n<h3 id=\"第五节\"> 附录 </h3>\n\n<ul>\n<li><a href=\"http://linux.vbird.org/linux_server/0140networkcommand.php\" target=\"_blank\" rel=\"noopener\">鸟哥的网络知识</a></li>\n<li><a href=\"http://www.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.tunnel.gre.html\" target=\"_blank\" rel=\"noopener\">GRE tuneling</a></li>\n<li><a href=\"http://baike.baidu.com/link?url=N1-VGuzQC0PJ2bCnOzYn-XRTlN8eFGCvIJQlTI6KDL5Fx3EQxoRGTrxazb11jfZQqlfeA6q2Ka0VKRVEc0Kdu3GEyhqe1W_Ae2h0Tqu5NacIjOSaSnUVeOe-9QV5dB8q0Wv_uq8-vqdnQICt39UZFK\" target=\"_blank\" rel=\"noopener\">VRRP</a></li>\n</ul>\n"},{"layout":"post","title":"Nginx 日志利器 GoAccess","date":"2015-12-10T15:28:00.000Z","comments":1,"description":"GoAccess Nginx","_content":"\n我们经常需要从 Nginx 日志分析得出很多有价值的东西，分析的方法是各种 shell, awk, python, 现在 [GoAccess](https://github.com/allinurl/goaccess) 给你另外一种选择, 值得拥有。\n\n* 安装\n用以下的方式安装，才能得到新版的 GoAccess, 功能更健全\n \n```\n$ echo \"deb http://deb.goaccess.io $(lsb_release -cs) main\"|sudo tee -a /etc/apt/sources.list\n$ wget -O - http://deb.goaccess.io/gnugpg.key | sudo apt-key add -\n$ sudo apt-get update\n$ sudo apt-get install goaccess\n```\n \n* 推荐配置\n \n安装完成之后，会生成一份 `/etc/goaccess.conf` 稍作编辑，这就是默认的配置，免去了后续每次都要定义格式\n\n```\ntime-format %T   # 只有这种方式才能解决 0.0us 的显示问题\ndate-format %d/%b/%Y\nlog-format %h %^[%d:%t %^] \"%r\" %s %b \"%R\" \"%u\" %T\n```\n \n* 使用\n\n输出报表，报表中，我们可以看到最常访问的 IP, 接口，以及每个接口使用带宽，平均响应时长，状态码等，对业务分析有较好的便利性\n \n```\n终端显示\ngoaccess -f access.log \n \n输出报表，报表中，我们可以看到top ip, 接口，以及接口使用带宽，平均响应时长，状态码等\ngoaccess -f access.log > report.html\n \n具体某段时间的输出\nsed -n '/5\\/Dec\\/2015/,/10\\/Dec\\/2010/ p' access.log | goaccess -a\n \n处理已经压缩的日志\nzcat access.log.*.gz | goaccess\n```\n\n","source":"_posts/2015-12-10-fen-xi-nginxri-zhi-de-li-qi-goaccess.markdown","raw":"---\nlayout: post\ntitle: \"Nginx 日志利器 GoAccess\"\ndate: 2015-12-10 23:28\ncomments: true\ncategories: System\ndescription: GoAccess Nginx\n---\n\n我们经常需要从 Nginx 日志分析得出很多有价值的东西，分析的方法是各种 shell, awk, python, 现在 [GoAccess](https://github.com/allinurl/goaccess) 给你另外一种选择, 值得拥有。\n\n* 安装\n用以下的方式安装，才能得到新版的 GoAccess, 功能更健全\n \n```\n$ echo \"deb http://deb.goaccess.io $(lsb_release -cs) main\"|sudo tee -a /etc/apt/sources.list\n$ wget -O - http://deb.goaccess.io/gnugpg.key | sudo apt-key add -\n$ sudo apt-get update\n$ sudo apt-get install goaccess\n```\n \n* 推荐配置\n \n安装完成之后，会生成一份 `/etc/goaccess.conf` 稍作编辑，这就是默认的配置，免去了后续每次都要定义格式\n\n```\ntime-format %T   # 只有这种方式才能解决 0.0us 的显示问题\ndate-format %d/%b/%Y\nlog-format %h %^[%d:%t %^] \"%r\" %s %b \"%R\" \"%u\" %T\n```\n \n* 使用\n\n输出报表，报表中，我们可以看到最常访问的 IP, 接口，以及每个接口使用带宽，平均响应时长，状态码等，对业务分析有较好的便利性\n \n```\n终端显示\ngoaccess -f access.log \n \n输出报表，报表中，我们可以看到top ip, 接口，以及接口使用带宽，平均响应时长，状态码等\ngoaccess -f access.log > report.html\n \n具体某段时间的输出\nsed -n '/5\\/Dec\\/2015/,/10\\/Dec\\/2010/ p' access.log | goaccess -a\n \n处理已经压缩的日志\nzcat access.log.*.gz | goaccess\n```\n\n","slug":"2015-12-10-fen-xi-nginxri-zhi-de-li-qi-goaccess","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdab0048nctj2gybrn5f","content":"<p>我们经常需要从 Nginx 日志分析得出很多有价值的东西，分析的方法是各种 shell, awk, python, 现在 <a href=\"https://github.com/allinurl/goaccess\" target=\"_blank\" rel=\"noopener\">GoAccess</a> 给你另外一种选择, 值得拥有。</p>\n<ul>\n<li>安装<br>用以下的方式安装，才能得到新版的 GoAccess, 功能更健全</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ echo &quot;deb http://deb.goaccess.io $(lsb_release -cs) main&quot;|sudo tee -a /etc/apt/sources.list</span><br><span class=\"line\">$ wget -O - http://deb.goaccess.io/gnugpg.key | sudo apt-key add -</span><br><span class=\"line\">$ sudo apt-get update</span><br><span class=\"line\">$ sudo apt-get install goaccess</span><br></pre></td></tr></table></figure>\n<ul>\n<li>推荐配置</li>\n</ul>\n<p>安装完成之后，会生成一份 <code>/etc/goaccess.conf</code> 稍作编辑，这就是默认的配置，免去了后续每次都要定义格式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">time-format %T   # 只有这种方式才能解决 0.0us 的显示问题</span><br><span class=\"line\">date-format %d/%b/%Y</span><br><span class=\"line\">log-format %h %^[%d:%t %^] &quot;%r&quot; %s %b &quot;%R&quot; &quot;%u&quot; %T</span><br></pre></td></tr></table></figure>\n<ul>\n<li>使用</li>\n</ul>\n<p>输出报表，报表中，我们可以看到最常访问的 IP, 接口，以及每个接口使用带宽，平均响应时长，状态码等，对业务分析有较好的便利性</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">终端显示</span><br><span class=\"line\">goaccess -f access.log </span><br><span class=\"line\"> </span><br><span class=\"line\">输出报表，报表中，我们可以看到top ip, 接口，以及接口使用带宽，平均响应时长，状态码等</span><br><span class=\"line\">goaccess -f access.log &gt; report.html</span><br><span class=\"line\"> </span><br><span class=\"line\">具体某段时间的输出</span><br><span class=\"line\">sed -n &apos;/5\\/Dec\\/2015/,/10\\/Dec\\/2010/ p&apos; access.log | goaccess -a</span><br><span class=\"line\"> </span><br><span class=\"line\">处理已经压缩的日志</span><br><span class=\"line\">zcat access.log.*.gz | goaccess</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>我们经常需要从 Nginx 日志分析得出很多有价值的东西，分析的方法是各种 shell, awk, python, 现在 <a href=\"https://github.com/allinurl/goaccess\" target=\"_blank\" rel=\"noopener\">GoAccess</a> 给你另外一种选择, 值得拥有。</p>\n<ul>\n<li>安装<br>用以下的方式安装，才能得到新版的 GoAccess, 功能更健全</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ echo &quot;deb http://deb.goaccess.io $(lsb_release -cs) main&quot;|sudo tee -a /etc/apt/sources.list</span><br><span class=\"line\">$ wget -O - http://deb.goaccess.io/gnugpg.key | sudo apt-key add -</span><br><span class=\"line\">$ sudo apt-get update</span><br><span class=\"line\">$ sudo apt-get install goaccess</span><br></pre></td></tr></table></figure>\n<ul>\n<li>推荐配置</li>\n</ul>\n<p>安装完成之后，会生成一份 <code>/etc/goaccess.conf</code> 稍作编辑，这就是默认的配置，免去了后续每次都要定义格式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">time-format %T   # 只有这种方式才能解决 0.0us 的显示问题</span><br><span class=\"line\">date-format %d/%b/%Y</span><br><span class=\"line\">log-format %h %^[%d:%t %^] &quot;%r&quot; %s %b &quot;%R&quot; &quot;%u&quot; %T</span><br></pre></td></tr></table></figure>\n<ul>\n<li>使用</li>\n</ul>\n<p>输出报表，报表中，我们可以看到最常访问的 IP, 接口，以及每个接口使用带宽，平均响应时长，状态码等，对业务分析有较好的便利性</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">终端显示</span><br><span class=\"line\">goaccess -f access.log </span><br><span class=\"line\"> </span><br><span class=\"line\">输出报表，报表中，我们可以看到top ip, 接口，以及接口使用带宽，平均响应时长，状态码等</span><br><span class=\"line\">goaccess -f access.log &gt; report.html</span><br><span class=\"line\"> </span><br><span class=\"line\">具体某段时间的输出</span><br><span class=\"line\">sed -n &apos;/5\\/Dec\\/2015/,/10\\/Dec\\/2010/ p&apos; access.log | goaccess -a</span><br><span class=\"line\"> </span><br><span class=\"line\">处理已经压缩的日志</span><br><span class=\"line\">zcat access.log.*.gz | goaccess</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":" 实时监控 nginx qps 的拓展","date":"2016-01-07T04:59:00.000Z","comments":1,"description":"Nginx lua","_content":"\n用下班时间写了一个 ngx lua 的拓展, [GitHub](https://github.com/zheng-ji/ngx_lua_reqstatus)。可以:\n\n- [x] 实时监控域名的 qps\n- [x] 实时监控域名的 5xx 个数\n- [x] 实时监控域名的 响应时长\n- [x] 并附带 Ganglia 监控插件\n\n## 使用\n\n*  配置 `nginx.conf`\n\n```\nhttp {\n    ...\n    ...\n\n    lua_shared_dict statics_dict    1M; # 初始化变量\n    lua_package_path \"/etc/nginx/ngx_lua_reqstatus/?.lua\";  #路径\n    log_by_lua_file \"/etc/nginx/ngx_lua_reqstatus/hook.lua\"; # 添加此句\n\n    server {\n        listen 80;\n        server_name  justforfun.com; \n\n        location /{\n            ...\n        }\n    }\n    # 监控服务\n    server {\n        listen 127.0.0.1:6080;\n        location /{\n            access_by_lua_file \"/etc/nginx/ngx_lua_reqstatus/status.lua\";\n        }\n    }\n}\n```\n\n* 效果\n\n```\ncurl localhost:6080/?domain=justforfun.com\n```\n\n* 输出\n\n```\nServer Name:    justforfun.com\nSeconds SinceLast:   1.4399998188019 secs\nRequest Count:      1\nAverage Req Time:   0 secs\nRequests Per Secs:  0.69444453182781\n5xx num:    0\n```\n\n\n","source":"_posts/2016-01-07-shi-shi-jian-kong-nginx-qps-de-tuo-zhan.markdown","raw":"---\nlayout: post\ntitle: \" 实时监控 nginx qps 的拓展\"\ndate: 2016-01-07 12:59\ncomments: true\ncategories: System\ndescription: Nginx lua\n---\n\n用下班时间写了一个 ngx lua 的拓展, [GitHub](https://github.com/zheng-ji/ngx_lua_reqstatus)。可以:\n\n- [x] 实时监控域名的 qps\n- [x] 实时监控域名的 5xx 个数\n- [x] 实时监控域名的 响应时长\n- [x] 并附带 Ganglia 监控插件\n\n## 使用\n\n*  配置 `nginx.conf`\n\n```\nhttp {\n    ...\n    ...\n\n    lua_shared_dict statics_dict    1M; # 初始化变量\n    lua_package_path \"/etc/nginx/ngx_lua_reqstatus/?.lua\";  #路径\n    log_by_lua_file \"/etc/nginx/ngx_lua_reqstatus/hook.lua\"; # 添加此句\n\n    server {\n        listen 80;\n        server_name  justforfun.com; \n\n        location /{\n            ...\n        }\n    }\n    # 监控服务\n    server {\n        listen 127.0.0.1:6080;\n        location /{\n            access_by_lua_file \"/etc/nginx/ngx_lua_reqstatus/status.lua\";\n        }\n    }\n}\n```\n\n* 效果\n\n```\ncurl localhost:6080/?domain=justforfun.com\n```\n\n* 输出\n\n```\nServer Name:    justforfun.com\nSeconds SinceLast:   1.4399998188019 secs\nRequest Count:      1\nAverage Req Time:   0 secs\nRequests Per Secs:  0.69444453182781\n5xx num:    0\n```\n\n\n","slug":"2016-01-07-shi-shi-jian-kong-nginx-qps-de-tuo-zhan","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdac004anctjbtmktdbq","content":"<p>用下班时间写了一个 ngx lua 的拓展, <a href=\"https://github.com/zheng-ji/ngx_lua_reqstatus\" target=\"_blank\" rel=\"noopener\">GitHub</a>。可以:</p>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 实时监控域名的 qps</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 实时监控域名的 5xx 个数</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 实时监控域名的 响应时长</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 并附带 Ganglia 监控插件</li>\n</ul>\n<h2 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h2><ul>\n<li>配置 <code>nginx.conf</code></li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\">    lua_shared_dict statics_dict    1M; # 初始化变量</span><br><span class=\"line\">    lua_package_path &quot;/etc/nginx/ngx_lua_reqstatus/?.lua&quot;;  #路径</span><br><span class=\"line\">    log_by_lua_file &quot;/etc/nginx/ngx_lua_reqstatus/hook.lua&quot;; # 添加此句</span><br><span class=\"line\"></span><br><span class=\"line\">    server &#123;</span><br><span class=\"line\">        listen 80;</span><br><span class=\"line\">        server_name  justforfun.com; </span><br><span class=\"line\"></span><br><span class=\"line\">        location /&#123;</span><br><span class=\"line\">            ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    # 监控服务</span><br><span class=\"line\">    server &#123;</span><br><span class=\"line\">        listen 127.0.0.1:6080;</span><br><span class=\"line\">        location /&#123;</span><br><span class=\"line\">            access_by_lua_file &quot;/etc/nginx/ngx_lua_reqstatus/status.lua&quot;;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>效果</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:6080/?domain=justforfun.com</span><br></pre></td></tr></table></figure>\n<ul>\n<li>输出</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Server Name:    justforfun.com</span><br><span class=\"line\">Seconds SinceLast:   1.4399998188019 secs</span><br><span class=\"line\">Request Count:      1</span><br><span class=\"line\">Average Req Time:   0 secs</span><br><span class=\"line\">Requests Per Secs:  0.69444453182781</span><br><span class=\"line\">5xx num:    0</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>用下班时间写了一个 ngx lua 的拓展, <a href=\"https://github.com/zheng-ji/ngx_lua_reqstatus\" target=\"_blank\" rel=\"noopener\">GitHub</a>。可以:</p>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 实时监控域名的 qps</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 实时监控域名的 5xx 个数</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 实时监控域名的 响应时长</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 并附带 Ganglia 监控插件</li>\n</ul>\n<h2 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h2><ul>\n<li>配置 <code>nginx.conf</code></li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\">    lua_shared_dict statics_dict    1M; # 初始化变量</span><br><span class=\"line\">    lua_package_path &quot;/etc/nginx/ngx_lua_reqstatus/?.lua&quot;;  #路径</span><br><span class=\"line\">    log_by_lua_file &quot;/etc/nginx/ngx_lua_reqstatus/hook.lua&quot;; # 添加此句</span><br><span class=\"line\"></span><br><span class=\"line\">    server &#123;</span><br><span class=\"line\">        listen 80;</span><br><span class=\"line\">        server_name  justforfun.com; </span><br><span class=\"line\"></span><br><span class=\"line\">        location /&#123;</span><br><span class=\"line\">            ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    # 监控服务</span><br><span class=\"line\">    server &#123;</span><br><span class=\"line\">        listen 127.0.0.1:6080;</span><br><span class=\"line\">        location /&#123;</span><br><span class=\"line\">            access_by_lua_file &quot;/etc/nginx/ngx_lua_reqstatus/status.lua&quot;;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>效果</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:6080/?domain=justforfun.com</span><br></pre></td></tr></table></figure>\n<ul>\n<li>输出</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Server Name:    justforfun.com</span><br><span class=\"line\">Seconds SinceLast:   1.4399998188019 secs</span><br><span class=\"line\">Request Count:      1</span><br><span class=\"line\">Average Req Time:   0 secs</span><br><span class=\"line\">Requests Per Secs:  0.69444453182781</span><br><span class=\"line\">5xx num:    0</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Redis 该选择哪种持久化配置","date":"2016-03-10T15:32:00.000Z","comments":1,"description":"Redsi AOF RDB","_content":"\n这个标题或许会让你想起[《黑客帝国》](https://movie.douban.com/subject/1291843/)里经典的台词，你要选择蓝色药丸，还是红色药丸？\n\nRedis 是我们重度使用的一个开源软件，对它的持久化配置做一番相对深入的总结，是值得的。目前它有两种主流的持久化存储方式 SnapShot 以及 AOF 。\n\n* [什么是 Snapshot](#第一节)\n* [什么是 AOF ](#第二节)\n* [选择哪种药丸](#第三节)\n\n\n<h3 id=\"第一节\">什么是 Snapshot</h3>\n\nSnapshot 将内存中数据以结构化的方式序列化到 rdb 文件中，是默认的持久化方式，便于解析引擎快速解析和内存实施。快照得由间隔时间，变更次数同时符合才会触发， 该过程中并不阻塞客户端请求，copy-on-write 方式也意味着极端情况下可能会导致实际数据2倍内存的使用量。它首先将数据写入临时文件，结束后，将临时文件重名为 dump.rdb。可以使用 `redis-check-dump` 用来检测完整性\n\n只有快照结束后才会将旧的文件替换成新的，因此任何时候 RDB 文件都是完整的。如果在触发 snapshot 之前，server 失效。会导致上一个时间点之后的数据未能序列化到 rdb 文件，安全性上稍弱。 \n\n我们可手动执行 save 或 bgsave 命令让 redis 执行快照。两个命令的区别在于:\n\n* save 是由主进程进行快照操作，会阻塞其它请求;\n* bgsave 会通过 fork 子进程进行快照操作;\n\nRDB 文件默认是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。设置如下，可以关闭快照功能\n\n```\nsave \"\"\n```\n\n\n#### 相关配置\n\n```\n# snapshot触发的时机，save <seconds> <changes>， 比如600秒有2个操作\nsave 600 2\n# 当snapshot 时出现错误无法继续时，是否阻塞客户端变更操作 \nstop-writes-on-bgsave-error yes \n# 是否启用rdb文件压缩，默认为 yes cpu消耗，快速传输  \nrdbcompression yes  \n# rdb文件名称  \ndbfilename dump.rdb  \n```\n\n\n<h3 id=\"第二节\">什么是 AOF</h3>\n\nAppend-only file，将 `操作 + 数据` 以格式化指令的方式追加到操作日志文件的尾部，在 append 操作返回后， 已经写入到文件或者即将写入，才进行实际的数据变更，日志文件保存了历史的操作过程；当 server 需要数据恢复时，可以直接回放此日志文件，即可还原所有的操作过程。 如果你期望数据更少的丢失，那么可以采用 AOF 模式。可以用 redis-check-aof 检测文件是否完整。\n\nAOF 就是日志会记录变更操(例如：set/del等)，会导致AOF文件非常的庞大，意味着server失效后，数据恢复的过程将会很长；事实上，一条数据经过多次变更，将会产生多条AOF记录，其实只要保存当前的状态，历史的操作记录是可以抛弃的， 由此催生了 AOF ReWrite。\n\n#### 什么是 AOF Rewrite\n\n其实是压缩 AOF 文件的过程，Redis 采取了类似 Snapshot 的方式：基于 `copy-on-write`，全量遍历内存中数据，然后逐个序列到 aof 文件中。因此 AOF Rewrite 能够正确反应当前内存数据的状态， Rewrite 过程中，新的变更操作将仍然被写入到原 AOF 文件中，同时这些新的变更操作也会被收集起来， 并不阻塞客户端请求。\n\n\n#### 相关配置\n\n```\n##只有在yes下，aof重写/文件同步等特性才会生效  \nappendonly no  \n  \n##指定aof文件名称  \nappendfilename appendonly.aof  \n  \n##指定aof操作中文件同步策略，有三个合法值：always everysec no，默认为everysec  \nappendfsync everysec  \n\n##在aof-rewrite期间，appendfsync 是否暂缓文件同步，no 表示不暂缓，yes 表示暂缓，默认为no  \nno-appendfsync-on-rewrite no  \n  \n##aof文件rewrite触发的最小文件尺寸 只有大于此aof文件大于此尺寸是才会触发rewrite，默认64mb，建议512mb  \nauto-aof-rewrite-min-size 64mb  \n  \n##相对于上一次rewrite，本次rewrite触发时aof文件应该增长的百分比\nauto-aof-rewrite-percentage 100  \n```\n\n#### appendfsync 方式：\n\n* always：每一条 aof 记录都立即同步到文件，这是最安全的方式，但是更多的磁盘操作和阻塞延迟，IO 开支较大。\n* everysec：每秒同步一次，性能和安全也是redis推荐的方式。如果服务器故障，有可能导致最近一秒内aof记录丢失。\n* no：redis并不直接调用文件同步，而是交给操作系统来处理，操作系统可以根据buffer填充情况等择机触发同步；性能较好，在物理服务器故障时，数据丢失量会因OS配置有关。\n\n\n<h3 id=\"第三节\">选择哪种药丸</h3>\n\n* AOF更安全，可将数据及时同步到文件中，但需要较多的磁盘IO，AOF文件尺寸较大，文件内容恢复相对较慢， 也更完整。\n* Snapshot，安全性较差，它是正常时期数据备份及 master-slave 数据同步的最佳手段，文件尺寸较小，恢复数度较快。\n\n#### 主从架构的环境下的选择\n\n* 通常 master 使用AOF，slave 使用 Snapshot，master 需要确保数据完整性，slave 提供只读服务.\n* 如果你的网络稳定性差， 物理环境糟糕情况下，那么 master， slave均采取 AOF，这个在 master， slave角色切换时，可以减少时间成本；\n","source":"_posts/2016-03-10-gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi.markdown","raw":"---\nlayout: post\ntitle: \"Redis 该选择哪种持久化配置\"\ndate: 2016-03-10 23:32\ncomments: true\ncategories: System\ndescription: Redsi AOF RDB\n---\n\n这个标题或许会让你想起[《黑客帝国》](https://movie.douban.com/subject/1291843/)里经典的台词，你要选择蓝色药丸，还是红色药丸？\n\nRedis 是我们重度使用的一个开源软件，对它的持久化配置做一番相对深入的总结，是值得的。目前它有两种主流的持久化存储方式 SnapShot 以及 AOF 。\n\n* [什么是 Snapshot](#第一节)\n* [什么是 AOF ](#第二节)\n* [选择哪种药丸](#第三节)\n\n\n<h3 id=\"第一节\">什么是 Snapshot</h3>\n\nSnapshot 将内存中数据以结构化的方式序列化到 rdb 文件中，是默认的持久化方式，便于解析引擎快速解析和内存实施。快照得由间隔时间，变更次数同时符合才会触发， 该过程中并不阻塞客户端请求，copy-on-write 方式也意味着极端情况下可能会导致实际数据2倍内存的使用量。它首先将数据写入临时文件，结束后，将临时文件重名为 dump.rdb。可以使用 `redis-check-dump` 用来检测完整性\n\n只有快照结束后才会将旧的文件替换成新的，因此任何时候 RDB 文件都是完整的。如果在触发 snapshot 之前，server 失效。会导致上一个时间点之后的数据未能序列化到 rdb 文件，安全性上稍弱。 \n\n我们可手动执行 save 或 bgsave 命令让 redis 执行快照。两个命令的区别在于:\n\n* save 是由主进程进行快照操作，会阻塞其它请求;\n* bgsave 会通过 fork 子进程进行快照操作;\n\nRDB 文件默认是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。设置如下，可以关闭快照功能\n\n```\nsave \"\"\n```\n\n\n#### 相关配置\n\n```\n# snapshot触发的时机，save <seconds> <changes>， 比如600秒有2个操作\nsave 600 2\n# 当snapshot 时出现错误无法继续时，是否阻塞客户端变更操作 \nstop-writes-on-bgsave-error yes \n# 是否启用rdb文件压缩，默认为 yes cpu消耗，快速传输  \nrdbcompression yes  \n# rdb文件名称  \ndbfilename dump.rdb  \n```\n\n\n<h3 id=\"第二节\">什么是 AOF</h3>\n\nAppend-only file，将 `操作 + 数据` 以格式化指令的方式追加到操作日志文件的尾部，在 append 操作返回后， 已经写入到文件或者即将写入，才进行实际的数据变更，日志文件保存了历史的操作过程；当 server 需要数据恢复时，可以直接回放此日志文件，即可还原所有的操作过程。 如果你期望数据更少的丢失，那么可以采用 AOF 模式。可以用 redis-check-aof 检测文件是否完整。\n\nAOF 就是日志会记录变更操(例如：set/del等)，会导致AOF文件非常的庞大，意味着server失效后，数据恢复的过程将会很长；事实上，一条数据经过多次变更，将会产生多条AOF记录，其实只要保存当前的状态，历史的操作记录是可以抛弃的， 由此催生了 AOF ReWrite。\n\n#### 什么是 AOF Rewrite\n\n其实是压缩 AOF 文件的过程，Redis 采取了类似 Snapshot 的方式：基于 `copy-on-write`，全量遍历内存中数据，然后逐个序列到 aof 文件中。因此 AOF Rewrite 能够正确反应当前内存数据的状态， Rewrite 过程中，新的变更操作将仍然被写入到原 AOF 文件中，同时这些新的变更操作也会被收集起来， 并不阻塞客户端请求。\n\n\n#### 相关配置\n\n```\n##只有在yes下，aof重写/文件同步等特性才会生效  \nappendonly no  \n  \n##指定aof文件名称  \nappendfilename appendonly.aof  \n  \n##指定aof操作中文件同步策略，有三个合法值：always everysec no，默认为everysec  \nappendfsync everysec  \n\n##在aof-rewrite期间，appendfsync 是否暂缓文件同步，no 表示不暂缓，yes 表示暂缓，默认为no  \nno-appendfsync-on-rewrite no  \n  \n##aof文件rewrite触发的最小文件尺寸 只有大于此aof文件大于此尺寸是才会触发rewrite，默认64mb，建议512mb  \nauto-aof-rewrite-min-size 64mb  \n  \n##相对于上一次rewrite，本次rewrite触发时aof文件应该增长的百分比\nauto-aof-rewrite-percentage 100  \n```\n\n#### appendfsync 方式：\n\n* always：每一条 aof 记录都立即同步到文件，这是最安全的方式，但是更多的磁盘操作和阻塞延迟，IO 开支较大。\n* everysec：每秒同步一次，性能和安全也是redis推荐的方式。如果服务器故障，有可能导致最近一秒内aof记录丢失。\n* no：redis并不直接调用文件同步，而是交给操作系统来处理，操作系统可以根据buffer填充情况等择机触发同步；性能较好，在物理服务器故障时，数据丢失量会因OS配置有关。\n\n\n<h3 id=\"第三节\">选择哪种药丸</h3>\n\n* AOF更安全，可将数据及时同步到文件中，但需要较多的磁盘IO，AOF文件尺寸较大，文件内容恢复相对较慢， 也更完整。\n* Snapshot，安全性较差，它是正常时期数据备份及 master-slave 数据同步的最佳手段，文件尺寸较小，恢复数度较快。\n\n#### 主从架构的环境下的选择\n\n* 通常 master 使用AOF，slave 使用 Snapshot，master 需要确保数据完整性，slave 提供只读服务.\n* 如果你的网络稳定性差， 物理环境糟糕情况下，那么 master， slave均采取 AOF，这个在 master， slave角色切换时，可以减少时间成本；\n","slug":"2016-03-10-gai-xuan-ze-na-chong-redischi-jiu-hua-pei-zhi","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdad004cnctjzfufn53k","content":"<p>这个标题或许会让你想起<a href=\"https://movie.douban.com/subject/1291843/\" target=\"_blank\" rel=\"noopener\">《黑客帝国》</a>里经典的台词，你要选择蓝色药丸，还是红色药丸？</p>\n<p>Redis 是我们重度使用的一个开源软件，对它的持久化配置做一番相对深入的总结，是值得的。目前它有两种主流的持久化存储方式 SnapShot 以及 AOF 。</p>\n<ul>\n<li><a href=\"#第一节\">什么是 Snapshot</a></li>\n<li><a href=\"#第二节\">什么是 AOF </a></li>\n<li><a href=\"#第三节\">选择哪种药丸</a></li>\n</ul>\n<h3 id=\"第一节\">什么是 Snapshot</h3>\n\n<p>Snapshot 将内存中数据以结构化的方式序列化到 rdb 文件中，是默认的持久化方式，便于解析引擎快速解析和内存实施。快照得由间隔时间，变更次数同时符合才会触发， 该过程中并不阻塞客户端请求，copy-on-write 方式也意味着极端情况下可能会导致实际数据2倍内存的使用量。它首先将数据写入临时文件，结束后，将临时文件重名为 dump.rdb。可以使用 <code>redis-check-dump</code> 用来检测完整性</p>\n<p>只有快照结束后才会将旧的文件替换成新的，因此任何时候 RDB 文件都是完整的。如果在触发 snapshot 之前，server 失效。会导致上一个时间点之后的数据未能序列化到 rdb 文件，安全性上稍弱。 </p>\n<p>我们可手动执行 save 或 bgsave 命令让 redis 执行快照。两个命令的区别在于:</p>\n<ul>\n<li>save 是由主进程进行快照操作，会阻塞其它请求;</li>\n<li>bgsave 会通过 fork 子进程进行快照操作;</li>\n</ul>\n<p>RDB 文件默认是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。设置如下，可以关闭快照功能</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">save &quot;&quot;</span><br></pre></td></tr></table></figure>\n<h4 id=\"相关配置\"><a href=\"#相关配置\" class=\"headerlink\" title=\"相关配置\"></a>相关配置</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># snapshot触发的时机，save &lt;seconds&gt; &lt;changes&gt;， 比如600秒有2个操作</span><br><span class=\"line\">save 600 2</span><br><span class=\"line\"># 当snapshot 时出现错误无法继续时，是否阻塞客户端变更操作 </span><br><span class=\"line\">stop-writes-on-bgsave-error yes </span><br><span class=\"line\"># 是否启用rdb文件压缩，默认为 yes cpu消耗，快速传输  </span><br><span class=\"line\">rdbcompression yes  </span><br><span class=\"line\"># rdb文件名称  </span><br><span class=\"line\">dbfilename dump.rdb</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二节\">什么是 AOF</h3>\n\n<p>Append-only file，将 <code>操作 + 数据</code> 以格式化指令的方式追加到操作日志文件的尾部，在 append 操作返回后， 已经写入到文件或者即将写入，才进行实际的数据变更，日志文件保存了历史的操作过程；当 server 需要数据恢复时，可以直接回放此日志文件，即可还原所有的操作过程。 如果你期望数据更少的丢失，那么可以采用 AOF 模式。可以用 redis-check-aof 检测文件是否完整。</p>\n<p>AOF 就是日志会记录变更操(例如：set/del等)，会导致AOF文件非常的庞大，意味着server失效后，数据恢复的过程将会很长；事实上，一条数据经过多次变更，将会产生多条AOF记录，其实只要保存当前的状态，历史的操作记录是可以抛弃的， 由此催生了 AOF ReWrite。</p>\n<h4 id=\"什么是-AOF-Rewrite\"><a href=\"#什么是-AOF-Rewrite\" class=\"headerlink\" title=\"什么是 AOF Rewrite\"></a>什么是 AOF Rewrite</h4><p>其实是压缩 AOF 文件的过程，Redis 采取了类似 Snapshot 的方式：基于 <code>copy-on-write</code>，全量遍历内存中数据，然后逐个序列到 aof 文件中。因此 AOF Rewrite 能够正确反应当前内存数据的状态， Rewrite 过程中，新的变更操作将仍然被写入到原 AOF 文件中，同时这些新的变更操作也会被收集起来， 并不阻塞客户端请求。</p>\n<h4 id=\"相关配置-1\"><a href=\"#相关配置-1\" class=\"headerlink\" title=\"相关配置\"></a>相关配置</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">##只有在yes下，aof重写/文件同步等特性才会生效  </span><br><span class=\"line\">appendonly no  </span><br><span class=\"line\">  </span><br><span class=\"line\">##指定aof文件名称  </span><br><span class=\"line\">appendfilename appendonly.aof  </span><br><span class=\"line\">  </span><br><span class=\"line\">##指定aof操作中文件同步策略，有三个合法值：always everysec no，默认为everysec  </span><br><span class=\"line\">appendfsync everysec  </span><br><span class=\"line\"></span><br><span class=\"line\">##在aof-rewrite期间，appendfsync 是否暂缓文件同步，no 表示不暂缓，yes 表示暂缓，默认为no  </span><br><span class=\"line\">no-appendfsync-on-rewrite no  </span><br><span class=\"line\">  </span><br><span class=\"line\">##aof文件rewrite触发的最小文件尺寸 只有大于此aof文件大于此尺寸是才会触发rewrite，默认64mb，建议512mb  </span><br><span class=\"line\">auto-aof-rewrite-min-size 64mb  </span><br><span class=\"line\">  </span><br><span class=\"line\">##相对于上一次rewrite，本次rewrite触发时aof文件应该增长的百分比</span><br><span class=\"line\">auto-aof-rewrite-percentage 100</span><br></pre></td></tr></table></figure>\n<h4 id=\"appendfsync-方式：\"><a href=\"#appendfsync-方式：\" class=\"headerlink\" title=\"appendfsync 方式：\"></a>appendfsync 方式：</h4><ul>\n<li>always：每一条 aof 记录都立即同步到文件，这是最安全的方式，但是更多的磁盘操作和阻塞延迟，IO 开支较大。</li>\n<li>everysec：每秒同步一次，性能和安全也是redis推荐的方式。如果服务器故障，有可能导致最近一秒内aof记录丢失。</li>\n<li>no：redis并不直接调用文件同步，而是交给操作系统来处理，操作系统可以根据buffer填充情况等择机触发同步；性能较好，在物理服务器故障时，数据丢失量会因OS配置有关。</li>\n</ul>\n<h3 id=\"第三节\">选择哪种药丸</h3>\n\n<ul>\n<li>AOF更安全，可将数据及时同步到文件中，但需要较多的磁盘IO，AOF文件尺寸较大，文件内容恢复相对较慢， 也更完整。</li>\n<li>Snapshot，安全性较差，它是正常时期数据备份及 master-slave 数据同步的最佳手段，文件尺寸较小，恢复数度较快。</li>\n</ul>\n<h4 id=\"主从架构的环境下的选择\"><a href=\"#主从架构的环境下的选择\" class=\"headerlink\" title=\"主从架构的环境下的选择\"></a>主从架构的环境下的选择</h4><ul>\n<li>通常 master 使用AOF，slave 使用 Snapshot，master 需要确保数据完整性，slave 提供只读服务.</li>\n<li>如果你的网络稳定性差， 物理环境糟糕情况下，那么 master， slave均采取 AOF，这个在 master， slave角色切换时，可以减少时间成本；</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>这个标题或许会让你想起<a href=\"https://movie.douban.com/subject/1291843/\" target=\"_blank\" rel=\"noopener\">《黑客帝国》</a>里经典的台词，你要选择蓝色药丸，还是红色药丸？</p>\n<p>Redis 是我们重度使用的一个开源软件，对它的持久化配置做一番相对深入的总结，是值得的。目前它有两种主流的持久化存储方式 SnapShot 以及 AOF 。</p>\n<ul>\n<li><a href=\"#第一节\">什么是 Snapshot</a></li>\n<li><a href=\"#第二节\">什么是 AOF </a></li>\n<li><a href=\"#第三节\">选择哪种药丸</a></li>\n</ul>\n<h3 id=\"第一节\">什么是 Snapshot</h3>\n\n<p>Snapshot 将内存中数据以结构化的方式序列化到 rdb 文件中，是默认的持久化方式，便于解析引擎快速解析和内存实施。快照得由间隔时间，变更次数同时符合才会触发， 该过程中并不阻塞客户端请求，copy-on-write 方式也意味着极端情况下可能会导致实际数据2倍内存的使用量。它首先将数据写入临时文件，结束后，将临时文件重名为 dump.rdb。可以使用 <code>redis-check-dump</code> 用来检测完整性</p>\n<p>只有快照结束后才会将旧的文件替换成新的，因此任何时候 RDB 文件都是完整的。如果在触发 snapshot 之前，server 失效。会导致上一个时间点之后的数据未能序列化到 rdb 文件，安全性上稍弱。 </p>\n<p>我们可手动执行 save 或 bgsave 命令让 redis 执行快照。两个命令的区别在于:</p>\n<ul>\n<li>save 是由主进程进行快照操作，会阻塞其它请求;</li>\n<li>bgsave 会通过 fork 子进程进行快照操作;</li>\n</ul>\n<p>RDB 文件默认是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。设置如下，可以关闭快照功能</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">save &quot;&quot;</span><br></pre></td></tr></table></figure>\n<h4 id=\"相关配置\"><a href=\"#相关配置\" class=\"headerlink\" title=\"相关配置\"></a>相关配置</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># snapshot触发的时机，save &lt;seconds&gt; &lt;changes&gt;， 比如600秒有2个操作</span><br><span class=\"line\">save 600 2</span><br><span class=\"line\"># 当snapshot 时出现错误无法继续时，是否阻塞客户端变更操作 </span><br><span class=\"line\">stop-writes-on-bgsave-error yes </span><br><span class=\"line\"># 是否启用rdb文件压缩，默认为 yes cpu消耗，快速传输  </span><br><span class=\"line\">rdbcompression yes  </span><br><span class=\"line\"># rdb文件名称  </span><br><span class=\"line\">dbfilename dump.rdb</span><br></pre></td></tr></table></figure>\n<h3 id=\"第二节\">什么是 AOF</h3>\n\n<p>Append-only file，将 <code>操作 + 数据</code> 以格式化指令的方式追加到操作日志文件的尾部，在 append 操作返回后， 已经写入到文件或者即将写入，才进行实际的数据变更，日志文件保存了历史的操作过程；当 server 需要数据恢复时，可以直接回放此日志文件，即可还原所有的操作过程。 如果你期望数据更少的丢失，那么可以采用 AOF 模式。可以用 redis-check-aof 检测文件是否完整。</p>\n<p>AOF 就是日志会记录变更操(例如：set/del等)，会导致AOF文件非常的庞大，意味着server失效后，数据恢复的过程将会很长；事实上，一条数据经过多次变更，将会产生多条AOF记录，其实只要保存当前的状态，历史的操作记录是可以抛弃的， 由此催生了 AOF ReWrite。</p>\n<h4 id=\"什么是-AOF-Rewrite\"><a href=\"#什么是-AOF-Rewrite\" class=\"headerlink\" title=\"什么是 AOF Rewrite\"></a>什么是 AOF Rewrite</h4><p>其实是压缩 AOF 文件的过程，Redis 采取了类似 Snapshot 的方式：基于 <code>copy-on-write</code>，全量遍历内存中数据，然后逐个序列到 aof 文件中。因此 AOF Rewrite 能够正确反应当前内存数据的状态， Rewrite 过程中，新的变更操作将仍然被写入到原 AOF 文件中，同时这些新的变更操作也会被收集起来， 并不阻塞客户端请求。</p>\n<h4 id=\"相关配置-1\"><a href=\"#相关配置-1\" class=\"headerlink\" title=\"相关配置\"></a>相关配置</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">##只有在yes下，aof重写/文件同步等特性才会生效  </span><br><span class=\"line\">appendonly no  </span><br><span class=\"line\">  </span><br><span class=\"line\">##指定aof文件名称  </span><br><span class=\"line\">appendfilename appendonly.aof  </span><br><span class=\"line\">  </span><br><span class=\"line\">##指定aof操作中文件同步策略，有三个合法值：always everysec no，默认为everysec  </span><br><span class=\"line\">appendfsync everysec  </span><br><span class=\"line\"></span><br><span class=\"line\">##在aof-rewrite期间，appendfsync 是否暂缓文件同步，no 表示不暂缓，yes 表示暂缓，默认为no  </span><br><span class=\"line\">no-appendfsync-on-rewrite no  </span><br><span class=\"line\">  </span><br><span class=\"line\">##aof文件rewrite触发的最小文件尺寸 只有大于此aof文件大于此尺寸是才会触发rewrite，默认64mb，建议512mb  </span><br><span class=\"line\">auto-aof-rewrite-min-size 64mb  </span><br><span class=\"line\">  </span><br><span class=\"line\">##相对于上一次rewrite，本次rewrite触发时aof文件应该增长的百分比</span><br><span class=\"line\">auto-aof-rewrite-percentage 100</span><br></pre></td></tr></table></figure>\n<h4 id=\"appendfsync-方式：\"><a href=\"#appendfsync-方式：\" class=\"headerlink\" title=\"appendfsync 方式：\"></a>appendfsync 方式：</h4><ul>\n<li>always：每一条 aof 记录都立即同步到文件，这是最安全的方式，但是更多的磁盘操作和阻塞延迟，IO 开支较大。</li>\n<li>everysec：每秒同步一次，性能和安全也是redis推荐的方式。如果服务器故障，有可能导致最近一秒内aof记录丢失。</li>\n<li>no：redis并不直接调用文件同步，而是交给操作系统来处理，操作系统可以根据buffer填充情况等择机触发同步；性能较好，在物理服务器故障时，数据丢失量会因OS配置有关。</li>\n</ul>\n<h3 id=\"第三节\">选择哪种药丸</h3>\n\n<ul>\n<li>AOF更安全，可将数据及时同步到文件中，但需要较多的磁盘IO，AOF文件尺寸较大，文件内容恢复相对较慢， 也更完整。</li>\n<li>Snapshot，安全性较差，它是正常时期数据备份及 master-slave 数据同步的最佳手段，文件尺寸较小，恢复数度较快。</li>\n</ul>\n<h4 id=\"主从架构的环境下的选择\"><a href=\"#主从架构的环境下的选择\" class=\"headerlink\" title=\"主从架构的环境下的选择\"></a>主从架构的环境下的选择</h4><ul>\n<li>通常 master 使用AOF，slave 使用 Snapshot，master 需要确保数据完整性，slave 提供只读服务.</li>\n<li>如果你的网络稳定性差， 物理环境糟糕情况下，那么 master， slave均采取 AOF，这个在 master， slave角色切换时，可以减少时间成本；</li>\n</ul>\n"},{"layout":"post","title":"Flume 实时收集 Nginx 日志","date":"2016-04-23T01:13:00.000Z","comments":1,"description":"flume","_content":"\n\n在分布式系统中，各个机器都有程序运行的本地日志，有时为了分析需求，不得不这些分散的日志汇总需求，相信很多人会选择 Rsync，Scp 之类，\n但它们的实时性不强，而且也会带来名字冲突的问题。扩展性差强人意，一点也不优雅。\n\n现实中，我们就碰到了这样的需求：实时汇总线上多台服务器的 Nginx 日志。Flume 立功了。\n\n# Flume 简介\n\n[**F**lume](https://flume.apache.org/) 是一个分布式，可靠高效的日志收集系统，它允许用户自定义数据传输模型，因此可扩展性也强。也有较强的容错和恢复机制.\n以下是几个重要的概念\n\n- Event：Event 是 Flume 数据传输的基本单元。flume 以事件的形式将数据从源头传送到最终的目的。\n- Agent：Agent包含 Sources, Channels, Sinks 和其他组件，它利用这些组件将events从一个节点传输到另一个节点或最终目的。\n- Source：Source负责接收events，并将events批量的放到一个或多个Channels。\n- Channel：Channel位于 Source 和 Sink 之间，用于缓存进来的events，当Sink成功的将events发送到下一跳的channel或最终目的，events从Channel移除。\n- Sink：Sink 负责将 events 传输到下一跳或最终目的，成功完成后将events从channel移除。\n\n{% img /images/2016/04/flume.jpg %}\n\n\n- Source 就有 Syslog Source, Kafka Source,HTTP Source, Exec Source Avro Source 等。\n- Sink 有 Kafka Sink, Avro Sink, File Roll Sink, HDFS Sink 等。\n- Channel 有 Memory Channel,File Channel 等\n\n它提供了一个骨架，以及多种 Source, Sink, Channel, 让你设计合适的数据模型。事实上也可以多个 Flume 联动完成，就像地铁的车厢一样。\n\n\n# 定义数据流模型\n\n回到我们开头的场景,我们要将多台服务器的 Nginx 日志进行汇总分析，\n\n分成两个 flume 来实现\n\n- Flume1 数据流是 Exec Source -> Memory Channel -> Avro Sink,部署在业务机器上\n- Flume2 数据流是 Avro Source -> Memory Channel -> FileRoll Sink\n\n{% img /images/2016/04/flume1toflume2.jpg %}\n\n# 需要的准备\n\n你需要安装\n\n\n- 下载 [Flume](https://flume.apache.org/download.html)\n- 安装 JavaSDk,并在下载解压之后的 conf/flume-env.sh，配置\n  \n```sh\n# 我用的是oracle-java-8\nexport JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre/\n```\n  \n- 思考你的数据流动模型，编写配置，如上文所说的Flume1, tail2avro.conf  ：\n\n```\nagent.sources = s1\nagent.channels = c1\nagent.sinks = k1\n\nagent.sources.s1.type=exec\nagent.sources.s1.command=tail -F <Your File Path>\nagent.sources.s1.channels=c1\n\nagent.channels.c1.type=memory\nagent.channels.c1.capacity=10000\nagent.channels.c1.transactionCapacity=10000\n\nagent.sinks.k1.type = avro\nagent.sinks.k1.hostname = <Your Target Address>\nagent.sinks.k1.port = <Your Target Port>\nagent.sinks.k1.channel=c1\n```\n\nFlume2 中的 avro2file.conf \n\n```\nagent.sources = s1\nagent.channels = c1\nagent.sinks = k1\n\nagent.sources.s1.type = avro\nagent.sources.s1.bind = <Your Address>\nagent.sources.s1.port = <Your Port>\nagent.sources.s1.channels = c1\n\nagent.sinks.k1.type = file_roll\nagent.sinks.k1.sink.directory = /data/log/ngxlog\n# 滚动间隔\nagent.sinks.k1.sink.rollInterval = 86400\nagent.sinks.k1.channel = c1\n\nagent.channels.c1.type = memory\n# 队列里 Event 的容量\nagent.channels.c1.capacity = 10000\nagent.channels.c1.transactionCapacity = 10000\nagent.channels.c1.keep-alive = 60\n```\n\n- 启动运行\n\n```\n# 启动flume1\nbin/flume-ng agent -n agent -c conf -f conf/tail2avro.conf \\\n-Dflume.root.logger=WARN\n\n# 启动flume2\nin/flume-ng agent -n agent -c conf -f conf/avro2file.conf \\\n-Dflume.root.logger=INFO\n```\n\n## 参考\n\n- [FlumeUserGuide](https://flume.apache.org/FlumeUserGuide.html) 官方的 FlumeUserGuide\n","source":"_posts/2016-04-23-flume-shi-shi-shou-ji-nginx-ri-zhi.markdown","raw":"---\nlayout: post\ntitle: \"Flume 实时收集 Nginx 日志\"\ndate: 2016-04-23 09:13\ncomments: true\ncategories: System\ndescription: flume\n---\n\n\n在分布式系统中，各个机器都有程序运行的本地日志，有时为了分析需求，不得不这些分散的日志汇总需求，相信很多人会选择 Rsync，Scp 之类，\n但它们的实时性不强，而且也会带来名字冲突的问题。扩展性差强人意，一点也不优雅。\n\n现实中，我们就碰到了这样的需求：实时汇总线上多台服务器的 Nginx 日志。Flume 立功了。\n\n# Flume 简介\n\n[**F**lume](https://flume.apache.org/) 是一个分布式，可靠高效的日志收集系统，它允许用户自定义数据传输模型，因此可扩展性也强。也有较强的容错和恢复机制.\n以下是几个重要的概念\n\n- Event：Event 是 Flume 数据传输的基本单元。flume 以事件的形式将数据从源头传送到最终的目的。\n- Agent：Agent包含 Sources, Channels, Sinks 和其他组件，它利用这些组件将events从一个节点传输到另一个节点或最终目的。\n- Source：Source负责接收events，并将events批量的放到一个或多个Channels。\n- Channel：Channel位于 Source 和 Sink 之间，用于缓存进来的events，当Sink成功的将events发送到下一跳的channel或最终目的，events从Channel移除。\n- Sink：Sink 负责将 events 传输到下一跳或最终目的，成功完成后将events从channel移除。\n\n{% img /images/2016/04/flume.jpg %}\n\n\n- Source 就有 Syslog Source, Kafka Source,HTTP Source, Exec Source Avro Source 等。\n- Sink 有 Kafka Sink, Avro Sink, File Roll Sink, HDFS Sink 等。\n- Channel 有 Memory Channel,File Channel 等\n\n它提供了一个骨架，以及多种 Source, Sink, Channel, 让你设计合适的数据模型。事实上也可以多个 Flume 联动完成，就像地铁的车厢一样。\n\n\n# 定义数据流模型\n\n回到我们开头的场景,我们要将多台服务器的 Nginx 日志进行汇总分析，\n\n分成两个 flume 来实现\n\n- Flume1 数据流是 Exec Source -> Memory Channel -> Avro Sink,部署在业务机器上\n- Flume2 数据流是 Avro Source -> Memory Channel -> FileRoll Sink\n\n{% img /images/2016/04/flume1toflume2.jpg %}\n\n# 需要的准备\n\n你需要安装\n\n\n- 下载 [Flume](https://flume.apache.org/download.html)\n- 安装 JavaSDk,并在下载解压之后的 conf/flume-env.sh，配置\n  \n```sh\n# 我用的是oracle-java-8\nexport JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre/\n```\n  \n- 思考你的数据流动模型，编写配置，如上文所说的Flume1, tail2avro.conf  ：\n\n```\nagent.sources = s1\nagent.channels = c1\nagent.sinks = k1\n\nagent.sources.s1.type=exec\nagent.sources.s1.command=tail -F <Your File Path>\nagent.sources.s1.channels=c1\n\nagent.channels.c1.type=memory\nagent.channels.c1.capacity=10000\nagent.channels.c1.transactionCapacity=10000\n\nagent.sinks.k1.type = avro\nagent.sinks.k1.hostname = <Your Target Address>\nagent.sinks.k1.port = <Your Target Port>\nagent.sinks.k1.channel=c1\n```\n\nFlume2 中的 avro2file.conf \n\n```\nagent.sources = s1\nagent.channels = c1\nagent.sinks = k1\n\nagent.sources.s1.type = avro\nagent.sources.s1.bind = <Your Address>\nagent.sources.s1.port = <Your Port>\nagent.sources.s1.channels = c1\n\nagent.sinks.k1.type = file_roll\nagent.sinks.k1.sink.directory = /data/log/ngxlog\n# 滚动间隔\nagent.sinks.k1.sink.rollInterval = 86400\nagent.sinks.k1.channel = c1\n\nagent.channels.c1.type = memory\n# 队列里 Event 的容量\nagent.channels.c1.capacity = 10000\nagent.channels.c1.transactionCapacity = 10000\nagent.channels.c1.keep-alive = 60\n```\n\n- 启动运行\n\n```\n# 启动flume1\nbin/flume-ng agent -n agent -c conf -f conf/tail2avro.conf \\\n-Dflume.root.logger=WARN\n\n# 启动flume2\nin/flume-ng agent -n agent -c conf -f conf/avro2file.conf \\\n-Dflume.root.logger=INFO\n```\n\n## 参考\n\n- [FlumeUserGuide](https://flume.apache.org/FlumeUserGuide.html) 官方的 FlumeUserGuide\n","slug":"2016-04-23-flume-shi-shi-shou-ji-nginx-ri-zhi","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdae004enctjr1dxp4ah","content":"<p>在分布式系统中，各个机器都有程序运行的本地日志，有时为了分析需求，不得不这些分散的日志汇总需求，相信很多人会选择 Rsync，Scp 之类，<br>但它们的实时性不强，而且也会带来名字冲突的问题。扩展性差强人意，一点也不优雅。</p>\n<p>现实中，我们就碰到了这样的需求：实时汇总线上多台服务器的 Nginx 日志。Flume 立功了。</p>\n<h1 id=\"Flume-简介\"><a href=\"#Flume-简介\" class=\"headerlink\" title=\"Flume 简介\"></a>Flume 简介</h1><p><a href=\"https://flume.apache.org/\" target=\"_blank\" rel=\"noopener\"><strong>F</strong>lume</a> 是一个分布式，可靠高效的日志收集系统，它允许用户自定义数据传输模型，因此可扩展性也强。也有较强的容错和恢复机制.<br>以下是几个重要的概念</p>\n<ul>\n<li>Event：Event 是 Flume 数据传输的基本单元。flume 以事件的形式将数据从源头传送到最终的目的。</li>\n<li>Agent：Agent包含 Sources, Channels, Sinks 和其他组件，它利用这些组件将events从一个节点传输到另一个节点或最终目的。</li>\n<li>Source：Source负责接收events，并将events批量的放到一个或多个Channels。</li>\n<li>Channel：Channel位于 Source 和 Sink 之间，用于缓存进来的events，当Sink成功的将events发送到下一跳的channel或最终目的，events从Channel移除。</li>\n<li>Sink：Sink 负责将 events 传输到下一跳或最终目的，成功完成后将events从channel移除。</li>\n</ul>\n<img src=\"/images/2016/04/flume.jpg\">\n<ul>\n<li>Source 就有 Syslog Source, Kafka Source,HTTP Source, Exec Source Avro Source 等。</li>\n<li>Sink 有 Kafka Sink, Avro Sink, File Roll Sink, HDFS Sink 等。</li>\n<li>Channel 有 Memory Channel,File Channel 等</li>\n</ul>\n<p>它提供了一个骨架，以及多种 Source, Sink, Channel, 让你设计合适的数据模型。事实上也可以多个 Flume 联动完成，就像地铁的车厢一样。</p>\n<h1 id=\"定义数据流模型\"><a href=\"#定义数据流模型\" class=\"headerlink\" title=\"定义数据流模型\"></a>定义数据流模型</h1><p>回到我们开头的场景,我们要将多台服务器的 Nginx 日志进行汇总分析，</p>\n<p>分成两个 flume 来实现</p>\n<ul>\n<li>Flume1 数据流是 Exec Source -&gt; Memory Channel -&gt; Avro Sink,部署在业务机器上</li>\n<li>Flume2 数据流是 Avro Source -&gt; Memory Channel -&gt; FileRoll Sink</li>\n</ul>\n<img src=\"/images/2016/04/flume1toflume2.jpg\">\n<h1 id=\"需要的准备\"><a href=\"#需要的准备\" class=\"headerlink\" title=\"需要的准备\"></a>需要的准备</h1><p>你需要安装</p>\n<ul>\n<li>下载 <a href=\"https://flume.apache.org/download.html\" target=\"_blank\" rel=\"noopener\">Flume</a></li>\n<li>安装 JavaSDk,并在下载解压之后的 conf/flume-env.sh，配置</li>\n</ul>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 我用的是oracle-java-8</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre/</span><br></pre></td></tr></table></figure>\n<ul>\n<li>思考你的数据流动模型，编写配置，如上文所说的Flume1, tail2avro.conf  ：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">agent.sources = s1</span><br><span class=\"line\">agent.channels = c1</span><br><span class=\"line\">agent.sinks = k1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.sources.s1.type=exec</span><br><span class=\"line\">agent.sources.s1.command=tail -F &lt;Your File Path&gt;</span><br><span class=\"line\">agent.sources.s1.channels=c1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.channels.c1.type=memory</span><br><span class=\"line\">agent.channels.c1.capacity=10000</span><br><span class=\"line\">agent.channels.c1.transactionCapacity=10000</span><br><span class=\"line\"></span><br><span class=\"line\">agent.sinks.k1.type = avro</span><br><span class=\"line\">agent.sinks.k1.hostname = &lt;Your Target Address&gt;</span><br><span class=\"line\">agent.sinks.k1.port = &lt;Your Target Port&gt;</span><br><span class=\"line\">agent.sinks.k1.channel=c1</span><br></pre></td></tr></table></figure>\n<p>Flume2 中的 avro2file.conf </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">agent.sources = s1</span><br><span class=\"line\">agent.channels = c1</span><br><span class=\"line\">agent.sinks = k1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.sources.s1.type = avro</span><br><span class=\"line\">agent.sources.s1.bind = &lt;Your Address&gt;</span><br><span class=\"line\">agent.sources.s1.port = &lt;Your Port&gt;</span><br><span class=\"line\">agent.sources.s1.channels = c1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.sinks.k1.type = file_roll</span><br><span class=\"line\">agent.sinks.k1.sink.directory = /data/log/ngxlog</span><br><span class=\"line\"># 滚动间隔</span><br><span class=\"line\">agent.sinks.k1.sink.rollInterval = 86400</span><br><span class=\"line\">agent.sinks.k1.channel = c1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.channels.c1.type = memory</span><br><span class=\"line\"># 队列里 Event 的容量</span><br><span class=\"line\">agent.channels.c1.capacity = 10000</span><br><span class=\"line\">agent.channels.c1.transactionCapacity = 10000</span><br><span class=\"line\">agent.channels.c1.keep-alive = 60</span><br></pre></td></tr></table></figure>\n<ul>\n<li>启动运行</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 启动flume1</span><br><span class=\"line\">bin/flume-ng agent -n agent -c conf -f conf/tail2avro.conf \\</span><br><span class=\"line\">-Dflume.root.logger=WARN</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动flume2</span><br><span class=\"line\">in/flume-ng agent -n agent -c conf -f conf/avro2file.conf \\</span><br><span class=\"line\">-Dflume.root.logger=INFO</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li><a href=\"https://flume.apache.org/FlumeUserGuide.html\" target=\"_blank\" rel=\"noopener\">FlumeUserGuide</a> 官方的 FlumeUserGuide</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>在分布式系统中，各个机器都有程序运行的本地日志，有时为了分析需求，不得不这些分散的日志汇总需求，相信很多人会选择 Rsync，Scp 之类，<br>但它们的实时性不强，而且也会带来名字冲突的问题。扩展性差强人意，一点也不优雅。</p>\n<p>现实中，我们就碰到了这样的需求：实时汇总线上多台服务器的 Nginx 日志。Flume 立功了。</p>\n<h1 id=\"Flume-简介\"><a href=\"#Flume-简介\" class=\"headerlink\" title=\"Flume 简介\"></a>Flume 简介</h1><p><a href=\"https://flume.apache.org/\" target=\"_blank\" rel=\"noopener\"><strong>F</strong>lume</a> 是一个分布式，可靠高效的日志收集系统，它允许用户自定义数据传输模型，因此可扩展性也强。也有较强的容错和恢复机制.<br>以下是几个重要的概念</p>\n<ul>\n<li>Event：Event 是 Flume 数据传输的基本单元。flume 以事件的形式将数据从源头传送到最终的目的。</li>\n<li>Agent：Agent包含 Sources, Channels, Sinks 和其他组件，它利用这些组件将events从一个节点传输到另一个节点或最终目的。</li>\n<li>Source：Source负责接收events，并将events批量的放到一个或多个Channels。</li>\n<li>Channel：Channel位于 Source 和 Sink 之间，用于缓存进来的events，当Sink成功的将events发送到下一跳的channel或最终目的，events从Channel移除。</li>\n<li>Sink：Sink 负责将 events 传输到下一跳或最终目的，成功完成后将events从channel移除。</li>\n</ul>\n<img src=\"/images/2016/04/flume.jpg\">\n<ul>\n<li>Source 就有 Syslog Source, Kafka Source,HTTP Source, Exec Source Avro Source 等。</li>\n<li>Sink 有 Kafka Sink, Avro Sink, File Roll Sink, HDFS Sink 等。</li>\n<li>Channel 有 Memory Channel,File Channel 等</li>\n</ul>\n<p>它提供了一个骨架，以及多种 Source, Sink, Channel, 让你设计合适的数据模型。事实上也可以多个 Flume 联动完成，就像地铁的车厢一样。</p>\n<h1 id=\"定义数据流模型\"><a href=\"#定义数据流模型\" class=\"headerlink\" title=\"定义数据流模型\"></a>定义数据流模型</h1><p>回到我们开头的场景,我们要将多台服务器的 Nginx 日志进行汇总分析，</p>\n<p>分成两个 flume 来实现</p>\n<ul>\n<li>Flume1 数据流是 Exec Source -&gt; Memory Channel -&gt; Avro Sink,部署在业务机器上</li>\n<li>Flume2 数据流是 Avro Source -&gt; Memory Channel -&gt; FileRoll Sink</li>\n</ul>\n<img src=\"/images/2016/04/flume1toflume2.jpg\">\n<h1 id=\"需要的准备\"><a href=\"#需要的准备\" class=\"headerlink\" title=\"需要的准备\"></a>需要的准备</h1><p>你需要安装</p>\n<ul>\n<li>下载 <a href=\"https://flume.apache.org/download.html\" target=\"_blank\" rel=\"noopener\">Flume</a></li>\n<li>安装 JavaSDk,并在下载解压之后的 conf/flume-env.sh，配置</li>\n</ul>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 我用的是oracle-java-8</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre/</span><br></pre></td></tr></table></figure>\n<ul>\n<li>思考你的数据流动模型，编写配置，如上文所说的Flume1, tail2avro.conf  ：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">agent.sources = s1</span><br><span class=\"line\">agent.channels = c1</span><br><span class=\"line\">agent.sinks = k1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.sources.s1.type=exec</span><br><span class=\"line\">agent.sources.s1.command=tail -F &lt;Your File Path&gt;</span><br><span class=\"line\">agent.sources.s1.channels=c1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.channels.c1.type=memory</span><br><span class=\"line\">agent.channels.c1.capacity=10000</span><br><span class=\"line\">agent.channels.c1.transactionCapacity=10000</span><br><span class=\"line\"></span><br><span class=\"line\">agent.sinks.k1.type = avro</span><br><span class=\"line\">agent.sinks.k1.hostname = &lt;Your Target Address&gt;</span><br><span class=\"line\">agent.sinks.k1.port = &lt;Your Target Port&gt;</span><br><span class=\"line\">agent.sinks.k1.channel=c1</span><br></pre></td></tr></table></figure>\n<p>Flume2 中的 avro2file.conf </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">agent.sources = s1</span><br><span class=\"line\">agent.channels = c1</span><br><span class=\"line\">agent.sinks = k1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.sources.s1.type = avro</span><br><span class=\"line\">agent.sources.s1.bind = &lt;Your Address&gt;</span><br><span class=\"line\">agent.sources.s1.port = &lt;Your Port&gt;</span><br><span class=\"line\">agent.sources.s1.channels = c1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.sinks.k1.type = file_roll</span><br><span class=\"line\">agent.sinks.k1.sink.directory = /data/log/ngxlog</span><br><span class=\"line\"># 滚动间隔</span><br><span class=\"line\">agent.sinks.k1.sink.rollInterval = 86400</span><br><span class=\"line\">agent.sinks.k1.channel = c1</span><br><span class=\"line\"></span><br><span class=\"line\">agent.channels.c1.type = memory</span><br><span class=\"line\"># 队列里 Event 的容量</span><br><span class=\"line\">agent.channels.c1.capacity = 10000</span><br><span class=\"line\">agent.channels.c1.transactionCapacity = 10000</span><br><span class=\"line\">agent.channels.c1.keep-alive = 60</span><br></pre></td></tr></table></figure>\n<ul>\n<li>启动运行</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 启动flume1</span><br><span class=\"line\">bin/flume-ng agent -n agent -c conf -f conf/tail2avro.conf \\</span><br><span class=\"line\">-Dflume.root.logger=WARN</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动flume2</span><br><span class=\"line\">in/flume-ng agent -n agent -c conf -f conf/avro2file.conf \\</span><br><span class=\"line\">-Dflume.root.logger=INFO</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li><a href=\"https://flume.apache.org/FlumeUserGuide.html\" target=\"_blank\" rel=\"noopener\">FlumeUserGuide</a> 官方的 FlumeUserGuide</li>\n</ul>\n"},{"layout":"post","title":"Ansible Dynamic Inventory","date":"2016-04-24T12:53:00.000Z","comments":1,"description":"ansible","_content":"\nAnsible 在使用的过程中，如果机器数量比较固定，且变更不多的情况下，可在 /etc/ansible/hosts 文件里面配置固定的组合机器IP， 并给他起组的别名，执行 Ansible 脚本便可以通过别名找到相应的机器。\n\n```\n[webservers]\n111.222.333.444 ansible_ssh_port=888\n```\n\n假如你有很多台机器，且机器经常变更导致IP时常变换，你还想把IP逐个写入 /etc/ansible/hosts 就不现实了。你也许会问，若不把 IP 写进 /etc/ansible/hosts，那不是没法用 Ansible 指挥这些机器？\n感谢 Ansible Dynamic Inventory， 如果我们能通过编程等手段获取变更机器的IP，我们还是有办法实现的。\n\n### Dynamic Inventory 的原理\n\n* 通过编程的方式,也就是动态获取机器的 json 信息;\n* Ansible 通过解析这串 json 字符串;\n\n```\nansible -i yourprogram.py -m raw  -a 'cd /home'\n```\n\nAnsible Dynamic Inventory 对程序返回的 json 的转义是这样的：\n\n```\n{\"devtest-asg\": {\"hosts\": [\"172.31.21.164\"], \"vars\": {\"ansible_ssh_port\": 12306}}}\n```\n\n翻译一下就是  /etc/ansible/hosts 中的:\n\n```\n[devtest-asg]\n172.31.21.164 ansible_ssh_port=12306\n```\n\n### 一个实战的例子\n\n官方文档对 Inventory 仅作概念性描述，阅读完后仍是一头雾水，不知如何下手。 让我们用一个例子来豁然开朗吧。 我们使用 AWS 的 AutoScaling Group，以下简称 ASG，ASG 会在某种自定义的条件下会自动开启和关闭机器，这给我们在辨别IP，定位机器的时候造成困扰。因此我们需要 Ansible Dynamic Inventory\n\n我们使用 AWS 的 boto 库来获取 ASG 的实例信息.以下程序(get_host.py)中要实现的方法就是列出返回机器信息的 json 串。\n\n```python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport json\nimport boto\nimport boto.ec2\nimport boto.ec2.autoscale\n\nAWS_REGION = 'BBB'\nAWS_ACCESS_KEY = 'xxxx'\nAWS_SECRET_KEY = 'yyy'\n\nresult = {}\ndef getData():\n    conn_as = boto.ec2.autoscale.connect_to_region(\n            'cn-north-1',\n            aws_access_key_id=AWS_ACCESS_KEY,\n            aws_secret_access_key=AWS_SECRET_KEY)\n    group = conn_as.get_all_groups(names=['devtest-asg'])[0]\n    conn_ec2 = boto.ec2.connect_to_region(\n            AWS_REGION,\n            aws_access_key_id=AWS_ACCESS_KEY,\n            aws_secret_access_key=AWS_SECRET_KEY)\n\n    instance_ids = [i.instance_id for i in group.instances]\n    reservations = conn_ec2.get_all_instances(instance_ids)\n    instances = [i for r in reservations for i in r.instances]\n\n    result['devtest-asg'] = {}\n    result['devtest-asg']['hosts'] = []\n    for r in reservations:\n        for i in r.instances:\n            result['devtest-asg']['hosts'].append('%s' % i.private_ip_address)\n            result['devtest-asg']['vars'] = {'ansible_ssh_port': 36000}\n\ndef getlists():\n    getData()\n    print json.dumps(result)\n\ngetlists()\n```\n\n执行以下命令就可以愉快地使用 Ansible 了，其中 devtest-asg 是 ASG 的别名：\n\n```\nansible -i get_host.py  devtest-asg -m raw -a 'ls /'\n```\n","source":"_posts/2016-04-24-ansible-dynamic-inventory.markdown","raw":"---\nlayout: post\ntitle: \"Ansible Dynamic Inventory\"\ndate: 2016-04-24 20:53\ncomments: true\ncategories: System\ndescription: ansible\n---\n\nAnsible 在使用的过程中，如果机器数量比较固定，且变更不多的情况下，可在 /etc/ansible/hosts 文件里面配置固定的组合机器IP， 并给他起组的别名，执行 Ansible 脚本便可以通过别名找到相应的机器。\n\n```\n[webservers]\n111.222.333.444 ansible_ssh_port=888\n```\n\n假如你有很多台机器，且机器经常变更导致IP时常变换，你还想把IP逐个写入 /etc/ansible/hosts 就不现实了。你也许会问，若不把 IP 写进 /etc/ansible/hosts，那不是没法用 Ansible 指挥这些机器？\n感谢 Ansible Dynamic Inventory， 如果我们能通过编程等手段获取变更机器的IP，我们还是有办法实现的。\n\n### Dynamic Inventory 的原理\n\n* 通过编程的方式,也就是动态获取机器的 json 信息;\n* Ansible 通过解析这串 json 字符串;\n\n```\nansible -i yourprogram.py -m raw  -a 'cd /home'\n```\n\nAnsible Dynamic Inventory 对程序返回的 json 的转义是这样的：\n\n```\n{\"devtest-asg\": {\"hosts\": [\"172.31.21.164\"], \"vars\": {\"ansible_ssh_port\": 12306}}}\n```\n\n翻译一下就是  /etc/ansible/hosts 中的:\n\n```\n[devtest-asg]\n172.31.21.164 ansible_ssh_port=12306\n```\n\n### 一个实战的例子\n\n官方文档对 Inventory 仅作概念性描述，阅读完后仍是一头雾水，不知如何下手。 让我们用一个例子来豁然开朗吧。 我们使用 AWS 的 AutoScaling Group，以下简称 ASG，ASG 会在某种自定义的条件下会自动开启和关闭机器，这给我们在辨别IP，定位机器的时候造成困扰。因此我们需要 Ansible Dynamic Inventory\n\n我们使用 AWS 的 boto 库来获取 ASG 的实例信息.以下程序(get_host.py)中要实现的方法就是列出返回机器信息的 json 串。\n\n```python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport json\nimport boto\nimport boto.ec2\nimport boto.ec2.autoscale\n\nAWS_REGION = 'BBB'\nAWS_ACCESS_KEY = 'xxxx'\nAWS_SECRET_KEY = 'yyy'\n\nresult = {}\ndef getData():\n    conn_as = boto.ec2.autoscale.connect_to_region(\n            'cn-north-1',\n            aws_access_key_id=AWS_ACCESS_KEY,\n            aws_secret_access_key=AWS_SECRET_KEY)\n    group = conn_as.get_all_groups(names=['devtest-asg'])[0]\n    conn_ec2 = boto.ec2.connect_to_region(\n            AWS_REGION,\n            aws_access_key_id=AWS_ACCESS_KEY,\n            aws_secret_access_key=AWS_SECRET_KEY)\n\n    instance_ids = [i.instance_id for i in group.instances]\n    reservations = conn_ec2.get_all_instances(instance_ids)\n    instances = [i for r in reservations for i in r.instances]\n\n    result['devtest-asg'] = {}\n    result['devtest-asg']['hosts'] = []\n    for r in reservations:\n        for i in r.instances:\n            result['devtest-asg']['hosts'].append('%s' % i.private_ip_address)\n            result['devtest-asg']['vars'] = {'ansible_ssh_port': 36000}\n\ndef getlists():\n    getData()\n    print json.dumps(result)\n\ngetlists()\n```\n\n执行以下命令就可以愉快地使用 Ansible 了，其中 devtest-asg 是 ASG 的别名：\n\n```\nansible -i get_host.py  devtest-asg -m raw -a 'ls /'\n```\n","slug":"2016-04-24-ansible-dynamic-inventory","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdag004gnctjzdgxl8di","content":"<p>Ansible 在使用的过程中，如果机器数量比较固定，且变更不多的情况下，可在 /etc/ansible/hosts 文件里面配置固定的组合机器IP， 并给他起组的别名，执行 Ansible 脚本便可以通过别名找到相应的机器。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[webservers]</span><br><span class=\"line\">111.222.333.444 ansible_ssh_port=888</span><br></pre></td></tr></table></figure>\n<p>假如你有很多台机器，且机器经常变更导致IP时常变换，你还想把IP逐个写入 /etc/ansible/hosts 就不现实了。你也许会问，若不把 IP 写进 /etc/ansible/hosts，那不是没法用 Ansible 指挥这些机器？<br>感谢 Ansible Dynamic Inventory， 如果我们能通过编程等手段获取变更机器的IP，我们还是有办法实现的。</p>\n<h3 id=\"Dynamic-Inventory-的原理\"><a href=\"#Dynamic-Inventory-的原理\" class=\"headerlink\" title=\"Dynamic Inventory 的原理\"></a>Dynamic Inventory 的原理</h3><ul>\n<li>通过编程的方式,也就是动态获取机器的 json 信息;</li>\n<li>Ansible 通过解析这串 json 字符串;</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ansible -i yourprogram.py -m raw  -a &apos;cd /home&apos;</span><br></pre></td></tr></table></figure>\n<p>Ansible Dynamic Inventory 对程序返回的 json 的转义是这样的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;devtest-asg&quot;: &#123;&quot;hosts&quot;: [&quot;172.31.21.164&quot;], &quot;vars&quot;: &#123;&quot;ansible_ssh_port&quot;: 12306&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>\n<p>翻译一下就是  /etc/ansible/hosts 中的:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[devtest-asg]</span><br><span class=\"line\">172.31.21.164 ansible_ssh_port=12306</span><br></pre></td></tr></table></figure>\n<h3 id=\"一个实战的例子\"><a href=\"#一个实战的例子\" class=\"headerlink\" title=\"一个实战的例子\"></a>一个实战的例子</h3><p>官方文档对 Inventory 仅作概念性描述，阅读完后仍是一头雾水，不知如何下手。 让我们用一个例子来豁然开朗吧。 我们使用 AWS 的 AutoScaling Group，以下简称 ASG，ASG 会在某种自定义的条件下会自动开启和关闭机器，这给我们在辨别IP，定位机器的时候造成困扰。因此我们需要 Ansible Dynamic Inventory</p>\n<p>我们使用 AWS 的 boto 库来获取 ASG 的实例信息.以下程序(get_host.py)中要实现的方法就是列出返回机器信息的 json 串。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> boto</span><br><span class=\"line\"><span class=\"keyword\">import</span> boto.ec2</span><br><span class=\"line\"><span class=\"keyword\">import</span> boto.ec2.autoscale</span><br><span class=\"line\"></span><br><span class=\"line\">AWS_REGION = <span class=\"string\">'BBB'</span></span><br><span class=\"line\">AWS_ACCESS_KEY = <span class=\"string\">'xxxx'</span></span><br><span class=\"line\">AWS_SECRET_KEY = <span class=\"string\">'yyy'</span></span><br><span class=\"line\"></span><br><span class=\"line\">result = &#123;&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">getData</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    conn_as = boto.ec2.autoscale.connect_to_region(</span><br><span class=\"line\">            <span class=\"string\">'cn-north-1'</span>,</span><br><span class=\"line\">            aws_access_key_id=AWS_ACCESS_KEY,</span><br><span class=\"line\">            aws_secret_access_key=AWS_SECRET_KEY)</span><br><span class=\"line\">    group = conn_as.get_all_groups(names=[<span class=\"string\">'devtest-asg'</span>])[<span class=\"number\">0</span>]</span><br><span class=\"line\">    conn_ec2 = boto.ec2.connect_to_region(</span><br><span class=\"line\">            AWS_REGION,</span><br><span class=\"line\">            aws_access_key_id=AWS_ACCESS_KEY,</span><br><span class=\"line\">            aws_secret_access_key=AWS_SECRET_KEY)</span><br><span class=\"line\"></span><br><span class=\"line\">    instance_ids = [i.instance_id <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> group.instances]</span><br><span class=\"line\">    reservations = conn_ec2.get_all_instances(instance_ids)</span><br><span class=\"line\">    instances = [i <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> reservations <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> r.instances]</span><br><span class=\"line\"></span><br><span class=\"line\">    result[<span class=\"string\">'devtest-asg'</span>] = &#123;&#125;</span><br><span class=\"line\">    result[<span class=\"string\">'devtest-asg'</span>][<span class=\"string\">'hosts'</span>] = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> reservations:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> r.instances:</span><br><span class=\"line\">            result[<span class=\"string\">'devtest-asg'</span>][<span class=\"string\">'hosts'</span>].append(<span class=\"string\">'%s'</span> % i.private_ip_address)</span><br><span class=\"line\">            result[<span class=\"string\">'devtest-asg'</span>][<span class=\"string\">'vars'</span>] = &#123;<span class=\"string\">'ansible_ssh_port'</span>: <span class=\"number\">36000</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">getlists</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    getData()</span><br><span class=\"line\">    <span class=\"keyword\">print</span> json.dumps(result)</span><br><span class=\"line\"></span><br><span class=\"line\">getlists()</span><br></pre></td></tr></table></figure>\n<p>执行以下命令就可以愉快地使用 Ansible 了，其中 devtest-asg 是 ASG 的别名：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ansible -i get_host.py  devtest-asg -m raw -a &apos;ls /&apos;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>Ansible 在使用的过程中，如果机器数量比较固定，且变更不多的情况下，可在 /etc/ansible/hosts 文件里面配置固定的组合机器IP， 并给他起组的别名，执行 Ansible 脚本便可以通过别名找到相应的机器。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[webservers]</span><br><span class=\"line\">111.222.333.444 ansible_ssh_port=888</span><br></pre></td></tr></table></figure>\n<p>假如你有很多台机器，且机器经常变更导致IP时常变换，你还想把IP逐个写入 /etc/ansible/hosts 就不现实了。你也许会问，若不把 IP 写进 /etc/ansible/hosts，那不是没法用 Ansible 指挥这些机器？<br>感谢 Ansible Dynamic Inventory， 如果我们能通过编程等手段获取变更机器的IP，我们还是有办法实现的。</p>\n<h3 id=\"Dynamic-Inventory-的原理\"><a href=\"#Dynamic-Inventory-的原理\" class=\"headerlink\" title=\"Dynamic Inventory 的原理\"></a>Dynamic Inventory 的原理</h3><ul>\n<li>通过编程的方式,也就是动态获取机器的 json 信息;</li>\n<li>Ansible 通过解析这串 json 字符串;</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ansible -i yourprogram.py -m raw  -a &apos;cd /home&apos;</span><br></pre></td></tr></table></figure>\n<p>Ansible Dynamic Inventory 对程序返回的 json 的转义是这样的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;devtest-asg&quot;: &#123;&quot;hosts&quot;: [&quot;172.31.21.164&quot;], &quot;vars&quot;: &#123;&quot;ansible_ssh_port&quot;: 12306&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>\n<p>翻译一下就是  /etc/ansible/hosts 中的:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[devtest-asg]</span><br><span class=\"line\">172.31.21.164 ansible_ssh_port=12306</span><br></pre></td></tr></table></figure>\n<h3 id=\"一个实战的例子\"><a href=\"#一个实战的例子\" class=\"headerlink\" title=\"一个实战的例子\"></a>一个实战的例子</h3><p>官方文档对 Inventory 仅作概念性描述，阅读完后仍是一头雾水，不知如何下手。 让我们用一个例子来豁然开朗吧。 我们使用 AWS 的 AutoScaling Group，以下简称 ASG，ASG 会在某种自定义的条件下会自动开启和关闭机器，这给我们在辨别IP，定位机器的时候造成困扰。因此我们需要 Ansible Dynamic Inventory</p>\n<p>我们使用 AWS 的 boto 库来获取 ASG 的实例信息.以下程序(get_host.py)中要实现的方法就是列出返回机器信息的 json 串。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> boto</span><br><span class=\"line\"><span class=\"keyword\">import</span> boto.ec2</span><br><span class=\"line\"><span class=\"keyword\">import</span> boto.ec2.autoscale</span><br><span class=\"line\"></span><br><span class=\"line\">AWS_REGION = <span class=\"string\">'BBB'</span></span><br><span class=\"line\">AWS_ACCESS_KEY = <span class=\"string\">'xxxx'</span></span><br><span class=\"line\">AWS_SECRET_KEY = <span class=\"string\">'yyy'</span></span><br><span class=\"line\"></span><br><span class=\"line\">result = &#123;&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">getData</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    conn_as = boto.ec2.autoscale.connect_to_region(</span><br><span class=\"line\">            <span class=\"string\">'cn-north-1'</span>,</span><br><span class=\"line\">            aws_access_key_id=AWS_ACCESS_KEY,</span><br><span class=\"line\">            aws_secret_access_key=AWS_SECRET_KEY)</span><br><span class=\"line\">    group = conn_as.get_all_groups(names=[<span class=\"string\">'devtest-asg'</span>])[<span class=\"number\">0</span>]</span><br><span class=\"line\">    conn_ec2 = boto.ec2.connect_to_region(</span><br><span class=\"line\">            AWS_REGION,</span><br><span class=\"line\">            aws_access_key_id=AWS_ACCESS_KEY,</span><br><span class=\"line\">            aws_secret_access_key=AWS_SECRET_KEY)</span><br><span class=\"line\"></span><br><span class=\"line\">    instance_ids = [i.instance_id <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> group.instances]</span><br><span class=\"line\">    reservations = conn_ec2.get_all_instances(instance_ids)</span><br><span class=\"line\">    instances = [i <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> reservations <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> r.instances]</span><br><span class=\"line\"></span><br><span class=\"line\">    result[<span class=\"string\">'devtest-asg'</span>] = &#123;&#125;</span><br><span class=\"line\">    result[<span class=\"string\">'devtest-asg'</span>][<span class=\"string\">'hosts'</span>] = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> reservations:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> r.instances:</span><br><span class=\"line\">            result[<span class=\"string\">'devtest-asg'</span>][<span class=\"string\">'hosts'</span>].append(<span class=\"string\">'%s'</span> % i.private_ip_address)</span><br><span class=\"line\">            result[<span class=\"string\">'devtest-asg'</span>][<span class=\"string\">'vars'</span>] = &#123;<span class=\"string\">'ansible_ssh_port'</span>: <span class=\"number\">36000</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">getlists</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    getData()</span><br><span class=\"line\">    <span class=\"keyword\">print</span> json.dumps(result)</span><br><span class=\"line\"></span><br><span class=\"line\">getlists()</span><br></pre></td></tr></table></figure>\n<p>执行以下命令就可以愉快地使用 Ansible 了，其中 devtest-asg 是 ASG 的别名：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ansible -i get_host.py  devtest-asg -m raw -a &apos;ls /&apos;</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"准确监控 MySQL 复制延迟","date":"2016-06-03T15:35:00.000Z","comments":1,"description":"mysql pt-heartbeat","_content":"\nMySQL 建立主从复制后，在 `Slave_IO_Running`,`Slave_SQL_Runing` 都是 Yes 的前提下，通过监控 `Second_Behind_Master` 的数值来判断主从延迟时间，该值为0时是否意味着主从同步是无延迟的呢？\n\n```sql\nmysql> show slave status\\G;\n*************************** 1. row ***************************\nSlave_IO_State: Waiting for master to send event\n....\nSlave_IO_Running: Yes\nSlave_SQL_Running: Yes\nSeconds_Behind_Master: 0\n...\n```\n\n很遗憾，我们并不能这样去判断，因为你看到的有可能是假象。\n\n\nMySQL的同步是异步完成的，其中\n\n* IO thread 接收从主库的 binlog，然后在从库生成 relay log\n* SQL thead 解析 relay log 后在从库上进行重放\n\n`Second_Behind_Master`(以下简称SBM) 是 SQL thread 在执行IO thread 生成的relay log的时间差。relay log中event的时间戳是主库上的时间戳，而SQL thread的时间戳是从库上的，SBM 代表的是从库延后主库的时间差。\n\n主库上执行了一个大的操作，这个操作在主库上没执行完毕的时候，从库的 SBM 会显示为0，而当主库执行完毕传到从库上开始执行的时候,SBM 就会显示很大，在网络状况不好的情况下，更是容易出现 SBM 在零和一个巨大的数值反复飘忽的现象。\n\n\n### pt-heartbeat 帮我们准确地检测\n\npt-heartbeat 是 percona-toolkit 中用来检测主从延迟的工具，需要在主库和从库同时配合才能完成\n\n* 首先在主库创建监控的表，并定时更新\n\n```\n//创建 heartbeat 表\npt-heartbeat --user=root --ask-pass \\\n            --host=localhost -D <YourDatabase> \\\n            --create-table --update \n\n//每隔60s,定时更新状态，以守护进程的方式执行\npt-heartbeat --user=root --ask-pass \\\n           --host=localhost -D <YourDatabase>\\\n           --interval=60 --update --replace --daemonize\n```\n它会在指定的数据库里生产一张名为 heartbeat 的表，每隔60秒定时更新binlog 文件和位置，以及时间戳。\n\n```\n+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+\n| ts                         | server_id | file             | position  | relay_master_log_file | exec_master_log_pos |\n+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+\n| 2016-06-03T22:26:29.000720 |         6 | mysql-bin.004| 716| mysql-bin.002|           291330290 |\n+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+\n```\n\n* 接着在从库以守护进程执行定期检测,并将结果重定向到文本\n\n```\npt-heartbeat --user=root --ask-pass \\\n     --host=localhost -D <YourDatabase> --interval=60 \\\n     --file=/tmp/output.txt --monitor --daemonize\n```\n\n文本的内容只有一行，每隔指定的时间就会被覆盖\n\n```\n29.00s [ 30.20s,  6.04s,  2.01s ]\n```\n\n29s 表示的是瞬间的延迟时间，30.20s 表示1分钟的延迟时间，6.04秒表示5分钟的延迟时间，2.01秒表示以及15分钟的延迟时间，在主从机器时间校准的前提下，这个数据才是客观准确的主从延迟。\n","source":"_posts/2016-06-03-zhun-que-jian-ce-mysql-fu-zhi-yan-chi.markdown","raw":"---\nlayout: post\ntitle: \"准确监控 MySQL 复制延迟\"\ndate: 2016-06-03 23:35\ncomments: true\ncategories: DataBase\ndescription: mysql pt-heartbeat\n---\n\nMySQL 建立主从复制后，在 `Slave_IO_Running`,`Slave_SQL_Runing` 都是 Yes 的前提下，通过监控 `Second_Behind_Master` 的数值来判断主从延迟时间，该值为0时是否意味着主从同步是无延迟的呢？\n\n```sql\nmysql> show slave status\\G;\n*************************** 1. row ***************************\nSlave_IO_State: Waiting for master to send event\n....\nSlave_IO_Running: Yes\nSlave_SQL_Running: Yes\nSeconds_Behind_Master: 0\n...\n```\n\n很遗憾，我们并不能这样去判断，因为你看到的有可能是假象。\n\n\nMySQL的同步是异步完成的，其中\n\n* IO thread 接收从主库的 binlog，然后在从库生成 relay log\n* SQL thead 解析 relay log 后在从库上进行重放\n\n`Second_Behind_Master`(以下简称SBM) 是 SQL thread 在执行IO thread 生成的relay log的时间差。relay log中event的时间戳是主库上的时间戳，而SQL thread的时间戳是从库上的，SBM 代表的是从库延后主库的时间差。\n\n主库上执行了一个大的操作，这个操作在主库上没执行完毕的时候，从库的 SBM 会显示为0，而当主库执行完毕传到从库上开始执行的时候,SBM 就会显示很大，在网络状况不好的情况下，更是容易出现 SBM 在零和一个巨大的数值反复飘忽的现象。\n\n\n### pt-heartbeat 帮我们准确地检测\n\npt-heartbeat 是 percona-toolkit 中用来检测主从延迟的工具，需要在主库和从库同时配合才能完成\n\n* 首先在主库创建监控的表，并定时更新\n\n```\n//创建 heartbeat 表\npt-heartbeat --user=root --ask-pass \\\n            --host=localhost -D <YourDatabase> \\\n            --create-table --update \n\n//每隔60s,定时更新状态，以守护进程的方式执行\npt-heartbeat --user=root --ask-pass \\\n           --host=localhost -D <YourDatabase>\\\n           --interval=60 --update --replace --daemonize\n```\n它会在指定的数据库里生产一张名为 heartbeat 的表，每隔60秒定时更新binlog 文件和位置，以及时间戳。\n\n```\n+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+\n| ts                         | server_id | file             | position  | relay_master_log_file | exec_master_log_pos |\n+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+\n| 2016-06-03T22:26:29.000720 |         6 | mysql-bin.004| 716| mysql-bin.002|           291330290 |\n+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+\n```\n\n* 接着在从库以守护进程执行定期检测,并将结果重定向到文本\n\n```\npt-heartbeat --user=root --ask-pass \\\n     --host=localhost -D <YourDatabase> --interval=60 \\\n     --file=/tmp/output.txt --monitor --daemonize\n```\n\n文本的内容只有一行，每隔指定的时间就会被覆盖\n\n```\n29.00s [ 30.20s,  6.04s,  2.01s ]\n```\n\n29s 表示的是瞬间的延迟时间，30.20s 表示1分钟的延迟时间，6.04秒表示5分钟的延迟时间，2.01秒表示以及15分钟的延迟时间，在主从机器时间校准的前提下，这个数据才是客观准确的主从延迟。\n","slug":"2016-06-03-zhun-que-jian-ce-mysql-fu-zhi-yan-chi","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdai004inctjnm2lkk3n","content":"<p>MySQL 建立主从复制后，在 <code>Slave_IO_Running</code>,<code>Slave_SQL_Runing</code> 都是 Yes 的前提下，通过监控 <code>Second_Behind_Master</code> 的数值来判断主从延迟时间，该值为0时是否意味着主从同步是无延迟的呢？</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show slave status\\G;</span><br><span class=\"line\">*************************** 1. row ***************************</span><br><span class=\"line\">Slave_IO_State: Waiting for master to send event</span><br><span class=\"line\">....</span><br><span class=\"line\">Slave_IO_Running: Yes</span><br><span class=\"line\">Slave_SQL_Running: Yes</span><br><span class=\"line\">Seconds_Behind_Master: 0</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>很遗憾，我们并不能这样去判断，因为你看到的有可能是假象。</p>\n<p>MySQL的同步是异步完成的，其中</p>\n<ul>\n<li>IO thread 接收从主库的 binlog，然后在从库生成 relay log</li>\n<li>SQL thead 解析 relay log 后在从库上进行重放</li>\n</ul>\n<p><code>Second_Behind_Master</code>(以下简称SBM) 是 SQL thread 在执行IO thread 生成的relay log的时间差。relay log中event的时间戳是主库上的时间戳，而SQL thread的时间戳是从库上的，SBM 代表的是从库延后主库的时间差。</p>\n<p>主库上执行了一个大的操作，这个操作在主库上没执行完毕的时候，从库的 SBM 会显示为0，而当主库执行完毕传到从库上开始执行的时候,SBM 就会显示很大，在网络状况不好的情况下，更是容易出现 SBM 在零和一个巨大的数值反复飘忽的现象。</p>\n<h3 id=\"pt-heartbeat-帮我们准确地检测\"><a href=\"#pt-heartbeat-帮我们准确地检测\" class=\"headerlink\" title=\"pt-heartbeat 帮我们准确地检测\"></a>pt-heartbeat 帮我们准确地检测</h3><p>pt-heartbeat 是 percona-toolkit 中用来检测主从延迟的工具，需要在主库和从库同时配合才能完成</p>\n<ul>\n<li>首先在主库创建监控的表，并定时更新</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//创建 heartbeat 表</span><br><span class=\"line\">pt-heartbeat --user=root --ask-pass \\</span><br><span class=\"line\">            --host=localhost -D &lt;YourDatabase&gt; \\</span><br><span class=\"line\">            --create-table --update </span><br><span class=\"line\"></span><br><span class=\"line\">//每隔60s,定时更新状态，以守护进程的方式执行</span><br><span class=\"line\">pt-heartbeat --user=root --ask-pass \\</span><br><span class=\"line\">           --host=localhost -D &lt;YourDatabase&gt;\\</span><br><span class=\"line\">           --interval=60 --update --replace --daemonize</span><br></pre></td></tr></table></figure>\n<p>它会在指定的数据库里生产一张名为 heartbeat 的表，每隔60秒定时更新binlog 文件和位置，以及时间戳。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span><br><span class=\"line\">| ts                         | server_id | file             | position  | relay_master_log_file | exec_master_log_pos |</span><br><span class=\"line\">+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span><br><span class=\"line\">| 2016-06-03T22:26:29.000720 |         6 | mysql-bin.004| 716| mysql-bin.002|           291330290 |</span><br><span class=\"line\">+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span><br></pre></td></tr></table></figure>\n<ul>\n<li>接着在从库以守护进程执行定期检测,并将结果重定向到文本</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pt-heartbeat --user=root --ask-pass \\</span><br><span class=\"line\">     --host=localhost -D &lt;YourDatabase&gt; --interval=60 \\</span><br><span class=\"line\">     --file=/tmp/output.txt --monitor --daemonize</span><br></pre></td></tr></table></figure>\n<p>文本的内容只有一行，每隔指定的时间就会被覆盖</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">29.00s [ 30.20s,  6.04s,  2.01s ]</span><br></pre></td></tr></table></figure>\n<p>29s 表示的是瞬间的延迟时间，30.20s 表示1分钟的延迟时间，6.04秒表示5分钟的延迟时间，2.01秒表示以及15分钟的延迟时间，在主从机器时间校准的前提下，这个数据才是客观准确的主从延迟。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>MySQL 建立主从复制后，在 <code>Slave_IO_Running</code>,<code>Slave_SQL_Runing</code> 都是 Yes 的前提下，通过监控 <code>Second_Behind_Master</code> 的数值来判断主从延迟时间，该值为0时是否意味着主从同步是无延迟的呢？</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; show slave status\\G;</span><br><span class=\"line\">*************************** 1. row ***************************</span><br><span class=\"line\">Slave_IO_State: Waiting for master to send event</span><br><span class=\"line\">....</span><br><span class=\"line\">Slave_IO_Running: Yes</span><br><span class=\"line\">Slave_SQL_Running: Yes</span><br><span class=\"line\">Seconds_Behind_Master: 0</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>很遗憾，我们并不能这样去判断，因为你看到的有可能是假象。</p>\n<p>MySQL的同步是异步完成的，其中</p>\n<ul>\n<li>IO thread 接收从主库的 binlog，然后在从库生成 relay log</li>\n<li>SQL thead 解析 relay log 后在从库上进行重放</li>\n</ul>\n<p><code>Second_Behind_Master</code>(以下简称SBM) 是 SQL thread 在执行IO thread 生成的relay log的时间差。relay log中event的时间戳是主库上的时间戳，而SQL thread的时间戳是从库上的，SBM 代表的是从库延后主库的时间差。</p>\n<p>主库上执行了一个大的操作，这个操作在主库上没执行完毕的时候，从库的 SBM 会显示为0，而当主库执行完毕传到从库上开始执行的时候,SBM 就会显示很大，在网络状况不好的情况下，更是容易出现 SBM 在零和一个巨大的数值反复飘忽的现象。</p>\n<h3 id=\"pt-heartbeat-帮我们准确地检测\"><a href=\"#pt-heartbeat-帮我们准确地检测\" class=\"headerlink\" title=\"pt-heartbeat 帮我们准确地检测\"></a>pt-heartbeat 帮我们准确地检测</h3><p>pt-heartbeat 是 percona-toolkit 中用来检测主从延迟的工具，需要在主库和从库同时配合才能完成</p>\n<ul>\n<li>首先在主库创建监控的表，并定时更新</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//创建 heartbeat 表</span><br><span class=\"line\">pt-heartbeat --user=root --ask-pass \\</span><br><span class=\"line\">            --host=localhost -D &lt;YourDatabase&gt; \\</span><br><span class=\"line\">            --create-table --update </span><br><span class=\"line\"></span><br><span class=\"line\">//每隔60s,定时更新状态，以守护进程的方式执行</span><br><span class=\"line\">pt-heartbeat --user=root --ask-pass \\</span><br><span class=\"line\">           --host=localhost -D &lt;YourDatabase&gt;\\</span><br><span class=\"line\">           --interval=60 --update --replace --daemonize</span><br></pre></td></tr></table></figure>\n<p>它会在指定的数据库里生产一张名为 heartbeat 的表，每隔60秒定时更新binlog 文件和位置，以及时间戳。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span><br><span class=\"line\">| ts                         | server_id | file             | position  | relay_master_log_file | exec_master_log_pos |</span><br><span class=\"line\">+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span><br><span class=\"line\">| 2016-06-03T22:26:29.000720 |         6 | mysql-bin.004| 716| mysql-bin.002|           291330290 |</span><br><span class=\"line\">+----------------------------+-----------+------------------+-----------+-----------------------+---------------------+</span><br></pre></td></tr></table></figure>\n<ul>\n<li>接着在从库以守护进程执行定期检测,并将结果重定向到文本</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pt-heartbeat --user=root --ask-pass \\</span><br><span class=\"line\">     --host=localhost -D &lt;YourDatabase&gt; --interval=60 \\</span><br><span class=\"line\">     --file=/tmp/output.txt --monitor --daemonize</span><br></pre></td></tr></table></figure>\n<p>文本的内容只有一行，每隔指定的时间就会被覆盖</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">29.00s [ 30.20s,  6.04s,  2.01s ]</span><br></pre></td></tr></table></figure>\n<p>29s 表示的是瞬间的延迟时间，30.20s 表示1分钟的延迟时间，6.04秒表示5分钟的延迟时间，2.01秒表示以及15分钟的延迟时间，在主从机器时间校准的前提下，这个数据才是客观准确的主从延迟。</p>\n"},{"layout":"post","title":"环境变量的那些事","date":"2016-07-16T03:35:00.000Z","comments":1,"description":"ssh","_content":"\n* [四种模式下的环境变量加载](#第一节)\n* [跨机器SSH 传递环境变量](#第二节)\n\n<h3 id=\"第一节\">四种模式下的环境变量加载</h3>\n\n名词解析\n\n1. login shell: 指用户以非图形化界面 ssh登陆到机器上时获得的第一个 shell。 \n2. interactive: 交互式，有输入提示符，它的标准输入输出和错误输出都会显示在控制台上。\n\n* interactive + login shell\n\n比如登陆机器后的第一个 shell 就是这种场景。它首先加载 /etc/profile，然后再依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找\n\n```\n~/.bash_profile\n~/.bash_login\n~/.profile\n```\n\n设计如此多的配置是为了兼容 bourne shell 和 C shell，尽量杜绝使用 .bash_login，如果已创建，需要创建 .bash_profile 覆盖\n\n* noninteractive + login shell\n\nbash -l script.sh 就是这种场景。`-l` 参数是将shell作为一个login shell启动，配置文件的加载与第一种完全一样。\n\n* interactive + non-login shell\n\n在一个已有shell中运行bash，此时会打开一个交互式的shell，因为不再需要登陆，所以不是login shell。启动 shell 时会去查找并加载\n\n```\n/etc/bash.bashrc\n~/.bashrc \n```\n\n* non-interactive + non-login shell\n\n比如执行脚本 bash script.sh 或者 ssh user@remote command。这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。\n\n从网上看到一个清晰的图\n\n```\n+----------------+--------+-----------+---------------+\n|                | login  |interactive|non-interactive|\n|                |        |non-login  |non-login      |\n+----------------+--------+-----------+---------------+\n|/etc/profile    |   A    |           |               |\n+----------------+--------+-----------+---------------+\n|/etc/bash.bashrc|        |    A      |               |\n+----------------+--------+-----------+---------------+\n|~/.bashrc       |        |    B      |               |\n+----------------+--------+-----------+---------------+\n|~/.bash_profile |   B1   |           |               |\n+----------------+--------+-----------+---------------+\n|~/.bash_login   |   B2   |           |               |\n+----------------+--------+-----------+---------------+\n|~/.profile      |   B3   |           |               |\n+----------------+--------+-----------+---------------+\n|BASH_ENV        |        |           |       A       |\n+----------------+--------+-----------+---------------+\n```\n----\n\n<h3 id=\"第二节\">跨机器传递环境变量</h3>\n\n假设要传递的变量叫做 $VARNAME\n\n客户端机器的 `/etc/ssh_config` 添加 \n\n```\nSendEnv VARNAME\n```\n\n服务端机器的 `/etc/sshd_config` 添加\n\n``` \nAcceptEnv VARNAME\n```\n\n客户端机器的 $VARNAME 就可以通过 ssh 传递到服务端机器，继续使用.\n\n---\n\n### 参考\n\n[ssh连接远程主机执行脚本的环境变量问题](http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote/)\n","source":"_posts/2016-07-16-bash-jia-zai-shun-xu.markdown","raw":"---\nlayout: post\ntitle: \"环境变量的那些事\"\ndate: 2016-07-16 11:35\ncomments: true\ncategories: System\ndescription: ssh\n---\n\n* [四种模式下的环境变量加载](#第一节)\n* [跨机器SSH 传递环境变量](#第二节)\n\n<h3 id=\"第一节\">四种模式下的环境变量加载</h3>\n\n名词解析\n\n1. login shell: 指用户以非图形化界面 ssh登陆到机器上时获得的第一个 shell。 \n2. interactive: 交互式，有输入提示符，它的标准输入输出和错误输出都会显示在控制台上。\n\n* interactive + login shell\n\n比如登陆机器后的第一个 shell 就是这种场景。它首先加载 /etc/profile，然后再依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找\n\n```\n~/.bash_profile\n~/.bash_login\n~/.profile\n```\n\n设计如此多的配置是为了兼容 bourne shell 和 C shell，尽量杜绝使用 .bash_login，如果已创建，需要创建 .bash_profile 覆盖\n\n* noninteractive + login shell\n\nbash -l script.sh 就是这种场景。`-l` 参数是将shell作为一个login shell启动，配置文件的加载与第一种完全一样。\n\n* interactive + non-login shell\n\n在一个已有shell中运行bash，此时会打开一个交互式的shell，因为不再需要登陆，所以不是login shell。启动 shell 时会去查找并加载\n\n```\n/etc/bash.bashrc\n~/.bashrc \n```\n\n* non-interactive + non-login shell\n\n比如执行脚本 bash script.sh 或者 ssh user@remote command。这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。\n\n从网上看到一个清晰的图\n\n```\n+----------------+--------+-----------+---------------+\n|                | login  |interactive|non-interactive|\n|                |        |non-login  |non-login      |\n+----------------+--------+-----------+---------------+\n|/etc/profile    |   A    |           |               |\n+----------------+--------+-----------+---------------+\n|/etc/bash.bashrc|        |    A      |               |\n+----------------+--------+-----------+---------------+\n|~/.bashrc       |        |    B      |               |\n+----------------+--------+-----------+---------------+\n|~/.bash_profile |   B1   |           |               |\n+----------------+--------+-----------+---------------+\n|~/.bash_login   |   B2   |           |               |\n+----------------+--------+-----------+---------------+\n|~/.profile      |   B3   |           |               |\n+----------------+--------+-----------+---------------+\n|BASH_ENV        |        |           |       A       |\n+----------------+--------+-----------+---------------+\n```\n----\n\n<h3 id=\"第二节\">跨机器传递环境变量</h3>\n\n假设要传递的变量叫做 $VARNAME\n\n客户端机器的 `/etc/ssh_config` 添加 \n\n```\nSendEnv VARNAME\n```\n\n服务端机器的 `/etc/sshd_config` 添加\n\n``` \nAcceptEnv VARNAME\n```\n\n客户端机器的 $VARNAME 就可以通过 ssh 传递到服务端机器，继续使用.\n\n---\n\n### 参考\n\n[ssh连接远程主机执行脚本的环境变量问题](http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote/)\n","slug":"2016-07-16-bash-jia-zai-shun-xu","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdaj004knctjjrvcyiqp","content":"<ul>\n<li><a href=\"#第一节\">四种模式下的环境变量加载</a></li>\n<li><a href=\"#第二节\">跨机器SSH 传递环境变量</a></li>\n</ul>\n<h3 id=\"第一节\">四种模式下的环境变量加载</h3>\n\n<p>名词解析</p>\n<ol>\n<li>login shell: 指用户以非图形化界面 ssh登陆到机器上时获得的第一个 shell。 </li>\n<li>interactive: 交互式，有输入提示符，它的标准输入输出和错误输出都会显示在控制台上。</li>\n</ol>\n<ul>\n<li>interactive + login shell</li>\n</ul>\n<p>比如登陆机器后的第一个 shell 就是这种场景。它首先加载 /etc/profile，然后再依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~/.bash_profile</span><br><span class=\"line\">~/.bash_login</span><br><span class=\"line\">~/.profile</span><br></pre></td></tr></table></figure>\n<p>设计如此多的配置是为了兼容 bourne shell 和 C shell，尽量杜绝使用 .bash_login，如果已创建，需要创建 .bash_profile 覆盖</p>\n<ul>\n<li>noninteractive + login shell</li>\n</ul>\n<p>bash -l script.sh 就是这种场景。<code>-l</code> 参数是将shell作为一个login shell启动，配置文件的加载与第一种完全一样。</p>\n<ul>\n<li>interactive + non-login shell</li>\n</ul>\n<p>在一个已有shell中运行bash，此时会打开一个交互式的shell，因为不再需要登陆，所以不是login shell。启动 shell 时会去查找并加载</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/etc/bash.bashrc</span><br><span class=\"line\">~/.bashrc</span><br></pre></td></tr></table></figure>\n<ul>\n<li>non-interactive + non-login shell</li>\n</ul>\n<p>比如执行脚本 bash script.sh 或者 ssh user@remote command。这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。</p>\n<p>从网上看到一个清晰的图</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|                | login  |interactive|non-interactive|</span><br><span class=\"line\">|                |        |non-login  |non-login      |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|/etc/profile    |   A    |           |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|/etc/bash.bashrc|        |    A      |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|~/.bashrc       |        |    B      |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|~/.bash_profile |   B1   |           |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|~/.bash_login   |   B2   |           |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|~/.profile      |   B3   |           |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|BASH_ENV        |        |           |       A       |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br></pre></td></tr></table></figure>\n<hr>\n<h3 id=\"第二节\">跨机器传递环境变量</h3>\n\n<p>假设要传递的变量叫做 $VARNAME</p>\n<p>客户端机器的 <code>/etc/ssh_config</code> 添加 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SendEnv VARNAME</span><br></pre></td></tr></table></figure>\n<p>服务端机器的 <code>/etc/sshd_config</code> 添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AcceptEnv VARNAME</span><br></pre></td></tr></table></figure>\n<p>客户端机器的 $VARNAME 就可以通过 ssh 传递到服务端机器，继续使用.</p>\n<hr>\n<h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><p><a href=\"http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote/\" target=\"_blank\" rel=\"noopener\">ssh连接远程主机执行脚本的环境变量问题</a></p>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li><a href=\"#第一节\">四种模式下的环境变量加载</a></li>\n<li><a href=\"#第二节\">跨机器SSH 传递环境变量</a></li>\n</ul>\n<h3 id=\"第一节\">四种模式下的环境变量加载</h3>\n\n<p>名词解析</p>\n<ol>\n<li>login shell: 指用户以非图形化界面 ssh登陆到机器上时获得的第一个 shell。 </li>\n<li>interactive: 交互式，有输入提示符，它的标准输入输出和错误输出都会显示在控制台上。</li>\n</ol>\n<ul>\n<li>interactive + login shell</li>\n</ul>\n<p>比如登陆机器后的第一个 shell 就是这种场景。它首先加载 /etc/profile，然后再依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~/.bash_profile</span><br><span class=\"line\">~/.bash_login</span><br><span class=\"line\">~/.profile</span><br></pre></td></tr></table></figure>\n<p>设计如此多的配置是为了兼容 bourne shell 和 C shell，尽量杜绝使用 .bash_login，如果已创建，需要创建 .bash_profile 覆盖</p>\n<ul>\n<li>noninteractive + login shell</li>\n</ul>\n<p>bash -l script.sh 就是这种场景。<code>-l</code> 参数是将shell作为一个login shell启动，配置文件的加载与第一种完全一样。</p>\n<ul>\n<li>interactive + non-login shell</li>\n</ul>\n<p>在一个已有shell中运行bash，此时会打开一个交互式的shell，因为不再需要登陆，所以不是login shell。启动 shell 时会去查找并加载</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/etc/bash.bashrc</span><br><span class=\"line\">~/.bashrc</span><br></pre></td></tr></table></figure>\n<ul>\n<li>non-interactive + non-login shell</li>\n</ul>\n<p>比如执行脚本 bash script.sh 或者 ssh user@remote command。这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。</p>\n<p>从网上看到一个清晰的图</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|                | login  |interactive|non-interactive|</span><br><span class=\"line\">|                |        |non-login  |non-login      |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|/etc/profile    |   A    |           |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|/etc/bash.bashrc|        |    A      |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|~/.bashrc       |        |    B      |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|~/.bash_profile |   B1   |           |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|~/.bash_login   |   B2   |           |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|~/.profile      |   B3   |           |               |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br><span class=\"line\">|BASH_ENV        |        |           |       A       |</span><br><span class=\"line\">+----------------+--------+-----------+---------------+</span><br></pre></td></tr></table></figure>\n<hr>\n<h3 id=\"第二节\">跨机器传递环境变量</h3>\n\n<p>假设要传递的变量叫做 $VARNAME</p>\n<p>客户端机器的 <code>/etc/ssh_config</code> 添加 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SendEnv VARNAME</span><br></pre></td></tr></table></figure>\n<p>服务端机器的 <code>/etc/sshd_config</code> 添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AcceptEnv VARNAME</span><br></pre></td></tr></table></figure>\n<p>客户端机器的 $VARNAME 就可以通过 ssh 传递到服务端机器，继续使用.</p>\n<hr>\n<h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><p><a href=\"http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote/\" target=\"_blank\" rel=\"noopener\">ssh连接远程主机执行脚本的环境变量问题</a></p>\n"},{"layout":"post","title":"Celery的Crontab实践","date":"2016-07-23T12:19:00.000Z","comments":1,"description":"celery crontab","_content":"\n有时候我们需要处理耗时的操作，同时又要保持较快的响应速度，就需要借助异步队列的帮助。Celery 作为异步队列服务，想必是很多人和我一样的选择。用法在官方文档也详细介绍，不再赘述。\n  \n这次想记录的是用 Celery 来实现定时任务。这里也有一点点坑。\n  \n以下是 `main.py` 的内容\n \n```python\nfrom celery import Celery\nfrom lib import distribute\nfrom celery.schedules import crontab\n\napp = distribute.app\napp.conf.update(\n    CELERYBEAT_SCHEDULE = {\n        'every-minute': {\n            'task': 'test_cron',\n            'schedule': crontab(minute=\"*\"),\n            'args': (16, 13),\n        }\n    },\n    CELERY_INCLUDE=(\"apps.tasks\",)\n)\nif __name__ == '__main__':\n    app.start()\n```\n\n实际工作单元,我放在 apps 目录下的 `tasks.py` 文件中\n\n```py\nfrom lib.distribute import app\n@app.task(name=\"test_cron\")\ndef mul(x, y):\n    return x * y\n```\n\n上述是一个简单的 Crontab 应用，它仅需要以下命令就能执行,\n其中  `--beat` 表示 crontab 的应用\n\n```\npython main.py worker --beat -l info\n```\n\n起初我想把异步队列和定时任务放在一起,就加上了一句 CELERY_QUEUES 的配置\n\n```python\napp.conf.update(\n    // 添加的部分\n    CELERY_QUEUES=(\n        Queue(\n          'test', Exchange('test_exchange'),\n           routing_key='test_queue'\n        ),\n    ),\n    CELERYBEAT_SCHEDULE = {\n        'every-minute': {\n            'task': 'test_cron',\n            'schedule': crontab(minute=\"*\"),\n            'args': (16, 13),\n        }\n    },\n    CELERY_INCLUDE=(\"apps.tasks\",)\n)\n```\n\n同样用上述命令开启worker，发现这个时候 Crontab 不能工作了，后来看到官方的文档：\n\n> celery beat and celery worker as separate services instead. \n\n也就是说 Celery 的 Beat 需要和其他异步worker 分开，单独执行。\n\n相关代码[链接](https://github.com/zheng-ji/ToyCollection/tree/master/celery_proj)\n","source":"_posts/2016-07-23-celeryde-crontabshi-jian.markdown","raw":"---\nlayout: post\ntitle: \"Celery的Crontab实践\"\ndate: 2016-07-23 20:19\ncomments: true\ncategories: Programe\ndescription: celery crontab\n---\n\n有时候我们需要处理耗时的操作，同时又要保持较快的响应速度，就需要借助异步队列的帮助。Celery 作为异步队列服务，想必是很多人和我一样的选择。用法在官方文档也详细介绍，不再赘述。\n  \n这次想记录的是用 Celery 来实现定时任务。这里也有一点点坑。\n  \n以下是 `main.py` 的内容\n \n```python\nfrom celery import Celery\nfrom lib import distribute\nfrom celery.schedules import crontab\n\napp = distribute.app\napp.conf.update(\n    CELERYBEAT_SCHEDULE = {\n        'every-minute': {\n            'task': 'test_cron',\n            'schedule': crontab(minute=\"*\"),\n            'args': (16, 13),\n        }\n    },\n    CELERY_INCLUDE=(\"apps.tasks\",)\n)\nif __name__ == '__main__':\n    app.start()\n```\n\n实际工作单元,我放在 apps 目录下的 `tasks.py` 文件中\n\n```py\nfrom lib.distribute import app\n@app.task(name=\"test_cron\")\ndef mul(x, y):\n    return x * y\n```\n\n上述是一个简单的 Crontab 应用，它仅需要以下命令就能执行,\n其中  `--beat` 表示 crontab 的应用\n\n```\npython main.py worker --beat -l info\n```\n\n起初我想把异步队列和定时任务放在一起,就加上了一句 CELERY_QUEUES 的配置\n\n```python\napp.conf.update(\n    // 添加的部分\n    CELERY_QUEUES=(\n        Queue(\n          'test', Exchange('test_exchange'),\n           routing_key='test_queue'\n        ),\n    ),\n    CELERYBEAT_SCHEDULE = {\n        'every-minute': {\n            'task': 'test_cron',\n            'schedule': crontab(minute=\"*\"),\n            'args': (16, 13),\n        }\n    },\n    CELERY_INCLUDE=(\"apps.tasks\",)\n)\n```\n\n同样用上述命令开启worker，发现这个时候 Crontab 不能工作了，后来看到官方的文档：\n\n> celery beat and celery worker as separate services instead. \n\n也就是说 Celery 的 Beat 需要和其他异步worker 分开，单独执行。\n\n相关代码[链接](https://github.com/zheng-ji/ToyCollection/tree/master/celery_proj)\n","slug":"2016-07-23-celeryde-crontabshi-jian","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdak004mnctj5ij8j32s","content":"<p>有时候我们需要处理耗时的操作，同时又要保持较快的响应速度，就需要借助异步队列的帮助。Celery 作为异步队列服务，想必是很多人和我一样的选择。用法在官方文档也详细介绍，不再赘述。</p>\n<p>这次想记录的是用 Celery 来实现定时任务。这里也有一点点坑。</p>\n<p>以下是 <code>main.py</code> 的内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> celery <span class=\"keyword\">import</span> Celery</span><br><span class=\"line\"><span class=\"keyword\">from</span> lib <span class=\"keyword\">import</span> distribute</span><br><span class=\"line\"><span class=\"keyword\">from</span> celery.schedules <span class=\"keyword\">import</span> crontab</span><br><span class=\"line\"></span><br><span class=\"line\">app = distribute.app</span><br><span class=\"line\">app.conf.update(</span><br><span class=\"line\">    CELERYBEAT_SCHEDULE = &#123;</span><br><span class=\"line\">        <span class=\"string\">'every-minute'</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">'task'</span>: <span class=\"string\">'test_cron'</span>,</span><br><span class=\"line\">            <span class=\"string\">'schedule'</span>: crontab(minute=<span class=\"string\">\"*\"</span>),</span><br><span class=\"line\">            <span class=\"string\">'args'</span>: (<span class=\"number\">16</span>, <span class=\"number\">13</span>),</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    CELERY_INCLUDE=(<span class=\"string\">\"apps.tasks\"</span>,)</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    app.start()</span><br></pre></td></tr></table></figure>\n<p>实际工作单元,我放在 apps 目录下的 <code>tasks.py</code> 文件中</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> lib.distribute <span class=\"keyword\">import</span> app</span><br><span class=\"line\"><span class=\"meta\">@app.task(name=\"test_cron\")</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">mul</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x * y</span><br></pre></td></tr></table></figure>\n<p>上述是一个简单的 Crontab 应用，它仅需要以下命令就能执行,<br>其中  <code>--beat</code> 表示 crontab 的应用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python main.py worker --beat -l info</span><br></pre></td></tr></table></figure>\n<p>起初我想把异步队列和定时任务放在一起,就加上了一句 CELERY_QUEUES 的配置</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">app.conf.update(</span><br><span class=\"line\">    // 添加的部分</span><br><span class=\"line\">    CELERY_QUEUES=(</span><br><span class=\"line\">        Queue(</span><br><span class=\"line\">          <span class=\"string\">'test'</span>, Exchange(<span class=\"string\">'test_exchange'</span>),</span><br><span class=\"line\">           routing_key=<span class=\"string\">'test_queue'</span></span><br><span class=\"line\">        ),</span><br><span class=\"line\">    ),</span><br><span class=\"line\">    CELERYBEAT_SCHEDULE = &#123;</span><br><span class=\"line\">        <span class=\"string\">'every-minute'</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">'task'</span>: <span class=\"string\">'test_cron'</span>,</span><br><span class=\"line\">            <span class=\"string\">'schedule'</span>: crontab(minute=<span class=\"string\">\"*\"</span>),</span><br><span class=\"line\">            <span class=\"string\">'args'</span>: (<span class=\"number\">16</span>, <span class=\"number\">13</span>),</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    CELERY_INCLUDE=(<span class=\"string\">\"apps.tasks\"</span>,)</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>同样用上述命令开启worker，发现这个时候 Crontab 不能工作了，后来看到官方的文档：</p>\n<blockquote>\n<p>celery beat and celery worker as separate services instead. </p>\n</blockquote>\n<p>也就是说 Celery 的 Beat 需要和其他异步worker 分开，单独执行。</p>\n<p>相关代码<a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/celery_proj\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>有时候我们需要处理耗时的操作，同时又要保持较快的响应速度，就需要借助异步队列的帮助。Celery 作为异步队列服务，想必是很多人和我一样的选择。用法在官方文档也详细介绍，不再赘述。</p>\n<p>这次想记录的是用 Celery 来实现定时任务。这里也有一点点坑。</p>\n<p>以下是 <code>main.py</code> 的内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> celery <span class=\"keyword\">import</span> Celery</span><br><span class=\"line\"><span class=\"keyword\">from</span> lib <span class=\"keyword\">import</span> distribute</span><br><span class=\"line\"><span class=\"keyword\">from</span> celery.schedules <span class=\"keyword\">import</span> crontab</span><br><span class=\"line\"></span><br><span class=\"line\">app = distribute.app</span><br><span class=\"line\">app.conf.update(</span><br><span class=\"line\">    CELERYBEAT_SCHEDULE = &#123;</span><br><span class=\"line\">        <span class=\"string\">'every-minute'</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">'task'</span>: <span class=\"string\">'test_cron'</span>,</span><br><span class=\"line\">            <span class=\"string\">'schedule'</span>: crontab(minute=<span class=\"string\">\"*\"</span>),</span><br><span class=\"line\">            <span class=\"string\">'args'</span>: (<span class=\"number\">16</span>, <span class=\"number\">13</span>),</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    CELERY_INCLUDE=(<span class=\"string\">\"apps.tasks\"</span>,)</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    app.start()</span><br></pre></td></tr></table></figure>\n<p>实际工作单元,我放在 apps 目录下的 <code>tasks.py</code> 文件中</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> lib.distribute <span class=\"keyword\">import</span> app</span><br><span class=\"line\"><span class=\"meta\">@app.task(name=\"test_cron\")</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">mul</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x * y</span><br></pre></td></tr></table></figure>\n<p>上述是一个简单的 Crontab 应用，它仅需要以下命令就能执行,<br>其中  <code>--beat</code> 表示 crontab 的应用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python main.py worker --beat -l info</span><br></pre></td></tr></table></figure>\n<p>起初我想把异步队列和定时任务放在一起,就加上了一句 CELERY_QUEUES 的配置</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">app.conf.update(</span><br><span class=\"line\">    // 添加的部分</span><br><span class=\"line\">    CELERY_QUEUES=(</span><br><span class=\"line\">        Queue(</span><br><span class=\"line\">          <span class=\"string\">'test'</span>, Exchange(<span class=\"string\">'test_exchange'</span>),</span><br><span class=\"line\">           routing_key=<span class=\"string\">'test_queue'</span></span><br><span class=\"line\">        ),</span><br><span class=\"line\">    ),</span><br><span class=\"line\">    CELERYBEAT_SCHEDULE = &#123;</span><br><span class=\"line\">        <span class=\"string\">'every-minute'</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">'task'</span>: <span class=\"string\">'test_cron'</span>,</span><br><span class=\"line\">            <span class=\"string\">'schedule'</span>: crontab(minute=<span class=\"string\">\"*\"</span>),</span><br><span class=\"line\">            <span class=\"string\">'args'</span>: (<span class=\"number\">16</span>, <span class=\"number\">13</span>),</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    CELERY_INCLUDE=(<span class=\"string\">\"apps.tasks\"</span>,)</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>同样用上述命令开启worker，发现这个时候 Crontab 不能工作了，后来看到官方的文档：</p>\n<blockquote>\n<p>celery beat and celery worker as separate services instead. </p>\n</blockquote>\n<p>也就是说 Celery 的 Beat 需要和其他异步worker 分开，单独执行。</p>\n<p>相关代码<a href=\"https://github.com/zheng-ji/ToyCollection/tree/master/celery_proj\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n"},{"layout":"post","title":"CuckooFilter，BloomFilter的优化","date":"2016-08-01T11:48:00.000Z","comments":1,"description":"BloomFilter CuckooFilter","_content":"\n面对海量数据，我们需要一个索引数据结构，用来帮助查询，快速判断数据记录是否存在，这类数据结构叫过滤器，常用的选择是 `Bloom Filter`. 而 `Cuckoo Filter` 是它的优化变种。借此也用 Golang 实践了这个[算法](https://github.com/zheng-ji/goCuckoo)。\n\n![goCuckoo](https://cloud.githubusercontent.com/assets/1414745/17084380/8c3a4896-51ee-11e6-869e-b087226cc5ce.jpg)\n\n`Bloom Filter` 的位图模式有两个问题：\n\n* 误报，它能判断元素一定不存在，但只能判断可能存在，因为存在其它元素被映射到部分相同位上，导致该位置1，那么一个不存在的元素可能会被误报成存在；\n* 漏报，如果删除了某个元素，导致该映射位被置0，那么本来存在的元素会被漏报成不存在。 \n\n`Cuckoo Filter`，可以确保该元素存在的必然性，又可以在不违背此前提下删除任意元素，仅仅比 `Bloom Filter` 牺牲了微量空间效率。 它的的数据模型: \n\n* 每个元素对应两个哈希算法，在哈希碰撞时会启用备用哈希算法。\n* 每一个桶是有4路的，每个槽对应一个指纹。\n\n![model](https://cloud.githubusercontent.com/assets/1414745/17103421/c97635e0-52b0-11e6-83ac-1b1fdbb5d31c.png)\n\n\nFeature\n--------\n\n* 支持删除操作\n* 支持快速查找，支持 O(1) 查找速度\n* 高效的空间利用，四路槽的表，可以有95% 的空间利用率\n* 可替代布隆过滤器\n\n\nInstallation\n-------------\n\n```\ngo get github.com/zheng-ji/goCuckoo\n```\n\nExample\n-------\n\n```go\nimport (\n\t\"fmt\"\n\t\"github.com/zheng-ji/goCuckoo\"\n)\n\nfunc main() {\n    // speicify capacity \n\tfilter := cuckoo.NewCuckooFilter(10000)\n\n\tfilter.Insert([]byte(\"zheng-ji\"))\n\tfilter.Insert([]byte(\"stupid\"))\n\tfilter.Insert([]byte(\"coder\"))\n\n\tif filter.Find([]byte(\"stupid\")) {\n\t\tfmt.Println(\"exist\")\n\t} else {\n\t\tfmt.Println(\"Not exist\")\n\t}\n\n\tfilter.Del([]byte(\"stupid\"))\n\tfilter.Println(filter.Size())\n}\n```\n\n参考\n-------------\n\n- [CMU Paper](http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pdf)\n- [CMU PPT](http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pptx)\n- [CoolShell Article](http://coolshell.cn/articles/17225.html)\n","source":"_posts/2016-08-01-cuckoofilter.markdown","raw":"---\nlayout: post\ntitle: \"CuckooFilter，BloomFilter的优化\"\ndate: 2016-08-01 19:48\ncomments: true\ndescription: BloomFilter CuckooFilter\ncategories: Programe\n---\n\n面对海量数据，我们需要一个索引数据结构，用来帮助查询，快速判断数据记录是否存在，这类数据结构叫过滤器，常用的选择是 `Bloom Filter`. 而 `Cuckoo Filter` 是它的优化变种。借此也用 Golang 实践了这个[算法](https://github.com/zheng-ji/goCuckoo)。\n\n![goCuckoo](https://cloud.githubusercontent.com/assets/1414745/17084380/8c3a4896-51ee-11e6-869e-b087226cc5ce.jpg)\n\n`Bloom Filter` 的位图模式有两个问题：\n\n* 误报，它能判断元素一定不存在，但只能判断可能存在，因为存在其它元素被映射到部分相同位上，导致该位置1，那么一个不存在的元素可能会被误报成存在；\n* 漏报，如果删除了某个元素，导致该映射位被置0，那么本来存在的元素会被漏报成不存在。 \n\n`Cuckoo Filter`，可以确保该元素存在的必然性，又可以在不违背此前提下删除任意元素，仅仅比 `Bloom Filter` 牺牲了微量空间效率。 它的的数据模型: \n\n* 每个元素对应两个哈希算法，在哈希碰撞时会启用备用哈希算法。\n* 每一个桶是有4路的，每个槽对应一个指纹。\n\n![model](https://cloud.githubusercontent.com/assets/1414745/17103421/c97635e0-52b0-11e6-83ac-1b1fdbb5d31c.png)\n\n\nFeature\n--------\n\n* 支持删除操作\n* 支持快速查找，支持 O(1) 查找速度\n* 高效的空间利用，四路槽的表，可以有95% 的空间利用率\n* 可替代布隆过滤器\n\n\nInstallation\n-------------\n\n```\ngo get github.com/zheng-ji/goCuckoo\n```\n\nExample\n-------\n\n```go\nimport (\n\t\"fmt\"\n\t\"github.com/zheng-ji/goCuckoo\"\n)\n\nfunc main() {\n    // speicify capacity \n\tfilter := cuckoo.NewCuckooFilter(10000)\n\n\tfilter.Insert([]byte(\"zheng-ji\"))\n\tfilter.Insert([]byte(\"stupid\"))\n\tfilter.Insert([]byte(\"coder\"))\n\n\tif filter.Find([]byte(\"stupid\")) {\n\t\tfmt.Println(\"exist\")\n\t} else {\n\t\tfmt.Println(\"Not exist\")\n\t}\n\n\tfilter.Del([]byte(\"stupid\"))\n\tfilter.Println(filter.Size())\n}\n```\n\n参考\n-------------\n\n- [CMU Paper](http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pdf)\n- [CMU PPT](http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pptx)\n- [CoolShell Article](http://coolshell.cn/articles/17225.html)\n","slug":"2016-08-01-cuckoofilter","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdal004onctj9waak92k","content":"<p>面对海量数据，我们需要一个索引数据结构，用来帮助查询，快速判断数据记录是否存在，这类数据结构叫过滤器，常用的选择是 <code>Bloom Filter</code>. 而 <code>Cuckoo Filter</code> 是它的优化变种。借此也用 Golang 实践了这个<a href=\"https://github.com/zheng-ji/goCuckoo\" target=\"_blank\" rel=\"noopener\">算法</a>。</p>\n<p><img src=\"https://cloud.githubusercontent.com/assets/1414745/17084380/8c3a4896-51ee-11e6-869e-b087226cc5ce.jpg\" alt=\"goCuckoo\"></p>\n<p><code>Bloom Filter</code> 的位图模式有两个问题：</p>\n<ul>\n<li>误报，它能判断元素一定不存在，但只能判断可能存在，因为存在其它元素被映射到部分相同位上，导致该位置1，那么一个不存在的元素可能会被误报成存在；</li>\n<li>漏报，如果删除了某个元素，导致该映射位被置0，那么本来存在的元素会被漏报成不存在。 </li>\n</ul>\n<p><code>Cuckoo Filter</code>，可以确保该元素存在的必然性，又可以在不违背此前提下删除任意元素，仅仅比 <code>Bloom Filter</code> 牺牲了微量空间效率。 它的的数据模型: </p>\n<ul>\n<li>每个元素对应两个哈希算法，在哈希碰撞时会启用备用哈希算法。</li>\n<li>每一个桶是有4路的，每个槽对应一个指纹。</li>\n</ul>\n<p><img src=\"https://cloud.githubusercontent.com/assets/1414745/17103421/c97635e0-52b0-11e6-83ac-1b1fdbb5d31c.png\" alt=\"model\"></p>\n<h2 id=\"Feature\"><a href=\"#Feature\" class=\"headerlink\" title=\"Feature\"></a>Feature</h2><ul>\n<li>支持删除操作</li>\n<li>支持快速查找，支持 O(1) 查找速度</li>\n<li>高效的空间利用，四路槽的表，可以有95% 的空间利用率</li>\n<li>可替代布隆过滤器</li>\n</ul>\n<h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go get github.com/zheng-ji/goCuckoo</span><br></pre></td></tr></table></figure>\n<h2 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"fmt\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"github.com/zheng-ji/goCuckoo\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// speicify capacity </span></span><br><span class=\"line\">\tfilter := cuckoo.NewCuckooFilter(<span class=\"number\">10000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tfilter.Insert([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"zheng-ji\"</span>))</span><br><span class=\"line\">\tfilter.Insert([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"stupid\"</span>))</span><br><span class=\"line\">\tfilter.Insert([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"coder\"</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> filter.Find([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"stupid\"</span>)) &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"string\">\"exist\"</span>)</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"string\">\"Not exist\"</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfilter.Del([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"stupid\"</span>))</span><br><span class=\"line\">\tfilter.Println(filter.Size())</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li><a href=\"http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pdf\" target=\"_blank\" rel=\"noopener\">CMU Paper</a></li>\n<li><a href=\"http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pptx\" target=\"_blank\" rel=\"noopener\">CMU PPT</a></li>\n<li><a href=\"http://coolshell.cn/articles/17225.html\" target=\"_blank\" rel=\"noopener\">CoolShell Article</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>面对海量数据，我们需要一个索引数据结构，用来帮助查询，快速判断数据记录是否存在，这类数据结构叫过滤器，常用的选择是 <code>Bloom Filter</code>. 而 <code>Cuckoo Filter</code> 是它的优化变种。借此也用 Golang 实践了这个<a href=\"https://github.com/zheng-ji/goCuckoo\" target=\"_blank\" rel=\"noopener\">算法</a>。</p>\n<p><img src=\"https://cloud.githubusercontent.com/assets/1414745/17084380/8c3a4896-51ee-11e6-869e-b087226cc5ce.jpg\" alt=\"goCuckoo\"></p>\n<p><code>Bloom Filter</code> 的位图模式有两个问题：</p>\n<ul>\n<li>误报，它能判断元素一定不存在，但只能判断可能存在，因为存在其它元素被映射到部分相同位上，导致该位置1，那么一个不存在的元素可能会被误报成存在；</li>\n<li>漏报，如果删除了某个元素，导致该映射位被置0，那么本来存在的元素会被漏报成不存在。 </li>\n</ul>\n<p><code>Cuckoo Filter</code>，可以确保该元素存在的必然性，又可以在不违背此前提下删除任意元素，仅仅比 <code>Bloom Filter</code> 牺牲了微量空间效率。 它的的数据模型: </p>\n<ul>\n<li>每个元素对应两个哈希算法，在哈希碰撞时会启用备用哈希算法。</li>\n<li>每一个桶是有4路的，每个槽对应一个指纹。</li>\n</ul>\n<p><img src=\"https://cloud.githubusercontent.com/assets/1414745/17103421/c97635e0-52b0-11e6-83ac-1b1fdbb5d31c.png\" alt=\"model\"></p>\n<h2 id=\"Feature\"><a href=\"#Feature\" class=\"headerlink\" title=\"Feature\"></a>Feature</h2><ul>\n<li>支持删除操作</li>\n<li>支持快速查找，支持 O(1) 查找速度</li>\n<li>高效的空间利用，四路槽的表，可以有95% 的空间利用率</li>\n<li>可替代布隆过滤器</li>\n</ul>\n<h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go get github.com/zheng-ji/goCuckoo</span><br></pre></td></tr></table></figure>\n<h2 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"fmt\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"github.com/zheng-ji/goCuckoo\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// speicify capacity </span></span><br><span class=\"line\">\tfilter := cuckoo.NewCuckooFilter(<span class=\"number\">10000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tfilter.Insert([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"zheng-ji\"</span>))</span><br><span class=\"line\">\tfilter.Insert([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"stupid\"</span>))</span><br><span class=\"line\">\tfilter.Insert([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"coder\"</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> filter.Find([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"stupid\"</span>)) &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"string\">\"exist\"</span>)</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"string\">\"Not exist\"</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfilter.Del([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"stupid\"</span>))</span><br><span class=\"line\">\tfilter.Println(filter.Size())</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li><a href=\"http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pdf\" target=\"_blank\" rel=\"noopener\">CMU Paper</a></li>\n<li><a href=\"http://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pptx\" target=\"_blank\" rel=\"noopener\">CMU PPT</a></li>\n<li><a href=\"http://coolshell.cn/articles/17225.html\" target=\"_blank\" rel=\"noopener\">CoolShell Article</a></li>\n</ul>\n"},{"layout":"post","title":"共享内存与信号量","date":"2016-09-25T15:37:00.000Z","comments":1,"description":"共享内存 信号量","_content":"\n今天和朋友聊天，他多次提到了共享内存，惭愧的是我没怎么用上，只是从 APUE 等神书阅读到此类名词。这个周末，我来搞懂它们。\n\n### 共享内存\n\n它是 Linux 最底层的通信机制，被称为最快的通信机制。多个进程共享同一个内存区域实现进程间通信。一个进程创建一个共享内存区域，并将数据存放到共享内存中，而后多个进程对其进行访问。\n\n借鉴网友的例子，我做了注释和修改，一个进程写共享内存 (shmwrite.c)，一个进程读共享内存(shmread.c)。\n\n共享内存并未提供同步机制，在第一个进程结束对共享内存的写操作之前，并无自动机制阻止第二个进程开始对它进行读取。上述代码中，我通过自己维护了一个变量 isWritten 来控制同步行为。\n\n还好，伟大的计算机先驱们提供了信号量来帮我们解决同步的问题。\n\n\n### 信号量\n为了防止出现因多个程序同时访问一个共享资源带来的问题，Linux 使用 信号量协调进程对共享资源的访问的。\n信号量只能进行两种操作等待和发送信号，即 P(sv) 和 V(sv).\n\n* P(sv)：当sv的值大于零，就减1；当它的值为零，就挂起该进程的执行。\n* V(sv)：当有其他进程因等待sv而被挂起，就让它恢复运行，当没有进程因等待sv而挂起，就给它加1.\n\n比如：两个进程共享信号量 sv，其中一个进程执行了 P(sv) 操作，它将得到信号量，进入临界区，将 sv 减1。此时sv=0,第二个进程将被阻止进入临界区，它会被挂起以等待第一个进程离开临界区域,并执行 V(sv) 释放信号量，这时第二个进程就可以恢复执行。\n\n### mmap 还是 shmget\n\n这两个东西某种程度上很类似。\n\n内存映射，将用户空间的一段内存区域映射到内核空间,用户对这段内存区域的修改可以直接反映到内核空间，同样，内核空间对这段区域的修改也直接反映用户空间。两者之间需要大量数据传输等操作的话效率是非常高的.\n\nmmap 并不是完全为了用于共享内存而设计的。它提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而 Posix 或系统V的共享内存 IPC 则纯粹用于共享目的.\n\nmmap 使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用 read()，write() 等操作。mmap 并不分配空间, 只是将文件映射到调用进程的地址空间里 然后你就可以用 memcpy 等操作写文件。\n\n---\n\n附上代码：\n\n* 共享数据结构: [shmdata.h](https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmdata.h)\n* 读共享内存：[shmread.c](https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmread.c)\n* 写共享内存：[shmwrite.c](https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmwrite.c)\n","source":"_posts/2016-09-25-gong-xiang-nei-cun-yu-xin-hao-liang.markdown","raw":"---\nlayout: post\ntitle: \"共享内存与信号量\"\ndate: 2016-09-25 23:37\ncomments: true\ndescription: 共享内存 信号量\ncategories: System\n---\n\n今天和朋友聊天，他多次提到了共享内存，惭愧的是我没怎么用上，只是从 APUE 等神书阅读到此类名词。这个周末，我来搞懂它们。\n\n### 共享内存\n\n它是 Linux 最底层的通信机制，被称为最快的通信机制。多个进程共享同一个内存区域实现进程间通信。一个进程创建一个共享内存区域，并将数据存放到共享内存中，而后多个进程对其进行访问。\n\n借鉴网友的例子，我做了注释和修改，一个进程写共享内存 (shmwrite.c)，一个进程读共享内存(shmread.c)。\n\n共享内存并未提供同步机制，在第一个进程结束对共享内存的写操作之前，并无自动机制阻止第二个进程开始对它进行读取。上述代码中，我通过自己维护了一个变量 isWritten 来控制同步行为。\n\n还好，伟大的计算机先驱们提供了信号量来帮我们解决同步的问题。\n\n\n### 信号量\n为了防止出现因多个程序同时访问一个共享资源带来的问题，Linux 使用 信号量协调进程对共享资源的访问的。\n信号量只能进行两种操作等待和发送信号，即 P(sv) 和 V(sv).\n\n* P(sv)：当sv的值大于零，就减1；当它的值为零，就挂起该进程的执行。\n* V(sv)：当有其他进程因等待sv而被挂起，就让它恢复运行，当没有进程因等待sv而挂起，就给它加1.\n\n比如：两个进程共享信号量 sv，其中一个进程执行了 P(sv) 操作，它将得到信号量，进入临界区，将 sv 减1。此时sv=0,第二个进程将被阻止进入临界区，它会被挂起以等待第一个进程离开临界区域,并执行 V(sv) 释放信号量，这时第二个进程就可以恢复执行。\n\n### mmap 还是 shmget\n\n这两个东西某种程度上很类似。\n\n内存映射，将用户空间的一段内存区域映射到内核空间,用户对这段内存区域的修改可以直接反映到内核空间，同样，内核空间对这段区域的修改也直接反映用户空间。两者之间需要大量数据传输等操作的话效率是非常高的.\n\nmmap 并不是完全为了用于共享内存而设计的。它提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而 Posix 或系统V的共享内存 IPC 则纯粹用于共享目的.\n\nmmap 使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用 read()，write() 等操作。mmap 并不分配空间, 只是将文件映射到调用进程的地址空间里 然后你就可以用 memcpy 等操作写文件。\n\n---\n\n附上代码：\n\n* 共享数据结构: [shmdata.h](https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmdata.h)\n* 读共享内存：[shmread.c](https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmread.c)\n* 写共享内存：[shmwrite.c](https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmwrite.c)\n","slug":"2016-09-25-gong-xiang-nei-cun-yu-xin-hao-liang","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdam004qnctj05g8cuec","content":"<p>今天和朋友聊天，他多次提到了共享内存，惭愧的是我没怎么用上，只是从 APUE 等神书阅读到此类名词。这个周末，我来搞懂它们。</p>\n<h3 id=\"共享内存\"><a href=\"#共享内存\" class=\"headerlink\" title=\"共享内存\"></a>共享内存</h3><p>它是 Linux 最底层的通信机制，被称为最快的通信机制。多个进程共享同一个内存区域实现进程间通信。一个进程创建一个共享内存区域，并将数据存放到共享内存中，而后多个进程对其进行访问。</p>\n<p>借鉴网友的例子，我做了注释和修改，一个进程写共享内存 (shmwrite.c)，一个进程读共享内存(shmread.c)。</p>\n<p>共享内存并未提供同步机制，在第一个进程结束对共享内存的写操作之前，并无自动机制阻止第二个进程开始对它进行读取。上述代码中，我通过自己维护了一个变量 isWritten 来控制同步行为。</p>\n<p>还好，伟大的计算机先驱们提供了信号量来帮我们解决同步的问题。</p>\n<h3 id=\"信号量\"><a href=\"#信号量\" class=\"headerlink\" title=\"信号量\"></a>信号量</h3><p>为了防止出现因多个程序同时访问一个共享资源带来的问题，Linux 使用 信号量协调进程对共享资源的访问的。<br>信号量只能进行两种操作等待和发送信号，即 P(sv) 和 V(sv).</p>\n<ul>\n<li>P(sv)：当sv的值大于零，就减1；当它的值为零，就挂起该进程的执行。</li>\n<li>V(sv)：当有其他进程因等待sv而被挂起，就让它恢复运行，当没有进程因等待sv而挂起，就给它加1.</li>\n</ul>\n<p>比如：两个进程共享信号量 sv，其中一个进程执行了 P(sv) 操作，它将得到信号量，进入临界区，将 sv 减1。此时sv=0,第二个进程将被阻止进入临界区，它会被挂起以等待第一个进程离开临界区域,并执行 V(sv) 释放信号量，这时第二个进程就可以恢复执行。</p>\n<h3 id=\"mmap-还是-shmget\"><a href=\"#mmap-还是-shmget\" class=\"headerlink\" title=\"mmap 还是 shmget\"></a>mmap 还是 shmget</h3><p>这两个东西某种程度上很类似。</p>\n<p>内存映射，将用户空间的一段内存区域映射到内核空间,用户对这段内存区域的修改可以直接反映到内核空间，同样，内核空间对这段区域的修改也直接反映用户空间。两者之间需要大量数据传输等操作的话效率是非常高的.</p>\n<p>mmap 并不是完全为了用于共享内存而设计的。它提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而 Posix 或系统V的共享内存 IPC 则纯粹用于共享目的.</p>\n<p>mmap 使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用 read()，write() 等操作。mmap 并不分配空间, 只是将文件映射到调用进程的地址空间里 然后你就可以用 memcpy 等操作写文件。</p>\n<hr>\n<p>附上代码：</p>\n<ul>\n<li>共享数据结构: <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmdata.h\" target=\"_blank\" rel=\"noopener\">shmdata.h</a></li>\n<li>读共享内存：<a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmread.c\" target=\"_blank\" rel=\"noopener\">shmread.c</a></li>\n<li>写共享内存：<a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmwrite.c\" target=\"_blank\" rel=\"noopener\">shmwrite.c</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>今天和朋友聊天，他多次提到了共享内存，惭愧的是我没怎么用上，只是从 APUE 等神书阅读到此类名词。这个周末，我来搞懂它们。</p>\n<h3 id=\"共享内存\"><a href=\"#共享内存\" class=\"headerlink\" title=\"共享内存\"></a>共享内存</h3><p>它是 Linux 最底层的通信机制，被称为最快的通信机制。多个进程共享同一个内存区域实现进程间通信。一个进程创建一个共享内存区域，并将数据存放到共享内存中，而后多个进程对其进行访问。</p>\n<p>借鉴网友的例子，我做了注释和修改，一个进程写共享内存 (shmwrite.c)，一个进程读共享内存(shmread.c)。</p>\n<p>共享内存并未提供同步机制，在第一个进程结束对共享内存的写操作之前，并无自动机制阻止第二个进程开始对它进行读取。上述代码中，我通过自己维护了一个变量 isWritten 来控制同步行为。</p>\n<p>还好，伟大的计算机先驱们提供了信号量来帮我们解决同步的问题。</p>\n<h3 id=\"信号量\"><a href=\"#信号量\" class=\"headerlink\" title=\"信号量\"></a>信号量</h3><p>为了防止出现因多个程序同时访问一个共享资源带来的问题，Linux 使用 信号量协调进程对共享资源的访问的。<br>信号量只能进行两种操作等待和发送信号，即 P(sv) 和 V(sv).</p>\n<ul>\n<li>P(sv)：当sv的值大于零，就减1；当它的值为零，就挂起该进程的执行。</li>\n<li>V(sv)：当有其他进程因等待sv而被挂起，就让它恢复运行，当没有进程因等待sv而挂起，就给它加1.</li>\n</ul>\n<p>比如：两个进程共享信号量 sv，其中一个进程执行了 P(sv) 操作，它将得到信号量，进入临界区，将 sv 减1。此时sv=0,第二个进程将被阻止进入临界区，它会被挂起以等待第一个进程离开临界区域,并执行 V(sv) 释放信号量，这时第二个进程就可以恢复执行。</p>\n<h3 id=\"mmap-还是-shmget\"><a href=\"#mmap-还是-shmget\" class=\"headerlink\" title=\"mmap 还是 shmget\"></a>mmap 还是 shmget</h3><p>这两个东西某种程度上很类似。</p>\n<p>内存映射，将用户空间的一段内存区域映射到内核空间,用户对这段内存区域的修改可以直接反映到内核空间，同样，内核空间对这段区域的修改也直接反映用户空间。两者之间需要大量数据传输等操作的话效率是非常高的.</p>\n<p>mmap 并不是完全为了用于共享内存而设计的。它提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而 Posix 或系统V的共享内存 IPC 则纯粹用于共享目的.</p>\n<p>mmap 使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用 read()，write() 等操作。mmap 并不分配空间, 只是将文件映射到调用进程的地址空间里 然后你就可以用 memcpy 等操作写文件。</p>\n<hr>\n<p>附上代码：</p>\n<ul>\n<li>共享数据结构: <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmdata.h\" target=\"_blank\" rel=\"noopener\">shmdata.h</a></li>\n<li>读共享内存：<a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmread.c\" target=\"_blank\" rel=\"noopener\">shmread.c</a></li>\n<li>写共享内存：<a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/shared_memory/shmwrite.c\" target=\"_blank\" rel=\"noopener\">shmwrite.c</a></li>\n</ul>\n"},{"layout":"post","title":"记一次使用 redis 协议诡异的bug","date":"2016-09-28T00:21:00.000Z","description":"Redis 协议","_content":"\n记录昨天定位一个诡异 bug 的过程，我耗费了不少精力，你若有兴趣，请带着一点耐心看完它。\n\n* [问题背景](#第一节)\n* [重新问题 ](#第二节)\n* [试着解决问题](#第三节)\n* [一点总结](#第四节)\n\n<h3 id=\"第一节\">问题背景</h3>\n\n我们使用 [go-redis-server](https://github.com/youmi/go-redis-server) 开发具有 redis 协议的服务。 按照文档，我们实现了如下接口，其背后访问的是 AWS 的 Dynamodb，我们的服务也开发了监控接口，以供我们这些程序狗知道它发生了什么。\n\n```go\nfunc (handler *RedisHandler) Get(key string) (result string, err error)\nfunc (handler *RedisHandler) Set(key string, val string) (err error)\nfunc (handler *RedisHandler) Del(key string) (count int, err error)\n```\n\n这样，我们就能通过 redis 客户端来执行 Get，Set，Del 操作。\n\n我在批量写入几千条数据时，通过监控接口，我看到服务突然卡住的样子，没有 Get，Set的统计信息了。但我能肯定的是客户端一直有数据在往服务写入，或者读写。\n同时从 AWS 监控得到的反馈是 Dynamodb 使用超过预设值，我调高了读写预设值，重启服务，就恢复可用（重启大法好）。\n程序试运行十多天，只发生过一次异常，之后再无重现。\n这个事情没有搞清楚，就成为我一个心结。\n\n<h3 id=\"第二节\">重现问题</h3>\n\n我们来看看代码\n\n```go\nfunc (handler *RedisHandler) \nSet(key string, val string) (err error) {\n\t...\n\n\tm, err := JSONToMap(val)\n\t_, err = table.PutItem(m)\n\tif err != nil {\n\t\tlog.Log.Errorf(\"PutItem failed, \n\t\ttable: %s, primary key: %s, value: %+v, \n\t\terr: %s\", \n\t\ttableName, primaryVal, m, err.Error())\n\t\treturn\n\t}\n\treturn\n}\n```\n\nSet接口，简单的将数据写入 Dynamodb，Dynamodb 如果异常就返回错误，然后通过redis协议返回给客户端。\n\n我很大程度确定那时候是因为 AWS Dynamodb 的异常导致这个错误的。除非这个巧合太牛逼了，难道 go-redis-server 接口不支持返回错误不成吗？这个猜想很快就被我们用实验否定了。\n\n我想重新触发 AWS Dynamodb 返回写容量超标的错误，测试了一阵子，并不容易重现。有点沮丧，这个时候我回忆起 aws-go-sdk 的特点，如果给Dynamodb 字段 赋予空值，是会有异常返回的，\n类似如下：\n\n```\nValidationException: One or more parameter values were invalid:\nAn AttributeValue may not contain an empty string\n\tstatus code: 400\n```\n\n空值的测试明显容易制造。我在本地也开启服务，端口是1234，用 pyredis 作为客户端做测试。\n测试脚本\n\n```python\nimport redis\nimport json\nimport random\nr = redis.Redis(host='localhost',port=1234,db=0)\n\ntable_name = 'test'\nprimary_key = 'a'\n\ni = 0\nwhile True:\n    if i > 2:\n        break\n    data = {\n        'a': str(random.random()),\n        'b': ‘’,\n    }\n    key = '{0}:{1}:{2}'.format(table_name, primary_key, data[primary_key])\n    value = json.dumps(data)\n    r.set(key, value)\n    i = i + 1\n```\n\n发现测试程序卡在终端，一动不动，strace 测试程序\n\n```\n$ sudo strace -p 22404\nProcess 22404 attached\nrecvfrom(3,\n```\n\n感觉像是在等待服务器返回，但是等不到回报的样子。\n\n<h3 id=\"第三节\">试着解决问题</h3>\n\n难道 go-redis-server 这个框架有猫腻，我就开始了一下午的看源码之旅。不得不说源码写的真好。回头看我们出错的代码片段，我试着修改 err 信息，修改成自己定义的错误字符串。\n\n```go\nfunc (handler *RedisHandler) Set(key string, val string) (err error) {\n\t...\n\n\tm, err := JSONToMap(val)\n\t_, err = table.PutItem(m)\n\tif err != nil {\n\t\terr = errors.New(\"I am a Custom Error\")\n\t\treturn\n\t}\n\treturn\n}\n```\n\n再次执行测试脚本，这一次。2条测试数据很快就执行结束，并无阻塞。\n好像看到了一丝曙光：error 内容的不一样，导致不一样的结果。类型一样，那么我能怀疑的就是格式，或者长度了。\n\n```\nAWS 错误信息的格式：\nValidationException: One or more parameter values were invalid:\nAn AttributeValue may not contain an empty string\n\tstatus code: 400\n\n我自定义错误信息的格式：\nI am a Custom Error\n```\n\n我特意加长了自定义错误的长度，结果也是能顺利执行不阻塞客户端。但是我给自定义错误字符串加入了换行符，果然客户端再次测试会出现阻塞。当出现错误的时候，源码中是调用了 ErrorReply.WriteTo 这个函数，特别的。返回错误的协议格式是\n\n>第一个字节将是“-”,并以CR + LF 结尾\n\n配合源码，以下是 go-redis-server 最核心的逻辑调度代码。\n\n\n```go\nfor {\n\trequest, err := parseRequest(conn)\n\tif err != nil {\n\t\treturn err\n\t}\n\t\trequest.Host = clientAddr\n\t\trequest.ClientChan = clientChan\n\t\treply, err := srv.Apply(request)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, err = reply.WriteTo(conn); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\nfunc (er *ErrorReply) WriteTo(w io.Writer) (int64, error) {\n\tn, err := w.Write([]byte(\"-\" + er.code + \" \" + er.message + \"\\r\\n\"))\n\treturn int64(n), err\n}\n```\n\n从 [Redis协议官方文档](http://redis.cn/topics/protocol.html)，可以确定客户端与服务器端之间传输的每个 Redis 命令或者数据都以 `\\r\\n` 结尾。 我们的错误信息中间杀出了 `\\n`，导致协议错乱，redis 客户端不能理解协议，就阻塞了。\n\n<h3 id=\"第四节\">一点总结</h3>\n\n* 以后我们使用 go-redis-server 的服务时候，要记得检查返回的字符串或者错误信息有没有包含换行符，如果有，最好做一次过滤替换。\n\n* 出现这个bug,我和同事都觉得不可思议，非常神奇。在没有其他直观线索的条件下，阅读使用的库的源码，并在源码加上一些输出验证语言加以辅助，收到了效果，的确需要一些耐心。但我觉得是值得的。\n\n* 李笑来说有效阅读就是精度，这次阅读代码过程中我还有意外的收获，我发现了 reflect 的妙用，以及函数注册在框架可以那么用，读完觉得很满足的样子，值得再记录一番。\n\n---\n\n附链接：\n\n- [Redis官方协议](http://redis.cn/topics/protocol.html)\n- [go-redis-server](https://github.com/youmi/go-redis-server)\n","source":"_posts/2016-09-28-ji-yi-ci-redis-server-bug.markdown","raw":"---\nlayout: post\ntitle: \"记一次使用 redis 协议诡异的bug\"\ndate: 2016-09-28 08:21\ndescription: Redis 协议 \ncategories: Programe\n---\n\n记录昨天定位一个诡异 bug 的过程，我耗费了不少精力，你若有兴趣，请带着一点耐心看完它。\n\n* [问题背景](#第一节)\n* [重新问题 ](#第二节)\n* [试着解决问题](#第三节)\n* [一点总结](#第四节)\n\n<h3 id=\"第一节\">问题背景</h3>\n\n我们使用 [go-redis-server](https://github.com/youmi/go-redis-server) 开发具有 redis 协议的服务。 按照文档，我们实现了如下接口，其背后访问的是 AWS 的 Dynamodb，我们的服务也开发了监控接口，以供我们这些程序狗知道它发生了什么。\n\n```go\nfunc (handler *RedisHandler) Get(key string) (result string, err error)\nfunc (handler *RedisHandler) Set(key string, val string) (err error)\nfunc (handler *RedisHandler) Del(key string) (count int, err error)\n```\n\n这样，我们就能通过 redis 客户端来执行 Get，Set，Del 操作。\n\n我在批量写入几千条数据时，通过监控接口，我看到服务突然卡住的样子，没有 Get，Set的统计信息了。但我能肯定的是客户端一直有数据在往服务写入，或者读写。\n同时从 AWS 监控得到的反馈是 Dynamodb 使用超过预设值，我调高了读写预设值，重启服务，就恢复可用（重启大法好）。\n程序试运行十多天，只发生过一次异常，之后再无重现。\n这个事情没有搞清楚，就成为我一个心结。\n\n<h3 id=\"第二节\">重现问题</h3>\n\n我们来看看代码\n\n```go\nfunc (handler *RedisHandler) \nSet(key string, val string) (err error) {\n\t...\n\n\tm, err := JSONToMap(val)\n\t_, err = table.PutItem(m)\n\tif err != nil {\n\t\tlog.Log.Errorf(\"PutItem failed, \n\t\ttable: %s, primary key: %s, value: %+v, \n\t\terr: %s\", \n\t\ttableName, primaryVal, m, err.Error())\n\t\treturn\n\t}\n\treturn\n}\n```\n\nSet接口，简单的将数据写入 Dynamodb，Dynamodb 如果异常就返回错误，然后通过redis协议返回给客户端。\n\n我很大程度确定那时候是因为 AWS Dynamodb 的异常导致这个错误的。除非这个巧合太牛逼了，难道 go-redis-server 接口不支持返回错误不成吗？这个猜想很快就被我们用实验否定了。\n\n我想重新触发 AWS Dynamodb 返回写容量超标的错误，测试了一阵子，并不容易重现。有点沮丧，这个时候我回忆起 aws-go-sdk 的特点，如果给Dynamodb 字段 赋予空值，是会有异常返回的，\n类似如下：\n\n```\nValidationException: One or more parameter values were invalid:\nAn AttributeValue may not contain an empty string\n\tstatus code: 400\n```\n\n空值的测试明显容易制造。我在本地也开启服务，端口是1234，用 pyredis 作为客户端做测试。\n测试脚本\n\n```python\nimport redis\nimport json\nimport random\nr = redis.Redis(host='localhost',port=1234,db=0)\n\ntable_name = 'test'\nprimary_key = 'a'\n\ni = 0\nwhile True:\n    if i > 2:\n        break\n    data = {\n        'a': str(random.random()),\n        'b': ‘’,\n    }\n    key = '{0}:{1}:{2}'.format(table_name, primary_key, data[primary_key])\n    value = json.dumps(data)\n    r.set(key, value)\n    i = i + 1\n```\n\n发现测试程序卡在终端，一动不动，strace 测试程序\n\n```\n$ sudo strace -p 22404\nProcess 22404 attached\nrecvfrom(3,\n```\n\n感觉像是在等待服务器返回，但是等不到回报的样子。\n\n<h3 id=\"第三节\">试着解决问题</h3>\n\n难道 go-redis-server 这个框架有猫腻，我就开始了一下午的看源码之旅。不得不说源码写的真好。回头看我们出错的代码片段，我试着修改 err 信息，修改成自己定义的错误字符串。\n\n```go\nfunc (handler *RedisHandler) Set(key string, val string) (err error) {\n\t...\n\n\tm, err := JSONToMap(val)\n\t_, err = table.PutItem(m)\n\tif err != nil {\n\t\terr = errors.New(\"I am a Custom Error\")\n\t\treturn\n\t}\n\treturn\n}\n```\n\n再次执行测试脚本，这一次。2条测试数据很快就执行结束，并无阻塞。\n好像看到了一丝曙光：error 内容的不一样，导致不一样的结果。类型一样，那么我能怀疑的就是格式，或者长度了。\n\n```\nAWS 错误信息的格式：\nValidationException: One or more parameter values were invalid:\nAn AttributeValue may not contain an empty string\n\tstatus code: 400\n\n我自定义错误信息的格式：\nI am a Custom Error\n```\n\n我特意加长了自定义错误的长度，结果也是能顺利执行不阻塞客户端。但是我给自定义错误字符串加入了换行符，果然客户端再次测试会出现阻塞。当出现错误的时候，源码中是调用了 ErrorReply.WriteTo 这个函数，特别的。返回错误的协议格式是\n\n>第一个字节将是“-”,并以CR + LF 结尾\n\n配合源码，以下是 go-redis-server 最核心的逻辑调度代码。\n\n\n```go\nfor {\n\trequest, err := parseRequest(conn)\n\tif err != nil {\n\t\treturn err\n\t}\n\t\trequest.Host = clientAddr\n\t\trequest.ClientChan = clientChan\n\t\treply, err := srv.Apply(request)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, err = reply.WriteTo(conn); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\nfunc (er *ErrorReply) WriteTo(w io.Writer) (int64, error) {\n\tn, err := w.Write([]byte(\"-\" + er.code + \" \" + er.message + \"\\r\\n\"))\n\treturn int64(n), err\n}\n```\n\n从 [Redis协议官方文档](http://redis.cn/topics/protocol.html)，可以确定客户端与服务器端之间传输的每个 Redis 命令或者数据都以 `\\r\\n` 结尾。 我们的错误信息中间杀出了 `\\n`，导致协议错乱，redis 客户端不能理解协议，就阻塞了。\n\n<h3 id=\"第四节\">一点总结</h3>\n\n* 以后我们使用 go-redis-server 的服务时候，要记得检查返回的字符串或者错误信息有没有包含换行符，如果有，最好做一次过滤替换。\n\n* 出现这个bug,我和同事都觉得不可思议，非常神奇。在没有其他直观线索的条件下，阅读使用的库的源码，并在源码加上一些输出验证语言加以辅助，收到了效果，的确需要一些耐心。但我觉得是值得的。\n\n* 李笑来说有效阅读就是精度，这次阅读代码过程中我还有意外的收获，我发现了 reflect 的妙用，以及函数注册在框架可以那么用，读完觉得很满足的样子，值得再记录一番。\n\n---\n\n附链接：\n\n- [Redis官方协议](http://redis.cn/topics/protocol.html)\n- [go-redis-server](https://github.com/youmi/go-redis-server)\n","slug":"2016-09-28-ji-yi-ci-redis-server-bug","published":1,"updated":"2018-06-17T10:38:56.000Z","comments":1,"photos":[],"link":"","_id":"cjijzgdan004snctj0ht7e6h6","content":"<p>记录昨天定位一个诡异 bug 的过程，我耗费了不少精力，你若有兴趣，请带着一点耐心看完它。</p>\n<ul>\n<li><a href=\"#第一节\">问题背景</a></li>\n<li><a href=\"#第二节\">重新问题 </a></li>\n<li><a href=\"#第三节\">试着解决问题</a></li>\n<li><a href=\"#第四节\">一点总结</a></li>\n</ul>\n<h3 id=\"第一节\">问题背景</h3>\n\n<p>我们使用 <a href=\"https://github.com/youmi/go-redis-server\" target=\"_blank\" rel=\"noopener\">go-redis-server</a> 开发具有 redis 协议的服务。 按照文档，我们实现了如下接口，其背后访问的是 AWS 的 Dynamodb，我们的服务也开发了监控接口，以供我们这些程序狗知道它发生了什么。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(handler *RedisHandler)</span> <span class=\"title\">Get</span><span class=\"params\">(key <span class=\"keyword\">string</span>)</span> <span class=\"params\">(result <span class=\"keyword\">string</span>, err error)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(handler *RedisHandler)</span> <span class=\"title\">Set</span><span class=\"params\">(key <span class=\"keyword\">string</span>, val <span class=\"keyword\">string</span>)</span> <span class=\"params\">(err error)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(handler *RedisHandler)</span> <span class=\"title\">Del</span><span class=\"params\">(key <span class=\"keyword\">string</span>)</span> <span class=\"params\">(count <span class=\"keyword\">int</span>, err error)</span></span></span><br></pre></td></tr></table></figure>\n<p>这样，我们就能通过 redis 客户端来执行 Get，Set，Del 操作。</p>\n<p>我在批量写入几千条数据时，通过监控接口，我看到服务突然卡住的样子，没有 Get，Set的统计信息了。但我能肯定的是客户端一直有数据在往服务写入，或者读写。<br>同时从 AWS 监控得到的反馈是 Dynamodb 使用超过预设值，我调高了读写预设值，重启服务，就恢复可用（重启大法好）。<br>程序试运行十多天，只发生过一次异常，之后再无重现。<br>这个事情没有搞清楚，就成为我一个心结。</p>\n<h3 id=\"第二节\">重现问题</h3>\n\n<p>我们来看看代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(handler *RedisHandler)</span> </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">Set</span><span class=\"params\">(key <span class=\"keyword\">string</span>, val <span class=\"keyword\">string</span>)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\tm, err := JSONToMap(val)</span><br><span class=\"line\">\t_, err = table.PutItem(m)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\tlog.Log.Errorf(<span class=\"string\">\"PutItem failed, </span></span><br><span class=\"line\"><span class=\"string\">\t\ttable: %s, primary key: %s, value: %+v, </span></span><br><span class=\"line\"><span class=\"string\">\t\terr: %s\"</span>, </span><br><span class=\"line\">\t\ttableName, primaryVal, m, err.Error())</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Set接口，简单的将数据写入 Dynamodb，Dynamodb 如果异常就返回错误，然后通过redis协议返回给客户端。</p>\n<p>我很大程度确定那时候是因为 AWS Dynamodb 的异常导致这个错误的。除非这个巧合太牛逼了，难道 go-redis-server 接口不支持返回错误不成吗？这个猜想很快就被我们用实验否定了。</p>\n<p>我想重新触发 AWS Dynamodb 返回写容量超标的错误，测试了一阵子，并不容易重现。有点沮丧，这个时候我回忆起 aws-go-sdk 的特点，如果给Dynamodb 字段 赋予空值，是会有异常返回的，<br>类似如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ValidationException: One or more parameter values were invalid:</span><br><span class=\"line\">An AttributeValue may not contain an empty string</span><br><span class=\"line\">\tstatus code: 400</span><br></pre></td></tr></table></figure>\n<p>空值的测试明显容易制造。我在本地也开启服务，端口是1234，用 pyredis 作为客户端做测试。<br>测试脚本</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> redis</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\">r = redis.Redis(host=<span class=\"string\">'localhost'</span>,port=<span class=\"number\">1234</span>,db=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">table_name = <span class=\"string\">'test'</span></span><br><span class=\"line\">primary_key = <span class=\"string\">'a'</span></span><br><span class=\"line\"></span><br><span class=\"line\">i = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i &gt; <span class=\"number\">2</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">    data = &#123;</span><br><span class=\"line\">        <span class=\"string\">'a'</span>: str(random.random()),</span><br><span class=\"line\">        <span class=\"string\">'b'</span>: ‘’,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    key = <span class=\"string\">'&#123;0&#125;:&#123;1&#125;:&#123;2&#125;'</span>.format(table_name, primary_key, data[primary_key])</span><br><span class=\"line\">    value = json.dumps(data)</span><br><span class=\"line\">    r.set(key, value)</span><br><span class=\"line\">    i = i + <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<p>发现测试程序卡在终端，一动不动，strace 测试程序</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo strace -p 22404</span><br><span class=\"line\">Process 22404 attached</span><br><span class=\"line\">recvfrom(3,</span><br></pre></td></tr></table></figure>\n<p>感觉像是在等待服务器返回，但是等不到回报的样子。</p>\n<h3 id=\"第三节\">试着解决问题</h3>\n\n<p>难道 go-redis-server 这个框架有猫腻，我就开始了一下午的看源码之旅。不得不说源码写的真好。回头看我们出错的代码片段，我试着修改 err 信息，修改成自己定义的错误字符串。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(handler *RedisHandler)</span> <span class=\"title\">Set</span><span class=\"params\">(key <span class=\"keyword\">string</span>, val <span class=\"keyword\">string</span>)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\tm, err := JSONToMap(val)</span><br><span class=\"line\">\t_, err = table.PutItem(m)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\terr = errors.New(<span class=\"string\">\"I am a Custom Error\"</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>再次执行测试脚本，这一次。2条测试数据很快就执行结束，并无阻塞。<br>好像看到了一丝曙光：error 内容的不一样，导致不一样的结果。类型一样，那么我能怀疑的就是格式，或者长度了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AWS 错误信息的格式：</span><br><span class=\"line\">ValidationException: One or more parameter values were invalid:</span><br><span class=\"line\">An AttributeValue may not contain an empty string</span><br><span class=\"line\">\tstatus code: 400</span><br><span class=\"line\"></span><br><span class=\"line\">我自定义错误信息的格式：</span><br><span class=\"line\">I am a Custom Error</span><br></pre></td></tr></table></figure>\n<p>我特意加长了自定义错误的长度，结果也是能顺利执行不阻塞客户端。但是我给自定义错误字符串加入了换行符，果然客户端再次测试会出现阻塞。当出现错误的时候，源码中是调用了 ErrorReply.WriteTo 这个函数，特别的。返回错误的协议格式是</p>\n<blockquote>\n<p>第一个字节将是“-”,并以CR + LF 结尾</p>\n</blockquote>\n<p>配合源码，以下是 go-redis-server 最核心的逻辑调度代码。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">\trequest, err := parseRequest(conn)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t\trequest.Host = clientAddr</span><br><span class=\"line\">\t\trequest.ClientChan = clientChan</span><br><span class=\"line\">\t\treply, err := srv.Apply(request)</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> _, err = reply.WriteTo(conn); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(er *ErrorReply)</span> <span class=\"title\">WriteTo</span><span class=\"params\">(w io.Writer)</span> <span class=\"params\">(<span class=\"keyword\">int64</span>, error)</span></span> &#123;</span><br><span class=\"line\">\tn, err := w.Write([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"-\"</span> + er.code + <span class=\"string\">\" \"</span> + er.message + <span class=\"string\">\"\\r\\n\"</span>))</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"keyword\">int64</span>(n), err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>从 <a href=\"http://redis.cn/topics/protocol.html\" target=\"_blank\" rel=\"noopener\">Redis协议官方文档</a>，可以确定客户端与服务器端之间传输的每个 Redis 命令或者数据都以 <code>\\r\\n</code> 结尾。 我们的错误信息中间杀出了 <code>\\n</code>，导致协议错乱，redis 客户端不能理解协议，就阻塞了。</p>\n<h3 id=\"第四节\">一点总结</h3>\n\n<ul>\n<li><p>以后我们使用 go-redis-server 的服务时候，要记得检查返回的字符串或者错误信息有没有包含换行符，如果有，最好做一次过滤替换。</p>\n</li>\n<li><p>出现这个bug,我和同事都觉得不可思议，非常神奇。在没有其他直观线索的条件下，阅读使用的库的源码，并在源码加上一些输出验证语言加以辅助，收到了效果，的确需要一些耐心。但我觉得是值得的。</p>\n</li>\n<li><p>李笑来说有效阅读就是精度，这次阅读代码过程中我还有意外的收获，我发现了 reflect 的妙用，以及函数注册在框架可以那么用，读完觉得很满足的样子，值得再记录一番。</p>\n</li>\n</ul>\n<hr>\n<p>附链接：</p>\n<ul>\n<li><a href=\"http://redis.cn/topics/protocol.html\" target=\"_blank\" rel=\"noopener\">Redis官方协议</a></li>\n<li><a href=\"https://github.com/youmi/go-redis-server\" target=\"_blank\" rel=\"noopener\">go-redis-server</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>记录昨天定位一个诡异 bug 的过程，我耗费了不少精力，你若有兴趣，请带着一点耐心看完它。</p>\n<ul>\n<li><a href=\"#第一节\">问题背景</a></li>\n<li><a href=\"#第二节\">重新问题 </a></li>\n<li><a href=\"#第三节\">试着解决问题</a></li>\n<li><a href=\"#第四节\">一点总结</a></li>\n</ul>\n<h3 id=\"第一节\">问题背景</h3>\n\n<p>我们使用 <a href=\"https://github.com/youmi/go-redis-server\" target=\"_blank\" rel=\"noopener\">go-redis-server</a> 开发具有 redis 协议的服务。 按照文档，我们实现了如下接口，其背后访问的是 AWS 的 Dynamodb，我们的服务也开发了监控接口，以供我们这些程序狗知道它发生了什么。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(handler *RedisHandler)</span> <span class=\"title\">Get</span><span class=\"params\">(key <span class=\"keyword\">string</span>)</span> <span class=\"params\">(result <span class=\"keyword\">string</span>, err error)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(handler *RedisHandler)</span> <span class=\"title\">Set</span><span class=\"params\">(key <span class=\"keyword\">string</span>, val <span class=\"keyword\">string</span>)</span> <span class=\"params\">(err error)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(handler *RedisHandler)</span> <span class=\"title\">Del</span><span class=\"params\">(key <span class=\"keyword\">string</span>)</span> <span class=\"params\">(count <span class=\"keyword\">int</span>, err error)</span></span></span><br></pre></td></tr></table></figure>\n<p>这样，我们就能通过 redis 客户端来执行 Get，Set，Del 操作。</p>\n<p>我在批量写入几千条数据时，通过监控接口，我看到服务突然卡住的样子，没有 Get，Set的统计信息了。但我能肯定的是客户端一直有数据在往服务写入，或者读写。<br>同时从 AWS 监控得到的反馈是 Dynamodb 使用超过预设值，我调高了读写预设值，重启服务，就恢复可用（重启大法好）。<br>程序试运行十多天，只发生过一次异常，之后再无重现。<br>这个事情没有搞清楚，就成为我一个心结。</p>\n<h3 id=\"第二节\">重现问题</h3>\n\n<p>我们来看看代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(handler *RedisHandler)</span> </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">Set</span><span class=\"params\">(key <span class=\"keyword\">string</span>, val <span class=\"keyword\">string</span>)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\tm, err := JSONToMap(val)</span><br><span class=\"line\">\t_, err = table.PutItem(m)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\tlog.Log.Errorf(<span class=\"string\">\"PutItem failed, </span></span><br><span class=\"line\"><span class=\"string\">\t\ttable: %s, primary key: %s, value: %+v, </span></span><br><span class=\"line\"><span class=\"string\">\t\terr: %s\"</span>, </span><br><span class=\"line\">\t\ttableName, primaryVal, m, err.Error())</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Set接口，简单的将数据写入 Dynamodb，Dynamodb 如果异常就返回错误，然后通过redis协议返回给客户端。</p>\n<p>我很大程度确定那时候是因为 AWS Dynamodb 的异常导致这个错误的。除非这个巧合太牛逼了，难道 go-redis-server 接口不支持返回错误不成吗？这个猜想很快就被我们用实验否定了。</p>\n<p>我想重新触发 AWS Dynamodb 返回写容量超标的错误，测试了一阵子，并不容易重现。有点沮丧，这个时候我回忆起 aws-go-sdk 的特点，如果给Dynamodb 字段 赋予空值，是会有异常返回的，<br>类似如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ValidationException: One or more parameter values were invalid:</span><br><span class=\"line\">An AttributeValue may not contain an empty string</span><br><span class=\"line\">\tstatus code: 400</span><br></pre></td></tr></table></figure>\n<p>空值的测试明显容易制造。我在本地也开启服务，端口是1234，用 pyredis 作为客户端做测试。<br>测试脚本</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> redis</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\">r = redis.Redis(host=<span class=\"string\">'localhost'</span>,port=<span class=\"number\">1234</span>,db=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">table_name = <span class=\"string\">'test'</span></span><br><span class=\"line\">primary_key = <span class=\"string\">'a'</span></span><br><span class=\"line\"></span><br><span class=\"line\">i = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i &gt; <span class=\"number\">2</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">    data = &#123;</span><br><span class=\"line\">        <span class=\"string\">'a'</span>: str(random.random()),</span><br><span class=\"line\">        <span class=\"string\">'b'</span>: ‘’,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    key = <span class=\"string\">'&#123;0&#125;:&#123;1&#125;:&#123;2&#125;'</span>.format(table_name, primary_key, data[primary_key])</span><br><span class=\"line\">    value = json.dumps(data)</span><br><span class=\"line\">    r.set(key, value)</span><br><span class=\"line\">    i = i + <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<p>发现测试程序卡在终端，一动不动，strace 测试程序</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo strace -p 22404</span><br><span class=\"line\">Process 22404 attached</span><br><span class=\"line\">recvfrom(3,</span><br></pre></td></tr></table></figure>\n<p>感觉像是在等待服务器返回，但是等不到回报的样子。</p>\n<h3 id=\"第三节\">试着解决问题</h3>\n\n<p>难道 go-redis-server 这个框架有猫腻，我就开始了一下午的看源码之旅。不得不说源码写的真好。回头看我们出错的代码片段，我试着修改 err 信息，修改成自己定义的错误字符串。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(handler *RedisHandler)</span> <span class=\"title\">Set</span><span class=\"params\">(key <span class=\"keyword\">string</span>, val <span class=\"keyword\">string</span>)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\tm, err := JSONToMap(val)</span><br><span class=\"line\">\t_, err = table.PutItem(m)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\terr = errors.New(<span class=\"string\">\"I am a Custom Error\"</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>再次执行测试脚本，这一次。2条测试数据很快就执行结束，并无阻塞。<br>好像看到了一丝曙光：error 内容的不一样，导致不一样的结果。类型一样，那么我能怀疑的就是格式，或者长度了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AWS 错误信息的格式：</span><br><span class=\"line\">ValidationException: One or more parameter values were invalid:</span><br><span class=\"line\">An AttributeValue may not contain an empty string</span><br><span class=\"line\">\tstatus code: 400</span><br><span class=\"line\"></span><br><span class=\"line\">我自定义错误信息的格式：</span><br><span class=\"line\">I am a Custom Error</span><br></pre></td></tr></table></figure>\n<p>我特意加长了自定义错误的长度，结果也是能顺利执行不阻塞客户端。但是我给自定义错误字符串加入了换行符，果然客户端再次测试会出现阻塞。当出现错误的时候，源码中是调用了 ErrorReply.WriteTo 这个函数，特别的。返回错误的协议格式是</p>\n<blockquote>\n<p>第一个字节将是“-”,并以CR + LF 结尾</p>\n</blockquote>\n<p>配合源码，以下是 go-redis-server 最核心的逻辑调度代码。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">\trequest, err := parseRequest(conn)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t\trequest.Host = clientAddr</span><br><span class=\"line\">\t\trequest.ClientChan = clientChan</span><br><span class=\"line\">\t\treply, err := srv.Apply(request)</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> _, err = reply.WriteTo(conn); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(er *ErrorReply)</span> <span class=\"title\">WriteTo</span><span class=\"params\">(w io.Writer)</span> <span class=\"params\">(<span class=\"keyword\">int64</span>, error)</span></span> &#123;</span><br><span class=\"line\">\tn, err := w.Write([]<span class=\"keyword\">byte</span>(<span class=\"string\">\"-\"</span> + er.code + <span class=\"string\">\" \"</span> + er.message + <span class=\"string\">\"\\r\\n\"</span>))</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"keyword\">int64</span>(n), err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>从 <a href=\"http://redis.cn/topics/protocol.html\" target=\"_blank\" rel=\"noopener\">Redis协议官方文档</a>，可以确定客户端与服务器端之间传输的每个 Redis 命令或者数据都以 <code>\\r\\n</code> 结尾。 我们的错误信息中间杀出了 <code>\\n</code>，导致协议错乱，redis 客户端不能理解协议，就阻塞了。</p>\n<h3 id=\"第四节\">一点总结</h3>\n\n<ul>\n<li><p>以后我们使用 go-redis-server 的服务时候，要记得检查返回的字符串或者错误信息有没有包含换行符，如果有，最好做一次过滤替换。</p>\n</li>\n<li><p>出现这个bug,我和同事都觉得不可思议，非常神奇。在没有其他直观线索的条件下，阅读使用的库的源码，并在源码加上一些输出验证语言加以辅助，收到了效果，的确需要一些耐心。但我觉得是值得的。</p>\n</li>\n<li><p>李笑来说有效阅读就是精度，这次阅读代码过程中我还有意外的收获，我发现了 reflect 的妙用，以及函数注册在框架可以那么用，读完觉得很满足的样子，值得再记录一番。</p>\n</li>\n</ul>\n<hr>\n<p>附链接：</p>\n<ul>\n<li><a href=\"http://redis.cn/topics/protocol.html\" target=\"_blank\" rel=\"noopener\">Redis官方协议</a></li>\n<li><a href=\"https://github.com/youmi/go-redis-server\" target=\"_blank\" rel=\"noopener\">go-redis-server</a></li>\n</ul>\n"},{"layout":"post","title":"cgroup 限制计算资源","date":"2016-12-02T07:41:00.000Z","comments":1,"description":"cgroup","_content":"\nCgroup 实现了对计算机资源使用上的隔离，它是 Docker 底层的基础技术。我们可以用它来限制程序使用的CPU、内存、磁盘。\n\n### 安装\n\n在 Ubuntu 14.04 下安装的方法：\n\n```\nsudo apt-get install cgroup-bin\n```\n\n安装完后执行\n`mount -t cgroup` 会出现如下，可以看到它其实是一个文件系统\n\n```\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)\ncgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)\n...\ncgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,relatime,hugetlb)\n```\n\n如果没有看到以上的目录，这时候需要手动 mount 了\n\n```\ncd /sys/fs\nmkdir cgroup\nmount -t tmpfs cgroup_root ./cgroup\nmkdir cgroup/cpuset\nmount -t cgroup -ocpuset cpuset ./cgroup/cpuset/\nmkdir cgroup/cpu\nmount -t cgroup -ocpu cpu ./cgroup/cpu/\nmkdir cgroup/memory\nmount -t cgroup -omemory memory ./cgroup/memory/\n```\n\n### 实践\n\n我们来感性认识下 cgroup 吧，编写一个耗费 CPU 的程序，姑且叫暴走程序(baozou)\n\n```py\ncount = 0\nwhile True:\n    count = count + 1 - 1\n```\n\n运行该程序，top -p 之，100% CPU使用率\n\n```\n  PID      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       \n16515      20   0    2336    728    544 R  100.0  0.0   1:27.23 baozou\n```\n\n我想限制暴走程序 CPU 使用该如何做? 我们手动创建一个 cgroup 目录来针对它。\n\n```sh\ncd /sys/fs/cgroup/cpu\nmkdir calm      // 名字可自定义\nls /calm        // 该目录下自动生产与 CPU 有关的文件\ncgroup.clone_children  cpu.cfs_period_us  cpu.shares  notify_on_release\ncgroup.procs           cpu.cfs_quota_us   cpu.stat    tasks\n```\n\n接着写入限制规则\n\n```\n// 默认是100000，20000意味着限制它的cpu为20%\necho 20000 > /sys/fs/cgroup/cpu/calm/cpu.cfs_quota_us, \n\n// 写入程序的 PID 16515\necho 16515 > /sys/fs/cgroup/cpu/calm/tasks\n```\n\n于是 CPU 就降到 20% 。\n\n```\n  PID       PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       \n16515       20   0    2336    728    544 R  20.0  0.0   1:27.23 baozou\n```\n\n除了这种需要指定 PID 来限制资源的方法，也可通过指定规则来执行，更显得方便，效果和上述一致。\n\n```\nsudo cgexec -g cpu:calm ./baozou\n```\n\n可以看看这个限制规则做了什么?\n\n```\n$ sudo cgget calm\ncalm:\ncpu.shares: 1024\ncpu.cfs_quota_us: 20000\ncpu.stat: nr_periods 6943\n    nr_throttled 6941\n    throttled_time 563080015831\ncpu.cfs_period_us: 100000\n```\n\n上述的例子中，我们手动创建了 `calm`， 其实也能通过命令来做到的\n\n```\n// 创建cgroup 文件目录\nsudo cgcreate -g cpu:/calm -g memory:/calm\n\n// 设置限制的参数\nsudo cgset -r cpu.shares=200 calm\n\n// 限制了内存\nsudo cgset -r memory.limit_in_bytes=64k calm\n\n// 可以删除\nsudo cgdelete cpu/calm memory:/calm\n```\n\n---\n\n参考链接：\n\n* [Docker基础技术: Linux CGroup](http://coolshell.cn/articles/17049.html)\n* [cgroup实践](http://www.jianshu.com/p/dc3140699e79)\n","source":"_posts/2016-12-02-cgroupxian-zhi-ji-suan-zi-yuan.markdown","raw":"---\nlayout: post\ntitle: \"cgroup 限制计算资源\"\ndate: 2016-12-02 15:41\ncomments: true\ncategories: System\ndescription: cgroup\n---\n\nCgroup 实现了对计算机资源使用上的隔离，它是 Docker 底层的基础技术。我们可以用它来限制程序使用的CPU、内存、磁盘。\n\n### 安装\n\n在 Ubuntu 14.04 下安装的方法：\n\n```\nsudo apt-get install cgroup-bin\n```\n\n安装完后执行\n`mount -t cgroup` 会出现如下，可以看到它其实是一个文件系统\n\n```\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)\ncgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)\n...\ncgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,relatime,hugetlb)\n```\n\n如果没有看到以上的目录，这时候需要手动 mount 了\n\n```\ncd /sys/fs\nmkdir cgroup\nmount -t tmpfs cgroup_root ./cgroup\nmkdir cgroup/cpuset\nmount -t cgroup -ocpuset cpuset ./cgroup/cpuset/\nmkdir cgroup/cpu\nmount -t cgroup -ocpu cpu ./cgroup/cpu/\nmkdir cgroup/memory\nmount -t cgroup -omemory memory ./cgroup/memory/\n```\n\n### 实践\n\n我们来感性认识下 cgroup 吧，编写一个耗费 CPU 的程序，姑且叫暴走程序(baozou)\n\n```py\ncount = 0\nwhile True:\n    count = count + 1 - 1\n```\n\n运行该程序，top -p 之，100% CPU使用率\n\n```\n  PID      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       \n16515      20   0    2336    728    544 R  100.0  0.0   1:27.23 baozou\n```\n\n我想限制暴走程序 CPU 使用该如何做? 我们手动创建一个 cgroup 目录来针对它。\n\n```sh\ncd /sys/fs/cgroup/cpu\nmkdir calm      // 名字可自定义\nls /calm        // 该目录下自动生产与 CPU 有关的文件\ncgroup.clone_children  cpu.cfs_period_us  cpu.shares  notify_on_release\ncgroup.procs           cpu.cfs_quota_us   cpu.stat    tasks\n```\n\n接着写入限制规则\n\n```\n// 默认是100000，20000意味着限制它的cpu为20%\necho 20000 > /sys/fs/cgroup/cpu/calm/cpu.cfs_quota_us, \n\n// 写入程序的 PID 16515\necho 16515 > /sys/fs/cgroup/cpu/calm/tasks\n```\n\n于是 CPU 就降到 20% 。\n\n```\n  PID       PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       \n16515       20   0    2336    728    544 R  20.0  0.0   1:27.23 baozou\n```\n\n除了这种需要指定 PID 来限制资源的方法，也可通过指定规则来执行，更显得方便，效果和上述一致。\n\n```\nsudo cgexec -g cpu:calm ./baozou\n```\n\n可以看看这个限制规则做了什么?\n\n```\n$ sudo cgget calm\ncalm:\ncpu.shares: 1024\ncpu.cfs_quota_us: 20000\ncpu.stat: nr_periods 6943\n    nr_throttled 6941\n    throttled_time 563080015831\ncpu.cfs_period_us: 100000\n```\n\n上述的例子中，我们手动创建了 `calm`， 其实也能通过命令来做到的\n\n```\n// 创建cgroup 文件目录\nsudo cgcreate -g cpu:/calm -g memory:/calm\n\n// 设置限制的参数\nsudo cgset -r cpu.shares=200 calm\n\n// 限制了内存\nsudo cgset -r memory.limit_in_bytes=64k calm\n\n// 可以删除\nsudo cgdelete cpu/calm memory:/calm\n```\n\n---\n\n参考链接：\n\n* [Docker基础技术: Linux CGroup](http://coolshell.cn/articles/17049.html)\n* [cgroup实践](http://www.jianshu.com/p/dc3140699e79)\n","slug":"2016-12-02-cgroupxian-zhi-ji-suan-zi-yuan","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdao004unctj7gmg9nr2","content":"<p>Cgroup 实现了对计算机资源使用上的隔离，它是 Docker 底层的基础技术。我们可以用它来限制程序使用的CPU、内存、磁盘。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>在 Ubuntu 14.04 下安装的方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install cgroup-bin</span><br></pre></td></tr></table></figure>\n<p>安装完后执行<br><code>mount -t cgroup</code> 会出现如下，可以看到它其实是一个文件系统</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)</span><br><span class=\"line\">cgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)</span><br><span class=\"line\">...</span><br><span class=\"line\">cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,relatime,hugetlb)</span><br></pre></td></tr></table></figure>\n<p>如果没有看到以上的目录，这时候需要手动 mount 了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /sys/fs</span><br><span class=\"line\">mkdir cgroup</span><br><span class=\"line\">mount -t tmpfs cgroup_root ./cgroup</span><br><span class=\"line\">mkdir cgroup/cpuset</span><br><span class=\"line\">mount -t cgroup -ocpuset cpuset ./cgroup/cpuset/</span><br><span class=\"line\">mkdir cgroup/cpu</span><br><span class=\"line\">mount -t cgroup -ocpu cpu ./cgroup/cpu/</span><br><span class=\"line\">mkdir cgroup/memory</span><br><span class=\"line\">mount -t cgroup -omemory memory ./cgroup/memory/</span><br></pre></td></tr></table></figure>\n<h3 id=\"实践\"><a href=\"#实践\" class=\"headerlink\" title=\"实践\"></a>实践</h3><p>我们来感性认识下 cgroup 吧，编写一个耗费 CPU 的程序，姑且叫暴走程序(baozou)</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">count = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">    count = count + <span class=\"number\">1</span> - <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<p>运行该程序，top -p 之，100% CPU使用率</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  PID      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       </span><br><span class=\"line\">16515      20   0    2336    728    544 R  100.0  0.0   1:27.23 baozou</span><br></pre></td></tr></table></figure>\n<p>我想限制暴走程序 CPU 使用该如何做? 我们手动创建一个 cgroup 目录来针对它。</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /sys/fs/cgroup/cpu</span><br><span class=\"line\">mkdir calm      // 名字可自定义</span><br><span class=\"line\">ls /calm        // 该目录下自动生产与 CPU 有关的文件</span><br><span class=\"line\">cgroup.clone_children  cpu.cfs_period_us  cpu.shares  notify_on_release</span><br><span class=\"line\">cgroup.procs           cpu.cfs_quota_us   cpu.stat    tasks</span><br></pre></td></tr></table></figure>\n<p>接着写入限制规则</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 默认是100000，20000意味着限制它的cpu为20%</span><br><span class=\"line\">echo 20000 &gt; /sys/fs/cgroup/cpu/calm/cpu.cfs_quota_us, </span><br><span class=\"line\"></span><br><span class=\"line\">// 写入程序的 PID 16515</span><br><span class=\"line\">echo 16515 &gt; /sys/fs/cgroup/cpu/calm/tasks</span><br></pre></td></tr></table></figure>\n<p>于是 CPU 就降到 20% 。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  PID       PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       </span><br><span class=\"line\">16515       20   0    2336    728    544 R  20.0  0.0   1:27.23 baozou</span><br></pre></td></tr></table></figure>\n<p>除了这种需要指定 PID 来限制资源的方法，也可通过指定规则来执行，更显得方便，效果和上述一致。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo cgexec -g cpu:calm ./baozou</span><br></pre></td></tr></table></figure>\n<p>可以看看这个限制规则做了什么?</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo cgget calm</span><br><span class=\"line\">calm:</span><br><span class=\"line\">cpu.shares: 1024</span><br><span class=\"line\">cpu.cfs_quota_us: 20000</span><br><span class=\"line\">cpu.stat: nr_periods 6943</span><br><span class=\"line\">    nr_throttled 6941</span><br><span class=\"line\">    throttled_time 563080015831</span><br><span class=\"line\">cpu.cfs_period_us: 100000</span><br></pre></td></tr></table></figure>\n<p>上述的例子中，我们手动创建了 <code>calm</code>， 其实也能通过命令来做到的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 创建cgroup 文件目录</span><br><span class=\"line\">sudo cgcreate -g cpu:/calm -g memory:/calm</span><br><span class=\"line\"></span><br><span class=\"line\">// 设置限制的参数</span><br><span class=\"line\">sudo cgset -r cpu.shares=200 calm</span><br><span class=\"line\"></span><br><span class=\"line\">// 限制了内存</span><br><span class=\"line\">sudo cgset -r memory.limit_in_bytes=64k calm</span><br><span class=\"line\"></span><br><span class=\"line\">// 可以删除</span><br><span class=\"line\">sudo cgdelete cpu/calm memory:/calm</span><br></pre></td></tr></table></figure>\n<hr>\n<p>参考链接：</p>\n<ul>\n<li><a href=\"http://coolshell.cn/articles/17049.html\" target=\"_blank\" rel=\"noopener\">Docker基础技术: Linux CGroup</a></li>\n<li><a href=\"http://www.jianshu.com/p/dc3140699e79\" target=\"_blank\" rel=\"noopener\">cgroup实践</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>Cgroup 实现了对计算机资源使用上的隔离，它是 Docker 底层的基础技术。我们可以用它来限制程序使用的CPU、内存、磁盘。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>在 Ubuntu 14.04 下安装的方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install cgroup-bin</span><br></pre></td></tr></table></figure>\n<p>安装完后执行<br><code>mount -t cgroup</code> 会出现如下，可以看到它其实是一个文件系统</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)</span><br><span class=\"line\">cgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)</span><br><span class=\"line\">...</span><br><span class=\"line\">cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,relatime,hugetlb)</span><br></pre></td></tr></table></figure>\n<p>如果没有看到以上的目录，这时候需要手动 mount 了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /sys/fs</span><br><span class=\"line\">mkdir cgroup</span><br><span class=\"line\">mount -t tmpfs cgroup_root ./cgroup</span><br><span class=\"line\">mkdir cgroup/cpuset</span><br><span class=\"line\">mount -t cgroup -ocpuset cpuset ./cgroup/cpuset/</span><br><span class=\"line\">mkdir cgroup/cpu</span><br><span class=\"line\">mount -t cgroup -ocpu cpu ./cgroup/cpu/</span><br><span class=\"line\">mkdir cgroup/memory</span><br><span class=\"line\">mount -t cgroup -omemory memory ./cgroup/memory/</span><br></pre></td></tr></table></figure>\n<h3 id=\"实践\"><a href=\"#实践\" class=\"headerlink\" title=\"实践\"></a>实践</h3><p>我们来感性认识下 cgroup 吧，编写一个耗费 CPU 的程序，姑且叫暴走程序(baozou)</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">count = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</span><br><span class=\"line\">    count = count + <span class=\"number\">1</span> - <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<p>运行该程序，top -p 之，100% CPU使用率</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  PID      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       </span><br><span class=\"line\">16515      20   0    2336    728    544 R  100.0  0.0   1:27.23 baozou</span><br></pre></td></tr></table></figure>\n<p>我想限制暴走程序 CPU 使用该如何做? 我们手动创建一个 cgroup 目录来针对它。</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /sys/fs/cgroup/cpu</span><br><span class=\"line\">mkdir calm      // 名字可自定义</span><br><span class=\"line\">ls /calm        // 该目录下自动生产与 CPU 有关的文件</span><br><span class=\"line\">cgroup.clone_children  cpu.cfs_period_us  cpu.shares  notify_on_release</span><br><span class=\"line\">cgroup.procs           cpu.cfs_quota_us   cpu.stat    tasks</span><br></pre></td></tr></table></figure>\n<p>接着写入限制规则</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 默认是100000，20000意味着限制它的cpu为20%</span><br><span class=\"line\">echo 20000 &gt; /sys/fs/cgroup/cpu/calm/cpu.cfs_quota_us, </span><br><span class=\"line\"></span><br><span class=\"line\">// 写入程序的 PID 16515</span><br><span class=\"line\">echo 16515 &gt; /sys/fs/cgroup/cpu/calm/tasks</span><br></pre></td></tr></table></figure>\n<p>于是 CPU 就降到 20% 。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  PID       PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                       </span><br><span class=\"line\">16515       20   0    2336    728    544 R  20.0  0.0   1:27.23 baozou</span><br></pre></td></tr></table></figure>\n<p>除了这种需要指定 PID 来限制资源的方法，也可通过指定规则来执行，更显得方便，效果和上述一致。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo cgexec -g cpu:calm ./baozou</span><br></pre></td></tr></table></figure>\n<p>可以看看这个限制规则做了什么?</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo cgget calm</span><br><span class=\"line\">calm:</span><br><span class=\"line\">cpu.shares: 1024</span><br><span class=\"line\">cpu.cfs_quota_us: 20000</span><br><span class=\"line\">cpu.stat: nr_periods 6943</span><br><span class=\"line\">    nr_throttled 6941</span><br><span class=\"line\">    throttled_time 563080015831</span><br><span class=\"line\">cpu.cfs_period_us: 100000</span><br></pre></td></tr></table></figure>\n<p>上述的例子中，我们手动创建了 <code>calm</code>， 其实也能通过命令来做到的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 创建cgroup 文件目录</span><br><span class=\"line\">sudo cgcreate -g cpu:/calm -g memory:/calm</span><br><span class=\"line\"></span><br><span class=\"line\">// 设置限制的参数</span><br><span class=\"line\">sudo cgset -r cpu.shares=200 calm</span><br><span class=\"line\"></span><br><span class=\"line\">// 限制了内存</span><br><span class=\"line\">sudo cgset -r memory.limit_in_bytes=64k calm</span><br><span class=\"line\"></span><br><span class=\"line\">// 可以删除</span><br><span class=\"line\">sudo cgdelete cpu/calm memory:/calm</span><br></pre></td></tr></table></figure>\n<hr>\n<p>参考链接：</p>\n<ul>\n<li><a href=\"http://coolshell.cn/articles/17049.html\" target=\"_blank\" rel=\"noopener\">Docker基础技术: Linux CGroup</a></li>\n<li><a href=\"http://www.jianshu.com/p/dc3140699e79\" target=\"_blank\" rel=\"noopener\">cgroup实践</a></li>\n</ul>\n"},{"layout":"post","title":"Squid 做正向代理","date":"2017-02-22T14:30:00.000Z","comments":1,"description":"squid, 代理","_content":"\n### 正向代理和反向代理\n\n* 正向代理\n\n正向代理 是一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定原始服务器，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。\n\n* 反向代理\n\n反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。\n\n### 正向代理软件\n\nNginx 能做正向代理，遗憾的是它不能做 HTTPS 的正向代理。以下是一个例子。\n\n* 不能有 hostname。 \n* 必须有 resolver, 即 DNS\n* 配置正向代理参数，均是由 Nginx 变量组成\n\n```\nserver{\n      resolver 8.8.8.8;\n      resolver_timeout 30s; \n      listen 80;\n      location / {\n                proxy_pass http://$http_host$request_uri;\n                proxy_set_header Host $http_host;\n        }\n}\n```\n\nSquid 可正向代理 HTTP 以及 HTTPS\n\n\n```\nsudo apt-get install squid\n```\n\n编辑 `/etc/squid3/squid.conf`, 并重启\n\n```\nhttp_port 3128                 \t#代理服务器的端口\n#http_access deny !Safe_ports \t#注释掉此项\n#http_access deny manager     \t#注释掉此项\n\n#添加下面两项，设置哪些网段可以访问本代理服务器\nacl our_networks src 172.16.1.0/24 \nhttp_access allow our_networks\n```\n\n```\nsudo service squid3 restart\n```\n\nSquid 的层次代理值得一提， 若我们需要定期地切换代理服务器的话, 启动一个 Squid 代理, 而这个代理会将请求转发到其他代理上面. 然后我们只需定时更新本地 Squid 代理的配置文件, 然后重启这个本地代理即可. 层次代理用到了 `cache_peer` 这个配置文件\n\n```\ncache_peer hostname type http_port icp_port option\n\ne.g.\ncache_peer xxx.proxy.com parent 9020 0 no-query default login=xxxxx:yyyy\n```\n\n* hostname: 指被请求的同级子代理服务器或父代理服务器。可以用主机名或ip地址表示；\n* type：指明 hostname 的类型，是同级子代理服务器还是父代理服务器，也即 parent 还是 sibling；\n* http_port：hostname的监听端口；\n* icp_port：hostname 上的ICP监听端口，对于不支持ICP协议的可指定7；\n* options：可以包含一个或多个关键字。\n   1. proxy-only：指明从peer得到的数据在本地不进行缓存，缺省地，squid是要缓存这部分数据的；\n   2. weight=n：用于有多个peer的情况，如果多于一个以上的peer拥有你请求的数据时，squid通过计算每个peer ICP 响应时间来 决定其weight的值，然后 squid 向其中拥有最大 weight 的peer发出ICP请求。\n   3. no-query：不向该peer发送ICP请求。如果该peer不可用时，可以使用该选项；\n   4. Default：有点象路由表中的缺省路由，该peer将被用作最后的尝试手段。当你只有一个父代理服务器并且其不支持ICP协议时，可以使用default和no-query选项让所有请求都发送到该父代理服务器；\n* login=user:password：当你的父代理服务器要求用户认证时可以使用该选项来进行认证\n","source":"_posts/2017-02-22-zheng-xiang-yu-fan-xiang-dai-li.markdown","raw":"---\nlayout: post\ntitle: \"Squid 做正向代理\"\ndate: 2017-02-22 22:30\ncomments: true\ncategories: System\ndescription: squid, 代理\n---\n\n### 正向代理和反向代理\n\n* 正向代理\n\n正向代理 是一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定原始服务器，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。\n\n* 反向代理\n\n反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。\n\n### 正向代理软件\n\nNginx 能做正向代理，遗憾的是它不能做 HTTPS 的正向代理。以下是一个例子。\n\n* 不能有 hostname。 \n* 必须有 resolver, 即 DNS\n* 配置正向代理参数，均是由 Nginx 变量组成\n\n```\nserver{\n      resolver 8.8.8.8;\n      resolver_timeout 30s; \n      listen 80;\n      location / {\n                proxy_pass http://$http_host$request_uri;\n                proxy_set_header Host $http_host;\n        }\n}\n```\n\nSquid 可正向代理 HTTP 以及 HTTPS\n\n\n```\nsudo apt-get install squid\n```\n\n编辑 `/etc/squid3/squid.conf`, 并重启\n\n```\nhttp_port 3128                 \t#代理服务器的端口\n#http_access deny !Safe_ports \t#注释掉此项\n#http_access deny manager     \t#注释掉此项\n\n#添加下面两项，设置哪些网段可以访问本代理服务器\nacl our_networks src 172.16.1.0/24 \nhttp_access allow our_networks\n```\n\n```\nsudo service squid3 restart\n```\n\nSquid 的层次代理值得一提， 若我们需要定期地切换代理服务器的话, 启动一个 Squid 代理, 而这个代理会将请求转发到其他代理上面. 然后我们只需定时更新本地 Squid 代理的配置文件, 然后重启这个本地代理即可. 层次代理用到了 `cache_peer` 这个配置文件\n\n```\ncache_peer hostname type http_port icp_port option\n\ne.g.\ncache_peer xxx.proxy.com parent 9020 0 no-query default login=xxxxx:yyyy\n```\n\n* hostname: 指被请求的同级子代理服务器或父代理服务器。可以用主机名或ip地址表示；\n* type：指明 hostname 的类型，是同级子代理服务器还是父代理服务器，也即 parent 还是 sibling；\n* http_port：hostname的监听端口；\n* icp_port：hostname 上的ICP监听端口，对于不支持ICP协议的可指定7；\n* options：可以包含一个或多个关键字。\n   1. proxy-only：指明从peer得到的数据在本地不进行缓存，缺省地，squid是要缓存这部分数据的；\n   2. weight=n：用于有多个peer的情况，如果多于一个以上的peer拥有你请求的数据时，squid通过计算每个peer ICP 响应时间来 决定其weight的值，然后 squid 向其中拥有最大 weight 的peer发出ICP请求。\n   3. no-query：不向该peer发送ICP请求。如果该peer不可用时，可以使用该选项；\n   4. Default：有点象路由表中的缺省路由，该peer将被用作最后的尝试手段。当你只有一个父代理服务器并且其不支持ICP协议时，可以使用default和no-query选项让所有请求都发送到该父代理服务器；\n* login=user:password：当你的父代理服务器要求用户认证时可以使用该选项来进行认证\n","slug":"2017-02-22-zheng-xiang-yu-fan-xiang-dai-li","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdap004wnctjb4k6uj7h","content":"<h3 id=\"正向代理和反向代理\"><a href=\"#正向代理和反向代理\" class=\"headerlink\" title=\"正向代理和反向代理\"></a>正向代理和反向代理</h3><ul>\n<li>正向代理</li>\n</ul>\n<p>正向代理 是一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定原始服务器，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。</p>\n<ul>\n<li>反向代理</li>\n</ul>\n<p>反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。</p>\n<h3 id=\"正向代理软件\"><a href=\"#正向代理软件\" class=\"headerlink\" title=\"正向代理软件\"></a>正向代理软件</h3><p>Nginx 能做正向代理，遗憾的是它不能做 HTTPS 的正向代理。以下是一个例子。</p>\n<ul>\n<li>不能有 hostname。 </li>\n<li>必须有 resolver, 即 DNS</li>\n<li>配置正向代理参数，均是由 Nginx 变量组成</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server&#123;</span><br><span class=\"line\">      resolver 8.8.8.8;</span><br><span class=\"line\">      resolver_timeout 30s; </span><br><span class=\"line\">      listen 80;</span><br><span class=\"line\">      location / &#123;</span><br><span class=\"line\">                proxy_pass http://$http_host$request_uri;</span><br><span class=\"line\">                proxy_set_header Host $http_host;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Squid 可正向代理 HTTP 以及 HTTPS</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install squid</span><br></pre></td></tr></table></figure>\n<p>编辑 <code>/etc/squid3/squid.conf</code>, 并重启</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http_port 3128                 \t#代理服务器的端口</span><br><span class=\"line\">#http_access deny !Safe_ports \t#注释掉此项</span><br><span class=\"line\">#http_access deny manager     \t#注释掉此项</span><br><span class=\"line\"></span><br><span class=\"line\">#添加下面两项，设置哪些网段可以访问本代理服务器</span><br><span class=\"line\">acl our_networks src 172.16.1.0/24 </span><br><span class=\"line\">http_access allow our_networks</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo service squid3 restart</span><br></pre></td></tr></table></figure>\n<p>Squid 的层次代理值得一提， 若我们需要定期地切换代理服务器的话, 启动一个 Squid 代理, 而这个代理会将请求转发到其他代理上面. 然后我们只需定时更新本地 Squid 代理的配置文件, 然后重启这个本地代理即可. 层次代理用到了 <code>cache_peer</code> 这个配置文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cache_peer hostname type http_port icp_port option</span><br><span class=\"line\"></span><br><span class=\"line\">e.g.</span><br><span class=\"line\">cache_peer xxx.proxy.com parent 9020 0 no-query default login=xxxxx:yyyy</span><br></pre></td></tr></table></figure>\n<ul>\n<li>hostname: 指被请求的同级子代理服务器或父代理服务器。可以用主机名或ip地址表示；</li>\n<li>type：指明 hostname 的类型，是同级子代理服务器还是父代理服务器，也即 parent 还是 sibling；</li>\n<li>http_port：hostname的监听端口；</li>\n<li>icp_port：hostname 上的ICP监听端口，对于不支持ICP协议的可指定7；</li>\n<li>options：可以包含一个或多个关键字。<ol>\n<li>proxy-only：指明从peer得到的数据在本地不进行缓存，缺省地，squid是要缓存这部分数据的；</li>\n<li>weight=n：用于有多个peer的情况，如果多于一个以上的peer拥有你请求的数据时，squid通过计算每个peer ICP 响应时间来 决定其weight的值，然后 squid 向其中拥有最大 weight 的peer发出ICP请求。</li>\n<li>no-query：不向该peer发送ICP请求。如果该peer不可用时，可以使用该选项；</li>\n<li>Default：有点象路由表中的缺省路由，该peer将被用作最后的尝试手段。当你只有一个父代理服务器并且其不支持ICP协议时，可以使用default和no-query选项让所有请求都发送到该父代理服务器；</li>\n</ol>\n</li>\n<li>login=user:password：当你的父代理服务器要求用户认证时可以使用该选项来进行认证</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"正向代理和反向代理\"><a href=\"#正向代理和反向代理\" class=\"headerlink\" title=\"正向代理和反向代理\"></a>正向代理和反向代理</h3><ul>\n<li>正向代理</li>\n</ul>\n<p>正向代理 是一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定原始服务器，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。</p>\n<ul>\n<li>反向代理</li>\n</ul>\n<p>反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。</p>\n<h3 id=\"正向代理软件\"><a href=\"#正向代理软件\" class=\"headerlink\" title=\"正向代理软件\"></a>正向代理软件</h3><p>Nginx 能做正向代理，遗憾的是它不能做 HTTPS 的正向代理。以下是一个例子。</p>\n<ul>\n<li>不能有 hostname。 </li>\n<li>必须有 resolver, 即 DNS</li>\n<li>配置正向代理参数，均是由 Nginx 变量组成</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server&#123;</span><br><span class=\"line\">      resolver 8.8.8.8;</span><br><span class=\"line\">      resolver_timeout 30s; </span><br><span class=\"line\">      listen 80;</span><br><span class=\"line\">      location / &#123;</span><br><span class=\"line\">                proxy_pass http://$http_host$request_uri;</span><br><span class=\"line\">                proxy_set_header Host $http_host;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Squid 可正向代理 HTTP 以及 HTTPS</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install squid</span><br></pre></td></tr></table></figure>\n<p>编辑 <code>/etc/squid3/squid.conf</code>, 并重启</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http_port 3128                 \t#代理服务器的端口</span><br><span class=\"line\">#http_access deny !Safe_ports \t#注释掉此项</span><br><span class=\"line\">#http_access deny manager     \t#注释掉此项</span><br><span class=\"line\"></span><br><span class=\"line\">#添加下面两项，设置哪些网段可以访问本代理服务器</span><br><span class=\"line\">acl our_networks src 172.16.1.0/24 </span><br><span class=\"line\">http_access allow our_networks</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo service squid3 restart</span><br></pre></td></tr></table></figure>\n<p>Squid 的层次代理值得一提， 若我们需要定期地切换代理服务器的话, 启动一个 Squid 代理, 而这个代理会将请求转发到其他代理上面. 然后我们只需定时更新本地 Squid 代理的配置文件, 然后重启这个本地代理即可. 层次代理用到了 <code>cache_peer</code> 这个配置文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cache_peer hostname type http_port icp_port option</span><br><span class=\"line\"></span><br><span class=\"line\">e.g.</span><br><span class=\"line\">cache_peer xxx.proxy.com parent 9020 0 no-query default login=xxxxx:yyyy</span><br></pre></td></tr></table></figure>\n<ul>\n<li>hostname: 指被请求的同级子代理服务器或父代理服务器。可以用主机名或ip地址表示；</li>\n<li>type：指明 hostname 的类型，是同级子代理服务器还是父代理服务器，也即 parent 还是 sibling；</li>\n<li>http_port：hostname的监听端口；</li>\n<li>icp_port：hostname 上的ICP监听端口，对于不支持ICP协议的可指定7；</li>\n<li>options：可以包含一个或多个关键字。<ol>\n<li>proxy-only：指明从peer得到的数据在本地不进行缓存，缺省地，squid是要缓存这部分数据的；</li>\n<li>weight=n：用于有多个peer的情况，如果多于一个以上的peer拥有你请求的数据时，squid通过计算每个peer ICP 响应时间来 决定其weight的值，然后 squid 向其中拥有最大 weight 的peer发出ICP请求。</li>\n<li>no-query：不向该peer发送ICP请求。如果该peer不可用时，可以使用该选项；</li>\n<li>Default：有点象路由表中的缺省路由，该peer将被用作最后的尝试手段。当你只有一个父代理服务器并且其不支持ICP协议时，可以使用default和no-query选项让所有请求都发送到该父代理服务器；</li>\n</ol>\n</li>\n<li>login=user:password：当你的父代理服务器要求用户认证时可以使用该选项来进行认证</li>\n</ul>\n"},{"layout":"post","title":"zookeeper 笔记","date":"2017-02-25T09:30:00.000Z","comments":1,"description":"zookeeper","_content":"\nZooKeeper 是一个开源的分布式协调服务，是分布式数据一致性的解决方案。\n\n### 集群角色\n\n在 ZooKeeper 中，有三种角色： Leader，Follower，Observer\n\n一个 ZooKeeper 集群同时只会有一个Leader，其他都是 Follower 或 Observer。\nLeader 服务器为客户端提供读和写服务，Follower 和 Observer 都能提供读服务，不能提供写服务。区别在于，Observer 不参与 Leader 选举过程，也不参与写操作的过半写成功策略，因此 Observer 可以在不影响写性能的情况下提升集群的读性能。\n\n### 会话\n\n客户端和 ZooKeeper 服务器会与服务器建立一个 TCP 连接，通过这个连接，客户端能够通过心跳检测和服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能通过该连接接收来自服务器的 Watch 事件通知。\n\n\n### 数据节点\n\nZooKeeper 中的数据节点是指数据模型中的数据单元，称为 ZNode。ZooKeeper将所有数据存储在内存中，数据模型是一棵树（ZNode Tree），由斜杠进行分割的路径，就是一个ZNode。每个ZNode上都会保存自己的数据内容，同时会保存一系列属性信息。每个ZNode不仅本身可以写数据，还可以有下一级文件或目录。\n\n在ZooKeeper中，ZNode可以分为持久节点和临时节点两类。持久节点是指一旦这个 ZNode 被创建了，除非主动进行 ZNode 的移除操作，否则这个 ZNode 将一直保存在 ZooKeeper上。临时节点的生命周期跟客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。\n\nZooKeeper 允许用户为每个节点添加一个特殊的属性：SEQUENTIAL。一旦节点被标记上这个属性，那么在这个节点被创建的时候，ZooKeeper就会自动在其节点后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。\n\n### 版本\n\nZooKeeper 的每个 ZNode 上都会存储数据，对于每个ZNode，ZooKeeper都会为其维护一个叫作Stat的数据结构，Stat中记录了这个ZNode的三个数据版本，分别是 version（当前ZNode的版本, cversion（当前ZNode子节点的版本）和 aversion（当前ZNode的ACL版本）。\n\n### 事务\n\n在 ZooKeeper 中，能改变 ZooKeeper 服务器状态的操作称为事务操作。包括数据节点创建与删除、数据内容更新和客户端会话创建与失效等操作。对应每一个事务请求，ZooKeeper都会为其分配一个全局唯一的事务ID，用ZXID表示，通常是一个64位的数字。每一个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出ZooKeeper处理这些事务操作请求的全局顺序。\n\n### Watcher\n\nZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去。该机制是 ZooKeeper 实现分布式协调服务的重要特性。\n\n###  ACL\n\nZooKeeper 采用 Access Control Lists 策略来进行权限控制。ZooKeeper 定义了如下5种权限。\n\n```\nCREATE: 创建子节点的权限。\nREAD: 获取节点数据和子节点列表的权限。\nWRITE：更新节点数据的权限。\nDELETE: 删除子节点的权限。\nADMIN: 设置节点ACL的权限。\n注意：CREATE 和 DELETE 都是针对子节点的权限控制。\n```\n\n### ZAB 原子广播协议\n\nZooKeeper Atomic Broadcast（ZAB，ZooKeeper原子广播协议）的协议作为其数据一致性的核心算法。\n\n所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，而剩下的其他服务器则成为 Follower 服务器。Leader 服务器负责将一个客户端事务请求转换成一个事务 Proposal（提案）并将该 Proposal分发给集群中所有的 Follower 服务器。之后 Leader 服务器需要等待所有 Follower 服务器的反馈，一旦超过半数的 Follower 服务器进行了正确的反馈后，Leader 就会再次向所有的 Follower 服务器分发 Commit 消息，要求对刚才的 Proposal 进行提交。\n\n### 应用场景\n\n* 数据发布与订阅-配置中心\n\n发布者将数据发布到 ZooKeeper 节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中式管理和动态更新。全局配置信息就可以发布到 ZooKeeper 上，让客户端（集群的机器）去订阅该消息。\n\n客户端想服务端注册自己需要关注的节点，一旦该节点的数据发生变更，那么服务端就会向相应的客户端发送 Watcher 事件通知，客户端接收到这个消息通知后，需要主动到服务端获取最新的数据（推拉结合）。\n\n* 命名服务，即生成全局唯一的ID。\n\n* 分布式协调通知\n\nZooKeeper 中特有 Watcher 注册与异步通知机制，实现对数据变更的实时处理。不同的客户端都对ZK上同一个ZNode 进行注册，监听 ZNode 的变化（包括ZNode本身内容及子节点的），如果 ZNode 发生了变化，那么所有订阅的客户端都能够接收到相应的 Watcher 通知，并做出相应的处理，是一种通用的分布式系统机器间的通信方式。\n\n* 心跳检测\n\n基于 ZK 临时节点的特性，可以让不同的进程都在 ZK 的一个指定节点下创建临时子节点，不同的进程直接可以根据这个临时子节点来判断对应的进程是否存活。通过这种方式，检测和被检测系统直接并不需要直接相关联，而是通过 ZK 上的某个节点进行关联，大大减少了系统耦合。\n\n* 分布式锁\n\n分布式锁是控制分布式系统之间同步访问共享资源的一种方式。分布式锁又分为排他锁和共享锁两种。 排他锁又称为写锁或独占锁，共享锁又称为读锁。\n\n把 ZooKeeper 上一个 ZNode 看作是一个锁，获得锁就通过创建ZNode的方式来实现。所有客户端都去/x_lock节点下创建临时子节点/x_lock/lock。ZooKeeper会保证在所有客户端中，最终只有一个客户端能够创建成功，那么就可以认为该客户端获得了锁。同时，所有没有获取到锁的客户端就需要到/x_lock节点上注册一个子节点变更的 Watcher 监听，以便实时监听到 lock 节点的变更情况。\n\n","source":"_posts/2017-02-25-zookeeper-bi-ji.markdown","raw":"---\nlayout: post\ntitle: \"zookeeper 笔记\"\ndate: 2017-02-25 17:30\ncomments: true\ncategories: Server\ndescription: zookeeper\n---\n\nZooKeeper 是一个开源的分布式协调服务，是分布式数据一致性的解决方案。\n\n### 集群角色\n\n在 ZooKeeper 中，有三种角色： Leader，Follower，Observer\n\n一个 ZooKeeper 集群同时只会有一个Leader，其他都是 Follower 或 Observer。\nLeader 服务器为客户端提供读和写服务，Follower 和 Observer 都能提供读服务，不能提供写服务。区别在于，Observer 不参与 Leader 选举过程，也不参与写操作的过半写成功策略，因此 Observer 可以在不影响写性能的情况下提升集群的读性能。\n\n### 会话\n\n客户端和 ZooKeeper 服务器会与服务器建立一个 TCP 连接，通过这个连接，客户端能够通过心跳检测和服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能通过该连接接收来自服务器的 Watch 事件通知。\n\n\n### 数据节点\n\nZooKeeper 中的数据节点是指数据模型中的数据单元，称为 ZNode。ZooKeeper将所有数据存储在内存中，数据模型是一棵树（ZNode Tree），由斜杠进行分割的路径，就是一个ZNode。每个ZNode上都会保存自己的数据内容，同时会保存一系列属性信息。每个ZNode不仅本身可以写数据，还可以有下一级文件或目录。\n\n在ZooKeeper中，ZNode可以分为持久节点和临时节点两类。持久节点是指一旦这个 ZNode 被创建了，除非主动进行 ZNode 的移除操作，否则这个 ZNode 将一直保存在 ZooKeeper上。临时节点的生命周期跟客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。\n\nZooKeeper 允许用户为每个节点添加一个特殊的属性：SEQUENTIAL。一旦节点被标记上这个属性，那么在这个节点被创建的时候，ZooKeeper就会自动在其节点后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。\n\n### 版本\n\nZooKeeper 的每个 ZNode 上都会存储数据，对于每个ZNode，ZooKeeper都会为其维护一个叫作Stat的数据结构，Stat中记录了这个ZNode的三个数据版本，分别是 version（当前ZNode的版本, cversion（当前ZNode子节点的版本）和 aversion（当前ZNode的ACL版本）。\n\n### 事务\n\n在 ZooKeeper 中，能改变 ZooKeeper 服务器状态的操作称为事务操作。包括数据节点创建与删除、数据内容更新和客户端会话创建与失效等操作。对应每一个事务请求，ZooKeeper都会为其分配一个全局唯一的事务ID，用ZXID表示，通常是一个64位的数字。每一个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出ZooKeeper处理这些事务操作请求的全局顺序。\n\n### Watcher\n\nZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去。该机制是 ZooKeeper 实现分布式协调服务的重要特性。\n\n###  ACL\n\nZooKeeper 采用 Access Control Lists 策略来进行权限控制。ZooKeeper 定义了如下5种权限。\n\n```\nCREATE: 创建子节点的权限。\nREAD: 获取节点数据和子节点列表的权限。\nWRITE：更新节点数据的权限。\nDELETE: 删除子节点的权限。\nADMIN: 设置节点ACL的权限。\n注意：CREATE 和 DELETE 都是针对子节点的权限控制。\n```\n\n### ZAB 原子广播协议\n\nZooKeeper Atomic Broadcast（ZAB，ZooKeeper原子广播协议）的协议作为其数据一致性的核心算法。\n\n所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，而剩下的其他服务器则成为 Follower 服务器。Leader 服务器负责将一个客户端事务请求转换成一个事务 Proposal（提案）并将该 Proposal分发给集群中所有的 Follower 服务器。之后 Leader 服务器需要等待所有 Follower 服务器的反馈，一旦超过半数的 Follower 服务器进行了正确的反馈后，Leader 就会再次向所有的 Follower 服务器分发 Commit 消息，要求对刚才的 Proposal 进行提交。\n\n### 应用场景\n\n* 数据发布与订阅-配置中心\n\n发布者将数据发布到 ZooKeeper 节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中式管理和动态更新。全局配置信息就可以发布到 ZooKeeper 上，让客户端（集群的机器）去订阅该消息。\n\n客户端想服务端注册自己需要关注的节点，一旦该节点的数据发生变更，那么服务端就会向相应的客户端发送 Watcher 事件通知，客户端接收到这个消息通知后，需要主动到服务端获取最新的数据（推拉结合）。\n\n* 命名服务，即生成全局唯一的ID。\n\n* 分布式协调通知\n\nZooKeeper 中特有 Watcher 注册与异步通知机制，实现对数据变更的实时处理。不同的客户端都对ZK上同一个ZNode 进行注册，监听 ZNode 的变化（包括ZNode本身内容及子节点的），如果 ZNode 发生了变化，那么所有订阅的客户端都能够接收到相应的 Watcher 通知，并做出相应的处理，是一种通用的分布式系统机器间的通信方式。\n\n* 心跳检测\n\n基于 ZK 临时节点的特性，可以让不同的进程都在 ZK 的一个指定节点下创建临时子节点，不同的进程直接可以根据这个临时子节点来判断对应的进程是否存活。通过这种方式，检测和被检测系统直接并不需要直接相关联，而是通过 ZK 上的某个节点进行关联，大大减少了系统耦合。\n\n* 分布式锁\n\n分布式锁是控制分布式系统之间同步访问共享资源的一种方式。分布式锁又分为排他锁和共享锁两种。 排他锁又称为写锁或独占锁，共享锁又称为读锁。\n\n把 ZooKeeper 上一个 ZNode 看作是一个锁，获得锁就通过创建ZNode的方式来实现。所有客户端都去/x_lock节点下创建临时子节点/x_lock/lock。ZooKeeper会保证在所有客户端中，最终只有一个客户端能够创建成功，那么就可以认为该客户端获得了锁。同时，所有没有获取到锁的客户端就需要到/x_lock节点上注册一个子节点变更的 Watcher 监听，以便实时监听到 lock 节点的变更情况。\n\n","slug":"2017-02-25-zookeeper-bi-ji","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdaq004ynctj3mzutzmc","content":"<p>ZooKeeper 是一个开源的分布式协调服务，是分布式数据一致性的解决方案。</p>\n<h3 id=\"集群角色\"><a href=\"#集群角色\" class=\"headerlink\" title=\"集群角色\"></a>集群角色</h3><p>在 ZooKeeper 中，有三种角色： Leader，Follower，Observer</p>\n<p>一个 ZooKeeper 集群同时只会有一个Leader，其他都是 Follower 或 Observer。<br>Leader 服务器为客户端提供读和写服务，Follower 和 Observer 都能提供读服务，不能提供写服务。区别在于，Observer 不参与 Leader 选举过程，也不参与写操作的过半写成功策略，因此 Observer 可以在不影响写性能的情况下提升集群的读性能。</p>\n<h3 id=\"会话\"><a href=\"#会话\" class=\"headerlink\" title=\"会话\"></a>会话</h3><p>客户端和 ZooKeeper 服务器会与服务器建立一个 TCP 连接，通过这个连接，客户端能够通过心跳检测和服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能通过该连接接收来自服务器的 Watch 事件通知。</p>\n<h3 id=\"数据节点\"><a href=\"#数据节点\" class=\"headerlink\" title=\"数据节点\"></a>数据节点</h3><p>ZooKeeper 中的数据节点是指数据模型中的数据单元，称为 ZNode。ZooKeeper将所有数据存储在内存中，数据模型是一棵树（ZNode Tree），由斜杠进行分割的路径，就是一个ZNode。每个ZNode上都会保存自己的数据内容，同时会保存一系列属性信息。每个ZNode不仅本身可以写数据，还可以有下一级文件或目录。</p>\n<p>在ZooKeeper中，ZNode可以分为持久节点和临时节点两类。持久节点是指一旦这个 ZNode 被创建了，除非主动进行 ZNode 的移除操作，否则这个 ZNode 将一直保存在 ZooKeeper上。临时节点的生命周期跟客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。</p>\n<p>ZooKeeper 允许用户为每个节点添加一个特殊的属性：SEQUENTIAL。一旦节点被标记上这个属性，那么在这个节点被创建的时候，ZooKeeper就会自动在其节点后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。</p>\n<h3 id=\"版本\"><a href=\"#版本\" class=\"headerlink\" title=\"版本\"></a>版本</h3><p>ZooKeeper 的每个 ZNode 上都会存储数据，对于每个ZNode，ZooKeeper都会为其维护一个叫作Stat的数据结构，Stat中记录了这个ZNode的三个数据版本，分别是 version（当前ZNode的版本, cversion（当前ZNode子节点的版本）和 aversion（当前ZNode的ACL版本）。</p>\n<h3 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h3><p>在 ZooKeeper 中，能改变 ZooKeeper 服务器状态的操作称为事务操作。包括数据节点创建与删除、数据内容更新和客户端会话创建与失效等操作。对应每一个事务请求，ZooKeeper都会为其分配一个全局唯一的事务ID，用ZXID表示，通常是一个64位的数字。每一个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出ZooKeeper处理这些事务操作请求的全局顺序。</p>\n<h3 id=\"Watcher\"><a href=\"#Watcher\" class=\"headerlink\" title=\"Watcher\"></a>Watcher</h3><p>ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去。该机制是 ZooKeeper 实现分布式协调服务的重要特性。</p>\n<h3 id=\"ACL\"><a href=\"#ACL\" class=\"headerlink\" title=\"ACL\"></a>ACL</h3><p>ZooKeeper 采用 Access Control Lists 策略来进行权限控制。ZooKeeper 定义了如下5种权限。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE: 创建子节点的权限。</span><br><span class=\"line\">READ: 获取节点数据和子节点列表的权限。</span><br><span class=\"line\">WRITE：更新节点数据的权限。</span><br><span class=\"line\">DELETE: 删除子节点的权限。</span><br><span class=\"line\">ADMIN: 设置节点ACL的权限。</span><br><span class=\"line\">注意：CREATE 和 DELETE 都是针对子节点的权限控制。</span><br></pre></td></tr></table></figure>\n<h3 id=\"ZAB-原子广播协议\"><a href=\"#ZAB-原子广播协议\" class=\"headerlink\" title=\"ZAB 原子广播协议\"></a>ZAB 原子广播协议</h3><p>ZooKeeper Atomic Broadcast（ZAB，ZooKeeper原子广播协议）的协议作为其数据一致性的核心算法。</p>\n<p>所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，而剩下的其他服务器则成为 Follower 服务器。Leader 服务器负责将一个客户端事务请求转换成一个事务 Proposal（提案）并将该 Proposal分发给集群中所有的 Follower 服务器。之后 Leader 服务器需要等待所有 Follower 服务器的反馈，一旦超过半数的 Follower 服务器进行了正确的反馈后，Leader 就会再次向所有的 Follower 服务器分发 Commit 消息，要求对刚才的 Proposal 进行提交。</p>\n<h3 id=\"应用场景\"><a href=\"#应用场景\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h3><ul>\n<li>数据发布与订阅-配置中心</li>\n</ul>\n<p>发布者将数据发布到 ZooKeeper 节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中式管理和动态更新。全局配置信息就可以发布到 ZooKeeper 上，让客户端（集群的机器）去订阅该消息。</p>\n<p>客户端想服务端注册自己需要关注的节点，一旦该节点的数据发生变更，那么服务端就会向相应的客户端发送 Watcher 事件通知，客户端接收到这个消息通知后，需要主动到服务端获取最新的数据（推拉结合）。</p>\n<ul>\n<li><p>命名服务，即生成全局唯一的ID。</p>\n</li>\n<li><p>分布式协调通知</p>\n</li>\n</ul>\n<p>ZooKeeper 中特有 Watcher 注册与异步通知机制，实现对数据变更的实时处理。不同的客户端都对ZK上同一个ZNode 进行注册，监听 ZNode 的变化（包括ZNode本身内容及子节点的），如果 ZNode 发生了变化，那么所有订阅的客户端都能够接收到相应的 Watcher 通知，并做出相应的处理，是一种通用的分布式系统机器间的通信方式。</p>\n<ul>\n<li>心跳检测</li>\n</ul>\n<p>基于 ZK 临时节点的特性，可以让不同的进程都在 ZK 的一个指定节点下创建临时子节点，不同的进程直接可以根据这个临时子节点来判断对应的进程是否存活。通过这种方式，检测和被检测系统直接并不需要直接相关联，而是通过 ZK 上的某个节点进行关联，大大减少了系统耦合。</p>\n<ul>\n<li>分布式锁</li>\n</ul>\n<p>分布式锁是控制分布式系统之间同步访问共享资源的一种方式。分布式锁又分为排他锁和共享锁两种。 排他锁又称为写锁或独占锁，共享锁又称为读锁。</p>\n<p>把 ZooKeeper 上一个 ZNode 看作是一个锁，获得锁就通过创建ZNode的方式来实现。所有客户端都去/x_lock节点下创建临时子节点/x_lock/lock。ZooKeeper会保证在所有客户端中，最终只有一个客户端能够创建成功，那么就可以认为该客户端获得了锁。同时，所有没有获取到锁的客户端就需要到/x_lock节点上注册一个子节点变更的 Watcher 监听，以便实时监听到 lock 节点的变更情况。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>ZooKeeper 是一个开源的分布式协调服务，是分布式数据一致性的解决方案。</p>\n<h3 id=\"集群角色\"><a href=\"#集群角色\" class=\"headerlink\" title=\"集群角色\"></a>集群角色</h3><p>在 ZooKeeper 中，有三种角色： Leader，Follower，Observer</p>\n<p>一个 ZooKeeper 集群同时只会有一个Leader，其他都是 Follower 或 Observer。<br>Leader 服务器为客户端提供读和写服务，Follower 和 Observer 都能提供读服务，不能提供写服务。区别在于，Observer 不参与 Leader 选举过程，也不参与写操作的过半写成功策略，因此 Observer 可以在不影响写性能的情况下提升集群的读性能。</p>\n<h3 id=\"会话\"><a href=\"#会话\" class=\"headerlink\" title=\"会话\"></a>会话</h3><p>客户端和 ZooKeeper 服务器会与服务器建立一个 TCP 连接，通过这个连接，客户端能够通过心跳检测和服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能通过该连接接收来自服务器的 Watch 事件通知。</p>\n<h3 id=\"数据节点\"><a href=\"#数据节点\" class=\"headerlink\" title=\"数据节点\"></a>数据节点</h3><p>ZooKeeper 中的数据节点是指数据模型中的数据单元，称为 ZNode。ZooKeeper将所有数据存储在内存中，数据模型是一棵树（ZNode Tree），由斜杠进行分割的路径，就是一个ZNode。每个ZNode上都会保存自己的数据内容，同时会保存一系列属性信息。每个ZNode不仅本身可以写数据，还可以有下一级文件或目录。</p>\n<p>在ZooKeeper中，ZNode可以分为持久节点和临时节点两类。持久节点是指一旦这个 ZNode 被创建了，除非主动进行 ZNode 的移除操作，否则这个 ZNode 将一直保存在 ZooKeeper上。临时节点的生命周期跟客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。</p>\n<p>ZooKeeper 允许用户为每个节点添加一个特殊的属性：SEQUENTIAL。一旦节点被标记上这个属性，那么在这个节点被创建的时候，ZooKeeper就会自动在其节点后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。</p>\n<h3 id=\"版本\"><a href=\"#版本\" class=\"headerlink\" title=\"版本\"></a>版本</h3><p>ZooKeeper 的每个 ZNode 上都会存储数据，对于每个ZNode，ZooKeeper都会为其维护一个叫作Stat的数据结构，Stat中记录了这个ZNode的三个数据版本，分别是 version（当前ZNode的版本, cversion（当前ZNode子节点的版本）和 aversion（当前ZNode的ACL版本）。</p>\n<h3 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h3><p>在 ZooKeeper 中，能改变 ZooKeeper 服务器状态的操作称为事务操作。包括数据节点创建与删除、数据内容更新和客户端会话创建与失效等操作。对应每一个事务请求，ZooKeeper都会为其分配一个全局唯一的事务ID，用ZXID表示，通常是一个64位的数字。每一个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出ZooKeeper处理这些事务操作请求的全局顺序。</p>\n<h3 id=\"Watcher\"><a href=\"#Watcher\" class=\"headerlink\" title=\"Watcher\"></a>Watcher</h3><p>ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去。该机制是 ZooKeeper 实现分布式协调服务的重要特性。</p>\n<h3 id=\"ACL\"><a href=\"#ACL\" class=\"headerlink\" title=\"ACL\"></a>ACL</h3><p>ZooKeeper 采用 Access Control Lists 策略来进行权限控制。ZooKeeper 定义了如下5种权限。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE: 创建子节点的权限。</span><br><span class=\"line\">READ: 获取节点数据和子节点列表的权限。</span><br><span class=\"line\">WRITE：更新节点数据的权限。</span><br><span class=\"line\">DELETE: 删除子节点的权限。</span><br><span class=\"line\">ADMIN: 设置节点ACL的权限。</span><br><span class=\"line\">注意：CREATE 和 DELETE 都是针对子节点的权限控制。</span><br></pre></td></tr></table></figure>\n<h3 id=\"ZAB-原子广播协议\"><a href=\"#ZAB-原子广播协议\" class=\"headerlink\" title=\"ZAB 原子广播协议\"></a>ZAB 原子广播协议</h3><p>ZooKeeper Atomic Broadcast（ZAB，ZooKeeper原子广播协议）的协议作为其数据一致性的核心算法。</p>\n<p>所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，而剩下的其他服务器则成为 Follower 服务器。Leader 服务器负责将一个客户端事务请求转换成一个事务 Proposal（提案）并将该 Proposal分发给集群中所有的 Follower 服务器。之后 Leader 服务器需要等待所有 Follower 服务器的反馈，一旦超过半数的 Follower 服务器进行了正确的反馈后，Leader 就会再次向所有的 Follower 服务器分发 Commit 消息，要求对刚才的 Proposal 进行提交。</p>\n<h3 id=\"应用场景\"><a href=\"#应用场景\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h3><ul>\n<li>数据发布与订阅-配置中心</li>\n</ul>\n<p>发布者将数据发布到 ZooKeeper 节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中式管理和动态更新。全局配置信息就可以发布到 ZooKeeper 上，让客户端（集群的机器）去订阅该消息。</p>\n<p>客户端想服务端注册自己需要关注的节点，一旦该节点的数据发生变更，那么服务端就会向相应的客户端发送 Watcher 事件通知，客户端接收到这个消息通知后，需要主动到服务端获取最新的数据（推拉结合）。</p>\n<ul>\n<li><p>命名服务，即生成全局唯一的ID。</p>\n</li>\n<li><p>分布式协调通知</p>\n</li>\n</ul>\n<p>ZooKeeper 中特有 Watcher 注册与异步通知机制，实现对数据变更的实时处理。不同的客户端都对ZK上同一个ZNode 进行注册，监听 ZNode 的变化（包括ZNode本身内容及子节点的），如果 ZNode 发生了变化，那么所有订阅的客户端都能够接收到相应的 Watcher 通知，并做出相应的处理，是一种通用的分布式系统机器间的通信方式。</p>\n<ul>\n<li>心跳检测</li>\n</ul>\n<p>基于 ZK 临时节点的特性，可以让不同的进程都在 ZK 的一个指定节点下创建临时子节点，不同的进程直接可以根据这个临时子节点来判断对应的进程是否存活。通过这种方式，检测和被检测系统直接并不需要直接相关联，而是通过 ZK 上的某个节点进行关联，大大减少了系统耦合。</p>\n<ul>\n<li>分布式锁</li>\n</ul>\n<p>分布式锁是控制分布式系统之间同步访问共享资源的一种方式。分布式锁又分为排他锁和共享锁两种。 排他锁又称为写锁或独占锁，共享锁又称为读锁。</p>\n<p>把 ZooKeeper 上一个 ZNode 看作是一个锁，获得锁就通过创建ZNode的方式来实现。所有客户端都去/x_lock节点下创建临时子节点/x_lock/lock。ZooKeeper会保证在所有客户端中，最终只有一个客户端能够创建成功，那么就可以认为该客户端获得了锁。同时，所有没有获取到锁的客户端就需要到/x_lock节点上注册一个子节点变更的 Watcher 监听，以便实时监听到 lock 节点的变更情况。</p>\n"},{"layout":"post","title":"双端链表","date":"2017-05-29T15:19:00.000Z","comments":1,"description":"双端链表","_content":"\nNginx, Redis 项目中，均使用上了双链表。\n\n* 列表类型的键进行操作(RPUSH, LPOP)时，程序底层操作用的是双端链表。 [源码](https://github.com/antirez/redis/blob/unstable/src/adlist.c)\n\n* Nginx 典型应用是在连接池中。Nginx 会处理大量的 socket 连接，为提高并发处理链接的能力，引入了连接池，其实现这个连接池用到了双链表。[源码](https://github.com/nginx/nginx/blob/master/src/core/ngx_queue.c).\n\n对于双端链表，教科书上曾有提及，但如今映像并不深刻，再度理解并实践一次。\n\n### 结构定义与初始化\n\n```c\ntypedef struct Node {\n    int num;\n    struct Node * next; //前继指针\n    struct Node * pre;  //后继指针\n} Node;\n\ntypedef struct dlist {\n    Node * head; //双链表的指向头结点的元素\n    Node * tail; //双链表指向尾部节点的元素，方便从后检索\n} dlist;\n```\n\n初始化的双链表，`head`,`tail` 均为空。\n\n### 插入操作\n\n插入操作，是按照递增的顺序插入，涉及到双链表的更改，因此传参是指向链表的指针，分三种情况\n\n* 空链表插入头元素，head 与 tail 节点均要修改\n* 在链表尾部插入节点，要变动 tail 指针\n* 中间插入节点\n\n{% img /images/2017/05/dlist-insert.png %}\n\n```c\nstatic int insertDlist(dlist **list, int num) {\n    Node * head = (*list) -> head;\n    Node * tail = (*list) -> tail;\n\n    if (list == NULL) return -1;\n\n    Node * node = initNode(num);\n    if (node == NULL) return -1;\n\n    // empty dlist\n    if ((*list) -> head == NULL && (*list) -> tail == NULL) {\n        (*list)-> head = node;\n        (*list)-> tail = node;\n        return 0;\n    }\n\n    while (head -> next && head -> num < num) {\n        head = head -> next;\n    }\n\n    // at the end\n    if (head->next == NULL) {\n        head -> next = node;\n        node -> pre = head;\n        tail -> pre = node;\n        return 0;\n    } else {\n        // in the middle\n        node-> next = head -> next;\n        head -> next -> pre = node;\n        node -> pre = head;\n        head -> next = node;\n        return 0;\n    }\n}\n\n```\n\n### 删除操作\n\n删除操作，要涉及到双链表的更改，因此传参是指向链表的指针，分三种情况\n\n* 删除头结点，\n* 删除尾节点\n* 删除中间节点\n\n{% img /images/2017/05/dlist-delete.png %}\n\n```c\nstatic int deleteDlist(dlist ** list, int location) {\n    Node * head = (*list) -> head;\n    Node * now = NULL;\n    Node * last = NULL;\n\n    if (head == NULL)\n        return -1;\n    if (location <= 0 || location > numOfDlist(*list))\n        return -1;\n\n    if (location == 1) {\n        now = head;\n        (*list) -> head = now ->next;\n        head -> next ->pre = NULL;\n        if (now) {\n            free(now);\n            now = NULL;\n        }\n        return 0;\n    }\n    int num = 0;\n    while (head && num++ < location) {\n        head = head -> next;\n    }\n\n    if (head -> next == NULL) {\n        now = (*list) -> tail;\n        head -> pre -> next = NULL;\n        now -> pre = head->pre;\n        if (head) {\n            free(head);\n            head = NULL;\n        }\n    } else {\n        now = head -> next;\n        last = head -> pre;\n        now ->pre = head -> pre;\n        last -> next = head ->next;\n        if (head) {\n            free(head);\n            head = NULL;\n        }\n    }\n    return 0;\n}\n```\n\n本文所述是 C 语言实现的，[源码](https://github.com/zheng-ji/ToyCollection/blob/master/Dlist/mydlist.c)\n在 Go 语言之中, `container/list` 包实现了双链表，直接引入就可以使用了。\n","source":"_posts/2017-05-29-shuang-duan-lian-biao.markdown","raw":"---\nlayout: post\ntitle: \"双端链表\"\ndate: 2017-05-29 23:19\ncomments: true\ncategories: Programe\ndescription: 双端链表\n---\n\nNginx, Redis 项目中，均使用上了双链表。\n\n* 列表类型的键进行操作(RPUSH, LPOP)时，程序底层操作用的是双端链表。 [源码](https://github.com/antirez/redis/blob/unstable/src/adlist.c)\n\n* Nginx 典型应用是在连接池中。Nginx 会处理大量的 socket 连接，为提高并发处理链接的能力，引入了连接池，其实现这个连接池用到了双链表。[源码](https://github.com/nginx/nginx/blob/master/src/core/ngx_queue.c).\n\n对于双端链表，教科书上曾有提及，但如今映像并不深刻，再度理解并实践一次。\n\n### 结构定义与初始化\n\n```c\ntypedef struct Node {\n    int num;\n    struct Node * next; //前继指针\n    struct Node * pre;  //后继指针\n} Node;\n\ntypedef struct dlist {\n    Node * head; //双链表的指向头结点的元素\n    Node * tail; //双链表指向尾部节点的元素，方便从后检索\n} dlist;\n```\n\n初始化的双链表，`head`,`tail` 均为空。\n\n### 插入操作\n\n插入操作，是按照递增的顺序插入，涉及到双链表的更改，因此传参是指向链表的指针，分三种情况\n\n* 空链表插入头元素，head 与 tail 节点均要修改\n* 在链表尾部插入节点，要变动 tail 指针\n* 中间插入节点\n\n{% img /images/2017/05/dlist-insert.png %}\n\n```c\nstatic int insertDlist(dlist **list, int num) {\n    Node * head = (*list) -> head;\n    Node * tail = (*list) -> tail;\n\n    if (list == NULL) return -1;\n\n    Node * node = initNode(num);\n    if (node == NULL) return -1;\n\n    // empty dlist\n    if ((*list) -> head == NULL && (*list) -> tail == NULL) {\n        (*list)-> head = node;\n        (*list)-> tail = node;\n        return 0;\n    }\n\n    while (head -> next && head -> num < num) {\n        head = head -> next;\n    }\n\n    // at the end\n    if (head->next == NULL) {\n        head -> next = node;\n        node -> pre = head;\n        tail -> pre = node;\n        return 0;\n    } else {\n        // in the middle\n        node-> next = head -> next;\n        head -> next -> pre = node;\n        node -> pre = head;\n        head -> next = node;\n        return 0;\n    }\n}\n\n```\n\n### 删除操作\n\n删除操作，要涉及到双链表的更改，因此传参是指向链表的指针，分三种情况\n\n* 删除头结点，\n* 删除尾节点\n* 删除中间节点\n\n{% img /images/2017/05/dlist-delete.png %}\n\n```c\nstatic int deleteDlist(dlist ** list, int location) {\n    Node * head = (*list) -> head;\n    Node * now = NULL;\n    Node * last = NULL;\n\n    if (head == NULL)\n        return -1;\n    if (location <= 0 || location > numOfDlist(*list))\n        return -1;\n\n    if (location == 1) {\n        now = head;\n        (*list) -> head = now ->next;\n        head -> next ->pre = NULL;\n        if (now) {\n            free(now);\n            now = NULL;\n        }\n        return 0;\n    }\n    int num = 0;\n    while (head && num++ < location) {\n        head = head -> next;\n    }\n\n    if (head -> next == NULL) {\n        now = (*list) -> tail;\n        head -> pre -> next = NULL;\n        now -> pre = head->pre;\n        if (head) {\n            free(head);\n            head = NULL;\n        }\n    } else {\n        now = head -> next;\n        last = head -> pre;\n        now ->pre = head -> pre;\n        last -> next = head ->next;\n        if (head) {\n            free(head);\n            head = NULL;\n        }\n    }\n    return 0;\n}\n```\n\n本文所述是 C 语言实现的，[源码](https://github.com/zheng-ji/ToyCollection/blob/master/Dlist/mydlist.c)\n在 Go 语言之中, `container/list` 包实现了双链表，直接引入就可以使用了。\n","slug":"2017-05-29-shuang-duan-lian-biao","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdar0050nctj1md4okoi","content":"<p>Nginx, Redis 项目中，均使用上了双链表。</p>\n<ul>\n<li><p>列表类型的键进行操作(RPUSH, LPOP)时，程序底层操作用的是双端链表。 <a href=\"https://github.com/antirez/redis/blob/unstable/src/adlist.c\" target=\"_blank\" rel=\"noopener\">源码</a></p>\n</li>\n<li><p>Nginx 典型应用是在连接池中。Nginx 会处理大量的 socket 连接，为提高并发处理链接的能力，引入了连接池，其实现这个连接池用到了双链表。<a href=\"https://github.com/nginx/nginx/blob/master/src/core/ngx_queue.c\" target=\"_blank\" rel=\"noopener\">源码</a>.</p>\n</li>\n</ul>\n<p>对于双端链表，教科书上曾有提及，但如今映像并不深刻，再度理解并实践一次。</p>\n<h3 id=\"结构定义与初始化\"><a href=\"#结构定义与初始化\" class=\"headerlink\" title=\"结构定义与初始化\"></a>结构定义与初始化</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span> &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> num;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span> * <span class=\"title\">next</span>;</span> <span class=\"comment\">//前继指针</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span> * <span class=\"title\">pre</span>;</span>  <span class=\"comment\">//后继指针</span></span><br><span class=\"line\">&#125; Node;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dlist</span> &#123;</span></span><br><span class=\"line\">    Node * head; <span class=\"comment\">//双链表的指向头结点的元素</span></span><br><span class=\"line\">    Node * tail; <span class=\"comment\">//双链表指向尾部节点的元素，方便从后检索</span></span><br><span class=\"line\">&#125; dlist;</span><br></pre></td></tr></table></figure>\n<p>初始化的双链表，<code>head</code>,<code>tail</code> 均为空。</p>\n<h3 id=\"插入操作\"><a href=\"#插入操作\" class=\"headerlink\" title=\"插入操作\"></a>插入操作</h3><p>插入操作，是按照递增的顺序插入，涉及到双链表的更改，因此传参是指向链表的指针，分三种情况</p>\n<ul>\n<li>空链表插入头元素，head 与 tail 节点均要修改</li>\n<li>在链表尾部插入节点，要变动 tail 指针</li>\n<li>中间插入节点</li>\n</ul>\n<img src=\"/images/2017/05/dlist-insert.png\">\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">int</span> <span class=\"title\">insertDlist</span><span class=\"params\">(dlist **<span class=\"built_in\">list</span>, <span class=\"keyword\">int</span> num)</span> </span>&#123;</span><br><span class=\"line\">    Node * head = (*<span class=\"built_in\">list</span>) -&gt; head;</span><br><span class=\"line\">    Node * tail = (*<span class=\"built_in\">list</span>) -&gt; tail;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">list</span> == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    Node * node = initNode(num);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (node == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// empty dlist</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((*<span class=\"built_in\">list</span>) -&gt; head == <span class=\"literal\">NULL</span> &amp;&amp; (*<span class=\"built_in\">list</span>) -&gt; tail == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        (*<span class=\"built_in\">list</span>)-&gt; head = node;</span><br><span class=\"line\">        (*<span class=\"built_in\">list</span>)-&gt; tail = node;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (head -&gt; next &amp;&amp; head -&gt; num &lt; num) &#123;</span><br><span class=\"line\">        head = head -&gt; next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// at the end</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (head-&gt;next == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        head -&gt; next = node;</span><br><span class=\"line\">        node -&gt; pre = head;</span><br><span class=\"line\">        tail -&gt; pre = node;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// in the middle</span></span><br><span class=\"line\">        node-&gt; next = head -&gt; next;</span><br><span class=\"line\">        head -&gt; next -&gt; pre = node;</span><br><span class=\"line\">        node -&gt; pre = head;</span><br><span class=\"line\">        head -&gt; next = node;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"删除操作\"><a href=\"#删除操作\" class=\"headerlink\" title=\"删除操作\"></a>删除操作</h3><p>删除操作，要涉及到双链表的更改，因此传参是指向链表的指针，分三种情况</p>\n<ul>\n<li>删除头结点，</li>\n<li>删除尾节点</li>\n<li>删除中间节点</li>\n</ul>\n<img src=\"/images/2017/05/dlist-delete.png\">\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">int</span> <span class=\"title\">deleteDlist</span><span class=\"params\">(dlist ** <span class=\"built_in\">list</span>, <span class=\"keyword\">int</span> location)</span> </span>&#123;</span><br><span class=\"line\">    Node * head = (*<span class=\"built_in\">list</span>) -&gt; head;</span><br><span class=\"line\">    Node * now = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    Node * last = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (head == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (location &lt;= <span class=\"number\">0</span> || location &gt; numOfDlist(*<span class=\"built_in\">list</span>))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (location == <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">        now = head;</span><br><span class=\"line\">        (*<span class=\"built_in\">list</span>) -&gt; head = now -&gt;next;</span><br><span class=\"line\">        head -&gt; next -&gt;pre = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (now) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">free</span>(now);</span><br><span class=\"line\">            now = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> num = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (head &amp;&amp; num++ &lt; location) &#123;</span><br><span class=\"line\">        head = head -&gt; next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (head -&gt; next == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        now = (*<span class=\"built_in\">list</span>) -&gt; tail;</span><br><span class=\"line\">        head -&gt; pre -&gt; next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        now -&gt; pre = head-&gt;pre;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (head) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">free</span>(head);</span><br><span class=\"line\">            head = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        now = head -&gt; next;</span><br><span class=\"line\">        last = head -&gt; pre;</span><br><span class=\"line\">        now -&gt;pre = head -&gt; pre;</span><br><span class=\"line\">        last -&gt; next = head -&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (head) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">free</span>(head);</span><br><span class=\"line\">            head = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>本文所述是 C 语言实现的，<a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/Dlist/mydlist.c\" target=\"_blank\" rel=\"noopener\">源码</a><br>在 Go 语言之中, <code>container/list</code> 包实现了双链表，直接引入就可以使用了。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Nginx, Redis 项目中，均使用上了双链表。</p>\n<ul>\n<li><p>列表类型的键进行操作(RPUSH, LPOP)时，程序底层操作用的是双端链表。 <a href=\"https://github.com/antirez/redis/blob/unstable/src/adlist.c\" target=\"_blank\" rel=\"noopener\">源码</a></p>\n</li>\n<li><p>Nginx 典型应用是在连接池中。Nginx 会处理大量的 socket 连接，为提高并发处理链接的能力，引入了连接池，其实现这个连接池用到了双链表。<a href=\"https://github.com/nginx/nginx/blob/master/src/core/ngx_queue.c\" target=\"_blank\" rel=\"noopener\">源码</a>.</p>\n</li>\n</ul>\n<p>对于双端链表，教科书上曾有提及，但如今映像并不深刻，再度理解并实践一次。</p>\n<h3 id=\"结构定义与初始化\"><a href=\"#结构定义与初始化\" class=\"headerlink\" title=\"结构定义与初始化\"></a>结构定义与初始化</h3><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span> &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> num;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span> * <span class=\"title\">next</span>;</span> <span class=\"comment\">//前继指针</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span> * <span class=\"title\">pre</span>;</span>  <span class=\"comment\">//后继指针</span></span><br><span class=\"line\">&#125; Node;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">dlist</span> &#123;</span></span><br><span class=\"line\">    Node * head; <span class=\"comment\">//双链表的指向头结点的元素</span></span><br><span class=\"line\">    Node * tail; <span class=\"comment\">//双链表指向尾部节点的元素，方便从后检索</span></span><br><span class=\"line\">&#125; dlist;</span><br></pre></td></tr></table></figure>\n<p>初始化的双链表，<code>head</code>,<code>tail</code> 均为空。</p>\n<h3 id=\"插入操作\"><a href=\"#插入操作\" class=\"headerlink\" title=\"插入操作\"></a>插入操作</h3><p>插入操作，是按照递增的顺序插入，涉及到双链表的更改，因此传参是指向链表的指针，分三种情况</p>\n<ul>\n<li>空链表插入头元素，head 与 tail 节点均要修改</li>\n<li>在链表尾部插入节点，要变动 tail 指针</li>\n<li>中间插入节点</li>\n</ul>\n<img src=\"/images/2017/05/dlist-insert.png\">\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">int</span> <span class=\"title\">insertDlist</span><span class=\"params\">(dlist **<span class=\"built_in\">list</span>, <span class=\"keyword\">int</span> num)</span> </span>&#123;</span><br><span class=\"line\">    Node * head = (*<span class=\"built_in\">list</span>) -&gt; head;</span><br><span class=\"line\">    Node * tail = (*<span class=\"built_in\">list</span>) -&gt; tail;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">list</span> == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    Node * node = initNode(num);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (node == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// empty dlist</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((*<span class=\"built_in\">list</span>) -&gt; head == <span class=\"literal\">NULL</span> &amp;&amp; (*<span class=\"built_in\">list</span>) -&gt; tail == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        (*<span class=\"built_in\">list</span>)-&gt; head = node;</span><br><span class=\"line\">        (*<span class=\"built_in\">list</span>)-&gt; tail = node;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (head -&gt; next &amp;&amp; head -&gt; num &lt; num) &#123;</span><br><span class=\"line\">        head = head -&gt; next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// at the end</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (head-&gt;next == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        head -&gt; next = node;</span><br><span class=\"line\">        node -&gt; pre = head;</span><br><span class=\"line\">        tail -&gt; pre = node;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// in the middle</span></span><br><span class=\"line\">        node-&gt; next = head -&gt; next;</span><br><span class=\"line\">        head -&gt; next -&gt; pre = node;</span><br><span class=\"line\">        node -&gt; pre = head;</span><br><span class=\"line\">        head -&gt; next = node;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"删除操作\"><a href=\"#删除操作\" class=\"headerlink\" title=\"删除操作\"></a>删除操作</h3><p>删除操作，要涉及到双链表的更改，因此传参是指向链表的指针，分三种情况</p>\n<ul>\n<li>删除头结点，</li>\n<li>删除尾节点</li>\n<li>删除中间节点</li>\n</ul>\n<img src=\"/images/2017/05/dlist-delete.png\">\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">int</span> <span class=\"title\">deleteDlist</span><span class=\"params\">(dlist ** <span class=\"built_in\">list</span>, <span class=\"keyword\">int</span> location)</span> </span>&#123;</span><br><span class=\"line\">    Node * head = (*<span class=\"built_in\">list</span>) -&gt; head;</span><br><span class=\"line\">    Node * now = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    Node * last = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (head == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (location &lt;= <span class=\"number\">0</span> || location &gt; numOfDlist(*<span class=\"built_in\">list</span>))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (location == <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">        now = head;</span><br><span class=\"line\">        (*<span class=\"built_in\">list</span>) -&gt; head = now -&gt;next;</span><br><span class=\"line\">        head -&gt; next -&gt;pre = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (now) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">free</span>(now);</span><br><span class=\"line\">            now = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> num = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (head &amp;&amp; num++ &lt; location) &#123;</span><br><span class=\"line\">        head = head -&gt; next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (head -&gt; next == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        now = (*<span class=\"built_in\">list</span>) -&gt; tail;</span><br><span class=\"line\">        head -&gt; pre -&gt; next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        now -&gt; pre = head-&gt;pre;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (head) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">free</span>(head);</span><br><span class=\"line\">            head = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        now = head -&gt; next;</span><br><span class=\"line\">        last = head -&gt; pre;</span><br><span class=\"line\">        now -&gt;pre = head -&gt; pre;</span><br><span class=\"line\">        last -&gt; next = head -&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (head) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">free</span>(head);</span><br><span class=\"line\">            head = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>本文所述是 C 语言实现的，<a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/Dlist/mydlist.c\" target=\"_blank\" rel=\"noopener\">源码</a><br>在 Go 语言之中, <code>container/list</code> 包实现了双链表，直接引入就可以使用了。</p>\n"},{"layout":"post","title":"MIT 6.824 MapReduce","date":"2017-06-04T05:27:00.000Z","comments":1,"description":"分布式，MapReduce","_content":"\n学习 MIT 6.824 [Lab1 MapReduce](http://nil.csail.mit.edu/6.824/2017/labs/lab-1.html)，做下笔记\n\n### MapReduce 的思路\n\n* 把数据分成 M 份，每一份叫做 Mi\n* 启动一个 master 对象，由它来控制如何分配调控\n* master 挑出一个 worker，对 Mi 执行 map 操作，返回一个 KV 数组\n* 然后把 KV 数组分成 nReduce 份存在本地，等待 Reduce 操作。当 map 全部完成后，每个 Mi 产生 nReduce 份结果，每一个叫做 Ri。文件名：mrtmp-JobName-Mi-Ri 其中Mi Ri 分别表示数字，因此这一步会产生 M * nReduce 份文件。\n* 从每个 Mi 中选择一份 Ri。然后根据 Key 排序，把相同 Key 的 Value 合在一起，生成 Key /list(value)\n* 开始 Reduce，输入list(value)，最后会生成 R 份文件 mrtmp.JobName-res-Ri\n* 最后 Merge 成一个文件。\n\n### 作业步骤\n\n* Part1 完成 doMap 和 doReduce。doMap 完成3，4两个步骤. doReduce 完成5，6两个步骤。\n* Part2 实现 main/wc.go 在Part1的基础上完成函数调用而已。\n* Part3 把 map 和 reduce 的操作变成异步。用到了RPC，用channel 来实现并发控制。\n\n### 代码笔记\n\n[源码](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce)\n\n* common.go [11-32行](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common.go#L11)：可变参数打印日志，这个方法与C语言常用的类似\n* common_reduce.go [Line75](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_reduce.go#L75)：sort.strings 对字符串切片排序\n* commo_rpc.go [Line59](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_rpc.go#L59)：rpc调用方法\n* master.go [Line95-99](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L95)：当mr.newCond.Broadcast()被调用，此处就被唤醒，否则一直阻塞,mr.wait()所在的逻辑分支才会被唤醒，否则继续阻塞\n* master.go [Line15-16](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L15)：匿名参数，表示 Master 具有sync.Mutex的接口, 因而 Master 也能调用sync.Mutex的函数. 所以当调用 master.Lock()的时候也不足为奇\n* master_rpc.go [Line14](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L14),[Line37](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L37)：chanel 被close的时候，case <- shutdown 也就被触发了 \n","source":"_posts/2017-06-04-mit-6-dot-824-mapreduce.markdown","raw":"---\nlayout: post\ntitle: \"MIT 6.824 MapReduce\"\ndate: 2017-06-04 13:27\ncomments: true\ncategories: Programe\ndescription: 分布式，MapReduce\n---\n\n学习 MIT 6.824 [Lab1 MapReduce](http://nil.csail.mit.edu/6.824/2017/labs/lab-1.html)，做下笔记\n\n### MapReduce 的思路\n\n* 把数据分成 M 份，每一份叫做 Mi\n* 启动一个 master 对象，由它来控制如何分配调控\n* master 挑出一个 worker，对 Mi 执行 map 操作，返回一个 KV 数组\n* 然后把 KV 数组分成 nReduce 份存在本地，等待 Reduce 操作。当 map 全部完成后，每个 Mi 产生 nReduce 份结果，每一个叫做 Ri。文件名：mrtmp-JobName-Mi-Ri 其中Mi Ri 分别表示数字，因此这一步会产生 M * nReduce 份文件。\n* 从每个 Mi 中选择一份 Ri。然后根据 Key 排序，把相同 Key 的 Value 合在一起，生成 Key /list(value)\n* 开始 Reduce，输入list(value)，最后会生成 R 份文件 mrtmp.JobName-res-Ri\n* 最后 Merge 成一个文件。\n\n### 作业步骤\n\n* Part1 完成 doMap 和 doReduce。doMap 完成3，4两个步骤. doReduce 完成5，6两个步骤。\n* Part2 实现 main/wc.go 在Part1的基础上完成函数调用而已。\n* Part3 把 map 和 reduce 的操作变成异步。用到了RPC，用channel 来实现并发控制。\n\n### 代码笔记\n\n[源码](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce)\n\n* common.go [11-32行](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common.go#L11)：可变参数打印日志，这个方法与C语言常用的类似\n* common_reduce.go [Line75](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_reduce.go#L75)：sort.strings 对字符串切片排序\n* commo_rpc.go [Line59](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_rpc.go#L59)：rpc调用方法\n* master.go [Line95-99](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L95)：当mr.newCond.Broadcast()被调用，此处就被唤醒，否则一直阻塞,mr.wait()所在的逻辑分支才会被唤醒，否则继续阻塞\n* master.go [Line15-16](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L15)：匿名参数，表示 Master 具有sync.Mutex的接口, 因而 Master 也能调用sync.Mutex的函数. 所以当调用 master.Lock()的时候也不足为奇\n* master_rpc.go [Line14](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L14),[Line37](https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L37)：chanel 被close的时候，case <- shutdown 也就被触发了 \n","slug":"2017-06-04-mit-6-dot-824-mapreduce","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdas0052nctj90u0pv8i","content":"<p>学习 MIT 6.824 <a href=\"http://nil.csail.mit.edu/6.824/2017/labs/lab-1.html\" target=\"_blank\" rel=\"noopener\">Lab1 MapReduce</a>，做下笔记</p>\n<h3 id=\"MapReduce-的思路\"><a href=\"#MapReduce-的思路\" class=\"headerlink\" title=\"MapReduce 的思路\"></a>MapReduce 的思路</h3><ul>\n<li>把数据分成 M 份，每一份叫做 Mi</li>\n<li>启动一个 master 对象，由它来控制如何分配调控</li>\n<li>master 挑出一个 worker，对 Mi 执行 map 操作，返回一个 KV 数组</li>\n<li>然后把 KV 数组分成 nReduce 份存在本地，等待 Reduce 操作。当 map 全部完成后，每个 Mi 产生 nReduce 份结果，每一个叫做 Ri。文件名：mrtmp-JobName-Mi-Ri 其中Mi Ri 分别表示数字，因此这一步会产生 M * nReduce 份文件。</li>\n<li>从每个 Mi 中选择一份 Ri。然后根据 Key 排序，把相同 Key 的 Value 合在一起，生成 Key /list(value)</li>\n<li>开始 Reduce，输入list(value)，最后会生成 R 份文件 mrtmp.JobName-res-Ri</li>\n<li>最后 Merge 成一个文件。</li>\n</ul>\n<h3 id=\"作业步骤\"><a href=\"#作业步骤\" class=\"headerlink\" title=\"作业步骤\"></a>作业步骤</h3><ul>\n<li>Part1 完成 doMap 和 doReduce。doMap 完成3，4两个步骤. doReduce 完成5，6两个步骤。</li>\n<li>Part2 实现 main/wc.go 在Part1的基础上完成函数调用而已。</li>\n<li>Part3 把 map 和 reduce 的操作变成异步。用到了RPC，用channel 来实现并发控制。</li>\n</ul>\n<h3 id=\"代码笔记\"><a href=\"#代码笔记\" class=\"headerlink\" title=\"代码笔记\"></a>代码笔记</h3><p><a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce\" target=\"_blank\" rel=\"noopener\">源码</a></p>\n<ul>\n<li>common.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common.go#L11\" target=\"_blank\" rel=\"noopener\">11-32行</a>：可变参数打印日志，这个方法与C语言常用的类似</li>\n<li>common_reduce.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_reduce.go#L75\" target=\"_blank\" rel=\"noopener\">Line75</a>：sort.strings 对字符串切片排序</li>\n<li>commo_rpc.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_rpc.go#L59\" target=\"_blank\" rel=\"noopener\">Line59</a>：rpc调用方法</li>\n<li>master.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L95\" target=\"_blank\" rel=\"noopener\">Line95-99</a>：当mr.newCond.Broadcast()被调用，此处就被唤醒，否则一直阻塞,mr.wait()所在的逻辑分支才会被唤醒，否则继续阻塞</li>\n<li>master.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L15\" target=\"_blank\" rel=\"noopener\">Line15-16</a>：匿名参数，表示 Master 具有sync.Mutex的接口, 因而 Master 也能调用sync.Mutex的函数. 所以当调用 master.Lock()的时候也不足为奇</li>\n<li>master_rpc.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L14\" target=\"_blank\" rel=\"noopener\">Line14</a>,<a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L37\" target=\"_blank\" rel=\"noopener\">Line37</a>：chanel 被close的时候，case &lt;- shutdown 也就被触发了 </li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>学习 MIT 6.824 <a href=\"http://nil.csail.mit.edu/6.824/2017/labs/lab-1.html\" target=\"_blank\" rel=\"noopener\">Lab1 MapReduce</a>，做下笔记</p>\n<h3 id=\"MapReduce-的思路\"><a href=\"#MapReduce-的思路\" class=\"headerlink\" title=\"MapReduce 的思路\"></a>MapReduce 的思路</h3><ul>\n<li>把数据分成 M 份，每一份叫做 Mi</li>\n<li>启动一个 master 对象，由它来控制如何分配调控</li>\n<li>master 挑出一个 worker，对 Mi 执行 map 操作，返回一个 KV 数组</li>\n<li>然后把 KV 数组分成 nReduce 份存在本地，等待 Reduce 操作。当 map 全部完成后，每个 Mi 产生 nReduce 份结果，每一个叫做 Ri。文件名：mrtmp-JobName-Mi-Ri 其中Mi Ri 分别表示数字，因此这一步会产生 M * nReduce 份文件。</li>\n<li>从每个 Mi 中选择一份 Ri。然后根据 Key 排序，把相同 Key 的 Value 合在一起，生成 Key /list(value)</li>\n<li>开始 Reduce，输入list(value)，最后会生成 R 份文件 mrtmp.JobName-res-Ri</li>\n<li>最后 Merge 成一个文件。</li>\n</ul>\n<h3 id=\"作业步骤\"><a href=\"#作业步骤\" class=\"headerlink\" title=\"作业步骤\"></a>作业步骤</h3><ul>\n<li>Part1 完成 doMap 和 doReduce。doMap 完成3，4两个步骤. doReduce 完成5，6两个步骤。</li>\n<li>Part2 实现 main/wc.go 在Part1的基础上完成函数调用而已。</li>\n<li>Part3 把 map 和 reduce 的操作变成异步。用到了RPC，用channel 来实现并发控制。</li>\n</ul>\n<h3 id=\"代码笔记\"><a href=\"#代码笔记\" class=\"headerlink\" title=\"代码笔记\"></a>代码笔记</h3><p><a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce\" target=\"_blank\" rel=\"noopener\">源码</a></p>\n<ul>\n<li>common.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common.go#L11\" target=\"_blank\" rel=\"noopener\">11-32行</a>：可变参数打印日志，这个方法与C语言常用的类似</li>\n<li>common_reduce.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_reduce.go#L75\" target=\"_blank\" rel=\"noopener\">Line75</a>：sort.strings 对字符串切片排序</li>\n<li>commo_rpc.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/common_rpc.go#L59\" target=\"_blank\" rel=\"noopener\">Line59</a>：rpc调用方法</li>\n<li>master.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L95\" target=\"_blank\" rel=\"noopener\">Line95-99</a>：当mr.newCond.Broadcast()被调用，此处就被唤醒，否则一直阻塞,mr.wait()所在的逻辑分支才会被唤醒，否则继续阻塞</li>\n<li>master.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master.go#L15\" target=\"_blank\" rel=\"noopener\">Line15-16</a>：匿名参数，表示 Master 具有sync.Mutex的接口, 因而 Master 也能调用sync.Mutex的函数. 所以当调用 master.Lock()的时候也不足为奇</li>\n<li>master_rpc.go <a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L14\" target=\"_blank\" rel=\"noopener\">Line14</a>,<a href=\"https://github.com/zheng-ji/ToyCollection/blob/master/6.824-golabs-2017/src/mapreduce/master_rpc.go#L37\" target=\"_blank\" rel=\"noopener\">Line37</a>：chanel 被close的时候，case &lt;- shutdown 也就被触发了 </li>\n</ul>\n"},{"layout":"post","title":"HTTPServer 优雅关闭","date":"2017-07-13T01:04:00.000Z","comments":1,"description":"graceful shutdown","_content":"\n和同事聊到了服务在需要关闭的时候该如何优雅退出，顺藤摸瓜挖掘了Go1.8的特性。Go 1.8起新增了优雅退出 HTTPServer 的特性，也就是大家经常提到的 GraceFul ShutDown。\n\n```go\n// src/net/http/server.go\n// Shutdown gracefully shuts down the server without interrupting any active connections. Shutdown works by first closing all open listeners, then closing all idle connections, and then waiting indefinitely for connections to return to idle and then shut down. If the provided context expires before the shutdown is complete, then the context's error is returned.\n\nfunc (srv *Server) Shutdown(ctx context.Context) error {\n    atomic.AddInt32(&srv.inShutdown, 1)\n    defer atomic.AddInt32(&srv.inShutdown, -1)\n\n    srv.mu.Lock()\n    lnerr := srv.closeListenersLocked()\n    srv.closeDoneChanLocked()\n    srv.mu.Unlock()\n\n    ticker := time.NewTicker(shutdownPollInterval)\n    defer ticker.Stop()\n    for {\n        if srv.closeIdleConns() {\n            return lnerr\n        }\n        select {\n        case <-ctx.Done():\n            return ctx.Err()\n        case <-ticker.C:\n        }\n    }\n}\n```\n\n\n从文档注释得知，server.Shutdown 首先关闭所有 active 的 listener，以及所有处于 idle 状态的 Connections，然后无限等待那些处于 active 状态的 connection 变为 idle 状态后，关闭他们，Server退出。\n\n如果有一个 Connection 依然处于 active 状态，那么 server 将一直 block 在那里。\nShutdown 接受一个 Context 参数，调用者可以通过 Context 传入一个等待的超时时间。\n一旦超时，Shutdown 将直接返回。对于仍然处理 active 状态的Connection，就无能为力了。\n所以 Shutdown 超时时间尽量要比链接处理的时间长。\n\n了解完原理，我们用例子来感受一下这个特性。\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/signal\"\n\t\"time\"\n\t\"github.com/gin-gonic/gin\"\n)\n\nfunc main() {\n\trouter := gin.Default()\n\trouter.GET(\"/\", func(c *gin.Context) {\n\t\ttime.Sleep(3 * time.Second)\n\t\tlog.Printf(http.StatusOK, \"Handle request success\")\n\t})\n\n\tsrv := &http.Server{\n\t\tAddr:    \":8080\",\n\t\tHandler: router,\n\t}\n\n\tgo func() {\n\t\tif err := srv.ListenAndServe(); err != nil {\n\t\t\tlog.Printf(\"listen: %s\\n\", err)\n\t\t}\n\t}()\n\n\tquit := make(chan os.Signal)\n\tsignal.Notify(quit, os.Interrupt)\n\t<-quit\n\tlog.Println(\"Shutdown Server ...\")\n\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\tif err := srv.Shutdown(ctx); err != nil {\n\t\tlog.Fatal(\"Server Shutdown:\", err)\n\t}\n\tlog.Println(\"Server exist\")\n}\n```\n\n代码中，每个请求都等待3秒才完成，使用信号来捕捉程序退出。退出时，HTTPServer 等待5秒来\"善后\"。我发起`curl localhost:8080`来测试，随即按下 Ctrl+C 退出程序，结果显示，服务器坚持在处理完这个 HTTP 请求才退出。\n\n```\n[GIN-debug] [WARNING] Running in \"debug\" mode. Switch to \"release\" mode in production.\n - using env:\texport GIN_MODE=release\n - using code:\tgin.SetMode(gin.ReleaseMode)\n\n[GIN-debug] GET    /                         --> main.main.func1 (3 handlers)\nHandle Request success\n[GIN] 2017/07/12 - 20:30:47 | 200 |  3.000385597s | 127.0.0.1 |   GET     /\n^C  //终端输入Ctrl+C\nShutdown Server ...\nlisten: http: Server closed\nHandle Request success //在接收到关闭信号时，依然保证正在处理的请求正常处理完\n[GIN] 2017/07/12 - 20:30:53 | 200 |  3.000360362s | 127.0.0.1 |   GET     /\nServer exist\n```\n","source":"_posts/2017-07-13-httpserver-graceful-shutdown-in-go.markdown","raw":"---\nlayout: post\ntitle: \"HTTPServer 优雅关闭\"\ndate: 2017-07-13 09:04\ncomments: true\ncategories: Programe\ndescription: graceful shutdown\n---\n\n和同事聊到了服务在需要关闭的时候该如何优雅退出，顺藤摸瓜挖掘了Go1.8的特性。Go 1.8起新增了优雅退出 HTTPServer 的特性，也就是大家经常提到的 GraceFul ShutDown。\n\n```go\n// src/net/http/server.go\n// Shutdown gracefully shuts down the server without interrupting any active connections. Shutdown works by first closing all open listeners, then closing all idle connections, and then waiting indefinitely for connections to return to idle and then shut down. If the provided context expires before the shutdown is complete, then the context's error is returned.\n\nfunc (srv *Server) Shutdown(ctx context.Context) error {\n    atomic.AddInt32(&srv.inShutdown, 1)\n    defer atomic.AddInt32(&srv.inShutdown, -1)\n\n    srv.mu.Lock()\n    lnerr := srv.closeListenersLocked()\n    srv.closeDoneChanLocked()\n    srv.mu.Unlock()\n\n    ticker := time.NewTicker(shutdownPollInterval)\n    defer ticker.Stop()\n    for {\n        if srv.closeIdleConns() {\n            return lnerr\n        }\n        select {\n        case <-ctx.Done():\n            return ctx.Err()\n        case <-ticker.C:\n        }\n    }\n}\n```\n\n\n从文档注释得知，server.Shutdown 首先关闭所有 active 的 listener，以及所有处于 idle 状态的 Connections，然后无限等待那些处于 active 状态的 connection 变为 idle 状态后，关闭他们，Server退出。\n\n如果有一个 Connection 依然处于 active 状态，那么 server 将一直 block 在那里。\nShutdown 接受一个 Context 参数，调用者可以通过 Context 传入一个等待的超时时间。\n一旦超时，Shutdown 将直接返回。对于仍然处理 active 状态的Connection，就无能为力了。\n所以 Shutdown 超时时间尽量要比链接处理的时间长。\n\n了解完原理，我们用例子来感受一下这个特性。\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/signal\"\n\t\"time\"\n\t\"github.com/gin-gonic/gin\"\n)\n\nfunc main() {\n\trouter := gin.Default()\n\trouter.GET(\"/\", func(c *gin.Context) {\n\t\ttime.Sleep(3 * time.Second)\n\t\tlog.Printf(http.StatusOK, \"Handle request success\")\n\t})\n\n\tsrv := &http.Server{\n\t\tAddr:    \":8080\",\n\t\tHandler: router,\n\t}\n\n\tgo func() {\n\t\tif err := srv.ListenAndServe(); err != nil {\n\t\t\tlog.Printf(\"listen: %s\\n\", err)\n\t\t}\n\t}()\n\n\tquit := make(chan os.Signal)\n\tsignal.Notify(quit, os.Interrupt)\n\t<-quit\n\tlog.Println(\"Shutdown Server ...\")\n\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\tif err := srv.Shutdown(ctx); err != nil {\n\t\tlog.Fatal(\"Server Shutdown:\", err)\n\t}\n\tlog.Println(\"Server exist\")\n}\n```\n\n代码中，每个请求都等待3秒才完成，使用信号来捕捉程序退出。退出时，HTTPServer 等待5秒来\"善后\"。我发起`curl localhost:8080`来测试，随即按下 Ctrl+C 退出程序，结果显示，服务器坚持在处理完这个 HTTP 请求才退出。\n\n```\n[GIN-debug] [WARNING] Running in \"debug\" mode. Switch to \"release\" mode in production.\n - using env:\texport GIN_MODE=release\n - using code:\tgin.SetMode(gin.ReleaseMode)\n\n[GIN-debug] GET    /                         --> main.main.func1 (3 handlers)\nHandle Request success\n[GIN] 2017/07/12 - 20:30:47 | 200 |  3.000385597s | 127.0.0.1 |   GET     /\n^C  //终端输入Ctrl+C\nShutdown Server ...\nlisten: http: Server closed\nHandle Request success //在接收到关闭信号时，依然保证正在处理的请求正常处理完\n[GIN] 2017/07/12 - 20:30:53 | 200 |  3.000360362s | 127.0.0.1 |   GET     /\nServer exist\n```\n","slug":"2017-07-13-httpserver-graceful-shutdown-in-go","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdat0054nctjepcu0apm","content":"<p>和同事聊到了服务在需要关闭的时候该如何优雅退出，顺藤摸瓜挖掘了Go1.8的特性。Go 1.8起新增了优雅退出 HTTPServer 的特性，也就是大家经常提到的 GraceFul ShutDown。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// src/net/http/server.go</span></span><br><span class=\"line\"><span class=\"comment\">// Shutdown gracefully shuts down the server without interrupting any active connections. Shutdown works by first closing all open listeners, then closing all idle connections, and then waiting indefinitely for connections to return to idle and then shut down. If the provided context expires before the shutdown is complete, then the context's error is returned.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(srv *Server)</span> <span class=\"title\">Shutdown</span><span class=\"params\">(ctx context.Context)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">    atomic.AddInt32(&amp;srv.inShutdown, <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">defer</span> atomic.AddInt32(&amp;srv.inShutdown, <span class=\"number\">-1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    srv.mu.Lock()</span><br><span class=\"line\">    lnerr := srv.closeListenersLocked()</span><br><span class=\"line\">    srv.closeDoneChanLocked()</span><br><span class=\"line\">    srv.mu.Unlock()</span><br><span class=\"line\"></span><br><span class=\"line\">    ticker := time.NewTicker(shutdownPollInterval)</span><br><span class=\"line\">    <span class=\"keyword\">defer</span> ticker.Stop()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> srv.closeIdleConns() &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> lnerr</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">select</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> &lt;-ctx.Done():</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ctx.Err()</span><br><span class=\"line\">        <span class=\"keyword\">case</span> &lt;-ticker.C:</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>从文档注释得知，server.Shutdown 首先关闭所有 active 的 listener，以及所有处于 idle 状态的 Connections，然后无限等待那些处于 active 状态的 connection 变为 idle 状态后，关闭他们，Server退出。</p>\n<p>如果有一个 Connection 依然处于 active 状态，那么 server 将一直 block 在那里。<br>Shutdown 接受一个 Context 参数，调用者可以通过 Context 传入一个等待的超时时间。<br>一旦超时，Shutdown 将直接返回。对于仍然处理 active 状态的Connection，就无能为力了。<br>所以 Shutdown 超时时间尽量要比链接处理的时间长。</p>\n<p>了解完原理，我们用例子来感受一下这个特性。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"context\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"log\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"net/http\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"os\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"os/signal\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"time\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"github.com/gin-gonic/gin\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\trouter := gin.Default()</span><br><span class=\"line\">\trouter.GET(<span class=\"string\">\"/\"</span>, <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(c *gin.Context)</span></span> &#123;</span><br><span class=\"line\">\t\ttime.Sleep(<span class=\"number\">3</span> * time.Second)</span><br><span class=\"line\">\t\tlog.Printf(http.StatusOK, <span class=\"string\">\"Handle request success\"</span>)</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">\tsrv := &amp;http.Server&#123;</span><br><span class=\"line\">\t\tAddr:    <span class=\"string\">\":8080\"</span>,</span><br><span class=\"line\">\t\tHandler: router,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> err := srv.ListenAndServe(); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\tlog.Printf(<span class=\"string\">\"listen: %s\\n\"</span>, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">\tquit := <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> os.Signal)</span><br><span class=\"line\">\tsignal.Notify(quit, os.Interrupt)</span><br><span class=\"line\">\t&lt;-quit</span><br><span class=\"line\">\tlog.Println(<span class=\"string\">\"Shutdown Server ...\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tctx, cancel := context.WithTimeout(context.Background(), <span class=\"number\">5</span>*time.Second)</span><br><span class=\"line\">\t<span class=\"keyword\">defer</span> cancel()</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err := srv.Shutdown(ctx); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\tlog.Fatal(<span class=\"string\">\"Server Shutdown:\"</span>, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tlog.Println(<span class=\"string\">\"Server exist\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>代码中，每个请求都等待3秒才完成，使用信号来捕捉程序退出。退出时，HTTPServer 等待5秒来”善后”。我发起<code>curl localhost:8080</code>来测试，随即按下 Ctrl+C 退出程序，结果显示，服务器坚持在处理完这个 HTTP 请求才退出。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production.</span><br><span class=\"line\"> - using env:\texport GIN_MODE=release</span><br><span class=\"line\"> - using code:\tgin.SetMode(gin.ReleaseMode)</span><br><span class=\"line\"></span><br><span class=\"line\">[GIN-debug] GET    /                         --&gt; main.main.func1 (3 handlers)</span><br><span class=\"line\">Handle Request success</span><br><span class=\"line\">[GIN] 2017/07/12 - 20:30:47 | 200 |  3.000385597s | 127.0.0.1 |   GET     /</span><br><span class=\"line\">^C  //终端输入Ctrl+C</span><br><span class=\"line\">Shutdown Server ...</span><br><span class=\"line\">listen: http: Server closed</span><br><span class=\"line\">Handle Request success //在接收到关闭信号时，依然保证正在处理的请求正常处理完</span><br><span class=\"line\">[GIN] 2017/07/12 - 20:30:53 | 200 |  3.000360362s | 127.0.0.1 |   GET     /</span><br><span class=\"line\">Server exist</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>和同事聊到了服务在需要关闭的时候该如何优雅退出，顺藤摸瓜挖掘了Go1.8的特性。Go 1.8起新增了优雅退出 HTTPServer 的特性，也就是大家经常提到的 GraceFul ShutDown。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// src/net/http/server.go</span></span><br><span class=\"line\"><span class=\"comment\">// Shutdown gracefully shuts down the server without interrupting any active connections. Shutdown works by first closing all open listeners, then closing all idle connections, and then waiting indefinitely for connections to return to idle and then shut down. If the provided context expires before the shutdown is complete, then the context's error is returned.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(srv *Server)</span> <span class=\"title\">Shutdown</span><span class=\"params\">(ctx context.Context)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">    atomic.AddInt32(&amp;srv.inShutdown, <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">defer</span> atomic.AddInt32(&amp;srv.inShutdown, <span class=\"number\">-1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    srv.mu.Lock()</span><br><span class=\"line\">    lnerr := srv.closeListenersLocked()</span><br><span class=\"line\">    srv.closeDoneChanLocked()</span><br><span class=\"line\">    srv.mu.Unlock()</span><br><span class=\"line\"></span><br><span class=\"line\">    ticker := time.NewTicker(shutdownPollInterval)</span><br><span class=\"line\">    <span class=\"keyword\">defer</span> ticker.Stop()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> srv.closeIdleConns() &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> lnerr</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">select</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> &lt;-ctx.Done():</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ctx.Err()</span><br><span class=\"line\">        <span class=\"keyword\">case</span> &lt;-ticker.C:</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>从文档注释得知，server.Shutdown 首先关闭所有 active 的 listener，以及所有处于 idle 状态的 Connections，然后无限等待那些处于 active 状态的 connection 变为 idle 状态后，关闭他们，Server退出。</p>\n<p>如果有一个 Connection 依然处于 active 状态，那么 server 将一直 block 在那里。<br>Shutdown 接受一个 Context 参数，调用者可以通过 Context 传入一个等待的超时时间。<br>一旦超时，Shutdown 将直接返回。对于仍然处理 active 状态的Connection，就无能为力了。<br>所以 Shutdown 超时时间尽量要比链接处理的时间长。</p>\n<p>了解完原理，我们用例子来感受一下这个特性。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"context\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"log\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"net/http\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"os\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"os/signal\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"time\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"github.com/gin-gonic/gin\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\trouter := gin.Default()</span><br><span class=\"line\">\trouter.GET(<span class=\"string\">\"/\"</span>, <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(c *gin.Context)</span></span> &#123;</span><br><span class=\"line\">\t\ttime.Sleep(<span class=\"number\">3</span> * time.Second)</span><br><span class=\"line\">\t\tlog.Printf(http.StatusOK, <span class=\"string\">\"Handle request success\"</span>)</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">\tsrv := &amp;http.Server&#123;</span><br><span class=\"line\">\t\tAddr:    <span class=\"string\">\":8080\"</span>,</span><br><span class=\"line\">\t\tHandler: router,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> err := srv.ListenAndServe(); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\tlog.Printf(<span class=\"string\">\"listen: %s\\n\"</span>, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">\tquit := <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> os.Signal)</span><br><span class=\"line\">\tsignal.Notify(quit, os.Interrupt)</span><br><span class=\"line\">\t&lt;-quit</span><br><span class=\"line\">\tlog.Println(<span class=\"string\">\"Shutdown Server ...\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tctx, cancel := context.WithTimeout(context.Background(), <span class=\"number\">5</span>*time.Second)</span><br><span class=\"line\">\t<span class=\"keyword\">defer</span> cancel()</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err := srv.Shutdown(ctx); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\tlog.Fatal(<span class=\"string\">\"Server Shutdown:\"</span>, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tlog.Println(<span class=\"string\">\"Server exist\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>代码中，每个请求都等待3秒才完成，使用信号来捕捉程序退出。退出时，HTTPServer 等待5秒来”善后”。我发起<code>curl localhost:8080</code>来测试，随即按下 Ctrl+C 退出程序，结果显示，服务器坚持在处理完这个 HTTP 请求才退出。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production.</span><br><span class=\"line\"> - using env:\texport GIN_MODE=release</span><br><span class=\"line\"> - using code:\tgin.SetMode(gin.ReleaseMode)</span><br><span class=\"line\"></span><br><span class=\"line\">[GIN-debug] GET    /                         --&gt; main.main.func1 (3 handlers)</span><br><span class=\"line\">Handle Request success</span><br><span class=\"line\">[GIN] 2017/07/12 - 20:30:47 | 200 |  3.000385597s | 127.0.0.1 |   GET     /</span><br><span class=\"line\">^C  //终端输入Ctrl+C</span><br><span class=\"line\">Shutdown Server ...</span><br><span class=\"line\">listen: http: Server closed</span><br><span class=\"line\">Handle Request success //在接收到关闭信号时，依然保证正在处理的请求正常处理完</span><br><span class=\"line\">[GIN] 2017/07/12 - 20:30:53 | 200 |  3.000360362s | 127.0.0.1 |   GET     /</span><br><span class=\"line\">Server exist</span><br></pre></td></tr></table></figure>\n"},{"layout":"post","title":"半年随想","date":"2018-06-17T07:49:00.000Z","comments":1,"_content":"\n时光荏苒，这一次的博客更新，用了一年。 故事每天都在发生，不同时段的感悟也不尽相同。\n\n过去四年接触的是小公司式的后端全栈工作。庆幸认识到人生中导师和伙伴。我从一个满腔热情,但啥都不懂的小毛孩, 到后面成长为独挡一面, 负责全公司的运维架构, 以及传承培育新人的老家伙。依然清晰记得每次凌晨无缝迁移服务器的喜悦, 以及将新技术运用到实践当中, 节约成本带来的精神富足。不得不说这是一个技术人最纯粹的感动。也有过战友离开的彷徨, 面对人事压力的焦虑。 点点滴滴占据了令人感动的回忆, 倏忽之间一晃而过。\n\n新的征途几乎是一次完全的洗礼,进入微信, 从零开始接触 C++ 的后端开发, 以往熟悉的知识体系和经验都要翻开新的一页。开始硬磕指针和内存。\n\n半年的开发时间\n* 写了一个通用的三机容灾布隆过滤器，支撑小程序的统计\n* 改造几个组里的基础组件\n* 承担搜索的排序模块\n* 负载客服 IM 系统的设计与开发\n\n我也在慢慢接受和适应凶残的加班。 产品迭代速度快到有些窒息，这样的大背景下，我还在坚持记录文档的习惯，应该是微信的 \"奇葩\" 了, 我怕不靠谱的记忆力给自己，后人留坑。\n\n生活的难题也一道道出现,想来也没什么好的解决方法,锻炼身心是我能把控当下的选择。偶尔我会在地铁读读古人的诗词,以前没觉得有什么, 如今觉得古人的诗词实在是豁达开朗。\n\n说了挺多废话, 生活还在继续。相信认真生活的人运气不会太差, 愿我的朋友们也都有好运相伴。\n","source":"_posts/2018-06-17-ban-nian-sui-xiang.markdown","raw":"---\nlayout: post\ntitle: \"半年随想\"\ndate: 2018-06-17 15:49\ncomments: true\ncategories: Life\n---\n\n时光荏苒，这一次的博客更新，用了一年。 故事每天都在发生，不同时段的感悟也不尽相同。\n\n过去四年接触的是小公司式的后端全栈工作。庆幸认识到人生中导师和伙伴。我从一个满腔热情,但啥都不懂的小毛孩, 到后面成长为独挡一面, 负责全公司的运维架构, 以及传承培育新人的老家伙。依然清晰记得每次凌晨无缝迁移服务器的喜悦, 以及将新技术运用到实践当中, 节约成本带来的精神富足。不得不说这是一个技术人最纯粹的感动。也有过战友离开的彷徨, 面对人事压力的焦虑。 点点滴滴占据了令人感动的回忆, 倏忽之间一晃而过。\n\n新的征途几乎是一次完全的洗礼,进入微信, 从零开始接触 C++ 的后端开发, 以往熟悉的知识体系和经验都要翻开新的一页。开始硬磕指针和内存。\n\n半年的开发时间\n* 写了一个通用的三机容灾布隆过滤器，支撑小程序的统计\n* 改造几个组里的基础组件\n* 承担搜索的排序模块\n* 负载客服 IM 系统的设计与开发\n\n我也在慢慢接受和适应凶残的加班。 产品迭代速度快到有些窒息，这样的大背景下，我还在坚持记录文档的习惯，应该是微信的 \"奇葩\" 了, 我怕不靠谱的记忆力给自己，后人留坑。\n\n生活的难题也一道道出现,想来也没什么好的解决方法,锻炼身心是我能把控当下的选择。偶尔我会在地铁读读古人的诗词,以前没觉得有什么, 如今觉得古人的诗词实在是豁达开朗。\n\n说了挺多废话, 生活还在继续。相信认真生活的人运气不会太差, 愿我的朋友们也都有好运相伴。\n","slug":"2018-06-17-ban-nian-sui-xiang","published":1,"updated":"2018-06-17T11:55:31.000Z","photos":[],"link":"","_id":"cjijzgdau0056nctjpzz9955p","content":"<p>时光荏苒，这一次的博客更新，用了一年。 故事每天都在发生，不同时段的感悟也不尽相同。</p>\n<p>过去四年接触的是小公司式的后端全栈工作。庆幸认识到人生中导师和伙伴。我从一个满腔热情,但啥都不懂的小毛孩, 到后面成长为独挡一面, 负责全公司的运维架构, 以及传承培育新人的老家伙。依然清晰记得每次凌晨无缝迁移服务器的喜悦, 以及将新技术运用到实践当中, 节约成本带来的精神富足。不得不说这是一个技术人最纯粹的感动。也有过战友离开的彷徨, 面对人事压力的焦虑。 点点滴滴占据了令人感动的回忆, 倏忽之间一晃而过。</p>\n<p>新的征途几乎是一次完全的洗礼,进入微信, 从零开始接触 C++ 的后端开发, 以往熟悉的知识体系和经验都要翻开新的一页。开始硬磕指针和内存。</p>\n<p>半年的开发时间</p>\n<ul>\n<li>写了一个通用的三机容灾布隆过滤器，支撑小程序的统计</li>\n<li>改造几个组里的基础组件</li>\n<li>承担搜索的排序模块</li>\n<li>负载客服 IM 系统的设计与开发</li>\n</ul>\n<p>我也在慢慢接受和适应凶残的加班。 产品迭代速度快到有些窒息，这样的大背景下，我还在坚持记录文档的习惯，应该是微信的 “奇葩” 了, 我怕不靠谱的记忆力给自己，后人留坑。</p>\n<p>生活的难题也一道道出现,想来也没什么好的解决方法,锻炼身心是我能把控当下的选择。偶尔我会在地铁读读古人的诗词,以前没觉得有什么, 如今觉得古人的诗词实在是豁达开朗。</p>\n<p>说了挺多废话, 生活还在继续。相信认真生活的人运气不会太差, 愿我的朋友们也都有好运相伴。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>时光荏苒，这一次的博客更新，用了一年。 故事每天都在发生，不同时段的感悟也不尽相同。</p>\n<p>过去四年接触的是小公司式的后端全栈工作。庆幸认识到人生中导师和伙伴。我从一个满腔热情,但啥都不懂的小毛孩, 到后面成长为独挡一面, 负责全公司的运维架构, 以及传承培育新人的老家伙。依然清晰记得每次凌晨无缝迁移服务器的喜悦, 以及将新技术运用到实践当中, 节约成本带来的精神富足。不得不说这是一个技术人最纯粹的感动。也有过战友离开的彷徨, 面对人事压力的焦虑。 点点滴滴占据了令人感动的回忆, 倏忽之间一晃而过。</p>\n<p>新的征途几乎是一次完全的洗礼,进入微信, 从零开始接触 C++ 的后端开发, 以往熟悉的知识体系和经验都要翻开新的一页。开始硬磕指针和内存。</p>\n<p>半年的开发时间</p>\n<ul>\n<li>写了一个通用的三机容灾布隆过滤器，支撑小程序的统计</li>\n<li>改造几个组里的基础组件</li>\n<li>承担搜索的排序模块</li>\n<li>负载客服 IM 系统的设计与开发</li>\n</ul>\n<p>我也在慢慢接受和适应凶残的加班。 产品迭代速度快到有些窒息，这样的大背景下，我还在坚持记录文档的习惯，应该是微信的 “奇葩” 了, 我怕不靠谱的记忆力给自己，后人留坑。</p>\n<p>生活的难题也一道道出现,想来也没什么好的解决方法,锻炼身心是我能把控当下的选择。偶尔我会在地铁读读古人的诗词,以前没觉得有什么, 如今觉得古人的诗词实在是豁达开朗。</p>\n<p>说了挺多废话, 生活还在继续。相信认真生活的人运气不会太差, 愿我的朋友们也都有好运相伴。</p>\n"},{"layout":"post","title":"做快乐的程序员","date":"2012-05-07T05:23:00.000Z","comments":1,"_content":"看了一篇很不错的文章，忍不住转了，原文[链接](http://www.nowamagic.net/php/php_BeHappyProgrammer.php)\n\n### 什么是程序员的基本功？\n\n广义来说就比较多了，抛开数据结构、算法、编程思想、设计模式等不说，丰富的想象力，缜密的逻辑思维、学习能力、恒心和毅力、沟通能力….太多了，这些都算是基本功。\n\n所谓基本功，就是说抽空都要练习的。就像一个学武之人一样，每天早上要跑步、扎马步，也像一个京剧演员样，一大早就要吼几嗓子，我们程序员也得每天练习基本功。\n\n广义的基本功涉及到生活的方方面面，时时刻刻都能练习。这里着重强调下狭义的基本功：数据结构，基本算法、编程思想和设计模式、至少精通一门语言等。\n\n程序员都知道程序=数据结构+算法，可见数据结构和算方法对我我们程序员来说是何等重要。\n\n编程通俗一点说就是，想个办法把一堆旧数据按照要求整理整理变成另一堆新数据。首先要想好的就是把旧数据放好，你可以把计算机的存储设备想象成一个大的盒子。我们要想办法占用尽量小的空间（少用内存），把这些旧的数据放好。（当然还要考虑整理这些数据的方便性，比方说移除掉，或者新增数据等。）放好了旧的数据，现在就要开动大脑，想出个好方法—–如何操作才能使得整理的时间尽量的短（少用CPU）。编程其实就是这个目的，所以我们程序员常常思考的问题就是这两个了：1、如何放置数据 2、用什么方法处理速度快。\n\n一般来说，我们不需要太苛求占用尽量少的内存和CPU。毕竟现在的机器性能不是制约我们的主导因素，现在制约我们的主导因素是，“用尽量少的时间把需求合理的完成”。可以说，绝大部分企业对程序员的要求并不高，他们仅仅要求你按照需求在规定的时间做出来即可，并不是非常关心你占用多少计算机资源，硬盘不够，买，内存不足，补。但是这个并不意味着我们可以肆无忌惮的滥用计算机资源。\n\n举个实际的例子，假如浏览一个网页，本来需要1秒的时间能够打开，结果由于程序员的失误或粗心，或者说基本功力不足，使得整个过程变成2秒，你可能认为这个无所谓，不就是多了一秒么，应该没什么大不了的。如果你真这么想就大错特错了。\n\n就拿个一般的网站举例，每天1W PV，那么浪费的时间就是每天166.67分钟，1年就浪费60834.55分钟。约等于42个昼夜。你说这42个昼夜的时间干什么不好，非要浪费在计算机上，而且这个对计算机的损耗，以及浪费的电能等都还没有计算。\n\n可能有人说，对于这种普通的站点，一年42个昼夜也算不了什么，但是请注意我的例子只是说系统的一个地方，假如一个系统有不止一个这样的地方那就更夸张了。\n\n对于大型的互联网网站，这个就更夸张了，类似百度和google这样的企业，一天都有上亿的PV。就按1亿计算。大约是3年2月1.4天！\n\n对于我们做开源程序的程序员来说，这个尤其值得关注。要知道并不是每个HDWiki系统都是可以随意使用计算机资源的。\n\n### 重视解决问题的思路和事物的本质\n\n重视思想、重视问题的本质，不要浮在表面看待问题。例如我面试人的时候常常问一个 web 开发的基础问题：说说 session 的原理。这个对于搞 web 开发的人来说，是个很基本的问题。如果连 session 的原理都搞不清楚，说明这个人不是很喜欢思考。平时开发肯定都用别人说的，别人怎么说，他就怎么做。至于为什么一个用户能够登录成功，他始终是不清楚的。当然，不明白 session 的原理不是说就不能搞程序开发，一个项目也需要一些纯的coder。纯的coder就是按照要求填写代码的，基本不需要思考。我相信每个有追求的程序员都不会甘愿成为一个纯的 coder，那么，请在遇到实际问题的时候，多深入思考思考，多问几个为什么，一直深入到问题的本质。这样坚持下去，你绝对是一个有思想的程序员。碰到问题就很容易拿出一个靠谱的方案。\n\n可能会有人说，我怎么感觉平时没什么问题好问的，好像自己什么都知道了。知识就像是车轮，学得越多，这个车轮就越大，转一周所需要的行程就越长，而你会发现，车轮变大的同时，所接触的东西也是越来越多了，然后猛然发现，不会的东西变得更多了。如果一个人没有问题问，只能说明知道的太少了。\n\n在我们的日常工作中，需要问的东西太多了。为何我们要用框架？hibernate有什么用，用了有什么好处，用了有什么坏处？java为何是编程第一流行语言？Ruby 为何突然火爆起来了？PHP还能火多少年？HDWiki 能超过Discuz么？Lucene这个东西为何命名为Lucene？丁磊为何要养猪？……\n\n重视思想和本质带给我们什么好处呢？首先，作为一个了解本质的程序员，心里就很踏实，和其他技术人员交流，不会被鄙视。第二，能够让我们能够知其所以然，而不至于内心痛苦。例如数据库索引，大家都知道，建立了索引后，SQL查询条件”=”的时候，速度就提高很多。如果我们把这个当作经验背诵下来，你会马上碰到一个反例。例如当你的表有个标识字段，1表示有效，0表示无效。这时候如果在这个字段上建立了索引，按照经验，我们肯定认为速度会提高很多，但是实际上，基本没有变化。这个时候自己就很郁闷了。如果想做一个快乐的程序员，就一定要搞清楚索引的本质，为何索引建立后就快了。如果明白这个本质，就不会有这样的疑虑了。第三，能够让我们提高工作效率。第四，让自己更加清醒，不会被表象所迷惑。\n\n### 简单就是美，我们都是艺术家\n\n什么是美？我想是事物给人无论是哪种感官上的体验都还不错，这就是美了。比如夕阳柔和的余辉洒在眼中，呼吸带着草味儿的空气，要做的事情做好了，静坐着享 受美好的一刻。简单的东西不会使人厌烦，就好象天边几片单调的云彩，徐徐清风拂面，带来的是心情舒畅，头脑冷静，能给自己一个澄澈的思维空间。\n\n在程序的世界里，同样遵循这一原理。一个程序如果写的漂亮，很容易让别人看懂。程序不是写给机器看的，程序是写给人看的。当一个程序出问题了，我们希望迅速解决问题。如果程序写的很美，随便一个技术人员都能够看的懂，那么就非常有利于我们解决问题。\n\n有 百度知道，就有腾讯爱问，有浩方对战平台，就有QQ对战平台，有土豆网，就有了QQ视频，….马化腾自己也说：模仿也是一种成功！现在他用铁的事实来证实了这一点。\n\n对程序员来说，模仿能力也很重要。比方说我们要做一个弹出式DIV，这个时候你千万不要自己去从头开始去做。首先，我们要想办法找找看，看看是否有适合我们的已经存在的。如果有，我们直接下载，然后就可以用了。如果没有，可以找找类似的，然后再改改，还是可以为我所用。这样的话，可以为我们节省不少时间。 项目的进度有可能会提前。\n\n一个程序员刚进入一个公司的时候，短时间内还难以了解系统的整体构架。这个时候也不要发怵。怎么办呢？咱模仿项目组的其他老同学，模仿别人的开发流程、模仿别人的代码结构，模仿别人的命令规则……只要你模仿能力强，肯定把大家怔住了。给你的评价就很不错。为什么会这样呢，因为项目组的老同学正用的 肯定是目前比较合理的，只要你模仿着做，基本就不会有问题，你说你过试用期还会有问题？\n\n模仿能力就类似于段誉的“吸星大法”。吸星大法修炼起来的难处有两点：难处一，是要散去全身内力；难处二，散功之后，又须吸取旁人的真气。模仿和这个不同的地方就是，模仿只是复制，并不需要毁灭别人。从这个角度来说，模仿应该比吸星大法更加人道主义些。模仿有时候也得暂时忘掉或者放弃自己的然后再学习别人的。只有敞开心扉才能容纳万物！\n\n总之，模仿不仅能给我们节省不少的时间，还能够让我们迅速找到解决问题的正确思路和方法，正如牛顿所说“我之所以站得高，是因为我站在巨人的肩上”，模仿也是站在别人的肩膀上，能够省却我们不少的体力，何乐而不为呢？\n\n### 关注技术趋势，热爱学习\n\n作为专业的程序员，技术趋势不能不关注。IT行业发展迅猛，新的思想和新的东西不断涌现。如果我们不睁大双眼去观察，去了解，我们就会被逐渐淘汰。\n\n每天都有新的软件产品诞生，有新的版本发布，也有新的解决问题的方法出现。如果我们抽空关注下，我们很可能会有意外收获。例如今天，你看到一条消息，PHP5.3版本开始支持闭包。这个意味着什么呢？意味着你的程序写法可以进行更优美的改造。再如你看到消息说MySQL推 出了一种新的引擎，你就要看看这个引擎有什么特点，以后对我的工作有什么帮助。\n\n就是这样，我们在一点一滴中积累，每天坚持修炼自己的基本功，长期的坚持。我们会发现自己一天比一天快乐，因为我们每天都能够轻松的像艺术家一样说笑间就完成了自己的工作，你怎能不快乐？\n","source":"_posts/2013-08-28-zuo-kuai-le-de-cheng-xu-yuan.markdown","raw":"---\nlayout: post\ntitle: \"做快乐的程序员\"\ndate: 2012-05-07 13:23\ncomments: true\ncategories: Life\n---\n看了一篇很不错的文章，忍不住转了，原文[链接](http://www.nowamagic.net/php/php_BeHappyProgrammer.php)\n\n### 什么是程序员的基本功？\n\n广义来说就比较多了，抛开数据结构、算法、编程思想、设计模式等不说，丰富的想象力，缜密的逻辑思维、学习能力、恒心和毅力、沟通能力….太多了，这些都算是基本功。\n\n所谓基本功，就是说抽空都要练习的。就像一个学武之人一样，每天早上要跑步、扎马步，也像一个京剧演员样，一大早就要吼几嗓子，我们程序员也得每天练习基本功。\n\n广义的基本功涉及到生活的方方面面，时时刻刻都能练习。这里着重强调下狭义的基本功：数据结构，基本算法、编程思想和设计模式、至少精通一门语言等。\n\n程序员都知道程序=数据结构+算法，可见数据结构和算方法对我我们程序员来说是何等重要。\n\n编程通俗一点说就是，想个办法把一堆旧数据按照要求整理整理变成另一堆新数据。首先要想好的就是把旧数据放好，你可以把计算机的存储设备想象成一个大的盒子。我们要想办法占用尽量小的空间（少用内存），把这些旧的数据放好。（当然还要考虑整理这些数据的方便性，比方说移除掉，或者新增数据等。）放好了旧的数据，现在就要开动大脑，想出个好方法—–如何操作才能使得整理的时间尽量的短（少用CPU）。编程其实就是这个目的，所以我们程序员常常思考的问题就是这两个了：1、如何放置数据 2、用什么方法处理速度快。\n\n一般来说，我们不需要太苛求占用尽量少的内存和CPU。毕竟现在的机器性能不是制约我们的主导因素，现在制约我们的主导因素是，“用尽量少的时间把需求合理的完成”。可以说，绝大部分企业对程序员的要求并不高，他们仅仅要求你按照需求在规定的时间做出来即可，并不是非常关心你占用多少计算机资源，硬盘不够，买，内存不足，补。但是这个并不意味着我们可以肆无忌惮的滥用计算机资源。\n\n举个实际的例子，假如浏览一个网页，本来需要1秒的时间能够打开，结果由于程序员的失误或粗心，或者说基本功力不足，使得整个过程变成2秒，你可能认为这个无所谓，不就是多了一秒么，应该没什么大不了的。如果你真这么想就大错特错了。\n\n就拿个一般的网站举例，每天1W PV，那么浪费的时间就是每天166.67分钟，1年就浪费60834.55分钟。约等于42个昼夜。你说这42个昼夜的时间干什么不好，非要浪费在计算机上，而且这个对计算机的损耗，以及浪费的电能等都还没有计算。\n\n可能有人说，对于这种普通的站点，一年42个昼夜也算不了什么，但是请注意我的例子只是说系统的一个地方，假如一个系统有不止一个这样的地方那就更夸张了。\n\n对于大型的互联网网站，这个就更夸张了，类似百度和google这样的企业，一天都有上亿的PV。就按1亿计算。大约是3年2月1.4天！\n\n对于我们做开源程序的程序员来说，这个尤其值得关注。要知道并不是每个HDWiki系统都是可以随意使用计算机资源的。\n\n### 重视解决问题的思路和事物的本质\n\n重视思想、重视问题的本质，不要浮在表面看待问题。例如我面试人的时候常常问一个 web 开发的基础问题：说说 session 的原理。这个对于搞 web 开发的人来说，是个很基本的问题。如果连 session 的原理都搞不清楚，说明这个人不是很喜欢思考。平时开发肯定都用别人说的，别人怎么说，他就怎么做。至于为什么一个用户能够登录成功，他始终是不清楚的。当然，不明白 session 的原理不是说就不能搞程序开发，一个项目也需要一些纯的coder。纯的coder就是按照要求填写代码的，基本不需要思考。我相信每个有追求的程序员都不会甘愿成为一个纯的 coder，那么，请在遇到实际问题的时候，多深入思考思考，多问几个为什么，一直深入到问题的本质。这样坚持下去，你绝对是一个有思想的程序员。碰到问题就很容易拿出一个靠谱的方案。\n\n可能会有人说，我怎么感觉平时没什么问题好问的，好像自己什么都知道了。知识就像是车轮，学得越多，这个车轮就越大，转一周所需要的行程就越长，而你会发现，车轮变大的同时，所接触的东西也是越来越多了，然后猛然发现，不会的东西变得更多了。如果一个人没有问题问，只能说明知道的太少了。\n\n在我们的日常工作中，需要问的东西太多了。为何我们要用框架？hibernate有什么用，用了有什么好处，用了有什么坏处？java为何是编程第一流行语言？Ruby 为何突然火爆起来了？PHP还能火多少年？HDWiki 能超过Discuz么？Lucene这个东西为何命名为Lucene？丁磊为何要养猪？……\n\n重视思想和本质带给我们什么好处呢？首先，作为一个了解本质的程序员，心里就很踏实，和其他技术人员交流，不会被鄙视。第二，能够让我们能够知其所以然，而不至于内心痛苦。例如数据库索引，大家都知道，建立了索引后，SQL查询条件”=”的时候，速度就提高很多。如果我们把这个当作经验背诵下来，你会马上碰到一个反例。例如当你的表有个标识字段，1表示有效，0表示无效。这时候如果在这个字段上建立了索引，按照经验，我们肯定认为速度会提高很多，但是实际上，基本没有变化。这个时候自己就很郁闷了。如果想做一个快乐的程序员，就一定要搞清楚索引的本质，为何索引建立后就快了。如果明白这个本质，就不会有这样的疑虑了。第三，能够让我们提高工作效率。第四，让自己更加清醒，不会被表象所迷惑。\n\n### 简单就是美，我们都是艺术家\n\n什么是美？我想是事物给人无论是哪种感官上的体验都还不错，这就是美了。比如夕阳柔和的余辉洒在眼中，呼吸带着草味儿的空气，要做的事情做好了，静坐着享 受美好的一刻。简单的东西不会使人厌烦，就好象天边几片单调的云彩，徐徐清风拂面，带来的是心情舒畅，头脑冷静，能给自己一个澄澈的思维空间。\n\n在程序的世界里，同样遵循这一原理。一个程序如果写的漂亮，很容易让别人看懂。程序不是写给机器看的，程序是写给人看的。当一个程序出问题了，我们希望迅速解决问题。如果程序写的很美，随便一个技术人员都能够看的懂，那么就非常有利于我们解决问题。\n\n有 百度知道，就有腾讯爱问，有浩方对战平台，就有QQ对战平台，有土豆网，就有了QQ视频，….马化腾自己也说：模仿也是一种成功！现在他用铁的事实来证实了这一点。\n\n对程序员来说，模仿能力也很重要。比方说我们要做一个弹出式DIV，这个时候你千万不要自己去从头开始去做。首先，我们要想办法找找看，看看是否有适合我们的已经存在的。如果有，我们直接下载，然后就可以用了。如果没有，可以找找类似的，然后再改改，还是可以为我所用。这样的话，可以为我们节省不少时间。 项目的进度有可能会提前。\n\n一个程序员刚进入一个公司的时候，短时间内还难以了解系统的整体构架。这个时候也不要发怵。怎么办呢？咱模仿项目组的其他老同学，模仿别人的开发流程、模仿别人的代码结构，模仿别人的命令规则……只要你模仿能力强，肯定把大家怔住了。给你的评价就很不错。为什么会这样呢，因为项目组的老同学正用的 肯定是目前比较合理的，只要你模仿着做，基本就不会有问题，你说你过试用期还会有问题？\n\n模仿能力就类似于段誉的“吸星大法”。吸星大法修炼起来的难处有两点：难处一，是要散去全身内力；难处二，散功之后，又须吸取旁人的真气。模仿和这个不同的地方就是，模仿只是复制，并不需要毁灭别人。从这个角度来说，模仿应该比吸星大法更加人道主义些。模仿有时候也得暂时忘掉或者放弃自己的然后再学习别人的。只有敞开心扉才能容纳万物！\n\n总之，模仿不仅能给我们节省不少的时间，还能够让我们迅速找到解决问题的正确思路和方法，正如牛顿所说“我之所以站得高，是因为我站在巨人的肩上”，模仿也是站在别人的肩膀上，能够省却我们不少的体力，何乐而不为呢？\n\n### 关注技术趋势，热爱学习\n\n作为专业的程序员，技术趋势不能不关注。IT行业发展迅猛，新的思想和新的东西不断涌现。如果我们不睁大双眼去观察，去了解，我们就会被逐渐淘汰。\n\n每天都有新的软件产品诞生，有新的版本发布，也有新的解决问题的方法出现。如果我们抽空关注下，我们很可能会有意外收获。例如今天，你看到一条消息，PHP5.3版本开始支持闭包。这个意味着什么呢？意味着你的程序写法可以进行更优美的改造。再如你看到消息说MySQL推 出了一种新的引擎，你就要看看这个引擎有什么特点，以后对我的工作有什么帮助。\n\n就是这样，我们在一点一滴中积累，每天坚持修炼自己的基本功，长期的坚持。我们会发现自己一天比一天快乐，因为我们每天都能够轻松的像艺术家一样说笑间就完成了自己的工作，你怎能不快乐？\n","slug":"2013-08-28-zuo-kuai-le-de-cheng-xu-yuan","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdfg005fnctjs0wc9776","content":"<p>看了一篇很不错的文章，忍不住转了，原文<a href=\"http://www.nowamagic.net/php/php_BeHappyProgrammer.php\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n<h3 id=\"什么是程序员的基本功？\"><a href=\"#什么是程序员的基本功？\" class=\"headerlink\" title=\"什么是程序员的基本功？\"></a>什么是程序员的基本功？</h3><p>广义来说就比较多了，抛开数据结构、算法、编程思想、设计模式等不说，丰富的想象力，缜密的逻辑思维、学习能力、恒心和毅力、沟通能力….太多了，这些都算是基本功。</p>\n<p>所谓基本功，就是说抽空都要练习的。就像一个学武之人一样，每天早上要跑步、扎马步，也像一个京剧演员样，一大早就要吼几嗓子，我们程序员也得每天练习基本功。</p>\n<p>广义的基本功涉及到生活的方方面面，时时刻刻都能练习。这里着重强调下狭义的基本功：数据结构，基本算法、编程思想和设计模式、至少精通一门语言等。</p>\n<p>程序员都知道程序=数据结构+算法，可见数据结构和算方法对我我们程序员来说是何等重要。</p>\n<p>编程通俗一点说就是，想个办法把一堆旧数据按照要求整理整理变成另一堆新数据。首先要想好的就是把旧数据放好，你可以把计算机的存储设备想象成一个大的盒子。我们要想办法占用尽量小的空间（少用内存），把这些旧的数据放好。（当然还要考虑整理这些数据的方便性，比方说移除掉，或者新增数据等。）放好了旧的数据，现在就要开动大脑，想出个好方法—–如何操作才能使得整理的时间尽量的短（少用CPU）。编程其实就是这个目的，所以我们程序员常常思考的问题就是这两个了：1、如何放置数据 2、用什么方法处理速度快。</p>\n<p>一般来说，我们不需要太苛求占用尽量少的内存和CPU。毕竟现在的机器性能不是制约我们的主导因素，现在制约我们的主导因素是，“用尽量少的时间把需求合理的完成”。可以说，绝大部分企业对程序员的要求并不高，他们仅仅要求你按照需求在规定的时间做出来即可，并不是非常关心你占用多少计算机资源，硬盘不够，买，内存不足，补。但是这个并不意味着我们可以肆无忌惮的滥用计算机资源。</p>\n<p>举个实际的例子，假如浏览一个网页，本来需要1秒的时间能够打开，结果由于程序员的失误或粗心，或者说基本功力不足，使得整个过程变成2秒，你可能认为这个无所谓，不就是多了一秒么，应该没什么大不了的。如果你真这么想就大错特错了。</p>\n<p>就拿个一般的网站举例，每天1W PV，那么浪费的时间就是每天166.67分钟，1年就浪费60834.55分钟。约等于42个昼夜。你说这42个昼夜的时间干什么不好，非要浪费在计算机上，而且这个对计算机的损耗，以及浪费的电能等都还没有计算。</p>\n<p>可能有人说，对于这种普通的站点，一年42个昼夜也算不了什么，但是请注意我的例子只是说系统的一个地方，假如一个系统有不止一个这样的地方那就更夸张了。</p>\n<p>对于大型的互联网网站，这个就更夸张了，类似百度和google这样的企业，一天都有上亿的PV。就按1亿计算。大约是3年2月1.4天！</p>\n<p>对于我们做开源程序的程序员来说，这个尤其值得关注。要知道并不是每个HDWiki系统都是可以随意使用计算机资源的。</p>\n<h3 id=\"重视解决问题的思路和事物的本质\"><a href=\"#重视解决问题的思路和事物的本质\" class=\"headerlink\" title=\"重视解决问题的思路和事物的本质\"></a>重视解决问题的思路和事物的本质</h3><p>重视思想、重视问题的本质，不要浮在表面看待问题。例如我面试人的时候常常问一个 web 开发的基础问题：说说 session 的原理。这个对于搞 web 开发的人来说，是个很基本的问题。如果连 session 的原理都搞不清楚，说明这个人不是很喜欢思考。平时开发肯定都用别人说的，别人怎么说，他就怎么做。至于为什么一个用户能够登录成功，他始终是不清楚的。当然，不明白 session 的原理不是说就不能搞程序开发，一个项目也需要一些纯的coder。纯的coder就是按照要求填写代码的，基本不需要思考。我相信每个有追求的程序员都不会甘愿成为一个纯的 coder，那么，请在遇到实际问题的时候，多深入思考思考，多问几个为什么，一直深入到问题的本质。这样坚持下去，你绝对是一个有思想的程序员。碰到问题就很容易拿出一个靠谱的方案。</p>\n<p>可能会有人说，我怎么感觉平时没什么问题好问的，好像自己什么都知道了。知识就像是车轮，学得越多，这个车轮就越大，转一周所需要的行程就越长，而你会发现，车轮变大的同时，所接触的东西也是越来越多了，然后猛然发现，不会的东西变得更多了。如果一个人没有问题问，只能说明知道的太少了。</p>\n<p>在我们的日常工作中，需要问的东西太多了。为何我们要用框架？hibernate有什么用，用了有什么好处，用了有什么坏处？java为何是编程第一流行语言？Ruby 为何突然火爆起来了？PHP还能火多少年？HDWiki 能超过Discuz么？Lucene这个东西为何命名为Lucene？丁磊为何要养猪？……</p>\n<p>重视思想和本质带给我们什么好处呢？首先，作为一个了解本质的程序员，心里就很踏实，和其他技术人员交流，不会被鄙视。第二，能够让我们能够知其所以然，而不至于内心痛苦。例如数据库索引，大家都知道，建立了索引后，SQL查询条件”=”的时候，速度就提高很多。如果我们把这个当作经验背诵下来，你会马上碰到一个反例。例如当你的表有个标识字段，1表示有效，0表示无效。这时候如果在这个字段上建立了索引，按照经验，我们肯定认为速度会提高很多，但是实际上，基本没有变化。这个时候自己就很郁闷了。如果想做一个快乐的程序员，就一定要搞清楚索引的本质，为何索引建立后就快了。如果明白这个本质，就不会有这样的疑虑了。第三，能够让我们提高工作效率。第四，让自己更加清醒，不会被表象所迷惑。</p>\n<h3 id=\"简单就是美，我们都是艺术家\"><a href=\"#简单就是美，我们都是艺术家\" class=\"headerlink\" title=\"简单就是美，我们都是艺术家\"></a>简单就是美，我们都是艺术家</h3><p>什么是美？我想是事物给人无论是哪种感官上的体验都还不错，这就是美了。比如夕阳柔和的余辉洒在眼中，呼吸带着草味儿的空气，要做的事情做好了，静坐着享 受美好的一刻。简单的东西不会使人厌烦，就好象天边几片单调的云彩，徐徐清风拂面，带来的是心情舒畅，头脑冷静，能给自己一个澄澈的思维空间。</p>\n<p>在程序的世界里，同样遵循这一原理。一个程序如果写的漂亮，很容易让别人看懂。程序不是写给机器看的，程序是写给人看的。当一个程序出问题了，我们希望迅速解决问题。如果程序写的很美，随便一个技术人员都能够看的懂，那么就非常有利于我们解决问题。</p>\n<p>有 百度知道，就有腾讯爱问，有浩方对战平台，就有QQ对战平台，有土豆网，就有了QQ视频，….马化腾自己也说：模仿也是一种成功！现在他用铁的事实来证实了这一点。</p>\n<p>对程序员来说，模仿能力也很重要。比方说我们要做一个弹出式DIV，这个时候你千万不要自己去从头开始去做。首先，我们要想办法找找看，看看是否有适合我们的已经存在的。如果有，我们直接下载，然后就可以用了。如果没有，可以找找类似的，然后再改改，还是可以为我所用。这样的话，可以为我们节省不少时间。 项目的进度有可能会提前。</p>\n<p>一个程序员刚进入一个公司的时候，短时间内还难以了解系统的整体构架。这个时候也不要发怵。怎么办呢？咱模仿项目组的其他老同学，模仿别人的开发流程、模仿别人的代码结构，模仿别人的命令规则……只要你模仿能力强，肯定把大家怔住了。给你的评价就很不错。为什么会这样呢，因为项目组的老同学正用的 肯定是目前比较合理的，只要你模仿着做，基本就不会有问题，你说你过试用期还会有问题？</p>\n<p>模仿能力就类似于段誉的“吸星大法”。吸星大法修炼起来的难处有两点：难处一，是要散去全身内力；难处二，散功之后，又须吸取旁人的真气。模仿和这个不同的地方就是，模仿只是复制，并不需要毁灭别人。从这个角度来说，模仿应该比吸星大法更加人道主义些。模仿有时候也得暂时忘掉或者放弃自己的然后再学习别人的。只有敞开心扉才能容纳万物！</p>\n<p>总之，模仿不仅能给我们节省不少的时间，还能够让我们迅速找到解决问题的正确思路和方法，正如牛顿所说“我之所以站得高，是因为我站在巨人的肩上”，模仿也是站在别人的肩膀上，能够省却我们不少的体力，何乐而不为呢？</p>\n<h3 id=\"关注技术趋势，热爱学习\"><a href=\"#关注技术趋势，热爱学习\" class=\"headerlink\" title=\"关注技术趋势，热爱学习\"></a>关注技术趋势，热爱学习</h3><p>作为专业的程序员，技术趋势不能不关注。IT行业发展迅猛，新的思想和新的东西不断涌现。如果我们不睁大双眼去观察，去了解，我们就会被逐渐淘汰。</p>\n<p>每天都有新的软件产品诞生，有新的版本发布，也有新的解决问题的方法出现。如果我们抽空关注下，我们很可能会有意外收获。例如今天，你看到一条消息，PHP5.3版本开始支持闭包。这个意味着什么呢？意味着你的程序写法可以进行更优美的改造。再如你看到消息说MySQL推 出了一种新的引擎，你就要看看这个引擎有什么特点，以后对我的工作有什么帮助。</p>\n<p>就是这样，我们在一点一滴中积累，每天坚持修炼自己的基本功，长期的坚持。我们会发现自己一天比一天快乐，因为我们每天都能够轻松的像艺术家一样说笑间就完成了自己的工作，你怎能不快乐？</p>\n","site":{"data":{}},"excerpt":"","more":"<p>看了一篇很不错的文章，忍不住转了，原文<a href=\"http://www.nowamagic.net/php/php_BeHappyProgrammer.php\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n<h3 id=\"什么是程序员的基本功？\"><a href=\"#什么是程序员的基本功？\" class=\"headerlink\" title=\"什么是程序员的基本功？\"></a>什么是程序员的基本功？</h3><p>广义来说就比较多了，抛开数据结构、算法、编程思想、设计模式等不说，丰富的想象力，缜密的逻辑思维、学习能力、恒心和毅力、沟通能力….太多了，这些都算是基本功。</p>\n<p>所谓基本功，就是说抽空都要练习的。就像一个学武之人一样，每天早上要跑步、扎马步，也像一个京剧演员样，一大早就要吼几嗓子，我们程序员也得每天练习基本功。</p>\n<p>广义的基本功涉及到生活的方方面面，时时刻刻都能练习。这里着重强调下狭义的基本功：数据结构，基本算法、编程思想和设计模式、至少精通一门语言等。</p>\n<p>程序员都知道程序=数据结构+算法，可见数据结构和算方法对我我们程序员来说是何等重要。</p>\n<p>编程通俗一点说就是，想个办法把一堆旧数据按照要求整理整理变成另一堆新数据。首先要想好的就是把旧数据放好，你可以把计算机的存储设备想象成一个大的盒子。我们要想办法占用尽量小的空间（少用内存），把这些旧的数据放好。（当然还要考虑整理这些数据的方便性，比方说移除掉，或者新增数据等。）放好了旧的数据，现在就要开动大脑，想出个好方法—–如何操作才能使得整理的时间尽量的短（少用CPU）。编程其实就是这个目的，所以我们程序员常常思考的问题就是这两个了：1、如何放置数据 2、用什么方法处理速度快。</p>\n<p>一般来说，我们不需要太苛求占用尽量少的内存和CPU。毕竟现在的机器性能不是制约我们的主导因素，现在制约我们的主导因素是，“用尽量少的时间把需求合理的完成”。可以说，绝大部分企业对程序员的要求并不高，他们仅仅要求你按照需求在规定的时间做出来即可，并不是非常关心你占用多少计算机资源，硬盘不够，买，内存不足，补。但是这个并不意味着我们可以肆无忌惮的滥用计算机资源。</p>\n<p>举个实际的例子，假如浏览一个网页，本来需要1秒的时间能够打开，结果由于程序员的失误或粗心，或者说基本功力不足，使得整个过程变成2秒，你可能认为这个无所谓，不就是多了一秒么，应该没什么大不了的。如果你真这么想就大错特错了。</p>\n<p>就拿个一般的网站举例，每天1W PV，那么浪费的时间就是每天166.67分钟，1年就浪费60834.55分钟。约等于42个昼夜。你说这42个昼夜的时间干什么不好，非要浪费在计算机上，而且这个对计算机的损耗，以及浪费的电能等都还没有计算。</p>\n<p>可能有人说，对于这种普通的站点，一年42个昼夜也算不了什么，但是请注意我的例子只是说系统的一个地方，假如一个系统有不止一个这样的地方那就更夸张了。</p>\n<p>对于大型的互联网网站，这个就更夸张了，类似百度和google这样的企业，一天都有上亿的PV。就按1亿计算。大约是3年2月1.4天！</p>\n<p>对于我们做开源程序的程序员来说，这个尤其值得关注。要知道并不是每个HDWiki系统都是可以随意使用计算机资源的。</p>\n<h3 id=\"重视解决问题的思路和事物的本质\"><a href=\"#重视解决问题的思路和事物的本质\" class=\"headerlink\" title=\"重视解决问题的思路和事物的本质\"></a>重视解决问题的思路和事物的本质</h3><p>重视思想、重视问题的本质，不要浮在表面看待问题。例如我面试人的时候常常问一个 web 开发的基础问题：说说 session 的原理。这个对于搞 web 开发的人来说，是个很基本的问题。如果连 session 的原理都搞不清楚，说明这个人不是很喜欢思考。平时开发肯定都用别人说的，别人怎么说，他就怎么做。至于为什么一个用户能够登录成功，他始终是不清楚的。当然，不明白 session 的原理不是说就不能搞程序开发，一个项目也需要一些纯的coder。纯的coder就是按照要求填写代码的，基本不需要思考。我相信每个有追求的程序员都不会甘愿成为一个纯的 coder，那么，请在遇到实际问题的时候，多深入思考思考，多问几个为什么，一直深入到问题的本质。这样坚持下去，你绝对是一个有思想的程序员。碰到问题就很容易拿出一个靠谱的方案。</p>\n<p>可能会有人说，我怎么感觉平时没什么问题好问的，好像自己什么都知道了。知识就像是车轮，学得越多，这个车轮就越大，转一周所需要的行程就越长，而你会发现，车轮变大的同时，所接触的东西也是越来越多了，然后猛然发现，不会的东西变得更多了。如果一个人没有问题问，只能说明知道的太少了。</p>\n<p>在我们的日常工作中，需要问的东西太多了。为何我们要用框架？hibernate有什么用，用了有什么好处，用了有什么坏处？java为何是编程第一流行语言？Ruby 为何突然火爆起来了？PHP还能火多少年？HDWiki 能超过Discuz么？Lucene这个东西为何命名为Lucene？丁磊为何要养猪？……</p>\n<p>重视思想和本质带给我们什么好处呢？首先，作为一个了解本质的程序员，心里就很踏实，和其他技术人员交流，不会被鄙视。第二，能够让我们能够知其所以然，而不至于内心痛苦。例如数据库索引，大家都知道，建立了索引后，SQL查询条件”=”的时候，速度就提高很多。如果我们把这个当作经验背诵下来，你会马上碰到一个反例。例如当你的表有个标识字段，1表示有效，0表示无效。这时候如果在这个字段上建立了索引，按照经验，我们肯定认为速度会提高很多，但是实际上，基本没有变化。这个时候自己就很郁闷了。如果想做一个快乐的程序员，就一定要搞清楚索引的本质，为何索引建立后就快了。如果明白这个本质，就不会有这样的疑虑了。第三，能够让我们提高工作效率。第四，让自己更加清醒，不会被表象所迷惑。</p>\n<h3 id=\"简单就是美，我们都是艺术家\"><a href=\"#简单就是美，我们都是艺术家\" class=\"headerlink\" title=\"简单就是美，我们都是艺术家\"></a>简单就是美，我们都是艺术家</h3><p>什么是美？我想是事物给人无论是哪种感官上的体验都还不错，这就是美了。比如夕阳柔和的余辉洒在眼中，呼吸带着草味儿的空气，要做的事情做好了，静坐着享 受美好的一刻。简单的东西不会使人厌烦，就好象天边几片单调的云彩，徐徐清风拂面，带来的是心情舒畅，头脑冷静，能给自己一个澄澈的思维空间。</p>\n<p>在程序的世界里，同样遵循这一原理。一个程序如果写的漂亮，很容易让别人看懂。程序不是写给机器看的，程序是写给人看的。当一个程序出问题了，我们希望迅速解决问题。如果程序写的很美，随便一个技术人员都能够看的懂，那么就非常有利于我们解决问题。</p>\n<p>有 百度知道，就有腾讯爱问，有浩方对战平台，就有QQ对战平台，有土豆网，就有了QQ视频，….马化腾自己也说：模仿也是一种成功！现在他用铁的事实来证实了这一点。</p>\n<p>对程序员来说，模仿能力也很重要。比方说我们要做一个弹出式DIV，这个时候你千万不要自己去从头开始去做。首先，我们要想办法找找看，看看是否有适合我们的已经存在的。如果有，我们直接下载，然后就可以用了。如果没有，可以找找类似的，然后再改改，还是可以为我所用。这样的话，可以为我们节省不少时间。 项目的进度有可能会提前。</p>\n<p>一个程序员刚进入一个公司的时候，短时间内还难以了解系统的整体构架。这个时候也不要发怵。怎么办呢？咱模仿项目组的其他老同学，模仿别人的开发流程、模仿别人的代码结构，模仿别人的命令规则……只要你模仿能力强，肯定把大家怔住了。给你的评价就很不错。为什么会这样呢，因为项目组的老同学正用的 肯定是目前比较合理的，只要你模仿着做，基本就不会有问题，你说你过试用期还会有问题？</p>\n<p>模仿能力就类似于段誉的“吸星大法”。吸星大法修炼起来的难处有两点：难处一，是要散去全身内力；难处二，散功之后，又须吸取旁人的真气。模仿和这个不同的地方就是，模仿只是复制，并不需要毁灭别人。从这个角度来说，模仿应该比吸星大法更加人道主义些。模仿有时候也得暂时忘掉或者放弃自己的然后再学习别人的。只有敞开心扉才能容纳万物！</p>\n<p>总之，模仿不仅能给我们节省不少的时间，还能够让我们迅速找到解决问题的正确思路和方法，正如牛顿所说“我之所以站得高，是因为我站在巨人的肩上”，模仿也是站在别人的肩膀上，能够省却我们不少的体力，何乐而不为呢？</p>\n<h3 id=\"关注技术趋势，热爱学习\"><a href=\"#关注技术趋势，热爱学习\" class=\"headerlink\" title=\"关注技术趋势，热爱学习\"></a>关注技术趋势，热爱学习</h3><p>作为专业的程序员，技术趋势不能不关注。IT行业发展迅猛，新的思想和新的东西不断涌现。如果我们不睁大双眼去观察，去了解，我们就会被逐渐淘汰。</p>\n<p>每天都有新的软件产品诞生，有新的版本发布，也有新的解决问题的方法出现。如果我们抽空关注下，我们很可能会有意外收获。例如今天，你看到一条消息，PHP5.3版本开始支持闭包。这个意味着什么呢？意味着你的程序写法可以进行更优美的改造。再如你看到消息说MySQL推 出了一种新的引擎，你就要看看这个引擎有什么特点，以后对我的工作有什么帮助。</p>\n<p>就是这样，我们在一点一滴中积累，每天坚持修炼自己的基本功，长期的坚持。我们会发现自己一天比一天快乐，因为我们每天都能够轻松的像艺术家一样说笑间就完成了自己的工作，你怎能不快乐？</p>\n"},{"layout":"post","title":"[译]nginx pitfall","date":"2014-05-13T14:26:00.000Z","comments":1,"keywords":"Nginx pitfall","description":"Nginx pitfall","_content":"\n今天看完[Nginx Pitfall](http://wiki.nginx.org/Pitfalls),热血用了一个下午翻译了的，以下是正文\n\n##Nginx 陷阱##\n\n无论你是nginx的新用户还是老用户都会遇到nginx的一些陷阱，下面我们着重描述这些陷阱，以及如何避免犯错。这些问题多次出现在 #nginx channel on Freenode#上\n\n###[是指南教我这么做的]###\n\n不要轻易相信网上其他的配置指引，除非你知道这样做的真正意义，并且知道怎么清除它们。很多配置其实写的很糟糕，我们根据互联网上的错误配置收集到的陷阱，它们并非来自刻意搜索，而是来自网络上的疑惑问答，这些问题收到的共同回复是，他们因为看了一些错误配置指引所以不同意我们的方法。写此文的目的是为了阐述我们的观点，如果你也遇到如下问题，该文章正好为你准备。\n\n\n###[Root 放置在Location块内]###\n\n不好的配置\n\n```bash\nserver {\n  server_name www.domain.com;\n  location / {\n    root /var/www/nginx-default/;\n    [...]\n  }\n  location /foo {\n    root /var/www/nginx-default/;\n    [...]\n  }\n  location /bar {\n    root /var/www/nginx-default/;\n    [...]\n  }\n}\n```\n\n该配置可以正常工作，把 root 放在 location块内可以完美的运行，但是当你开始添加location快，你就发现问题了。如果你给每个loaction 块添加 root，一旦有一个 location 块没有匹配到,那么他就失去了 root ,让我们来看看正确的配置\n\n```\nserver {\n  server_name www.domain.com;\n  root /var/www/nginx-default/;\n  location / {\n    [...]\n  }\n  location /foo {\n    [...]\n  }\n  location /bar {\n    [...]\n  }\n}\n```\n\n###[多条 index 指令]###\n\n不好的配置\n\n```\nhttp {\n  index index.php index.htm index.html;\n  server {\n    server_name www.domain.com;\n    location / {\n      index index.php index.htm index.html;\n      [...]\n    }\n  }\n  server {\n    server_name domain.com;\n    location / {\n      index index.php index.htm index.html;\n      [...]\n    }\n    location /foo {\n      index index.php;\n      [...]\n    }\n  }\n}\n```\n\n为什么要重复多条不需要的 index 指令？事实上只需要用一次，它仅仅需要放置在 `http{}` 块内，后面的配置会继承它。\n\n正确的配置\n\n```\nhttp {\n  index index.php index.htm index.html;\n  server {\n    server_name www.domain.com;\n    location / {\n      [...]\n    }\n  }\n  server {\n    server_name domain.com;\n    location / {\n      [...]\n    }\n    location /foo {\n      [...]\n    }\n  }\n```\n\n###[使用if]###\n这里有小段篇幅是关于使用`if` 表达式，我们需要检查所谓的 “是否有害”，让我们看看那些错误的配置\n\n不好的配置\n\n```\nserver {\n  server_name domain.com *.domain.com;\n  if ($host ~* ^www\\.(.+)) {\n    set $raw_domain $1;\n    rewrite ^/(.*)$ $raw_domain/$1 permanent;\n    [...]\n  }\n}\n```\n这里明显有问题，第一条 `if` 指令就引起我们的注意，为什么是不好的配置呢, 你是否阅读过 [是否有害](http://wiki.nginx.org/IfIsEvil)。\n\n使用if 指令，nginx 会强制检查所有到来的请求，检测每一条指令是否有危害，这是极度低效的。使用两个 server 配置可以避免上述问题。\n\n正确的配置\n\n```\nserver {\n  server_name www.domain.com;\n  return 301 $scheme://domain.com$request_uri;\n}\nserver {\n  server_name domain.com;\n  [...]\n}\n```\n\n这种方法不仅是配置易读，而且降低了 nginx 的处理负担。我们摆脱了`if`指令的陷阱，我们也使用了 `$scheme` 代替了 URI scheme 是 http 还是 https 的硬编码.\n\n###[判断文件是否存在]###\n\n使用 `if` 指令确保文件是否存在，是糟糕的实践，如果你有机会接触较新的 nginx 版本，查看下`try_files` 指令，该指令更适合做该事情。\n\n不好的配置\n\n```\nserver {\n  root /var/www/domain.com;\n  location / {\n    if (!-f $request_filename) {\n      break;\n    }\n  }\n}\n```\n\n正确的配置\n\n```\nserver {\n  root /var/www/domain.com;\n  location / {\n    try_files $uri $uri/ /index.html;\n  }\n}\n```\n\n我们做的改变是，我们不使用`if`指令，而是使用 `try_files`,如果`$uri`不存在，尝试 `$uri/` 如果不存在，就使用默认的文件 `index.html`\n\n这个场景中，将会测试$uri是否存在，如果存在调用该服务，反之则会测试该目录是否存在，如果不存在就会调用 `index.html`，前提是`index.html`是存在的。这时候仅仅是简单的加载该页面。\n\n###[包的前端控制器模式]###\n\n“前端控制器模式”的设计很流行并广泛应用于 PHP 软件包，不乏很多比它更复杂的例子，使用 Drupal, Joomla 等，你只需要使用\n\n```\ntry_files $uri $uri/ /index.php?q=$uri&$args;\n```\n\n注意： - 参数名会依据你所使用的包不同而做相应的改变\n\n* `q`用于Drupal, Joomla, WordPress\n* `page` 用于CMS Made Simple\n\n一些软件甚至不需要查询字符串，可以通过`REQUEST_URI`获取（比如WordPress就支持）\n\n```\ntry_files $uri $uri/ /index.php;\n```\n\n当然，你的情况可能有所不一样，你可能需要更复杂的配置。对于简单的站点，该配置已经完美的支持，通常我们都是由浅入深地学习一样东西 。\n\n如果你不关心目录是否存在，你可以决定跳过该目录检查,并且移 `$uri/`\n\n###[传递不受控制的请求给PHP]###\n很多 PHP web 站点的 Nginx 配置要求，每一个URI需要附带`.php`给 PHP 解释器，注意到这里有一个关于PHP设置的严重安全隐患，因为它允许第三方执行任意代码。\n\n比如\n\n```\nlocation ~* \\.php$ {\n  fastcgi_pass backend;\n  ...\n}\n```\n\n这里每一个关于.php的请求将会传给 `FastCGI` 后端，这是PHP默认配置，在不知道文件的具体路径下,试图通过该配置执行该文件。\n\n举个例子，如果请求 `/forum/avatar/1232.jpg/file.php`不存在， PHP 解释器将会返回 `forum/avatar/1232.jpg`，如果该文件有内嵌php代码，就会相应地被执行了。\n\n避免上述情况的配置选项是：\n\n* 设置 php.ini 里的 `cgi.fix_pathinfo=0`，该配置使得 php 解释器仅仅执行具体制定的文件，停止执行不存在的文件。\n* 确保 nginx 指定具体的php可执行文件\n\n```\nlocation ~* (file_a|file_b|file_c)\\.php$ {\n  fastcgi_pass backend;\n  ...\n}\n```\n* 禁止执行用户上传目录中的php文件 \n\n```\nlocation /uploaddir {\n  location ~ \\.php$ {return 403;}\n  ...\n}\n```\n\n* 使用 `try_files`指令，过滤掉有问题的条件\n\n```\nlocation ~* \\.php$ {\n  try_files $uri =404;\n  fastcgi_pass backend;\n  ...\n}\n```\n\n* 使用嵌套块过滤有问题的条件\n\n```\nlocation ~* \\.php$ {\n  location ~ \\..*/.*\\.php$ {return 404;}\n  fastcgi_pass backend;\n  ...\n}\n\n```\n\n###[脚本文件名中的 FastCGI 路径]###\n外界很多配置指引依靠绝对路径来获取你的信息，在PHP配置块内经常存在，当你从软件仓库中安装 nginx,他的配置文件中会有 \"include fastcgi_params\",该文件在 nginx 文件夹 /etc/nginx 的目录下。\n\n正确的配置\n\n```\nfastcgi_param  SCRIPT_FILENAME    $document_root$fastcgi_script_name;\n```\n\n不好的配置\n\n```\nfastcgi_param  SCRIPT_FILENAME    /var/www/yoursite.com/$fastcgi_script_name;\n```\n\n`$document_root` 在哪里呢？他在`server`块中`root`指令，如果你的`root` 指令配置不存在， 请回头看看 `第一个陷阱`。\n\n\n###[麻烦的重写]###\n不要感到沮丧，你很容易被正则表达式迷糊住。事实上，我们可以努力让配置干净简洁不添加毫不相干的东西。\n\n不好的配置\n\n```\nrewrite ^/(.*)$ http://domain.com/$1 permanent;\n```\n\n不好的配置\n\n```\nrewrite ^ http://domain.com$request_uri? permanent;\n```\n\n正确的配置\n\n```\nreturn 301 http://domain.com$request_uri;\n```\n\n反复看这几个例子，OK，第一个重写捕获斜线前完整的URI。通过使用内置的变量 `$request_uri` 我们可以有效地避免做任何捕获或匹配,并通过返回指令,我们可以完全避免对正则表达式的使用。\n\n\n###[重写时丢失`http://`]###\n很简单，重写都是相互关联的，除非你特意设置nginx。重写规则挺简单的，仅仅添加一条规则。\n\n不好的配置\n\n```\n rewrite ^/blog(/.*)$ blog.domain.com$1 permanent;\n```\n\n正确的配置\n\n```\nrewrite ^/blog(/.*)$ http://blog.domain.com$1 permanent;\n```\n\n上述看到的例子，我们仅仅是给该条规则添加了`http://`，便实现了重写，很简单，也很实用。\n\n###[代理一切]###\n\n不好的配置\n\n```\nserver {\n    server_name example.org;\n    root /var/www/site;\n \n    location / {\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_pass unix:/tmp/phpcgi.socket;\n    }\n}\n```\n\n这个例子中，你转发请求给php,如果是 apache 服务器会这么干。但是 nginx 服务器不需要这样做，`try_files`指令会按顺序检测文件。这意味着nginx可以首先寻找需要测试的静态文件，如果找不到才返回用户指定的文件。通过这样的方式，php解释器不会执行任意php文件，除非你拥有该请求路径的php文件，而且能帮你节约资源，特别是当你直接通过php请求一个大小为1MB的图片1千次。\n\n正确的配置\n\n```\nserver {\n    server_name example.org;\n    root /var/www/site;\n \n    location / {\n        try_files $uri $uri/ @proxy;\n    }\n \n    location @proxy {\n        include fastcgi.conf;\n        fastcgi_pass unix:/tmp/php-fpm.sock;\n    }\n}\n```\n\n或者\n\n```\nserver {\n    server_name example.org;\n    root /var/www/site;\n \n    location / {\n        try_files $uri $uri/ /index.php;\n    }\n \n    location ~ \\.php$ {\n        include fastcgi.conf;\n        fastcgi_pass unix:/tmp/php-fpm.sock;\n    }\n}\n```\n\n\n如果被请求的 URI 存在就可以被 nginx 返回，如果不存在，那么是否存在一个具有index文件的目录里，同时，我们是否已经为该请求配置上了 index 指令。如果仍然不存在，重写规则将发送`index.php`到你的后端，只有当nginx前端不能处理你的请求，才会让后端服务参与进来。\n\n想想有你的请求中有多少是静态资源，比如图片，css，javascript,我们可以通过上述方式的配置来节约这些资源。\n\n\n###[配置改变，并没有生效]###\n\n你的配置很完美，但是你依然捶胸顿足。问题出现在你的浏览器缓存上，当你加载一些东西，浏览器会保存下来，也会记住了它是如何请求服务的，如果你使用 `types{}`块，你会遇到如下问题。\n\n修复\n\n[选项1] 在火狐中按下 `Ctrl+Shift+Delet` ,检测缓存，并且清空。其他的浏览器自行搜索清空缓存的方法，每一次修改配置，记得清空缓存，除非你确认不需要这么做，这一步骤会帮你避免很多头痛。\n\n在火狐中，你也可以选择一个更长久的解决方法，在URI搜索条内，输入`about:config`,然后搜索 `browser.cache.check_doc_frequency` ，设置其值为1，这样没加载一次包就会检测。\n\n[选项2] 使用 `curl`\n如果还行不通，而且你是在`vritualbox` 虚拟机里面运行 nginx,那么，可能是 `sendfile()` 惹得祸，你只需要注释掉 sendfile 指令，或者将其设置为 `off`,这个指令在`nginx.conf`里。\n\n```\nsendfile off\n```\n\n###[HTTP头部丢失]###\n\n如果你没有显性设置 \n\n```\n underscores_in_headers on\n```\n\nnginx 将会默认用下划线去掉http头部（这符合http标准），这么做是为了防止在映射CGI头信息时候有歧义。这个过程中破折号和下划线都被映射成了下划线。\n","source":"_posts/2014-05-13-nginx-pitfall.markdown","raw":"---\nlayout: post\ntitle: \"[译]nginx pitfall\"\ndate: 2014-05-13 22:26\ncomments: true\ncategories: Server\nkeywords: Nginx pitfall\ndescription: Nginx pitfall\n---\n\n今天看完[Nginx Pitfall](http://wiki.nginx.org/Pitfalls),热血用了一个下午翻译了的，以下是正文\n\n##Nginx 陷阱##\n\n无论你是nginx的新用户还是老用户都会遇到nginx的一些陷阱，下面我们着重描述这些陷阱，以及如何避免犯错。这些问题多次出现在 #nginx channel on Freenode#上\n\n###[是指南教我这么做的]###\n\n不要轻易相信网上其他的配置指引，除非你知道这样做的真正意义，并且知道怎么清除它们。很多配置其实写的很糟糕，我们根据互联网上的错误配置收集到的陷阱，它们并非来自刻意搜索，而是来自网络上的疑惑问答，这些问题收到的共同回复是，他们因为看了一些错误配置指引所以不同意我们的方法。写此文的目的是为了阐述我们的观点，如果你也遇到如下问题，该文章正好为你准备。\n\n\n###[Root 放置在Location块内]###\n\n不好的配置\n\n```bash\nserver {\n  server_name www.domain.com;\n  location / {\n    root /var/www/nginx-default/;\n    [...]\n  }\n  location /foo {\n    root /var/www/nginx-default/;\n    [...]\n  }\n  location /bar {\n    root /var/www/nginx-default/;\n    [...]\n  }\n}\n```\n\n该配置可以正常工作，把 root 放在 location块内可以完美的运行，但是当你开始添加location快，你就发现问题了。如果你给每个loaction 块添加 root，一旦有一个 location 块没有匹配到,那么他就失去了 root ,让我们来看看正确的配置\n\n```\nserver {\n  server_name www.domain.com;\n  root /var/www/nginx-default/;\n  location / {\n    [...]\n  }\n  location /foo {\n    [...]\n  }\n  location /bar {\n    [...]\n  }\n}\n```\n\n###[多条 index 指令]###\n\n不好的配置\n\n```\nhttp {\n  index index.php index.htm index.html;\n  server {\n    server_name www.domain.com;\n    location / {\n      index index.php index.htm index.html;\n      [...]\n    }\n  }\n  server {\n    server_name domain.com;\n    location / {\n      index index.php index.htm index.html;\n      [...]\n    }\n    location /foo {\n      index index.php;\n      [...]\n    }\n  }\n}\n```\n\n为什么要重复多条不需要的 index 指令？事实上只需要用一次，它仅仅需要放置在 `http{}` 块内，后面的配置会继承它。\n\n正确的配置\n\n```\nhttp {\n  index index.php index.htm index.html;\n  server {\n    server_name www.domain.com;\n    location / {\n      [...]\n    }\n  }\n  server {\n    server_name domain.com;\n    location / {\n      [...]\n    }\n    location /foo {\n      [...]\n    }\n  }\n```\n\n###[使用if]###\n这里有小段篇幅是关于使用`if` 表达式，我们需要检查所谓的 “是否有害”，让我们看看那些错误的配置\n\n不好的配置\n\n```\nserver {\n  server_name domain.com *.domain.com;\n  if ($host ~* ^www\\.(.+)) {\n    set $raw_domain $1;\n    rewrite ^/(.*)$ $raw_domain/$1 permanent;\n    [...]\n  }\n}\n```\n这里明显有问题，第一条 `if` 指令就引起我们的注意，为什么是不好的配置呢, 你是否阅读过 [是否有害](http://wiki.nginx.org/IfIsEvil)。\n\n使用if 指令，nginx 会强制检查所有到来的请求，检测每一条指令是否有危害，这是极度低效的。使用两个 server 配置可以避免上述问题。\n\n正确的配置\n\n```\nserver {\n  server_name www.domain.com;\n  return 301 $scheme://domain.com$request_uri;\n}\nserver {\n  server_name domain.com;\n  [...]\n}\n```\n\n这种方法不仅是配置易读，而且降低了 nginx 的处理负担。我们摆脱了`if`指令的陷阱，我们也使用了 `$scheme` 代替了 URI scheme 是 http 还是 https 的硬编码.\n\n###[判断文件是否存在]###\n\n使用 `if` 指令确保文件是否存在，是糟糕的实践，如果你有机会接触较新的 nginx 版本，查看下`try_files` 指令，该指令更适合做该事情。\n\n不好的配置\n\n```\nserver {\n  root /var/www/domain.com;\n  location / {\n    if (!-f $request_filename) {\n      break;\n    }\n  }\n}\n```\n\n正确的配置\n\n```\nserver {\n  root /var/www/domain.com;\n  location / {\n    try_files $uri $uri/ /index.html;\n  }\n}\n```\n\n我们做的改变是，我们不使用`if`指令，而是使用 `try_files`,如果`$uri`不存在，尝试 `$uri/` 如果不存在，就使用默认的文件 `index.html`\n\n这个场景中，将会测试$uri是否存在，如果存在调用该服务，反之则会测试该目录是否存在，如果不存在就会调用 `index.html`，前提是`index.html`是存在的。这时候仅仅是简单的加载该页面。\n\n###[包的前端控制器模式]###\n\n“前端控制器模式”的设计很流行并广泛应用于 PHP 软件包，不乏很多比它更复杂的例子，使用 Drupal, Joomla 等，你只需要使用\n\n```\ntry_files $uri $uri/ /index.php?q=$uri&$args;\n```\n\n注意： - 参数名会依据你所使用的包不同而做相应的改变\n\n* `q`用于Drupal, Joomla, WordPress\n* `page` 用于CMS Made Simple\n\n一些软件甚至不需要查询字符串，可以通过`REQUEST_URI`获取（比如WordPress就支持）\n\n```\ntry_files $uri $uri/ /index.php;\n```\n\n当然，你的情况可能有所不一样，你可能需要更复杂的配置。对于简单的站点，该配置已经完美的支持，通常我们都是由浅入深地学习一样东西 。\n\n如果你不关心目录是否存在，你可以决定跳过该目录检查,并且移 `$uri/`\n\n###[传递不受控制的请求给PHP]###\n很多 PHP web 站点的 Nginx 配置要求，每一个URI需要附带`.php`给 PHP 解释器，注意到这里有一个关于PHP设置的严重安全隐患，因为它允许第三方执行任意代码。\n\n比如\n\n```\nlocation ~* \\.php$ {\n  fastcgi_pass backend;\n  ...\n}\n```\n\n这里每一个关于.php的请求将会传给 `FastCGI` 后端，这是PHP默认配置，在不知道文件的具体路径下,试图通过该配置执行该文件。\n\n举个例子，如果请求 `/forum/avatar/1232.jpg/file.php`不存在， PHP 解释器将会返回 `forum/avatar/1232.jpg`，如果该文件有内嵌php代码，就会相应地被执行了。\n\n避免上述情况的配置选项是：\n\n* 设置 php.ini 里的 `cgi.fix_pathinfo=0`，该配置使得 php 解释器仅仅执行具体制定的文件，停止执行不存在的文件。\n* 确保 nginx 指定具体的php可执行文件\n\n```\nlocation ~* (file_a|file_b|file_c)\\.php$ {\n  fastcgi_pass backend;\n  ...\n}\n```\n* 禁止执行用户上传目录中的php文件 \n\n```\nlocation /uploaddir {\n  location ~ \\.php$ {return 403;}\n  ...\n}\n```\n\n* 使用 `try_files`指令，过滤掉有问题的条件\n\n```\nlocation ~* \\.php$ {\n  try_files $uri =404;\n  fastcgi_pass backend;\n  ...\n}\n```\n\n* 使用嵌套块过滤有问题的条件\n\n```\nlocation ~* \\.php$ {\n  location ~ \\..*/.*\\.php$ {return 404;}\n  fastcgi_pass backend;\n  ...\n}\n\n```\n\n###[脚本文件名中的 FastCGI 路径]###\n外界很多配置指引依靠绝对路径来获取你的信息，在PHP配置块内经常存在，当你从软件仓库中安装 nginx,他的配置文件中会有 \"include fastcgi_params\",该文件在 nginx 文件夹 /etc/nginx 的目录下。\n\n正确的配置\n\n```\nfastcgi_param  SCRIPT_FILENAME    $document_root$fastcgi_script_name;\n```\n\n不好的配置\n\n```\nfastcgi_param  SCRIPT_FILENAME    /var/www/yoursite.com/$fastcgi_script_name;\n```\n\n`$document_root` 在哪里呢？他在`server`块中`root`指令，如果你的`root` 指令配置不存在， 请回头看看 `第一个陷阱`。\n\n\n###[麻烦的重写]###\n不要感到沮丧，你很容易被正则表达式迷糊住。事实上，我们可以努力让配置干净简洁不添加毫不相干的东西。\n\n不好的配置\n\n```\nrewrite ^/(.*)$ http://domain.com/$1 permanent;\n```\n\n不好的配置\n\n```\nrewrite ^ http://domain.com$request_uri? permanent;\n```\n\n正确的配置\n\n```\nreturn 301 http://domain.com$request_uri;\n```\n\n反复看这几个例子，OK，第一个重写捕获斜线前完整的URI。通过使用内置的变量 `$request_uri` 我们可以有效地避免做任何捕获或匹配,并通过返回指令,我们可以完全避免对正则表达式的使用。\n\n\n###[重写时丢失`http://`]###\n很简单，重写都是相互关联的，除非你特意设置nginx。重写规则挺简单的，仅仅添加一条规则。\n\n不好的配置\n\n```\n rewrite ^/blog(/.*)$ blog.domain.com$1 permanent;\n```\n\n正确的配置\n\n```\nrewrite ^/blog(/.*)$ http://blog.domain.com$1 permanent;\n```\n\n上述看到的例子，我们仅仅是给该条规则添加了`http://`，便实现了重写，很简单，也很实用。\n\n###[代理一切]###\n\n不好的配置\n\n```\nserver {\n    server_name example.org;\n    root /var/www/site;\n \n    location / {\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_pass unix:/tmp/phpcgi.socket;\n    }\n}\n```\n\n这个例子中，你转发请求给php,如果是 apache 服务器会这么干。但是 nginx 服务器不需要这样做，`try_files`指令会按顺序检测文件。这意味着nginx可以首先寻找需要测试的静态文件，如果找不到才返回用户指定的文件。通过这样的方式，php解释器不会执行任意php文件，除非你拥有该请求路径的php文件，而且能帮你节约资源，特别是当你直接通过php请求一个大小为1MB的图片1千次。\n\n正确的配置\n\n```\nserver {\n    server_name example.org;\n    root /var/www/site;\n \n    location / {\n        try_files $uri $uri/ @proxy;\n    }\n \n    location @proxy {\n        include fastcgi.conf;\n        fastcgi_pass unix:/tmp/php-fpm.sock;\n    }\n}\n```\n\n或者\n\n```\nserver {\n    server_name example.org;\n    root /var/www/site;\n \n    location / {\n        try_files $uri $uri/ /index.php;\n    }\n \n    location ~ \\.php$ {\n        include fastcgi.conf;\n        fastcgi_pass unix:/tmp/php-fpm.sock;\n    }\n}\n```\n\n\n如果被请求的 URI 存在就可以被 nginx 返回，如果不存在，那么是否存在一个具有index文件的目录里，同时，我们是否已经为该请求配置上了 index 指令。如果仍然不存在，重写规则将发送`index.php`到你的后端，只有当nginx前端不能处理你的请求，才会让后端服务参与进来。\n\n想想有你的请求中有多少是静态资源，比如图片，css，javascript,我们可以通过上述方式的配置来节约这些资源。\n\n\n###[配置改变，并没有生效]###\n\n你的配置很完美，但是你依然捶胸顿足。问题出现在你的浏览器缓存上，当你加载一些东西，浏览器会保存下来，也会记住了它是如何请求服务的，如果你使用 `types{}`块，你会遇到如下问题。\n\n修复\n\n[选项1] 在火狐中按下 `Ctrl+Shift+Delet` ,检测缓存，并且清空。其他的浏览器自行搜索清空缓存的方法，每一次修改配置，记得清空缓存，除非你确认不需要这么做，这一步骤会帮你避免很多头痛。\n\n在火狐中，你也可以选择一个更长久的解决方法，在URI搜索条内，输入`about:config`,然后搜索 `browser.cache.check_doc_frequency` ，设置其值为1，这样没加载一次包就会检测。\n\n[选项2] 使用 `curl`\n如果还行不通，而且你是在`vritualbox` 虚拟机里面运行 nginx,那么，可能是 `sendfile()` 惹得祸，你只需要注释掉 sendfile 指令，或者将其设置为 `off`,这个指令在`nginx.conf`里。\n\n```\nsendfile off\n```\n\n###[HTTP头部丢失]###\n\n如果你没有显性设置 \n\n```\n underscores_in_headers on\n```\n\nnginx 将会默认用下划线去掉http头部（这符合http标准），这么做是为了防止在映射CGI头信息时候有歧义。这个过程中破折号和下划线都被映射成了下划线。\n","slug":"2014-05-13-nginx-pitfall","published":1,"updated":"2018-06-17T10:38:56.000Z","photos":[],"link":"","_id":"cjijzgdfh005gnctj4ezb1if8","content":"<p>今天看完<a href=\"http://wiki.nginx.org/Pitfalls\" target=\"_blank\" rel=\"noopener\">Nginx Pitfall</a>,热血用了一个下午翻译了的，以下是正文</p>\n<p>##Nginx 陷阱##</p>\n<p>无论你是nginx的新用户还是老用户都会遇到nginx的一些陷阱，下面我们着重描述这些陷阱，以及如何避免犯错。这些问题多次出现在 #nginx channel on Freenode#上</p>\n<p>###[是指南教我这么做的]###</p>\n<p>不要轻易相信网上其他的配置指引，除非你知道这样做的真正意义，并且知道怎么清除它们。很多配置其实写的很糟糕，我们根据互联网上的错误配置收集到的陷阱，它们并非来自刻意搜索，而是来自网络上的疑惑问答，这些问题收到的共同回复是，他们因为看了一些错误配置指引所以不同意我们的方法。写此文的目的是为了阐述我们的观点，如果你也遇到如下问题，该文章正好为你准备。</p>\n<p>###[Root 放置在Location块内]###</p>\n<p>不好的配置</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name www.domain.com;</span><br><span class=\"line\">  location / &#123;</span><br><span class=\"line\">    root /var/www/nginx-default/;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  location /foo &#123;</span><br><span class=\"line\">    root /var/www/nginx-default/;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  location /bar &#123;</span><br><span class=\"line\">    root /var/www/nginx-default/;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>该配置可以正常工作，把 root 放在 location块内可以完美的运行，但是当你开始添加location快，你就发现问题了。如果你给每个loaction 块添加 root，一旦有一个 location 块没有匹配到,那么他就失去了 root ,让我们来看看正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name www.domain.com;</span><br><span class=\"line\">  root /var/www/nginx-default/;</span><br><span class=\"line\">  location / &#123;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  location /foo &#123;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  location /bar &#123;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>###[多条 index 指令]###</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http &#123;</span><br><span class=\"line\">  index index.php index.htm index.html;</span><br><span class=\"line\">  server &#123;</span><br><span class=\"line\">    server_name www.domain.com;</span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">      index index.php index.htm index.html;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  server &#123;</span><br><span class=\"line\">    server_name domain.com;</span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">      index index.php index.htm index.html;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    location /foo &#123;</span><br><span class=\"line\">      index index.php;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>为什么要重复多条不需要的 index 指令？事实上只需要用一次，它仅仅需要放置在 <code>http{}</code> 块内，后面的配置会继承它。</p>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http &#123;</span><br><span class=\"line\">  index index.php index.htm index.html;</span><br><span class=\"line\">  server &#123;</span><br><span class=\"line\">    server_name www.domain.com;</span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  server &#123;</span><br><span class=\"line\">    server_name domain.com;</span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    location /foo &#123;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n<p>###[使用if]###<br>这里有小段篇幅是关于使用<code>if</code> 表达式，我们需要检查所谓的 “是否有害”，让我们看看那些错误的配置</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name domain.com *.domain.com;</span><br><span class=\"line\">  if ($host ~* ^www\\.(.+)) &#123;</span><br><span class=\"line\">    set $raw_domain $1;</span><br><span class=\"line\">    rewrite ^/(.*)$ $raw_domain/$1 permanent;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里明显有问题，第一条 <code>if</code> 指令就引起我们的注意，为什么是不好的配置呢, 你是否阅读过 <a href=\"http://wiki.nginx.org/IfIsEvil\" target=\"_blank\" rel=\"noopener\">是否有害</a>。</p>\n<p>使用if 指令，nginx 会强制检查所有到来的请求，检测每一条指令是否有危害，这是极度低效的。使用两个 server 配置可以避免上述问题。</p>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name www.domain.com;</span><br><span class=\"line\">  return 301 $scheme://domain.com$request_uri;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name domain.com;</span><br><span class=\"line\">  [...]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这种方法不仅是配置易读，而且降低了 nginx 的处理负担。我们摆脱了<code>if</code>指令的陷阱，我们也使用了 <code>$scheme</code> 代替了 URI scheme 是 http 还是 https 的硬编码.</p>\n<p>###[判断文件是否存在]###</p>\n<p>使用 <code>if</code> 指令确保文件是否存在，是糟糕的实践，如果你有机会接触较新的 nginx 版本，查看下<code>try_files</code> 指令，该指令更适合做该事情。</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  root /var/www/domain.com;</span><br><span class=\"line\">  location / &#123;</span><br><span class=\"line\">    if (!-f $request_filename) &#123;</span><br><span class=\"line\">      break;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  root /var/www/domain.com;</span><br><span class=\"line\">  location / &#123;</span><br><span class=\"line\">    try_files $uri $uri/ /index.html;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>我们做的改变是，我们不使用<code>if</code>指令，而是使用 <code>try_files</code>,如果<code>$uri</code>不存在，尝试 <code>$uri/</code> 如果不存在，就使用默认的文件 <code>index.html</code></p>\n<p>这个场景中，将会测试$uri是否存在，如果存在调用该服务，反之则会测试该目录是否存在，如果不存在就会调用 <code>index.html</code>，前提是<code>index.html</code>是存在的。这时候仅仅是简单的加载该页面。</p>\n<p>###[包的前端控制器模式]###</p>\n<p>“前端控制器模式”的设计很流行并广泛应用于 PHP 软件包，不乏很多比它更复杂的例子，使用 Drupal, Joomla 等，你只需要使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">try_files $uri $uri/ /index.php?q=$uri&amp;$args;</span><br></pre></td></tr></table></figure>\n<p>注意： - 参数名会依据你所使用的包不同而做相应的改变</p>\n<ul>\n<li><code>q</code>用于Drupal, Joomla, WordPress</li>\n<li><code>page</code> 用于CMS Made Simple</li>\n</ul>\n<p>一些软件甚至不需要查询字符串，可以通过<code>REQUEST_URI</code>获取（比如WordPress就支持）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">try_files $uri $uri/ /index.php;</span><br></pre></td></tr></table></figure>\n<p>当然，你的情况可能有所不一样，你可能需要更复杂的配置。对于简单的站点，该配置已经完美的支持，通常我们都是由浅入深地学习一样东西 。</p>\n<p>如果你不关心目录是否存在，你可以决定跳过该目录检查,并且移 <code>$uri/</code></p>\n<p>###[传递不受控制的请求给PHP]###<br>很多 PHP web 站点的 Nginx 配置要求，每一个URI需要附带<code>.php</code>给 PHP 解释器，注意到这里有一个关于PHP设置的严重安全隐患，因为它允许第三方执行任意代码。</p>\n<p>比如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~* \\.php$ &#123;</span><br><span class=\"line\">  fastcgi_pass backend;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里每一个关于.php的请求将会传给 <code>FastCGI</code> 后端，这是PHP默认配置，在不知道文件的具体路径下,试图通过该配置执行该文件。</p>\n<p>举个例子，如果请求 <code>/forum/avatar/1232.jpg/file.php</code>不存在， PHP 解释器将会返回 <code>forum/avatar/1232.jpg</code>，如果该文件有内嵌php代码，就会相应地被执行了。</p>\n<p>避免上述情况的配置选项是：</p>\n<ul>\n<li>设置 php.ini 里的 <code>cgi.fix_pathinfo=0</code>，该配置使得 php 解释器仅仅执行具体制定的文件，停止执行不存在的文件。</li>\n<li>确保 nginx 指定具体的php可执行文件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~* (file_a|file_b|file_c)\\.php$ &#123;</span><br><span class=\"line\">  fastcgi_pass backend;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>禁止执行用户上传目录中的php文件 </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /uploaddir &#123;</span><br><span class=\"line\">  location ~ \\.php$ &#123;return 403;&#125;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>使用 <code>try_files</code>指令，过滤掉有问题的条件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~* \\.php$ &#123;</span><br><span class=\"line\">  try_files $uri =404;</span><br><span class=\"line\">  fastcgi_pass backend;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>使用嵌套块过滤有问题的条件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~* \\.php$ &#123;</span><br><span class=\"line\">  location ~ \\..*/.*\\.php$ &#123;return 404;&#125;</span><br><span class=\"line\">  fastcgi_pass backend;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>###[脚本文件名中的 FastCGI 路径]###<br>外界很多配置指引依靠绝对路径来获取你的信息，在PHP配置块内经常存在，当你从软件仓库中安装 nginx,他的配置文件中会有 “include fastcgi_params”,该文件在 nginx 文件夹 /etc/nginx 的目录下。</p>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fastcgi_param  SCRIPT_FILENAME    $document_root$fastcgi_script_name;</span><br></pre></td></tr></table></figure>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fastcgi_param  SCRIPT_FILENAME    /var/www/yoursite.com/$fastcgi_script_name;</span><br></pre></td></tr></table></figure>\n<p><code>$document_root</code> 在哪里呢？他在<code>server</code>块中<code>root</code>指令，如果你的<code>root</code> 指令配置不存在， 请回头看看 <code>第一个陷阱</code>。</p>\n<p>###[麻烦的重写]###<br>不要感到沮丧，你很容易被正则表达式迷糊住。事实上，我们可以努力让配置干净简洁不添加毫不相干的东西。</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rewrite ^/(.*)$ http://domain.com/$1 permanent;</span><br></pre></td></tr></table></figure>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rewrite ^ http://domain.com$request_uri? permanent;</span><br></pre></td></tr></table></figure>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return 301 http://domain.com$request_uri;</span><br></pre></td></tr></table></figure>\n<p>反复看这几个例子，OK，第一个重写捕获斜线前完整的URI。通过使用内置的变量 <code>$request_uri</code> 我们可以有效地避免做任何捕获或匹配,并通过返回指令,我们可以完全避免对正则表达式的使用。</p>\n<p>###[重写时丢失<code>http://</code>]###<br>很简单，重写都是相互关联的，除非你特意设置nginx。重写规则挺简单的，仅仅添加一条规则。</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rewrite ^/blog(/.*)$ blog.domain.com$1 permanent;</span><br></pre></td></tr></table></figure>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rewrite ^/blog(/.*)$ http://blog.domain.com$1 permanent;</span><br></pre></td></tr></table></figure>\n<p>上述看到的例子，我们仅仅是给该条规则添加了<code>http://</code>，便实现了重写，很简单，也很实用。</p>\n<p>###[代理一切]###</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">    server_name example.org;</span><br><span class=\"line\">    root /var/www/site;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">        include fastcgi_params;</span><br><span class=\"line\">        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;</span><br><span class=\"line\">        fastcgi_pass unix:/tmp/phpcgi.socket;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这个例子中，你转发请求给php,如果是 apache 服务器会这么干。但是 nginx 服务器不需要这样做，<code>try_files</code>指令会按顺序检测文件。这意味着nginx可以首先寻找需要测试的静态文件，如果找不到才返回用户指定的文件。通过这样的方式，php解释器不会执行任意php文件，除非你拥有该请求路径的php文件，而且能帮你节约资源，特别是当你直接通过php请求一个大小为1MB的图片1千次。</p>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">    server_name example.org;</span><br><span class=\"line\">    root /var/www/site;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">        try_files $uri $uri/ @proxy;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location @proxy &#123;</span><br><span class=\"line\">        include fastcgi.conf;</span><br><span class=\"line\">        fastcgi_pass unix:/tmp/php-fpm.sock;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>或者</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">    server_name example.org;</span><br><span class=\"line\">    root /var/www/site;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">        try_files $uri $uri/ /index.php;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location ~ \\.php$ &#123;</span><br><span class=\"line\">        include fastcgi.conf;</span><br><span class=\"line\">        fastcgi_pass unix:/tmp/php-fpm.sock;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果被请求的 URI 存在就可以被 nginx 返回，如果不存在，那么是否存在一个具有index文件的目录里，同时，我们是否已经为该请求配置上了 index 指令。如果仍然不存在，重写规则将发送<code>index.php</code>到你的后端，只有当nginx前端不能处理你的请求，才会让后端服务参与进来。</p>\n<p>想想有你的请求中有多少是静态资源，比如图片，css，javascript,我们可以通过上述方式的配置来节约这些资源。</p>\n<p>###[配置改变，并没有生效]###</p>\n<p>你的配置很完美，但是你依然捶胸顿足。问题出现在你的浏览器缓存上，当你加载一些东西，浏览器会保存下来，也会记住了它是如何请求服务的，如果你使用 <code>types{}</code>块，你会遇到如下问题。</p>\n<p>修复</p>\n<p>[选项1] 在火狐中按下 <code>Ctrl+Shift+Delet</code> ,检测缓存，并且清空。其他的浏览器自行搜索清空缓存的方法，每一次修改配置，记得清空缓存，除非你确认不需要这么做，这一步骤会帮你避免很多头痛。</p>\n<p>在火狐中，你也可以选择一个更长久的解决方法，在URI搜索条内，输入<code>about:config</code>,然后搜索 <code>browser.cache.check_doc_frequency</code> ，设置其值为1，这样没加载一次包就会检测。</p>\n<p>[选项2] 使用 <code>curl</code><br>如果还行不通，而且你是在<code>vritualbox</code> 虚拟机里面运行 nginx,那么，可能是 <code>sendfile()</code> 惹得祸，你只需要注释掉 sendfile 指令，或者将其设置为 <code>off</code>,这个指令在<code>nginx.conf</code>里。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sendfile off</span><br></pre></td></tr></table></figure>\n<p>###[HTTP头部丢失]###</p>\n<p>如果你没有显性设置 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">underscores_in_headers on</span><br></pre></td></tr></table></figure>\n<p>nginx 将会默认用下划线去掉http头部（这符合http标准），这么做是为了防止在映射CGI头信息时候有歧义。这个过程中破折号和下划线都被映射成了下划线。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>今天看完<a href=\"http://wiki.nginx.org/Pitfalls\" target=\"_blank\" rel=\"noopener\">Nginx Pitfall</a>,热血用了一个下午翻译了的，以下是正文</p>\n<p>##Nginx 陷阱##</p>\n<p>无论你是nginx的新用户还是老用户都会遇到nginx的一些陷阱，下面我们着重描述这些陷阱，以及如何避免犯错。这些问题多次出现在 #nginx channel on Freenode#上</p>\n<p>###[是指南教我这么做的]###</p>\n<p>不要轻易相信网上其他的配置指引，除非你知道这样做的真正意义，并且知道怎么清除它们。很多配置其实写的很糟糕，我们根据互联网上的错误配置收集到的陷阱，它们并非来自刻意搜索，而是来自网络上的疑惑问答，这些问题收到的共同回复是，他们因为看了一些错误配置指引所以不同意我们的方法。写此文的目的是为了阐述我们的观点，如果你也遇到如下问题，该文章正好为你准备。</p>\n<p>###[Root 放置在Location块内]###</p>\n<p>不好的配置</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name www.domain.com;</span><br><span class=\"line\">  location / &#123;</span><br><span class=\"line\">    root /var/www/nginx-default/;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  location /foo &#123;</span><br><span class=\"line\">    root /var/www/nginx-default/;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  location /bar &#123;</span><br><span class=\"line\">    root /var/www/nginx-default/;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>该配置可以正常工作，把 root 放在 location块内可以完美的运行，但是当你开始添加location快，你就发现问题了。如果你给每个loaction 块添加 root，一旦有一个 location 块没有匹配到,那么他就失去了 root ,让我们来看看正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name www.domain.com;</span><br><span class=\"line\">  root /var/www/nginx-default/;</span><br><span class=\"line\">  location / &#123;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  location /foo &#123;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  location /bar &#123;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>###[多条 index 指令]###</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http &#123;</span><br><span class=\"line\">  index index.php index.htm index.html;</span><br><span class=\"line\">  server &#123;</span><br><span class=\"line\">    server_name www.domain.com;</span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">      index index.php index.htm index.html;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  server &#123;</span><br><span class=\"line\">    server_name domain.com;</span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">      index index.php index.htm index.html;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    location /foo &#123;</span><br><span class=\"line\">      index index.php;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>为什么要重复多条不需要的 index 指令？事实上只需要用一次，它仅仅需要放置在 <code>http{}</code> 块内，后面的配置会继承它。</p>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http &#123;</span><br><span class=\"line\">  index index.php index.htm index.html;</span><br><span class=\"line\">  server &#123;</span><br><span class=\"line\">    server_name www.domain.com;</span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  server &#123;</span><br><span class=\"line\">    server_name domain.com;</span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    location /foo &#123;</span><br><span class=\"line\">      [...]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n<p>###[使用if]###<br>这里有小段篇幅是关于使用<code>if</code> 表达式，我们需要检查所谓的 “是否有害”，让我们看看那些错误的配置</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name domain.com *.domain.com;</span><br><span class=\"line\">  if ($host ~* ^www\\.(.+)) &#123;</span><br><span class=\"line\">    set $raw_domain $1;</span><br><span class=\"line\">    rewrite ^/(.*)$ $raw_domain/$1 permanent;</span><br><span class=\"line\">    [...]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里明显有问题，第一条 <code>if</code> 指令就引起我们的注意，为什么是不好的配置呢, 你是否阅读过 <a href=\"http://wiki.nginx.org/IfIsEvil\" target=\"_blank\" rel=\"noopener\">是否有害</a>。</p>\n<p>使用if 指令，nginx 会强制检查所有到来的请求，检测每一条指令是否有危害，这是极度低效的。使用两个 server 配置可以避免上述问题。</p>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name www.domain.com;</span><br><span class=\"line\">  return 301 $scheme://domain.com$request_uri;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">  server_name domain.com;</span><br><span class=\"line\">  [...]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这种方法不仅是配置易读，而且降低了 nginx 的处理负担。我们摆脱了<code>if</code>指令的陷阱，我们也使用了 <code>$scheme</code> 代替了 URI scheme 是 http 还是 https 的硬编码.</p>\n<p>###[判断文件是否存在]###</p>\n<p>使用 <code>if</code> 指令确保文件是否存在，是糟糕的实践，如果你有机会接触较新的 nginx 版本，查看下<code>try_files</code> 指令，该指令更适合做该事情。</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  root /var/www/domain.com;</span><br><span class=\"line\">  location / &#123;</span><br><span class=\"line\">    if (!-f $request_filename) &#123;</span><br><span class=\"line\">      break;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">  root /var/www/domain.com;</span><br><span class=\"line\">  location / &#123;</span><br><span class=\"line\">    try_files $uri $uri/ /index.html;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>我们做的改变是，我们不使用<code>if</code>指令，而是使用 <code>try_files</code>,如果<code>$uri</code>不存在，尝试 <code>$uri/</code> 如果不存在，就使用默认的文件 <code>index.html</code></p>\n<p>这个场景中，将会测试$uri是否存在，如果存在调用该服务，反之则会测试该目录是否存在，如果不存在就会调用 <code>index.html</code>，前提是<code>index.html</code>是存在的。这时候仅仅是简单的加载该页面。</p>\n<p>###[包的前端控制器模式]###</p>\n<p>“前端控制器模式”的设计很流行并广泛应用于 PHP 软件包，不乏很多比它更复杂的例子，使用 Drupal, Joomla 等，你只需要使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">try_files $uri $uri/ /index.php?q=$uri&amp;$args;</span><br></pre></td></tr></table></figure>\n<p>注意： - 参数名会依据你所使用的包不同而做相应的改变</p>\n<ul>\n<li><code>q</code>用于Drupal, Joomla, WordPress</li>\n<li><code>page</code> 用于CMS Made Simple</li>\n</ul>\n<p>一些软件甚至不需要查询字符串，可以通过<code>REQUEST_URI</code>获取（比如WordPress就支持）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">try_files $uri $uri/ /index.php;</span><br></pre></td></tr></table></figure>\n<p>当然，你的情况可能有所不一样，你可能需要更复杂的配置。对于简单的站点，该配置已经完美的支持，通常我们都是由浅入深地学习一样东西 。</p>\n<p>如果你不关心目录是否存在，你可以决定跳过该目录检查,并且移 <code>$uri/</code></p>\n<p>###[传递不受控制的请求给PHP]###<br>很多 PHP web 站点的 Nginx 配置要求，每一个URI需要附带<code>.php</code>给 PHP 解释器，注意到这里有一个关于PHP设置的严重安全隐患，因为它允许第三方执行任意代码。</p>\n<p>比如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~* \\.php$ &#123;</span><br><span class=\"line\">  fastcgi_pass backend;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里每一个关于.php的请求将会传给 <code>FastCGI</code> 后端，这是PHP默认配置，在不知道文件的具体路径下,试图通过该配置执行该文件。</p>\n<p>举个例子，如果请求 <code>/forum/avatar/1232.jpg/file.php</code>不存在， PHP 解释器将会返回 <code>forum/avatar/1232.jpg</code>，如果该文件有内嵌php代码，就会相应地被执行了。</p>\n<p>避免上述情况的配置选项是：</p>\n<ul>\n<li>设置 php.ini 里的 <code>cgi.fix_pathinfo=0</code>，该配置使得 php 解释器仅仅执行具体制定的文件，停止执行不存在的文件。</li>\n<li>确保 nginx 指定具体的php可执行文件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~* (file_a|file_b|file_c)\\.php$ &#123;</span><br><span class=\"line\">  fastcgi_pass backend;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>禁止执行用户上传目录中的php文件 </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location /uploaddir &#123;</span><br><span class=\"line\">  location ~ \\.php$ &#123;return 403;&#125;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>使用 <code>try_files</code>指令，过滤掉有问题的条件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~* \\.php$ &#123;</span><br><span class=\"line\">  try_files $uri =404;</span><br><span class=\"line\">  fastcgi_pass backend;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>使用嵌套块过滤有问题的条件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~* \\.php$ &#123;</span><br><span class=\"line\">  location ~ \\..*/.*\\.php$ &#123;return 404;&#125;</span><br><span class=\"line\">  fastcgi_pass backend;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>###[脚本文件名中的 FastCGI 路径]###<br>外界很多配置指引依靠绝对路径来获取你的信息，在PHP配置块内经常存在，当你从软件仓库中安装 nginx,他的配置文件中会有 “include fastcgi_params”,该文件在 nginx 文件夹 /etc/nginx 的目录下。</p>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fastcgi_param  SCRIPT_FILENAME    $document_root$fastcgi_script_name;</span><br></pre></td></tr></table></figure>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fastcgi_param  SCRIPT_FILENAME    /var/www/yoursite.com/$fastcgi_script_name;</span><br></pre></td></tr></table></figure>\n<p><code>$document_root</code> 在哪里呢？他在<code>server</code>块中<code>root</code>指令，如果你的<code>root</code> 指令配置不存在， 请回头看看 <code>第一个陷阱</code>。</p>\n<p>###[麻烦的重写]###<br>不要感到沮丧，你很容易被正则表达式迷糊住。事实上，我们可以努力让配置干净简洁不添加毫不相干的东西。</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rewrite ^/(.*)$ http://domain.com/$1 permanent;</span><br></pre></td></tr></table></figure>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rewrite ^ http://domain.com$request_uri? permanent;</span><br></pre></td></tr></table></figure>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return 301 http://domain.com$request_uri;</span><br></pre></td></tr></table></figure>\n<p>反复看这几个例子，OK，第一个重写捕获斜线前完整的URI。通过使用内置的变量 <code>$request_uri</code> 我们可以有效地避免做任何捕获或匹配,并通过返回指令,我们可以完全避免对正则表达式的使用。</p>\n<p>###[重写时丢失<code>http://</code>]###<br>很简单，重写都是相互关联的，除非你特意设置nginx。重写规则挺简单的，仅仅添加一条规则。</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rewrite ^/blog(/.*)$ blog.domain.com$1 permanent;</span><br></pre></td></tr></table></figure>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rewrite ^/blog(/.*)$ http://blog.domain.com$1 permanent;</span><br></pre></td></tr></table></figure>\n<p>上述看到的例子，我们仅仅是给该条规则添加了<code>http://</code>，便实现了重写，很简单，也很实用。</p>\n<p>###[代理一切]###</p>\n<p>不好的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">    server_name example.org;</span><br><span class=\"line\">    root /var/www/site;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">        include fastcgi_params;</span><br><span class=\"line\">        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;</span><br><span class=\"line\">        fastcgi_pass unix:/tmp/phpcgi.socket;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这个例子中，你转发请求给php,如果是 apache 服务器会这么干。但是 nginx 服务器不需要这样做，<code>try_files</code>指令会按顺序检测文件。这意味着nginx可以首先寻找需要测试的静态文件，如果找不到才返回用户指定的文件。通过这样的方式，php解释器不会执行任意php文件，除非你拥有该请求路径的php文件，而且能帮你节约资源，特别是当你直接通过php请求一个大小为1MB的图片1千次。</p>\n<p>正确的配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">    server_name example.org;</span><br><span class=\"line\">    root /var/www/site;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">        try_files $uri $uri/ @proxy;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location @proxy &#123;</span><br><span class=\"line\">        include fastcgi.conf;</span><br><span class=\"line\">        fastcgi_pass unix:/tmp/php-fpm.sock;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>或者</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">    server_name example.org;</span><br><span class=\"line\">    root /var/www/site;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">        try_files $uri $uri/ /index.php;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">    location ~ \\.php$ &#123;</span><br><span class=\"line\">        include fastcgi.conf;</span><br><span class=\"line\">        fastcgi_pass unix:/tmp/php-fpm.sock;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果被请求的 URI 存在就可以被 nginx 返回，如果不存在，那么是否存在一个具有index文件的目录里，同时，我们是否已经为该请求配置上了 index 指令。如果仍然不存在，重写规则将发送<code>index.php</code>到你的后端，只有当nginx前端不能处理你的请求，才会让后端服务参与进来。</p>\n<p>想想有你的请求中有多少是静态资源，比如图片，css，javascript,我们可以通过上述方式的配置来节约这些资源。</p>\n<p>###[配置改变，并没有生效]###</p>\n<p>你的配置很完美，但是你依然捶胸顿足。问题出现在你的浏览器缓存上，当你加载一些东西，浏览器会保存下来，也会记住了它是如何请求服务的，如果你使用 <code>types{}</code>块，你会遇到如下问题。</p>\n<p>修复</p>\n<p>[选项1] 在火狐中按下 <code>Ctrl+Shift+Delet</code> ,检测缓存，并且清空。其他的浏览器自行搜索清空缓存的方法，每一次修改配置，记得清空缓存，除非你确认不需要这么做，这一步骤会帮你避免很多头痛。</p>\n<p>在火狐中，你也可以选择一个更长久的解决方法，在URI搜索条内，输入<code>about:config</code>,然后搜索 <code>browser.cache.check_doc_frequency</code> ，设置其值为1，这样没加载一次包就会检测。</p>\n<p>[选项2] 使用 <code>curl</code><br>如果还行不通，而且你是在<code>vritualbox</code> 虚拟机里面运行 nginx,那么，可能是 <code>sendfile()</code> 惹得祸，你只需要注释掉 sendfile 指令，或者将其设置为 <code>off</code>,这个指令在<code>nginx.conf</code>里。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sendfile off</span><br></pre></td></tr></table></figure>\n<p>###[HTTP头部丢失]###</p>\n<p>如果你没有显性设置 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">underscores_in_headers on</span><br></pre></td></tr></table></figure>\n<p>nginx 将会默认用下划线去掉http头部（这符合http标准），这么做是为了防止在映射CGI头信息时候有歧义。这个过程中破折号和下划线都被映射成了下划线。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjijzgd810006nctjsh3nm26t","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd86000bnctj6rxhjw60"},{"post_id":"cjijzgd7r0001nctjss1s50kk","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd88000enctjy6c8gh6q"},{"post_id":"cjijzgd830009nctjl44xz8ui","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgd8a000gnctja5btq5x8"},{"post_id":"cjijzgd7w0003nctjtaye4kcx","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgd8c000jnctjsc0ybrxy"},{"post_id":"cjijzgd87000dnctjljmt75ep","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd8e000lnctj2a2sh601"},{"post_id":"cjijzgd7z0005nctjo6ou3n9e","category_id":"cjijzgd86000cnctjo7cenkey","_id":"cjijzgd8f000onctj9ust6dpj"},{"post_id":"cjijzgd820007nctjn4ielrbb","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgd8h000qnctjzc4oj7o6"},{"post_id":"cjijzgd8f000nnctjifkzbyrt","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd8j000unctj8b0ljux1"},{"post_id":"cjijzgd85000anctjkwhp974g","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd8k000wnctj9ci16gjy"},{"post_id":"cjijzgd8g000pnctjjmu4ssic","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd8l000znctj7pf01q31"},{"post_id":"cjijzgd8i000tnctjm668omms","category_id":"cjijzgd8h000rnctjbs04cf06","_id":"cjijzgd8m0011nctjdt1my9fz"},{"post_id":"cjijzgd89000fnctj03gam2le","category_id":"cjijzgd8h000rnctjbs04cf06","_id":"cjijzgd8n0014nctj40cuzrhf"},{"post_id":"cjijzgd8j000vnctjhf66mq92","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd8p0016nctj4pbb75t1"},{"post_id":"cjijzgd8l000ynctj4hgranwb","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgd8q0019nctjswcyb7vg"},{"post_id":"cjijzgd8b000inctjb033fsxj","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd8r001bnctjej3whjij"},{"post_id":"cjijzgd8m0010nctjdjsjqseg","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd8s001enctjsub9bvie"},{"post_id":"cjijzgd8d000knctjtwisrcjj","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd8t001gnctjl8golu0j"},{"post_id":"cjijzgd8o0015nctjejy94i8m","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgd8u001jnctjoc9qrfxi"},{"post_id":"cjijzgd8p0018nctjff0vsloh","category_id":"cjijzgd8h000rnctjbs04cf06","_id":"cjijzgd8w001lnctjq28ty8k0"},{"post_id":"cjijzgd8h000snctj6a4c4ehe","category_id":"cjijzgd8p0017nctje5nwsuq3","_id":"cjijzgd8x001onctj0a3w6n9z"},{"post_id":"cjijzgd8r001dnctjutd4q9bv","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgd8y001qnctj3pu4298y"},{"post_id":"cjijzgd8n0013nctjkilz2o5u","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgd8z001snctjz7et1nlz"},{"post_id":"cjijzgd8s001fnctjvejda5vu","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd90001unctjrgbyrgoa"},{"post_id":"cjijzgd8q001anctjfimpo365","category_id":"cjijzgd8t001hnctjxclmct0a","_id":"cjijzgd91001wnctjda9fqqri"},{"post_id":"cjijzgd8v001knctjsgoheo89","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd92001znctjcfanpwhx"},{"post_id":"cjijzgd8w001nnctjyv9t1372","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgd920021nctj08jqhbkg"},{"post_id":"cjijzgd8x001pnctjb9e12thh","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd940023nctjxyr5u89t"},{"post_id":"cjijzgd8t001inctjat3r6l68","category_id":"cjijzgd8w001mnctj58lc9t15","_id":"cjijzgd950025nctjs8tmdco6"},{"post_id":"cjijzgd8y001rnctjn2amejrr","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd960027nctj6a9nubj3"},{"post_id":"cjijzgd90001vnctjvgum5clr","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd970029nctj1276g2b6"},{"post_id":"cjijzgd91001ynctjg5qdtjot","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd98002bnctjbbrbzn7q"},{"post_id":"cjijzgd920020nctjqw3i6p3q","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd99002dnctjgxm4c747"},{"post_id":"cjijzgd8z001tnctj2wqpazlh","category_id":"cjijzgd91001xnctj2c47ze31","_id":"cjijzgd99002fnctjx1ri78sm"},{"post_id":"cjijzgd930022nctjfskhyteo","category_id":"cjijzgd8h000rnctjbs04cf06","_id":"cjijzgd9a002hnctjewosc33x"},{"post_id":"cjijzgd940024nctjk4ml92vn","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd9b002jnctjvwu5c3nx"},{"post_id":"cjijzgd950026nctjizb924se","category_id":"cjijzgd86000cnctjo7cenkey","_id":"cjijzgd9c002lnctjx2jxp680"},{"post_id":"cjijzgd960028nctjj52drdno","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd9d002nnctj70w2mctp"},{"post_id":"cjijzgd97002anctj2yv19ngv","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd9e002pnctjd6mon9bq"},{"post_id":"cjijzgd98002cnctj3coce4dw","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd9f002rnctj9giiu9ux"},{"post_id":"cjijzgd99002enctjeyjb5rr0","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd9i002tnctj57xfdw8w"},{"post_id":"cjijzgd9a002gnctjm2fdgzaz","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgd9j002wnctj29b5f1ur"},{"post_id":"cjijzgd9b002inctj0avu1hbn","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgd9k002ynctjisqhyalh"},{"post_id":"cjijzgd9c002knctj29xqtk7z","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgd9m0031nctj324hdrua"},{"post_id":"cjijzgd9d002mnctjpe6rcqkd","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgd9n0033nctj2b868quu"},{"post_id":"cjijzgd9e002onctjt2u62tv3","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgd9o0035nctjamcoq6kg"},{"post_id":"cjijzgd9f002snctjkgu3tzth","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgd9q0037nctjg3e5dcwl"},{"post_id":"cjijzgd9j002xnctj64h0zdp3","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgd9r0039nctjls02st8x"},{"post_id":"cjijzgd9f002qnctj65loo7tr","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgd9s003bnctjch6enwa0"},{"post_id":"cjijzgd9l002znctj4rnu1gmx","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgd9u003dnctjimdpne4v"},{"post_id":"cjijzgd9m0032nctjnrn37qch","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgd9v003fnctjlho8xd4y"},{"post_id":"cjijzgd9i002vnctjhlqryycv","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgd9x003hnctj470y1pib"},{"post_id":"cjijzgd9n0034nctjue5f3i2i","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgd9y003jnctjg5dycgd3"},{"post_id":"cjijzgd9o0036nctju1dcfj8n","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgd9z003lnctjw26bsxh6"},{"post_id":"cjijzgd9q0038nctj2qh7b95r","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgda0003nnctjx78gsq6i"},{"post_id":"cjijzgd9r003anctjpvo9prnl","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgda1003pnctj6hi7txwk"},{"post_id":"cjijzgd9t003cnctjku0tc75j","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgda2003rnctjbnzgahwv"},{"post_id":"cjijzgd9u003enctjqi3esvw7","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgda3003tnctjtvupxdr9"},{"post_id":"cjijzgd9v003gnctjf228p45d","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgda4003vnctjewoe15bn"},{"post_id":"cjijzgd9x003inctjsxqdk30n","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgda5003xnctj8szhcw9g"},{"post_id":"cjijzgd9y003knctjgtijwaqz","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgda6003znctjfq695d9q"},{"post_id":"cjijzgda0003mnctj2k6ncbdf","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgda70041nctj9s5c9g0w"},{"post_id":"cjijzgda1003onctjf8yz2i1l","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgda80043nctjlnl8ihfb"},{"post_id":"cjijzgda1003qnctjt0oebs1m","category_id":"cjijzgd86000cnctjo7cenkey","_id":"cjijzgda90045nctj16083axc"},{"post_id":"cjijzgda2003snctj8xc2z3ll","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgdaa0047nctj5pkn98by"},{"post_id":"cjijzgda3003unctj49eef2tn","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgdac0049nctjwwupwg4j"},{"post_id":"cjijzgda5003wnctjy92s83hz","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdad004bnctjbqmmhbmk"},{"post_id":"cjijzgda5003ynctjwt84kiu4","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdae004dnctjrnpuqv2r"},{"post_id":"cjijzgda60040nctjvyyea7vn","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgdaf004fnctj6i264egn"},{"post_id":"cjijzgda70042nctjbnzaad93","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgdah004hnctj3n55e3ae"},{"post_id":"cjijzgda90044nctj8skehxzw","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdai004jnctjccfe1tin"},{"post_id":"cjijzgdaa0046nctj4zgd5hrh","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdak004lnctjkqn3269g"},{"post_id":"cjijzgdab0048nctj2gybrn5f","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdal004nnctjtkjy0s5i"},{"post_id":"cjijzgdac004anctjbtmktdbq","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdam004pnctjytz4nz06"},{"post_id":"cjijzgdad004cnctjzfufn53k","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdam004rnctj4lowtrr9"},{"post_id":"cjijzgdae004enctjr1dxp4ah","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdan004tnctj8lwdchp5"},{"post_id":"cjijzgdag004gnctjzdgxl8di","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdap004vnctjkia7cy4o"},{"post_id":"cjijzgdai004inctjnm2lkk3n","category_id":"cjijzgd8r001cnctj9d7xq87b","_id":"cjijzgdaq004xnctjucbeqta9"},{"post_id":"cjijzgdaj004knctjjrvcyiqp","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdar004znctjo5t6z8b9"},{"post_id":"cjijzgdak004mnctj5ij8j32s","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgdas0051nctj80inhe91"},{"post_id":"cjijzgdal004onctj9waak92k","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgdas0053nctjuktz2h9j"},{"post_id":"cjijzgdam004qnctj05g8cuec","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdat0055nctj0l5ctvyn"},{"post_id":"cjijzgdan004snctj0ht7e6h6","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgdau0057nctj47pwsh1d"},{"post_id":"cjijzgdao004unctj7gmg9nr2","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdau0058nctjbfqtso7h"},{"post_id":"cjijzgdap004wnctjb4k6uj7h","category_id":"cjijzgd9i002unctjzp9lry8e","_id":"cjijzgdav0059nctjhiw8vs7h"},{"post_id":"cjijzgdaq004ynctj3mzutzmc","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgdav005anctjd297peof"},{"post_id":"cjijzgdar0050nctj1md4okoi","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgdav005bnctjr9jzajkg"},{"post_id":"cjijzgdas0052nctj90u0pv8i","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgdav005cnctjwiubb505"},{"post_id":"cjijzgdat0054nctjepcu0apm","category_id":"cjijzgd8e000mnctjfakgnq01","_id":"cjijzgdav005dnctj5mkmcp1b"},{"post_id":"cjijzgdau0056nctjpzz9955p","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgdav005enctjutfkmluw"},{"post_id":"cjijzgdfg005fnctjs0wc9776","category_id":"cjijzgd7y0004nctjhpprizht","_id":"cjijzgdfk005hnctj6wiwjov2"},{"post_id":"cjijzgdfh005gnctj4ezb1if8","category_id":"cjijzgd830008nctjedzt0js3","_id":"cjijzgdfk005inctjblw2jpnu"}],"PostTag":[],"Tag":[]}}